{"2024-11-08T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2411.05787v1","updated":"2024-11-08T18:57:07Z","published":"2024-11-08T18:57:07Z","title":"Recycled Attention: Efficient inference for long-context language models","summary":"  Generating long sequences of tokens given a long-context input imposes a\nheavy computational burden for large language models (LLMs). One of the\ncomputational bottleneck comes from computing attention over a long sequence of\ninput at each generation step. In this paper, we propose Recycled Attention, an\ninference-time method which alternates between full context attention and\nattention over a subset of input tokens. When performing partial attention, we\nrecycle the attention pattern of a previous token that has performed full\nattention and attend only to the top K most attended tokens, reducing the cost\nof data movement and attention computation. Compared to previously proposed\ninference-time acceleration method which attends only to local context or\ntokens with high accumulative attention scores, our approach flexibly chooses\ntokens that are relevant to the current decoding step. We evaluate our methods\non RULER, a suite of tasks designed to comprehensively evaluate long-context\nabilities, and long-context language modeling tasks. Applying our method to\noff-the-shelf LLMs achieves comparable speedup to baselines which only consider\nlocal context while improving the performance by 2x. We further explore two\nideas to improve performance-efficiency trade-offs: (1) dynamically decide when\nto perform recycled or full attention step based on the query similarities and\n(2) continued pre-training the model with Recycled Attention.\n","authors":["Fangyuan Xu","Tanya Goyal","Eunsol Choi"],"pdf_url":"https://arxiv.org/pdf/2411.05787v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.08627v2","updated":"2024-11-08T18:56:42Z","published":"2024-04-12T17:41:05Z","title":"Is ChatGPT Transforming Academics' Writing Style?","summary":"  Based on one million arXiv papers submitted from May 2018 to January 2024, we\nassess the textual density of ChatGPT's writing style in their abstracts\nthrough a statistical analysis of word frequency changes. Our model is\ncalibrated and validated on a mixture of real abstracts and ChatGPT-modified\nabstracts (simulated data) after a careful noise analysis. The words used for\nestimation are not fixed but adaptive, including those with decreasing\nfrequency. We find that large language models (LLMs), represented by ChatGPT,\nare having an increasing impact on arXiv abstracts, especially in the field of\ncomputer science, where the fraction of LLM-style abstracts is estimated to be\napproximately 35%, if we take the responses of GPT-3.5 to one simple prompt,\n\"revise the following sentences\", as a baseline. We conclude with an analysis\nof both positive and negative aspects of the penetration of LLMs into\nacademics' writing style.\n","authors":["Mingmeng Geng","Roberto Trotta"],"pdf_url":"https://arxiv.org/pdf/2404.08627v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2403.09539v3","updated":"2024-11-08T18:56:41Z","published":"2024-03-14T16:27:49Z","title":"Logits of API-Protected LLMs Leak Proprietary Information","summary":"  Large language model (LLM) providers often hide the architectural details and\nparameters of their proprietary models by restricting public access to a\nlimited API. In this work we show that, with only a conservative assumption\nabout the model architecture, it is possible to learn a surprisingly large\namount of non-public information about an API-protected LLM from a relatively\nsmall number of API queries (e.g., costing under $1000 USD for OpenAI's\ngpt-3.5-turbo). Our findings are centered on one key observation: most modern\nLLMs suffer from a softmax bottleneck, which restricts the model outputs to a\nlinear subspace of the full output space. We exploit this fact to unlock\nseveral capabilities, including (but not limited to) obtaining cheap\nfull-vocabulary outputs, auditing for specific types of model updates,\nidentifying the source LLM given a single full LLM output, and even efficiently\ndiscovering the LLM's hidden size. Our empirical investigations show the\neffectiveness of our methods, which allow us to estimate the embedding size of\nOpenAI's gpt-3.5-turbo to be about 4096. Lastly, we discuss ways that LLM\nproviders can guard against these attacks, as well as how these capabilities\ncan be viewed as a feature (rather than a bug) by allowing for greater\ntransparency and accountability.\n","authors":["Matthew Finlayson","Xiang Ren","Swabha Swayamdipta"],"pdf_url":"https://arxiv.org/pdf/2403.09539v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05783v1","updated":"2024-11-08T18:50:37Z","published":"2024-11-08T18:50:37Z","title":"ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles","summary":"  Deaf and hard-of-hearing (DHH) students face significant barriers in\naccessing science, technology, engineering, and mathematics (STEM) education,\nnotably due to the scarcity of STEM resources in signed languages. To help\naddress this, we introduce ASL STEM Wiki: a parallel corpus of 254 Wikipedia\narticles on STEM topics in English, interpreted into over 300 hours of American\nSign Language (ASL). ASL STEM Wiki is the first continuous signing dataset\nfocused on STEM, facilitating the development of AI resources for STEM\neducation in ASL. We identify several use cases of ASL STEM Wiki with\nhuman-centered applications. For example, because this dataset highlights the\nfrequent use of fingerspelling for technical concepts, which inhibits DHH\nstudents' ability to learn, we develop models to identify fingerspelled words\n-- which can later be used to query for appropriate ASL signs to suggest to\ninterpreters.\n","authors":["Kayo Yin","Chinmay Singh","Fyodor O. Minakov","Vanessa Milan","Hal Daumé III","Cyril Zhang","Alex X. Lu","Danielle Bragg"],"pdf_url":"https://arxiv.org/pdf/2411.05783v1.pdf","comment":"Accepted to EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05781v1","updated":"2024-11-08T18:48:57Z","published":"2024-11-08T18:48:57Z","title":"Using Language Models to Disambiguate Lexical Choices in Translation","summary":"  In translation, a concept represented by a single word in a source language\ncan have multiple variations in a target language. The task of lexical\nselection requires using context to identify which variation is most\nappropriate for a source text. We work with native speakers of nine languages\nto create DTAiLS, a dataset of 1,377 sentence pairs that exhibit cross-lingual\nconcept variation when translating from English. We evaluate recent LLMs and\nneural machine translation systems on DTAiLS, with the best-performing model,\nGPT-4, achieving from 67 to 85% accuracy across languages. Finally, we use\nlanguage models to generate English rules describing target-language concept\nvariations. Providing weaker models with high-quality lexical rules improves\naccuracy substantially, in some cases reaching or outperforming GPT-4.\n","authors":["Josh Barua","Sanjay Subramanian","Kayo Yin","Alane Suhr"],"pdf_url":"https://arxiv.org/pdf/2411.05781v1.pdf","comment":"Accepted to EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05778v1","updated":"2024-11-08T18:45:06Z","published":"2024-11-08T18:45:06Z","title":"LLMs as Method Actors: A Model for Prompt Engineering and Architecture","summary":"  We introduce \"Method Actors\" as a mental model for guiding LLM prompt\nengineering and prompt architecture. Under this mental model, LLMs should be\nthought of as actors; prompts as scripts and cues; and LLM responses as\nperformances. We apply this mental model to the task of improving LLM\nperformance at playing Connections, a New York Times word puzzle game that\nprior research identified as a challenging benchmark for evaluating LLM\nreasoning. Our experiments with GPT-4o show that a \"Method Actors\" approach can\nsignificantly improve LLM performance over both a vanilla and \"Chain of\nThoughts\" approach. A vanilla approach solves 27% of Connections puzzles in our\ndataset and a \"Chain of Thoughts\" approach solves 41% of puzzles, whereas our\nstrongest \"Method Actor\" approach solves 86% of puzzles. We also test OpenAI's\nnewest model designed specifically for complex reasoning tasks, o1-preview.\nWhen asked to solve a puzzle all at once, o1-preview solves 79% of Connections\npuzzles in our dataset, and when allowed to build puzzle solutions one guess at\na time over multiple API calls, o1-preview solves 100% of the puzzles.\nIncorporating a \"Method Actor\" prompt architecture increases the percentage of\npuzzles that o1-preview solves perfectly from 76% to 87%.\n","authors":["Colin Doyle"],"pdf_url":"https://arxiv.org/pdf/2411.05778v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05777v1","updated":"2024-11-08T18:43:15Z","published":"2024-11-08T18:43:15Z","title":"Quantitative Assessment of Intersectional Empathetic Bias and\n  Understanding","summary":"  A growing amount of literature critiques the current operationalizations of\nempathy based on loose definitions of the construct. Such definitions\nnegatively affect dataset quality, model robustness, and evaluation\nreliability. We propose an empathy evaluation framework that operationalizes\nempathy close to its psychological origins. The framework measures the variance\nin responses of LLMs to prompts using existing metrics for empathy and\nemotional valence. The variance is introduced through the controlled generation\nof the prompts by varying social biases affecting context understanding, thus\nimpacting empathetic understanding. The control over generation ensures high\ntheoretical validity of the constructs in the prompt dataset. Also, it makes\nhigh-quality translation, especially into languages that currently have\nlittle-to-no way of evaluating empathy or bias, such as the Slavonic family,\nmore manageable. Using chosen LLMs and various prompt types, we demonstrate the\nempathy evaluation with the framework, including multiple-choice answers and\nfree generation. The variance in our initial evaluation sample is small and we\nwere unable to measure convincing differences between the empathetic\nunderstanding in contexts given by different social groups. However, the\nresults are promising because the models showed significant alterations their\nreasoning chains needed to capture the relatively subtle changes in the\nprompts. This provides the basis for future research into the construction of\nthe evaluation sample and statistical methods for measuring the results.\n","authors":["Vojtech Formanek","Ondrej Sotolar"],"pdf_url":"https://arxiv.org/pdf/2411.05777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05775v1","updated":"2024-11-08T18:36:33Z","published":"2024-11-08T18:36:33Z","title":"Fact or Fiction? Can LLMs be Reliable Annotators for Political Truths?","summary":"  Political misinformation poses significant challenges to democratic\nprocesses, shaping public opinion and trust in media. Manual fact-checking\nmethods face issues of scalability and annotator bias, while machine learning\nmodels require large, costly labelled datasets. This study investigates the use\nof state-of-the-art large language models (LLMs) as reliable annotators for\ndetecting political factuality in news articles. Using open-source LLMs, we\ncreate a politically diverse dataset, labelled for bias through LLM-generated\nannotations. These annotations are validated by human experts and further\nevaluated by LLM-based judges to assess the accuracy and reliability of the\nannotations. Our approach offers a scalable and robust alternative to\ntraditional fact-checking, enhancing transparency and public trust in media.\n","authors":["Veronica Chatrath","Marcelo Lotif","Shaina Raza"],"pdf_url":"https://arxiv.org/pdf/2411.05775v1.pdf","comment":"Accepted at Socially Responsible Language Modelling Research (SoLaR)\n  Workshop at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05764v1","updated":"2024-11-08T18:26:17Z","published":"2024-11-08T18:26:17Z","title":"FinDVer: Explainable Claim Verification over Long and Hybrid-Content\n  Financial Documents","summary":"  We introduce FinDVer, a comprehensive benchmark specifically designed to\nevaluate the explainable claim verification capabilities of LLMs in the context\nof understanding and analyzing long, hybrid-content financial documents.\nFinDVer contains 2,400 expert-annotated examples, divided into three subsets:\ninformation extraction, numerical reasoning, and knowledge-intensive reasoning,\neach addressing common scenarios encountered in real-world financial contexts.\nWe assess a broad spectrum of LLMs under long-context and RAG settings. Our\nresults show that even the current best-performing system, GPT-4o, still lags\nbehind human experts. We further provide in-depth analysis on long-context and\nRAG setting, Chain-of-Thought reasoning, and model reasoning errors, offering\ninsights to drive future advancements. We believe that FinDVer can serve as a\nvaluable benchmark for evaluating LLMs in claim verification over complex,\nexpert-domain documents.\n","authors":["Yilun Zhao","Yitao Long","Yuru Jiang","Chengye Wang","Weiyuan Chen","Hongjun Liu","Yiming Zhang","Xiangru Tang","Chen Zhao","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2411.05764v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05762v1","updated":"2024-11-08T18:25:06Z","published":"2024-11-08T18:25:06Z","title":"Multi-hop Evidence Pursuit Meets the Web: Team Papelo at FEVER 2024","summary":"  Separating disinformation from fact on the web has long challenged both the\nsearch and the reasoning powers of humans. We show that the reasoning power of\nlarge language models (LLMs) and the retrieval power of modern search engines\ncan be combined to automate this process and explainably verify claims. We\nintegrate LLMs and search under a multi-hop evidence pursuit strategy. This\nstrategy generates an initial question based on an input claim using a sequence\nto sequence model, searches and formulates an answer to the question, and\niteratively generates follow-up questions to pursue the evidence that is\nmissing using an LLM. We demonstrate our system on the FEVER 2024 (AVeriTeC)\nshared task. Compared to a strategy of generating all the questions at once,\nour method obtains .045 higher label accuracy and .155 higher AVeriTeC score\n(evaluating the adequacy of the evidence). Through ablations, we show the\nimportance of various design choices, such as the question generation method,\nmedium-sized context, reasoning with one document at a time, adding metadata,\nparaphrasing, reducing the problem to two classes, and reconsidering the final\nverdict. Our submitted system achieves .510 AVeriTeC score on the dev set and\n.477 AVeriTeC score on the test set.\n","authors":["Christopher Malon"],"pdf_url":"https://arxiv.org/pdf/2411.05762v1.pdf","comment":"To appear in the Seventh FEVER Workshop at EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05755v1","updated":"2024-11-08T18:16:58Z","published":"2024-11-08T18:16:58Z","title":"End-to-End Navigation with Vision Language Models: Transforming Spatial\n  Reasoning into Question-Answering","summary":"  We present VLMnav, an embodied framework to transform a Vision-Language Model\n(VLM) into an end-to-end navigation policy. In contrast to prior work, we do\nnot rely on a separation between perception, planning, and control; instead, we\nuse a VLM to directly select actions in one step. Surprisingly, we find that a\nVLM can be used as an end-to-end policy zero-shot, i.e., without any\nfine-tuning or exposure to navigation data. This makes our approach open-ended\nand generalizable to any downstream navigation task. We run an extensive study\nto evaluate the performance of our approach in comparison to baseline prompting\nmethods. In addition, we perform a design analysis to understand the most\nimpactful design decisions. Visual examples and code for our project can be\nfound at https://jirl-upenn.github.io/VLMnav/\n","authors":["Dylan Goetting","Himanshu Gaurav Singh","Antonio Loquercio"],"pdf_url":"https://arxiv.org/pdf/2411.05755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05752v1","updated":"2024-11-08T18:10:46Z","published":"2024-11-08T18:10:46Z","title":"FisherMask: Enhancing Neural Network Labeling Efficiency in Image\n  Classification Using Fisher Information","summary":"  Deep learning (DL) models are popular across various domains due to their\nremarkable performance and efficiency. However, their effectiveness relies\nheavily on large amounts of labeled data, which are often time-consuming and\nlabor-intensive to generate manually. To overcome this challenge, it is\nessential to develop strategies that reduce reliance on extensive labeled data\nwhile preserving model performance. In this paper, we propose FisherMask, a\nFisher information-based active learning (AL) approach that identifies key\nnetwork parameters by masking them based on their Fisher information values.\nFisherMask enhances batch AL by using Fisher information to select the most\ncritical parameters, allowing the identification of the most impactful samples\nduring AL training. Moreover, Fisher information possesses favorable\nstatistical properties, offering valuable insights into model behavior and\nproviding a better understanding of the performance characteristics within the\nAL pipeline. Our extensive experiments demonstrate that FisherMask\nsignificantly outperforms state-of-the-art methods on diverse datasets,\nincluding CIFAR-10 and FashionMNIST, especially under imbalanced settings.\nThese improvements lead to substantial gains in labeling efficiency. Hence\nserving as an effective tool to measure the sensitivity of model parameters to\ndata samples. Our code is available on\n\\url{https://github.com/sgchr273/FisherMask}.\n","authors":["Shreen Gul","Mohamed Elmahallawy","Sanjay Madria","Ardhendu Tripathy"],"pdf_url":"https://arxiv.org/pdf/2411.05752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05735v1","updated":"2024-11-08T17:50:24Z","published":"2024-11-08T17:50:24Z","title":"Aioli: A Unified Optimization Framework for Language Model Data Mixing","summary":"  Language model performance depends on identifying the optimal mixture of data\ngroups to train on (e.g., law, code, math). Prior work has proposed a diverse\nset of methods to efficiently learn mixture proportions, ranging from fitting\nregression models over training runs to dynamically updating proportions\nthroughout training. Surprisingly, we find that no existing method consistently\noutperforms a simple stratified sampling baseline in terms of average test\nperplexity per group. In this paper, we study the cause of this inconsistency\nby unifying existing methods into a standard optimization framework. We show\nthat all methods set proportions to minimize total loss, subject to a\nmethod-specific mixing law -- an assumption on how loss is a function of\nmixture proportions. We find that existing parameterizations of mixing laws can\nexpress the true loss-proportion relationship empirically, but the methods\nthemselves often set the mixing law parameters inaccurately, resulting in poor\nand inconsistent performance. Finally, we leverage the insights from our\nframework to derive a new online method named Aioli, which directly estimates\nthe mixing law parameters throughout training and uses them to dynamically\nadjust proportions. Empirically, Aioli outperforms stratified sampling on 6 out\nof 6 datasets by an average of 0.28 test perplexity points, whereas existing\nmethods fail to consistently beat stratified sampling, doing up to 6.9 points\nworse. Moreover, in a practical setting where proportions are learned on\nshorter runs due to computational constraints, Aioli can dynamically adjust\nthese proportions over the full training run, consistently improving\nperformance over existing methods by up to 12.01 test perplexity points.\n","authors":["Mayee F. Chen","Michael Y. Hu","Nicholas Lourie","Kyunghyun Cho","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2411.05735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01914v2","updated":"2024-11-08T17:33:31Z","published":"2024-06-04T02:51:26Z","title":"HPE-CogVLM: Advancing Vision Language Models with a Head Pose Grounding\n  Task","summary":"  Head pose estimation (HPE) requires a sophisticated understanding of 3D\nspatial relationships to generate precise yaw, pitch, and roll angles. Previous\nHPE models, primarily CNN-based, rely on cropped close-up human head images as\ninputs and often lack robustness in real-world scenario. Vision Language Models\n(VLMs) can analyze entire images while focusing on specific objects through\ntheir attention mechanisms. In this paper, we propose a novel framework to\nimprove the HPE accuracy by leveraging the object detection grounding\ncapability of a VLM, referred to as CogVLM. We empirically find that directly\nLoRA fine-tuning of this VLM for the HPE task fails to achieve desirable HPE\naccuracy, while some model merging methods can improve accuracy but frequently\nproduce blended invalid response formats, struggling to handle both object\ndetection and HPE tasks simultaneously. To integrate HPE capability into CogVLM\neffectively, we develop a novel LoRA layer-based model merging method. This\nmerging approach applies a high cosine similarity threshold and a\nwinner-takes-all layer selection strategy, aligning attention to the HPE task\nwhile preserving original object detection knowledge. It successfully resolves\nissues with blended invalid response formats and improves accuracy. Results\nshow that our HPE-CogVLM achieves a 31.5\\% reduction in Mean Absolute Error\nover the current state-of-the-art CNN model, 6DRepNet, in cross-dataset\nevaluation. Furthermore, HPE-CogVLM outperforms both directly LoRA fine-tuned\nand task arithmetic-based merged VLMs across all HPE metrics.\n","authors":["Yu Tian","Tianqi Shao","Tsukasa Demizu","Xuyang Wu","Hsin-Tai Wu"],"pdf_url":"https://arxiv.org/pdf/2406.01914v2.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2411.05706v1","updated":"2024-11-08T17:07:01Z","published":"2024-11-08T17:07:01Z","title":"Image2Text2Image: A Novel Framework for Label-Free Evaluation of\n  Image-to-Text Generation with Text-to-Image Diffusion Models","summary":"  Evaluating the quality of automatically generated image descriptions is a\ncomplex task that requires metrics capturing various dimensions, such as\ngrammaticality, coverage, accuracy, and truthfulness. Although human evaluation\nprovides valuable insights, its cost and time-consuming nature pose\nlimitations. Existing automated metrics like BLEU, ROUGE, METEOR, and CIDEr\nattempt to fill this gap, but they often exhibit weak correlations with human\njudgment. To address this challenge, we propose a novel evaluation framework\ncalled Image2Text2Image, which leverages diffusion models, such as Stable\nDiffusion or DALL-E, for text-to-image generation. In the Image2Text2Image\nframework, an input image is first processed by a selected image captioning\nmodel, chosen for evaluation, to generate a textual description. Using this\ngenerated description, a diffusion model then creates a new image. By comparing\nfeatures extracted from the original and generated images, we measure their\nsimilarity using a designated similarity metric. A high similarity score\nsuggests that the model has produced a faithful textual description, while a\nlow score highlights discrepancies, revealing potential weaknesses in the\nmodel's performance. Notably, our framework does not rely on human-annotated\nreference captions, making it a valuable tool for assessing image captioning\nmodels. Extensive experiments and human evaluations validate the efficacy of\nour proposed Image2Text2Image evaluation framework. The code and dataset will\nbe published to support further research in the community.\n","authors":["Jia-Hong Huang","Hongyi Zhu","Yixian Shen","Stevan Rudinac","Evangelos Kanoulas"],"pdf_url":"https://arxiv.org/pdf/2411.05706v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2408.01723"},{"id":"http://arxiv.org/abs/2406.02791v2","updated":"2024-11-08T16:50:24Z","published":"2024-06-04T21:29:56Z","title":"Language Models can Infer Action Semantics for Symbolic Planners from\n  Environment Feedback","summary":"  Symbolic planners can discover a sequence of actions from initial to goal\nstates given expert-defined, domain-specific logical action semantics. Large\nLanguage Models (LLMs) can directly generate such sequences, but limitations in\nreasoning and state-tracking often result in plans that are insufficient or\nunexecutable. We propose Predicting Semantics of Actions with Language Models\n(PSALM), which automatically learns action semantics by leveraging the\nstrengths of both symbolic planners and LLMs. PSALM repeatedly proposes and\nexecutes plans, using the LLM to partially generate plans and to infer\ndomain-specific action semantics based on execution outcomes. PSALM maintains a\nbelief over possible action semantics that is iteratively updated until a goal\nstate is reached. Experiments on 7 environments show that when learning just\nfrom one goal, PSALM boosts plan success rate from 36.4% (on Claude-3.5) to\n100%, and explores the environment more efficiently than prior work to infer\nground truth domain action semantics.\n","authors":["Wang Zhu","Ishika Singh","Robin Jia","Jesse Thomason"],"pdf_url":"https://arxiv.org/pdf/2406.02791v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.05977v3","updated":"2024-11-08T16:42:41Z","published":"2024-09-09T18:21:28Z","title":"Mathematical Formalized Problem Solving and Theorem Proving in Different\n  Fields in Lean 4","summary":"  Formalizing mathematical proofs using computerized verification languages\nlike Lean 4 has the potential to significantly impact the field of mathematics,\nit offers prominent capabilities for advancing mathematical reasoning. However,\nexisting efforts are largely limited to creating formalized versions of proofs\nfrom extensive online mathematical corpora, struggling to keep pace with the\nrapidly evolving nature of mathematics. To bridge the gap between traditional\nand computerized proof techniques, this paper explores the use of Large\nLanguage Models (LLMs) to generate formal proof steps and complete formalized\nproofs. By converting natural language (NL) mathematical proofs into formalized\nversions, this work introduces the basic structure and tactics of the Lean 4\nlanguage. The goal is to determine how AI can be leveraged to assist the\nmathematical formalization process and improve its performance. Several\nexamples are provided that demonstrate solving problems using both traditional\nand Lean 4-based approaches. Ultimately, this paper presents an explanation of\nthe foundations of Lean 4 and comparative analyses of the mathematical\nformalization process using traditional and AI-augmented techniques. The\nfindings indicate that AI- powered tools have significant potential to\naccelerate and enhance the formalization of mathematical proofs, paving the way\nfor more efficient and reliable theorem-proving for AI for Math in the future.\n","authors":["Xichen Tang"],"pdf_url":"https://arxiv.org/pdf/2409.05977v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05691v1","updated":"2024-11-08T16:42:33Z","published":"2024-11-08T16:42:33Z","title":"Asterisk*: Keep it Simple","summary":"  This paper describes Asterisk, a compact GPT-based model for generating text\nembeddings. The model uses a minimalist architecture with two layers, two\nattention heads, and 256 embedding dimensions. By applying knowledge\ndistillation from larger pretrained models, we explore the trade-offs between\nmodel size and performance while minimizing computational and memory\nrequirements. The model is primarily evaluated and optimized for classification\ntasks, with experimental results showing its moderate performance in zero-shot\nclassification across various downstream applications. With additional\nconfiguration, the model performance can approach or even surpass that of\nlarger architectures on specific classification tasks.\n","authors":["Andrew Semenov"],"pdf_url":"https://arxiv.org/pdf/2411.05691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00177v2","updated":"2024-11-08T16:42:18Z","published":"2024-10-31T19:48:12Z","title":"LLM4Mat-Bench: Benchmarking Large Language Models for Materials Property\n  Prediction","summary":"  Large language models (LLMs) are increasingly being used in materials\nscience. However, little attention has been given to benchmarking and\nstandardized evaluation for LLM-based materials property prediction, which\nhinders progress. We present LLM4Mat-Bench, the largest benchmark to date for\nevaluating the performance of LLMs in predicting the properties of crystalline\nmaterials. LLM4Mat-Bench contains about 1.9M crystal structures in total,\ncollected from 10 publicly available materials data sources, and 45 distinct\nproperties. LLM4Mat-Bench features different input modalities: crystal\ncomposition, CIF, and crystal text description, with 4.7M, 615.5M, and 3.1B\ntokens in total for each modality, respectively. We use LLM4Mat-Bench to\nfine-tune models with different sizes, including LLM-Prop and MatBERT, and\nprovide zero-shot and few-shot prompts to evaluate the property prediction\ncapabilities of LLM-chat-like models, including Llama, Gemma, and Mistral. The\nresults highlight the challenges of general-purpose LLMs in materials science\nand the need for task-specific predictive models and task-specific\ninstruction-tuned LLMs in materials property prediction.\n","authors":["Andre Niyongabo Rubungo","Kangming Li","Jason Hattrick-Simpers","Adji Bousso Dieng"],"pdf_url":"https://arxiv.org/pdf/2411.00177v2.pdf","comment":"Accepted at NeurIPS 2024-AI4Mat Workshop. The Benchmark and code can\n  be found at: https://github.com/vertaix/LLM4Mat-Bench"},{"id":"http://arxiv.org/abs/2408.05646v2","updated":"2024-11-08T16:29:33Z","published":"2024-08-10T22:47:12Z","title":"Eigen Attention: Attention in Low-Rank Space for KV Cache Compression","summary":"  Large language models (LLMs) represent a groundbreaking advancement in the\ndomain of natural language processing due to their impressive reasoning\nabilities. Recently, there has been considerable interest in increasing the\ncontext lengths for these models to enhance their applicability to complex\ntasks. However, at long context lengths and large batch sizes, the key-value\n(KV) cache, which stores the attention keys and values, emerges as the new\nbottleneck in memory usage during inference. To address this, we propose Eigen\nAttention, which performs the attention operation in a low-rank space, thereby\nreducing the KV cache memory overhead. Our proposed approach is orthogonal to\nexisting KV cache compression techniques and can be used synergistically with\nthem. Through extensive experiments over OPT, MPT, and Llama model families, we\ndemonstrate that Eigen Attention results in up to 40% reduction in KV cache\nsizes and up to 60% reduction in attention operation latency with minimal drop\nin performance. Code is available at\nhttps://github.com/UtkarshSaxena1/EigenAttn.\n","authors":["Utkarsh Saxena","Gobinda Saha","Sakshi Choudhary","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2408.05646v2.pdf","comment":"12 page, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2410.02525v4","updated":"2024-11-08T16:26:22Z","published":"2024-10-03T14:33:34Z","title":"Contextual Document Embeddings","summary":"  Dense document embeddings are central to neural retrieval. The dominant\nparadigm is to train and construct embeddings by running encoders directly on\nindividual documents. In this work, we argue that these embeddings, while\neffective, are implicitly out-of-context for targeted use cases of retrieval,\nand that a contextualized document embedding should take into account both the\ndocument and neighboring documents in context - analogous to contextualized\nword embeddings. We propose two complementary methods for contextualized\ndocument embeddings: first, an alternative contrastive learning objective that\nexplicitly incorporates the document neighbors into the intra-batch contextual\nloss; second, a new contextual architecture that explicitly encodes neighbor\ndocument information into the encoded representation. Results show that both\nmethods achieve better performance than biencoders in several settings, with\ndifferences especially pronounced out-of-domain. We achieve state-of-the-art\nresults on the MTEB benchmark with no hard negative mining, score distillation,\ndataset-specific instructions, intra-GPU example-sharing, or extremely large\nbatch sizes. Our method can be applied to improve performance on any\ncontrastive learning dataset and any biencoder.\n","authors":["John X. Morris","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2410.02525v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05665v1","updated":"2024-11-08T16:07:47Z","published":"2024-11-08T16:07:47Z","title":"Unmasking the Limits of Large Language Models: A Systematic Evaluation\n  of Masked Text Processing Ability through MskQA and MskCal","summary":"  This paper sheds light on the limitations of Large Language Models (LLMs) by\nrigorously evaluating their ability to process masked text. We introduce two\nnovel tasks: MskQA, measuring reasoning on masked question-answering datasets\nlike RealtimeQA, and MskCal, assessing numerical reasoning on masked arithmetic\nproblems.Testing GPT-4o and 4o-mini reveals that while LLMs exhibit some\nresilience to masked text, their performance is highly contingent on masking\nrates and semantic cues. Specifically, \"solid masking,\" where semantic clues\nare entirely absent, leads to a significant performance drop compared to\n\"partial lifting,\" where some semantic information is retained, indicating\nLLMs' reliance on surface-level patterns. Interestingly, GPT-4o consistently\noutperforms 4o-mini, particularly in MskCal, demonstrating a greater ability to\nhandle numerical reasoning with masked text. This underscores the crucial role\nof semantic cues in the reasoning process of LLMs. Our study illuminates the\ninterplay between background knowledge and reasoning ability in masked text\nprocessing, paving the way for a deeper understanding of LLM capabilities and\nlimitations, and highlighting the need for more robust evaluation methods to\naccurately assess their true comprehension abilities.\n","authors":["Fuka Matsuzaki","Haru-Tada Sato"],"pdf_url":"https://arxiv.org/pdf/2411.05665v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2411.04920v2","updated":"2024-11-08T16:06:09Z","published":"2024-11-07T17:57:03Z","title":"GPTKB: Building Very Large Knowledge Bases from Language Models","summary":"  General-domain knowledge bases (KB), in particular the \"big three\" --\nWikidata, Yago and DBpedia -- are the backbone of many intelligent\napplications. While these three have seen steady development, comprehensive KB\nconstruction at large has seen few fresh attempts. In this work, we propose to\nbuild a large general-domain KB entirely from a large language model (LLM). We\ndemonstrate the feasibility of large-scale KB construction from LLMs, while\nhighlighting specific challenges arising around entity recognition, entity and\nproperty canonicalization, and taxonomy construction. As a prototype, we use\nGPT-4o-mini to construct GPTKB, which contains 105 million triples for more\nthan 2.9 million entities, at a cost 100x less than previous KBC projects. Our\nwork is a landmark for two fields: For NLP, for the first time, it provides\n\\textit{constructive} insights into the knowledge (or beliefs) of LLMs. For the\nSemantic Web, it shows novel ways forward for the long-standing challenge of\ngeneral-domain KB construction. GPTKB is accessible at http://gptkb.org.\n","authors":["Yujia Hu","Shrestha Ghosh","Tuan-Phong Nguyen","Simon Razniewski"],"pdf_url":"https://arxiv.org/pdf/2411.04920v2.pdf","comment":"11 pages, 4 tables"},{"id":"http://arxiv.org/abs/2406.14553v2","updated":"2024-11-08T15:50:51Z","published":"2024-06-20T17:58:34Z","title":"xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned\n  MT Evaluation Metrics","summary":"  State-of-the-art trainable machine translation evaluation metrics like xCOMET\nachieve high correlation with human judgment but rely on large encoders (up to\n10.7B parameters), making them computationally expensive and inaccessible to\nresearchers with limited resources. To address this issue, we investigate\nwhether the knowledge stored in these large encoders can be compressed while\nmaintaining quality. We employ distillation, quantization, and pruning\ntechniques to create efficient xCOMET alternatives and introduce a novel data\ncollection pipeline for efficient black-box distillation. Our experiments show\nthat, using quantization, xCOMET can be compressed up to three times with no\nquality degradation. Additionally, through distillation, we create an\n278M-sized xCOMET-lite metric, which has only 2.6% of xCOMET-XXL parameters,\nbut retains 92.1% of its quality. Besides, it surpasses strong small-scale\nmetrics like COMET-22 and BLEURT-20 on the WMT22 metrics challenge dataset by\n6.4%, despite using 50% fewer parameters. All code, dataset, and models are\navailable online at https://github.com/NL2G/xCOMET-lite.\n","authors":["Daniil Larionov","Mikhail Seleznyov","Vasiliy Viskov","Alexander Panchenko","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2406.14553v2.pdf","comment":"EMNLP 2024 (Main Conference) Camera-Ready Version"},{"id":"http://arxiv.org/abs/2411.05641v1","updated":"2024-11-08T15:35:43Z","published":"2024-11-08T15:35:43Z","title":"Evaluating Large Language Model Capability in Vietnamese Fact-Checking\n  Data Generation","summary":"  Large Language Models (LLMs), with gradually improving reading comprehension\nand reasoning capabilities, are being applied to a range of complex language\ntasks, including the automatic generation of language data for various\npurposes. However, research on applying LLMs for automatic data generation in\nlow-resource languages like Vietnamese is still underdeveloped and lacks\ncomprehensive evaluation. In this paper, we explore the use of LLMs for\nautomatic data generation for the Vietnamese fact-checking task, which faces\nsignificant data limitations. Specifically, we focus on fact-checking data\nwhere claims are synthesized from multiple evidence sentences to assess the\ninformation synthesis capabilities of LLMs. We develop an automatic data\nconstruction process using simple prompt techniques on LLMs and explore several\nmethods to improve the quality of the generated data. To evaluate the quality\nof the data generated by LLMs, we conduct both manual quality assessments and\nperformance evaluations using language models. Experimental results and manual\nevaluations illustrate that while the quality of the generated data has\nsignificantly improved through fine-tuning techniques, LLMs still cannot match\nthe data quality produced by humans.\n","authors":["Long Truong To","Hung Tuan Le","Dat Van-Thanh Nguyen","Manh Trong Nguyen","Tri Thien Nguyen","Tin Van Huynh","Kiet Van Nguyen"],"pdf_url":"https://arxiv.org/pdf/2411.05641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05639v1","updated":"2024-11-08T15:34:08Z","published":"2024-11-08T15:34:08Z","title":"Assessing Open-Source Large Language Models on Argumentation Mining\n  Subtasks","summary":"  We explore the capability of four open-sourcelarge language models (LLMs) in\nargumentation mining (AM). We conduct experiments on three different corpora;\npersuasive essays(PE), argumentative microtexts (AMT) Part 1 and Part 2, based\non two argumentation mining sub-tasks: (i) argumentative discourse units\nclassifications (ADUC), and (ii) argumentative relation classification (ARC).\nThis work aims to assess the argumentation capability of open-source LLMs,\nincluding Mistral 7B, Mixtral8x7B, LlamA2 7B and LlamA3 8B in both, zero-shot\nand few-shot scenarios. Our analysis contributes to further assessing\ncomputational argumentation with open-source LLMs in future research efforts.\n","authors":["Mohammad Yeghaneh Abkenar","Weixing Wang","Hendrik Graupner","Manfred Stede"],"pdf_url":"https://arxiv.org/pdf/2411.05639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05638v1","updated":"2024-11-08T15:32:20Z","published":"2024-11-08T15:32:20Z","title":"Impact of Fake News on Social Media Towards Public Users of Different\n  Age Groups","summary":"  This study examines how fake news affects social media users across a range\nof age groups and how machine learning (ML) and artificial intelligence (AI)\ncan help reduce the spread of false information. The paper evaluates various\nmachine learning models for their efficacy in identifying and categorizing fake\nnews and examines current trends in the spread of fake news, including deepfake\ntechnology. The study assesses four models using a Kaggle dataset: Random\nForest, Support Vector Machine (SVM), Neural Networks, and Logistic Regression.\nThe results show that SVM and neural networks perform better than other models,\nwith accuracies of 93.29% and 93.69%, respectively. The study also emphasises\nhow people in the elder age group diminished capacity for critical analysis of\nnews content makes them more susceptible to disinformation. Natural language\nprocessing (NLP) and deep learning approaches have the potential to improve the\naccuracy of false news detection. Biases in AI and ML models and difficulties\nin identifying information generated by AI continue to be major problems in\nspite of the developments. The study recommends that datasets be expanded to\nencompass a wider range of languages and that detection algorithms be\ncontinuously improved to keep up with the latest advancements in disinformation\ntactics. In order to combat fake news and promote an informed and resilient\nsociety, this study emphasizes the value of cooperative efforts between AI\nresearchers, social media platforms, and governments.\n","authors":["Kahlil bin Abdul Hakim","Sathishkumar Veerappampalayam Easwaramoorthy"],"pdf_url":"https://arxiv.org/pdf/2411.05638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12964v2","updated":"2024-11-08T14:58:29Z","published":"2024-03-19T17:59:39Z","title":"Enhancing Vision-Language Few-Shot Adaptation with Negative Learning","summary":"  Large-scale pre-trained Vision-Language Models (VLMs) have exhibited\nimpressive zero-shot performance and transferability, allowing them to adapt to\ndownstream tasks in a data-efficient manner. However, when only a few labeled\nsamples are available, adapting VLMs to distinguish subtle differences between\nsimilar classes in specific downstream tasks remains challenging. In this work,\nwe propose a Simple yet effective Negative Learning approach, SimNL, to more\nefficiently exploit the task-specific knowledge from few-shot labeled samples.\nUnlike previous methods that focus on identifying a set of representative\npositive features defining \"what is a {CLASS}\", SimNL discovers a complementary\nset of negative features that define \"what is not a {CLASS}\", providing\nadditional insights that supplement the positive features to enhance\ntask-specific recognition capability. Further, we identify that current\nadaptation approaches are particularly vulnerable to potential noise in the\nfew-shot sample set. To mitigate this issue, we introduce a plug-and-play\nfew-shot instance reweighting technique to suppress noisy outliers and amplify\nclean samples for more stable adaptation. Our extensive experimental results\nacross 15 datasets validate that the proposed SimNL outperforms existing\nstate-of-the-art methods on both few-shot learning and domain generalization\ntasks while achieving competitive computational efficiency. Code is available\nat https://github.com/zhangce01/SimNL.\n","authors":["Ce Zhang","Simon Stepputtis","Katia Sycara","Yaqi Xie"],"pdf_url":"https://arxiv.org/pdf/2403.12964v2.pdf","comment":"Accepted by WACV 2025. Code is available at\n  https://github.com/zhangce01/SimNL"},{"id":"http://arxiv.org/abs/2411.04699v2","updated":"2024-11-08T14:29:03Z","published":"2024-11-07T13:33:34Z","title":"BhasaAnuvaad: A Speech Translation Dataset for 13 Indian Languages","summary":"  Automatic Speech Translation (AST) datasets for Indian languages remain\ncritically scarce, with public resources covering fewer than 10 of the 22\nofficial languages. This scarcity has resulted in AST systems for Indian\nlanguages lagging far behind those available for high-resource languages like\nEnglish. In this paper, we first evaluate the performance of widely-used AST\nsystems on Indian languages, identifying notable performance gaps and\nchallenges. Our findings show that while these systems perform adequately on\nread speech, they struggle significantly with spontaneous speech, including\ndisfluencies like pauses and hesitations. Additionally, there is a striking\nabsence of systems capable of accurately translating colloquial and informal\nlanguage, a key aspect of everyday communication. To this end, we introduce\nBhasaAnuvaad, the largest publicly available dataset for AST involving 13 out\nof 22 scheduled Indian languages and English spanning over 44,400 hours and 17M\ntext segments. BhasaAnuvaad contains data for English speech to Indic text, as\nwell as Indic speech to English text. This dataset comprises three key\ncategories: (1) Curated datasets from existing resources, (2) Large-scale web\nmining, and (3) Synthetic data generation. By offering this diverse and\nexpansive dataset, we aim to bridge the resource gap and promote advancements\nin AST for Indian languages.\n","authors":["Sparsh Jain","Ashwin Sankar","Devilal Choudhary","Dhairya Suman","Nikhil Narasimhan","Mohammed Safi Ur Rahman Khan","Anoop Kunchukuttan","Mitesh M Khapra","Raj Dabre"],"pdf_url":"https://arxiv.org/pdf/2411.04699v2.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2411.05593v1","updated":"2024-11-08T14:26:56Z","published":"2024-11-08T14:26:56Z","title":"Evaluating and Adapting Large Language Models to Represent Folktales in\n  Low-Resource Languages","summary":"  Folktales are a rich resource of knowledge about the society and culture of a\ncivilisation. Digital folklore research aims to use automated techniques to\nbetter understand these folktales, and it relies on abstract representations of\nthe textual data. Although a number of large language models (LLMs) claim to be\nable to represent low-resource langauges such as Irish and Gaelic, we present\ntwo classification tasks to explore how useful these representations are, and\nthree adaptations to improve the performance of these models. We find that\nadapting the models to work with longer sequences, and continuing pre-training\non the domain of folktales improves classification performance, although these\nfindings are tempered by the impressive performance of a baseline SVM with\nnon-contextual features.\n","authors":["JA Meaney","Beatrice Alex","William Lamb"],"pdf_url":"https://arxiv.org/pdf/2411.05593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15267v2","updated":"2024-11-08T14:02:13Z","published":"2024-06-21T16:03:21Z","title":"Evaluating Diversity in Automatic Poetry Generation","summary":"  Natural Language Generation (NLG), and more generally generative AI, are\namong the currently most impactful research fields. Creative NLG, such as\nautomatic poetry generation, is a fascinating niche in this area. While most\nprevious research has focused on forms of the Turing test when evaluating\nautomatic poetry generation -- can humans distinguish between automatic and\nhuman generated poetry -- we evaluate the diversity of automatically generated\npoetry (with a focus on quatrains), by comparing distributions of generated\npoetry to distributions of human poetry along structural, lexical, semantic and\nstylistic dimensions, assessing different model types (word vs.\ncharacter-level, general purpose LLMs vs. poetry-specific models), including\nthe very recent LLaMA3-8B, and types of fine-tuning (conditioned vs.\nunconditioned). We find that current automatic poetry systems are considerably\nunderdiverse along multiple dimensions -- they often do not rhyme sufficiently,\nare semantically too uniform and even do not match the length distribution of\nhuman poetry. Our experiments reveal, however, that style-conditioning and\ncharacter-level modeling clearly increases diversity across virtually all\ndimensions we explore. Our identified limitations may serve as the basis for\nmore genuinely diverse future poetry generation models.\n","authors":["Yanran Chen","Hannes Gröner","Sina Zarrieß","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2406.15267v2.pdf","comment":"EMNLP 2024 main; camera-ready"},{"id":"http://arxiv.org/abs/2410.21333v3","updated":"2024-11-08T13:11:58Z","published":"2024-10-27T18:30:41Z","title":"Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on\n  Tasks where Thinking Makes Humans Worse","summary":"  Chain-of-thought (CoT) prompting has become a widely used strategy for\nworking with large language and multimodal models. While CoT has been shown to\nimprove performance across many tasks, determining the settings in which it is\neffective remains an ongoing effort. In particular, it is still an open\nquestion in what settings CoT systematically reduces model performance. In this\npaper, we seek to identify the characteristics of tasks where CoT reduces\nperformance by drawing inspiration from cognitive psychology, looking at cases\nwhere (i) verbal thinking or deliberation hurts performance in humans, and (ii)\nthe constraints governing human performance generalize to language models.\nThree such cases are implicit statistical learning, visual recognition, and\nclassifying with patterns containing exceptions. In extensive experiments\nacross all three settings, we find that a diverse collection of\nstate-of-the-art models exhibit significant drop-offs in performance (e.g., up\nto 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using\ninference-time reasoning compared to zero-shot counterparts. We also identify\nthree tasks that satisfy condition (i) but not (ii), and find that while verbal\nthinking reduces human performance in these tasks, CoT retains or increases\nmodel performance. Overall, our results show that while there is not an exact\nparallel between the cognitive processes of models and those of humans,\nconsidering cases where thinking has negative consequences for human\nperformance can help us identify settings where it negatively impacts models.\nBy connecting the literature on human deliberation with evaluations of CoT, we\noffer a new tool that can be used in understanding the impact of prompt choices\nand inference-time reasoning.\n","authors":["Ryan Liu","Jiayi Geng","Addison J. Wu","Ilia Sucholutsky","Tania Lombrozo","Thomas L. Griffiths"],"pdf_url":"https://arxiv.org/pdf/2410.21333v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05547v1","updated":"2024-11-08T13:09:14Z","published":"2024-11-08T13:09:14Z","title":"Assessing the Answerability of Queries in Retrieval-Augmented Code\n  Generation","summary":"  Thanks to unprecedented language understanding and generation capabilities of\nlarge language model (LLM), Retrieval-augmented Code Generation (RaCG) has\nrecently been widely utilized among software developers. While this has\nincreased productivity, there are still frequent instances of incorrect codes\nbeing provided. In particular, there are cases where plausible yet incorrect\ncodes are generated for queries from users that cannot be answered with the\ngiven queries and API descriptions. This study proposes a task for evaluating\nanswerability, which assesses whether valid answers can be generated based on\nusers' queries and retrieved APIs in RaCG. Additionally, we build a benchmark\ndataset called Retrieval-augmented Code Generability Evaluation (RaCGEval) to\nevaluate the performance of models performing this task. Experimental results\nshow that this task remains at a very challenging level, with baseline models\nexhibiting a low performance of 46.7%. Furthermore, this study discusses\nmethods that could significantly improve performance.\n","authors":["Geonmin Kim","Jaeyeon Kim","Hancheol Park","Wooksu Shin","Tae-Ho Kim"],"pdf_url":"https://arxiv.org/pdf/2411.05547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16254v2","updated":"2024-11-08T12:54:16Z","published":"2024-06-24T01:31:03Z","title":"Confidence Regulation Neurons in Language Models","summary":"  Despite their widespread use, the mechanisms by which large language models\n(LLMs) represent and regulate uncertainty in next-token predictions remain\nlargely unexplored. This study investigates two critical components believed to\ninfluence this uncertainty: the recently discovered entropy neurons and a new\nset of components that we term token frequency neurons. Entropy neurons are\ncharacterized by an unusually high weight norm and influence the final layer\nnormalization (LayerNorm) scale to effectively scale down the logits. Our work\nshows that entropy neurons operate by writing onto an unembedding null space,\nallowing them to impact the residual stream norm with minimal direct effect on\nthe logits themselves. We observe the presence of entropy neurons across a\nrange of models, up to 7 billion parameters. On the other hand, token frequency\nneurons, which we discover and describe here for the first time, boost or\nsuppress each token's logit proportionally to its log frequency, thereby\nshifting the output distribution towards or away from the unigram distribution.\nFinally, we present a detailed case study where entropy neurons actively manage\nconfidence in the setting of induction, i.e. detecting and continuing repeated\nsubsequences.\n","authors":["Alessandro Stolfo","Ben Wu","Wes Gurnee","Yonatan Belinkov","Xingyi Song","Mrinmaya Sachan","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2406.16254v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2409.17044v2","updated":"2024-11-08T12:44:49Z","published":"2024-09-25T15:54:29Z","title":"How to Connect Speech Foundation Models and Large Language Models? What\n  Matters and What Does Not","summary":"  The remarkable performance achieved by Large Language Models (LLM) has driven\nresearch efforts to leverage them for a wide range of tasks and input\nmodalities. In speech-to-text (S2T) tasks, the emerging solution consists of\nprojecting the output of the encoder of a Speech Foundational Model (SFM) into\nthe LLM embedding space through an adapter module. However, no work has yet\ninvestigated how much the downstream-task performance depends on each component\n(SFM, adapter, LLM) nor whether the best design of the adapter depends on the\nchosen SFM and LLM. To fill this gap, we evaluate the combination of 5 adapter\nmodules, 2 LLMs (Mistral and Llama), and 2 SFMs (Whisper and SeamlessM4T) on\ntwo widespread S2T tasks, namely Automatic Speech Recognition and Speech\nTranslation. Our results demonstrate that the SFM plays a pivotal role in\ndownstream performance, while the adapter choice has moderate impact and\ndepends on the SFM and LLM.\n","authors":["Francesco Verdini","Pierfrancesco Melucci","Stefano Perna","Francesco Cariaggi","Marco Gaido","Sara Papi","Szymon Mazurek","Marek Kasztelnik","Luisa Bentivogli","Sébastien Bratières","Paolo Merialdo","Simone Scardapane"],"pdf_url":"https://arxiv.org/pdf/2409.17044v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05527v1","updated":"2024-11-08T12:35:58Z","published":"2024-11-08T12:35:58Z","title":"How Good is Your Wikipedia?","summary":"  Wikipedia's perceived high quality and broad language coverage have\nestablished it as a fundamental resource in multilingual NLP. In the context of\nlow-resource languages, however, these quality assumptions are increasingly\nbeing scrutinised. This paper critically examines the data quality of Wikipedia\nin a non-English setting by subjecting it to various quality filtering\ntechniques, revealing widespread issues such as a high percentage of one-line\narticles and duplicate articles. We evaluate the downstream impact of quality\nfiltering on Wikipedia and find that data quality pruning is an effective means\nfor resource-efficient training without hurting performance, especially for\nlow-resource languages. Moreover, we advocate for a shift in perspective from\nseeking a general definition of data quality towards a more language- and\ntask-specific one. Ultimately, we aim for this study to serve as a guide to\nusing Wikipedia for pretraining in a multilingual setting.\n","authors":["Kushal Tatariya","Artur Kulmizev","Wessel Poelman","Esther Ploeger","Marcel Bollmann","Johannes Bjerva","Jiaming Luo","Heather Lent","Miryam de Lhoneux"],"pdf_url":"https://arxiv.org/pdf/2411.05527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05508v1","updated":"2024-11-08T12:08:17Z","published":"2024-11-08T12:08:17Z","title":"An Early FIRST Reproduction and Improvements to Single-Token Decoding\n  for Fast Listwise Reranking","summary":"  Recent advances have demonstrated that large language models (LLMs) excel as\nlistwise rerankers, but their high computational demands remain a barrier to\nwidespread adoption. Further, the traditional language modeling (LM) objective\nis not ideally suited for reranking tasks. FIRST is a novel approach that\naddresses these challenges by integrating a learning-to-rank objective and\nleveraging the logits of only the first generated token, thereby significantly\nreducing inference latency compared to traditional LLM rerankers. In this\nstudy, we extend the evaluation of FIRST to the TREC Deep Learning datasets\n(DL19-22), validating its robustness across diverse domains. We investigate the\ninfluence of different first-stage retrievers on FIRST rerankers, observing\ndiminishing returns and patterns consistent with traditional LLM rerankers.\nThrough applying the FIRST objective to a broader range of backbone models, we\nachieve effectiveness surpassing the original implementation. Our experiments\nconfirm that fast reranking with single-token logits does not compromise\nout-of-domain reranking quality. To better quantify the computational savings\nin the original study, we measure and compare latency to find a 21%-42% gain\nacross various models and benchmarks. Moreover, while LM training implicitly\nimproves zero-shot single-token reranking, our experiments also raise questions\nabout whether LM pre-training may hinder subsequent fine-tuning with the FIRST\nobjective. These findings pave the way for more efficient and effective\nlistwise reranking in future applications.\n","authors":["Zijian Chen","Ronak Pradeep","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.05508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05504v1","updated":"2024-11-08T12:03:36Z","published":"2024-11-08T12:03:36Z","title":"LBPE: Long-token-first Tokenization to Improve Large Language Models","summary":"  The prevalent use of Byte Pair Encoding (BPE) in Large Language Models (LLMs)\nfacilitates robust handling of subword units and avoids issues of\nout-of-vocabulary words. Despite its success, a critical challenge persists:\nlong tokens, rich in semantic information, have fewer occurrences in tokenized\ndatasets compared to short tokens, which can result in imbalanced learning\nissue across different tokens. To address that, we propose LBPE, which\nprioritizes long tokens during the encoding process. LBPE generates tokens\naccording to their reverse ranks of token length rather than their ranks in the\nvocabulary, granting longer tokens higher priority during the encoding process.\nConsequently, LBPE smooths the frequency differences between short and long\ntokens, and thus mitigates the learning imbalance. Extensive experiments across\ndiverse language modeling tasks demonstrate that LBPE consistently outperforms\nthe original BPE, well demonstrating its effectiveness.\n","authors":["Haoran Lian","Yizhe Xiong","Zijia Lin","Jianwei Niu","Shasha Mo","Hui Chen","Peng Liu","Guiguang Ding"],"pdf_url":"https://arxiv.org/pdf/2411.05504v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2404.17808"},{"id":"http://arxiv.org/abs/2411.05503v1","updated":"2024-11-08T12:03:31Z","published":"2024-11-08T12:03:31Z","title":"KyrgyzNLP: Challenges, Progress, and Future","summary":"  Large language models (LLMs) have excelled in numerous benchmarks, advancing\nAI applications in both linguistic and non-linguistic tasks. However, this has\nprimarily benefited well-resourced languages, leaving less-resourced ones\n(LRLs) at a disadvantage. In this paper, we highlight the current state of the\nNLP field in the specific LRL: kyrgyz tili.\n  Human evaluation, including annotated datasets created by native speakers,\nremains an irreplaceable component of reliable NLP performance, especially for\nLRLs where automatic evaluations can fall short. In recent assessments of the\nresources for Turkic languages, Kyrgyz is labeled with the status 'Scraping\nBy', a severely under-resourced language spoken by millions. This is concerning\ngiven the growing importance of the language, not only in Kyrgyzstan but also\namong diaspora communities where it holds no official status.\n  We review prior efforts in the field, noting that many of the publicly\navailable resources have only recently been developed, with few exceptions\nbeyond dictionaries (the processed data used for the analysis is presented at\nhttps://kyrgyznlp.github.io/). While recent papers have made some headway, much\nmore remains to be done. Despite interest and support from both business and\ngovernment sectors in the Kyrgyz Republic, the situation for Kyrgyz language\nresources remains challenging. We stress the importance of community-driven\nefforts to build these resources, ensuring the future advancement\nsustainability. We then share our view of the most pressing challenges in\nKyrgyz NLP. Finally, we propose a roadmap for future development in terms of\nresearch topics and language resources.\n","authors":["Anton Alekseev","Timur Turatali"],"pdf_url":"https://arxiv.org/pdf/2411.05503v1.pdf","comment":"Keynote talk at the 12th International Conference on Analysis of\n  Images, Social Networks and Texts (AIST-2024)"},{"id":"http://arxiv.org/abs/2404.17808v2","updated":"2024-11-08T11:56:46Z","published":"2024-04-27T07:12:07Z","title":"Scaffold-BPE: Enhancing Byte Pair Encoding for Large Language Models\n  with Simple and Effective Scaffold Token Removal","summary":"  Byte Pair Encoding (BPE) serves as a foundation method for text tokenization\nin the Natural Language Processing (NLP) field. Despite its wide adoption, the\noriginal BPE algorithm harbors an inherent flaw: it inadvertently introduces a\nfrequency imbalance for tokens in the text corpus. Since BPE iteratively merges\nthe most frequent token pair in the text corpus to generate a new token and\nkeeps all generated tokens in the vocabulary, it unavoidably holds tokens that\nprimarily act as components of a longer token and appear infrequently on their\nown. We term such tokens as Scaffold Tokens. Due to their infrequent\noccurrences in the text corpus, Scaffold Tokens pose a learning imbalance\nissue. To address that issue, we propose Scaffold-BPE, which incorporates a\ndynamic scaffold token removal mechanism by parameter-free, computation-light,\nand easy-to-implement modifications to the original BPE method. This novel\napproach ensures the exclusion of low-frequency Scaffold Tokens from the token\nrepresentations for given texts, thereby mitigating the issue of frequency\nimbalance and facilitating model training. On extensive experiments across\nlanguage modeling and even machine translation, Scaffold-BPE consistently\noutperforms the original BPE, well demonstrating its effectiveness.\n","authors":["Haoran Lian","Yizhe Xiong","Jianwei Niu","Shasha Mo","Zhenpeng Su","Zijia Lin","Hui Chen","Peng Liu","Jungong Han","Guiguang Ding"],"pdf_url":"https://arxiv.org/pdf/2404.17808v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05479v1","updated":"2024-11-08T11:09:45Z","published":"2024-11-08T11:09:45Z","title":"EUREKHA: Enhancing User Representation for Key Hackers Identification in\n  Underground Forums","summary":"  Underground forums serve as hubs for cybercriminal activities, offering a\nspace for anonymity and evasion of conventional online oversight. In these\nhidden communities, malicious actors collaborate to exchange illicit knowledge,\ntools, and tactics, driving a range of cyber threats from hacking techniques to\nthe sale of stolen data, malware, and zero-day exploits. Identifying the key\ninstigators (i.e., key hackers), behind these operations is essential but\nremains a complex challenge. This paper presents a novel method called EUREKHA\n(Enhancing User Representation for Key Hacker Identification in Underground\nForums), designed to identify these key hackers by modeling each user as a\ntextual sequence. This sequence is processed through a large language model\n(LLM) for domain-specific adaptation, with LLMs acting as feature extractors.\nThese extracted features are then fed into a Graph Neural Network (GNN) to\nmodel user structural relationships, significantly improving identification\naccuracy. Furthermore, we employ BERTopic (Bidirectional Encoder\nRepresentations from Transformers Topic Modeling) to extract personalized\ntopics from user-generated content, enabling multiple textual representations\nper user and optimizing the selection of the most representative sequence. Our\nstudy demonstrates that fine-tuned LLMs outperform state-of-the-art methods in\nidentifying key hackers. Additionally, when combined with GNNs, our model\nachieves significant improvements, resulting in approximately 6% and 10%\nincreases in accuracy and F1-score, respectively, over existing methods.\nEUREKHA was tested on the Hack-Forums dataset, and we provide open-source\naccess to our code.\n","authors":["Abdoul Nasser Hassane Amadou","Anas Motii","Saida Elouardi","EL Houcine Bergou"],"pdf_url":"https://arxiv.org/pdf/2411.05479v1.pdf","comment":"Accepted at IEEE Trustcom 2024"},{"id":"http://arxiv.org/abs/2411.05460v1","updated":"2024-11-08T10:24:00Z","published":"2024-11-08T10:24:00Z","title":"Supporting Automated Fact-checking across Topics: Similarity-driven\n  Gradual Topic Learning for Claim Detection","summary":"  Selecting check-worthy claims for fact-checking is considered a crucial part\nof expediting the fact-checking process by filtering out and ranking the\ncheck-worthy claims for being validated among the impressive amount of claims\ncould be found online. The check-worthy claim detection task, however, becomes\nmore challenging when the model needs to deal with new topics that differ from\nthose seen earlier. In this study, we propose a domain-adaptation framework for\ncheck-worthy claims detection across topics for the Arabic language to adopt a\nnew topic, mimicking a real-life scenario of the daily emergence of events\nworldwide. We propose the Gradual Topic Learning (GTL) model, which builds an\nability to learning gradually and emphasizes the check-worthy claims for the\ntarget topic during several stages of the learning process. In addition, we\nintroduce the Similarity-driven Gradual Topic Learning (SGTL) model that\nsynthesizes gradual learning with a similarity-based strategy for the target\ntopic. Our experiments demonstrate the effectiveness of our proposed model,\nshowing an overall tendency for improving performance over the state-of-the-art\nbaseline across 11 out of the 14 topics under study.\n","authors":["Amani S. Abumansour","Arkaitz Zubiaga"],"pdf_url":"https://arxiv.org/pdf/2411.05460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05451v1","updated":"2024-11-08T09:58:02Z","published":"2024-11-08T09:58:02Z","title":"WorkflowLLM: Enhancing Workflow Orchestration Capability of Large\n  Language Models","summary":"  Recent advancements in large language models (LLMs) have driven a\nrevolutionary paradigm shift in process automation from Robotic Process\nAutomation to Agentic Process Automation by automating the workflow\norchestration procedure based on LLMs. However, existing LLMs (even the\nadvanced OpenAI GPT-4o) are confined to achieving satisfactory capability in\nworkflow orchestration. To address this limitation, we present WorkflowLLM, a\ndata-centric framework elaborately designed to enhance the capability of LLMs\nin workflow orchestration. It first constructs a large-scale fine-tuning\ndataset WorkflowBench with 106,763 samples, covering 1,503 APIs from 83\napplications across 28 categories. Specifically, the construction process can\nbe divided into three phases: (1) Data Collection: we collect real-world\nworkflow data from Apple Shortcuts and RoutineHub, transcribing them into\nPython-style code. We further equip them with generated hierarchical thought\nvia ChatGPT. (2) Query Expansion: we prompt ChatGPT to generate more task\nqueries to enrich the diversity and complexity of workflows. (3) Workflow\nGeneration: we leverage an annotator model trained on collected data to\ngenerate workflows for synthesized queries. Finally, we merge the synthetic\nsamples that pass quality confirmation with the collected samples to obtain the\nWorkflowBench. Based on WorkflowBench, we fine-tune Llama-3.1-8B to obtain\nWorkflowLlama. Our experiments show that WorkflowLlama demonstrates a strong\ncapacity to orchestrate complex workflows, while also achieving notable\ngeneralization performance on previously unseen APIs. Additionally,\nWorkflowBench exhibits robust zero-shot generalization capabilities on an\nout-of-distribution task planning dataset, T-Eval. Our data and code are\navailable at https://github.com/OpenBMB/WorkflowLLM.\n","authors":["Shengda Fan","Xin Cong","Yuepeng Fu","Zhong Zhang","Shuyan Zhang","Yuanwei Liu","Yesai Wu","Yankai Lin","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2411.05451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20895v2","updated":"2024-11-08T09:35:29Z","published":"2024-05-31T15:04:15Z","title":"A comparison of correspondence analysis with PMI-based word embedding\n  methods","summary":"  Popular word embedding methods such as GloVe and Word2Vec are related to the\nfactorization of the pointwise mutual information (PMI) matrix. In this paper,\nwe link correspondence analysis (CA) to the factorization of the PMI matrix. CA\nis a dimensionality reduction method that uses singular value decomposition\n(SVD), and we show that CA is mathematically close to the weighted\nfactorization of the PMI matrix. In addition, we present variants of CA that\nturn out to be successful in the factorization of the word-context matrix, i.e.\nCA applied to a matrix where the entries undergo a square-root transformation\n(ROOT-CA) and a root-root transformation (ROOTROOT-CA). While this study\nfocuses on traditional static word embedding methods, to extend the\ncontribution of this paper, we also include a comparison of transformer-based\nencoder BERT, i.e. contextual word embedding, with these traditional methods.\nAn empirical comparison among CA- and PMI-based methods as well as BERT shows\nthat overall results of ROOT-CA and ROOTROOT-CA are slightly better than those\nof the PMI-based methods and are competitive with BERT.\n","authors":["Qianqian Qi","Ayoub Bagheri","David J. Hessen","Peter G. M. van der Heijden"],"pdf_url":"https://arxiv.org/pdf/2405.20895v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05423v1","updated":"2024-11-08T09:15:56Z","published":"2024-11-08T09:15:56Z","title":"VISTA: Visual Integrated System for Tailored Automation in Math Problem\n  Generation Using LLM","summary":"  Generating accurate and consistent visual aids is a critical challenge in\nmathematics education, where visual representations like geometric shapes and\nfunctions play a pivotal role in enhancing student comprehension. This paper\nintroduces a novel multi-agent framework that leverages Large Language Models\n(LLMs) to automate the creation of complex mathematical visualizations\nalongside coherent problem text. Our approach not only simplifies the\ngeneration of precise visual aids but also aligns these aids with the problem's\ncore mathematical concepts, improving both problem creation and assessment. By\nintegrating multiple agents, each responsible for distinct tasks such as\nnumeric calculation, geometry validation, and visualization, our system\ndelivers mathematically accurate and contextually relevant problems with visual\naids. Evaluation across Geometry and Function problem types shows that our\nmethod significantly outperforms basic LLMs in terms of text coherence,\nconsistency, relevance and similarity, while maintaining the essential\ngeometrical and functional integrity of the original problems. Although some\nchallenges remain in ensuring consistent visual outputs, our framework\ndemonstrates the immense potential of LLMs in transforming the way educators\ngenerate and utilize visual aids in math education.\n","authors":["Jeongwoo Lee","Kwangsuk Park","Jihyeon Park"],"pdf_url":"https://arxiv.org/pdf/2411.05423v1.pdf","comment":"Accepted at NeurIPS 2024 Workshop on Large Foundation Models for\n  Educational Assessment (FM-Assess)"},{"id":"http://arxiv.org/abs/2411.05421v1","updated":"2024-11-08T09:14:22Z","published":"2024-11-08T09:14:22Z","title":"Learning the rules of peptide self-assembly through data mining with\n  large language models","summary":"  Peptides are ubiquitous and important biologically derived molecules, that\nhave been found to self-assemble to form a wide array of structures. Extensive\nresearch has explored the impacts of both internal chemical composition and\nexternal environmental stimuli on the self-assembly behaviour of these systems.\nHowever, there is yet to be a systematic study that gathers this rich\nliterature data and collectively examines these experimental factors to provide\na global picture of the fundamental rules that govern protein self-assembly\nbehavior. In this work, we curate a peptide assembly database through a\ncombination of manual processing by human experts and literature mining\nfacilitated by a large language model. As a result, we collect more than 1,000\nexperimental data entries with information about peptide sequence, experimental\nconditions and corresponding self-assembly phases. Utilizing the collected\ndata, ML models are trained and evaluated, demonstrating excellent accuracy\n(>80\\%) and efficiency in peptide assembly phase classification. Moreover, we\nfine-tune our GPT model for peptide literature mining with the developed\ndataset, which exhibits markedly superior performance in extracting information\nfrom academic publications relative to the pre-trained model. We find that this\nworkflow can substantially improve efficiency when exploring potential\nself-assembling peptide candidates, through guiding experimental work, while\nalso deepening our understanding of the mechanisms governing peptide\nself-assembly. In doing so, novel structures can be accessed for a range of\napplications including sensing, catalysis and biomaterials.\n","authors":["Zhenze Yang","Sarah K. Yorke","Tuomas P. J. Knowles","Markus J. Buehler"],"pdf_url":"https://arxiv.org/pdf/2411.05421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13698v2","updated":"2024-11-08T09:02:56Z","published":"2024-06-19T16:52:22Z","title":"MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of\n  Metaphorical Language","summary":"  Machine Translation (MT) has developed rapidly since the release of Large\nLanguage Models and current MT evaluation is performed through comparison with\nreference human translations or by predicting quality scores from human-labeled\ndata. However, these mainstream evaluation methods mainly focus on fluency and\nfactual reliability, whilst paying little attention to figurative quality. In\nthis paper, we investigate the figurative quality of MT and propose a set of\nhuman evaluation metrics focused on the translation of figurative language. We\nadditionally present a multilingual parallel metaphor corpus generated by\npost-editing. Our evaluation protocol is designed to estimate four aspects of\nMT: Metaphorical Equivalence, Emotion, Authenticity, and Quality. In doing so,\nwe observe that translations of figurative expressions display different traits\nfrom literal ones.\n","authors":["Shun Wang","Ge Zhang","Han Wu","Tyler Loakman","Wenhao Huang","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2406.13698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07230v2","updated":"2024-11-08T08:55:00Z","published":"2024-03-12T00:58:19Z","title":"Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked\n  Preferences","summary":"  Direct Preference Optimization (DPO) is an effective technique that leverages\npairwise preference data (usually one chosen and rejected response pair per\nuser prompt) to align LLMs to human preferences. In practice, multiple\nresponses can exist for a given prompt with varying quality relative to each\nother. With availability of such quality ratings for multiple responses, we\npropose utilizing these responses to create multiple preference pairs for a\ngiven prompt. Our work focuses on systematically using the constructed multiple\npreference pair in DPO training via curriculum learning methodology. In\nparticular, we order these multiple pairs of preference data from easy to hard\n(emulating curriculum training) according to various criteria. We show detailed\ncomparisons of our proposed approach to the standard single-pair DPO setting.\nOur method, which we call Curry-DPO consistently shows increased performance\ngains on MTbench, Vicuna, WizardLM, and the UltraFeedback test set,\nhighlighting its effectiveness. More specifically, Curry-DPO achieves a score\nof 7.43 on MT-bench with Zephy-7B model outperforming majority of existing LLMs\nwith similar parameter size. Curry-DPO also achieves the highest adjusted win\nrates on Vicuna, WizardLM, and UltraFeedback test datasets (90.7%, 87.1%, and\n87.9% respectively) in our experiments, with notable gains of upto 7.5% when\ncompared to standard DPO technique. We release the preference pairs used in\nalignment at:\nhttps://huggingface.co/datasets/ServiceNow-AI/Curriculum_DPO_preferences\n","authors":["Pulkit Pattnaik","Rishabh Maheshwary","Kelechi Ogueji","Vikas Yadav","Sathwik Tejaswi Madhusudhan"],"pdf_url":"https://arxiv.org/pdf/2403.07230v2.pdf","comment":"Published at EMNLP 2024 as long (findings) conference paper"},{"id":"http://arxiv.org/abs/2411.05407v1","updated":"2024-11-08T08:52:59Z","published":"2024-11-08T08:52:59Z","title":"Gap-Filling Prompting Enhances Code-Assisted Mathematical Reasoning","summary":"  Despite the strong performance of large language models (LLMs) in tasks like\nmathematical reasoning, their practical use is limited by high computational\ndemands and proprietary restrictions. Chain-of-thought (CoT) and\nprogram-of-thought (PoT) fine-tuning are common methods to transfer LLM\nknowledge to small language models (SLMs). However, CoT often leads to\ncalculation errors in SLMs, while PoT has shown more promise. While most\nPoT-based approaches focus on direct problem-to-code conversion or extracting\nonly the key information from questions and then providing code solution for\nit, this work emphasizes filling the gaps in the question to clearly illustrate\nthe solution path, which can be challenging for an SLM to understand when such\ninformation is not explicitly provided. Therefore, this paper introduces\nGap-Filling Prompting (GFP), a novel two-step prompting strategy designed to\nenhance the problem-solving process for SLMs. The first step identifies these\ngaps and provides hints for filling them, while the second step adds the hints\nto the question to generate a final code solution. Experimental results on two\nbenchmark datasets demonstrate that GFP significantly improves the mathematical\nreasoning abilities of SLMs.\n","authors":["Mohammad Ghiasvand Mohammadkhani"],"pdf_url":"https://arxiv.org/pdf/2411.05407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05403v1","updated":"2024-11-08T08:41:17Z","published":"2024-11-08T08:41:17Z","title":"Benchmarking Distributional Alignment of Large Language Models","summary":"  Language models (LMs) are increasingly used as simulacra for people, yet\ntheir ability to match the distribution of views of a specific demographic\ngroup and be \\textit{distributionally aligned} remains uncertain. This notion\nof distributional alignment is complex, as there is significant variation in\nthe types of attributes that are simulated. Prior works have underexplored the\nrole of three critical variables -- the question domain, steering method, and\ndistribution expression method -- which motivates our contribution of a\nbenchmark explicitly addressing these dimensions. We construct a dataset\nexpanding beyond political values, create human baselines for this task, and\nevaluate the extent to which an LM can align with a particular group's opinion\ndistribution to inform design choices of such simulation systems. Our analysis\nreveals open problems regarding if, and how, LMs can be used to simulate\nhumans, and that LLMs can more accurately describe the opinion distribution\nthan simulate such distributions.\n","authors":["Nicole Meister","Carlos Guestrin","Tatsunori Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2411.05403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05383v1","updated":"2024-11-08T07:43:15Z","published":"2024-11-08T07:43:15Z","title":"Towards Low-Resource Harmful Meme Detection with LMM Agents","summary":"  The proliferation of Internet memes in the age of social media necessitates\neffective identification of harmful ones. Due to the dynamic nature of memes,\nexisting data-driven models may struggle in low-resource scenarios where only a\nfew labeled examples are available. In this paper, we propose an agency-driven\nframework for low-resource harmful meme detection, employing both outward and\ninward analysis with few-shot annotated samples. Inspired by the powerful\ncapacity of Large Multimodal Models (LMMs) on multimodal reasoning, we first\nretrieve relative memes with annotations to leverage label information as\nauxiliary signals for the LMM agent. Then, we elicit knowledge-revising\nbehavior within the LMM agent to derive well-generalized insights into meme\nharmfulness. By combining these strategies, our approach enables dialectical\nreasoning over intricate and implicit harm-indicative patterns. Extensive\nexperiments conducted on three meme datasets demonstrate that our proposed\napproach achieves superior performance than state-of-the-art methods on the\nlow-resource harmful meme detection task.\n","authors":["Jianzhao Huang","Hongzhan Lin","Ziyan Liu","Ziyang Luo","Guang Chen","Jing Ma"],"pdf_url":"https://arxiv.org/pdf/2411.05383v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.04950v2","updated":"2024-11-08T07:34:45Z","published":"2024-11-07T18:28:40Z","title":"Estimating the Influence of Sequentially Correlated Literary Properties\n  in Textual Classification: A Data-Centric Hypothesis-Testing Approach","summary":"  Stylometry aims to distinguish authors by analyzing literary traits assumed\nto reflect semi-conscious choices distinct from elements like genre or theme.\nHowever, these components often overlap, complicating text classification based\nsolely on feature distributions. While some literary properties, such as\nthematic content, are likely to manifest as correlations between adjacent text\nunits, others, like authorial style, may be independent thereof. We introduce a\nhypothesis-testing approach to evaluate the influence of sequentially\ncorrelated literary properties on text classification, aiming to determine when\nthese correlations drive classification. Using a multivariate binary\ndistribution, our method models sequential correlations between text units as a\nstochastic process, assessing the likelihood of clustering across varying\nadjacency scales. This enables us to examine whether classification is\ndominated by sequentially correlated properties or remains independent. In\nexperiments on a diverse English prose corpus, our analysis integrates\ntraditional and neural embeddings within supervised and unsupervised\nframeworks. Results demonstrate that our approach effectively identifies when\ntextual classification is not primarily influenced by sequentially correlated\nliterary properties, particularly in cases where texts differ in authorial\nstyle or genre rather than by a single author within a similar genre.\n","authors":["Gideon Yoffe","Nachum Dershowitz","Ariel Vishne","Barak Sober"],"pdf_url":"https://arxiv.org/pdf/2411.04950v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04358v2","updated":"2024-11-08T07:31:26Z","published":"2024-11-07T01:31:48Z","title":"Robust and Efficient Fine-tuning of LLMs with Bayesian\n  Reparameterization of Low-Rank Adaptation","summary":"  Large Language Models (LLMs) are highly resource-intensive to fine-tune due\nto their enormous size. While low-rank adaptation is a prominent\nparameter-efficient fine-tuning approach, it suffers from sensitivity to\nhyperparameter choices, leading to instability in model performance on\nfine-tuning downstream tasks. This paper highlights the importance of effective\nparameterization in low-rank fine-tuning to reduce estimator variance and\nenhance the stability of final model outputs. We propose MonteCLoRA, an\nefficient fine-tuning technique, employing Monte Carlo estimation to learn an\nunbiased posterior estimation of low-rank parameters with low expected\nvariance, which stabilizes fine-tuned LLMs with only O(1) additional\nparameters. MonteCLoRA shows significant improvements in accuracy and\nrobustness, achieving up to 3.8% higher accuracy and 8.6% greater robustness\nthan existing efficient fine-tuning methods on natural language understanding\ntasks with pre-trained RoBERTa-base. Furthermore, in generative tasks with\npre-trained LLaMA-1-7B, MonteCLoRA demonstrates robust zero-shot performance\nwith 50% lower variance than the contemporary efficient fine-tuning methods.\nThe theoretical and empirical results presented in the paper underscore how\nparameterization and hyperpriors balance exploration-exploitation in the\nlow-rank parametric space, therefore leading to more optimal and robust\nparameter estimation during efficient fine-tuning.\n","authors":["Ayan Sengupta","Vaibhav Seth","Arinjay Pathak","Natraj Raman","Sriram Gopalakrishnan","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2411.04358v2.pdf","comment":"48 pages, 10 figures, 10 tables, Code:\n  https://github.com/LCS2-IIITD/MonteCLoRA"},{"id":"http://arxiv.org/abs/2411.05379v1","updated":"2024-11-08T07:20:21Z","published":"2024-11-08T07:20:21Z","title":"Word reuse and combination support efficient communication of emerging\n  concepts","summary":"  A key function of the lexicon is to express novel concepts as they emerge\nover time through a process known as lexicalization. The most common\nlexicalization strategies are the reuse and combination of existing words, but\nthey have typically been studied separately in the areas of word meaning\nextension and word formation. Here we offer an information-theoretic account of\nhow both strategies are constrained by a fundamental tradeoff between competing\ncommunicative pressures: word reuse tends to preserve the average length of\nword forms at the cost of less precision, while word combination tends to\nproduce more informative words at the expense of greater word length. We test\nour proposal against a large dataset of reuse items and compounds that appeared\nin English, French and Finnish over the past century. We find that these\nhistorically emerging items achieve higher levels of communicative efficiency\nthan hypothetical ways of constructing the lexicon, and both literal reuse\nitems and compounds tend to be more efficient than their non-literal\ncounterparts. These results suggest that reuse and combination are both\nconsistent with a unified account of lexicalization grounded in the theory of\nefficient communication.\n","authors":["Aotao Xu","Charles Kemp","Lea Frermann","Yang Xu"],"pdf_url":"https://arxiv.org/pdf/2411.05379v1.pdf","comment":"Published in Proceedings of the National Academy of Sciences"},{"id":"http://arxiv.org/abs/2411.05375v1","updated":"2024-11-08T07:05:06Z","published":"2024-11-08T07:05:06Z","title":"Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking","summary":"  Current automated fact-checking (AFC) approaches commonly evaluate evidence\neither implicitly via the predicted verdicts or by comparing retrieved evidence\nwith a predefined closed knowledge source, such as Wikipedia. However, these\nmethods suffer from limitations, resulting from their reliance on evaluation\nmetrics developed for different purposes and constraints imposed by closed\nknowledge sources. Recent advances in natural language generation (NLG)\nevaluation offer new possibilities for evidence assessment. In this work, we\nintroduce Ev2R, an evaluation framework for AFC that comprises three types of\napproaches for evidence evaluation: reference-based, proxy-reference, and\nreference-less. We evaluate their effectiveness through agreement with human\nratings and adversarial tests, and demonstrate that prompt-based scorers,\nparticularly those leveraging LLMs and reference evidence, outperform\ntraditional evaluation approaches.\n","authors":["Mubashara Akhtar","Michael Schlichtkrull","Andreas Vlachos"],"pdf_url":"https://arxiv.org/pdf/2411.05375v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2401.17263v5","updated":"2024-11-08T06:57:05Z","published":"2024-01-30T18:56:08Z","title":"Robust Prompt Optimization for Defending Language Models Against\n  Jailbreaking Attacks","summary":"  Despite advances in AI alignment, large language models (LLMs) remain\nvulnerable to adversarial attacks or jailbreaking, in which adversaries can\nmodify prompts to induce unwanted behavior. While some defenses have been\nproposed, they have not been adapted to newly proposed attacks and more\nchallenging threat models. To address this, we propose an optimization-based\nobjective for defending LLMs against jailbreaking attacks and an algorithm,\nRobust Prompt Optimization (RPO) to create robust system-level defenses. Our\napproach directly incorporates the adversary into the defensive objective and\noptimizes a lightweight and transferable suffix, enabling RPO to adapt to\nworst-case adaptive attacks. Our theoretical and experimental results show\nimproved robustness to both jailbreaks seen during optimization and unknown\njailbreaks, reducing the attack success rate (ASR) on GPT-4 to 6% and Llama-2\nto 0% on JailbreakBench, setting the state-of-the-art. Code can be found at\nhttps://github.com/lapisrocks/rpo\n","authors":["Andy Zhou","Bo Li","Haohan Wang"],"pdf_url":"https://arxiv.org/pdf/2401.17263v5.pdf","comment":"NeurIPS 2024 Spotlight; code available at\n  https://github.com/lapisrocks/rpo"},{"id":"http://arxiv.org/abs/2307.09254v2","updated":"2024-11-08T06:47:04Z","published":"2023-07-18T13:36:24Z","title":"Selective Generation for Controllable Language Models","summary":"  Trustworthiness of generative language models (GLMs) is crucial in their\ndeployment to critical decision making systems. Hence, certified risk control\nmethods such as selective prediction and conformal prediction have been applied\nto mitigating the hallucination problem in various supervised downstream tasks.\nHowever, the lack of appropriate correctness metric hinders applying such\nprincipled methods to language generation tasks. In this paper, we circumvent\nthis problem by leveraging the concept of textual entailment to evaluate the\ncorrectness of the generated sequence, and propose two selective generation\nalgorithms which control the false discovery rate with respect to the textual\nentailment relation (FDR-E) with a theoretical guarantee:\n$\\texttt{SGen}^{\\texttt{Sup}}$ and $\\texttt{SGen}^{\\texttt{Semi}}$.\n$\\texttt{SGen}^{\\texttt{Sup}}$, a direct modification of the selective\nprediction, is a supervised learning algorithm which exploits\nentailment-labeled data, annotated by humans. Since human annotation is costly,\nwe further propose a semi-supervised version, $\\texttt{SGen}^{\\texttt{Semi}}$,\nwhich fully utilizes the unlabeled data by pseudo-labeling, leveraging an\nentailment set function learned via conformal prediction. Furthermore,\n$\\texttt{SGen}^{\\texttt{Semi}}$ enables to use more general class of selection\nfunctions, neuro-selection functions, and provides users with an optimal\nselection function class given multiple candidates. Finally, we demonstrate the\nefficacy of the $\\texttt{SGen}$ family in achieving a desired FDR-E level with\ncomparable selection efficiency to those from baselines on both open and closed\nsource GLMs. Code and datasets are provided at\nhttps://github.com/ml-postech/selective-generation.\n","authors":["Minjae Lee","Kyungmin Kim","Taesoo Kim","Sangdon Park"],"pdf_url":"https://arxiv.org/pdf/2307.09254v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2411.05361v1","updated":"2024-11-08T06:33:22Z","published":"2024-11-08T06:33:22Z","title":"Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for\n  Measuring the Capabilities of Spoken Language Models with 180 Tasks","summary":"  Multimodal foundation models, such as Gemini and ChatGPT, have revolutionized\nhuman-machine interactions by seamlessly integrating various forms of data.\nDeveloping a universal spoken language model that comprehends a wide range of\nnatural language instructions is critical for bridging communication gaps and\nfacilitating more intuitive interactions. However, the absence of a\ncomprehensive evaluation benchmark poses a significant challenge. We present\nDynamic-SUPERB Phase-2, an open and evolving benchmark for the comprehensive\nevaluation of instruction-based universal speech models. Building upon the\nfirst generation, this second version incorporates 125 new tasks contributed\ncollaboratively by the global research community, expanding the benchmark to a\ntotal of 180 tasks, making it the largest benchmark for speech and audio\nevaluation. While the first generation of Dynamic-SUPERB was limited to\nclassification tasks, Dynamic-SUPERB Phase-2 broadens its evaluation\ncapabilities by introducing a wide array of novel and diverse tasks, including\nregression and sequence generation, across speech, music, and environmental\naudio. Evaluation results indicate that none of the models performed well\nuniversally. SALMONN-13B excelled in English ASR, while WavLLM demonstrated\nhigh accuracy in emotion recognition, but current models still require further\ninnovations to handle a broader range of tasks. We will soon open-source all\ntask data and the evaluation pipeline.\n","authors":["Chien-yu Huang","Wei-Chih Chen","Shu-wen Yang","Andy T. Liu","Chen-An Li","Yu-Xiang Lin","Wei-Cheng Tseng","Anuj Diwan","Yi-Jen Shih","Jiatong Shi","William Chen","Xuanjun Chen","Chi-Yuan Hsiao","Puyuan Peng","Shih-Heng Wang","Chun-Yi Kuan","Ke-Han Lu","Kai-Wei Chang","Chih-Kai Yang","Fabian Ritter-Gutierrez","Ming To Chuang","Kuan-Po Huang","Siddhant Arora","You-Kuan Lin","Eunjung Yeo","Kalvin Chang","Chung-Ming Chien","Kwanghee Choi","Cheng-Hsiu Hsieh","Yi-Cheng Lin","Chee-En Yu","I-Hsiang Chiu","Heitor R. Guimarães","Jionghao Han","Tzu-Quan Lin","Tzu-Yuan Lin","Homu Chang","Ting-Wu Chang","Chun Wei Chen","Shou-Jen Chen","Yu-Hua Chen","Hsi-Chun Cheng","Kunal Dhawan","Jia-Lin Fang","Shi-Xin Fang","Kuan-Yu Fang Chiang","Chi An Fu","Hsien-Fu Hsiao","Ching Yu Hsu","Shao-Syuan Huang","Lee Chen Wei","Hsi-Che Lin","Hsuan-Hao Lin","Hsuan-Ting Lin","Jian-Ren Lin","Ting-Chun Liu","Li-Chun Lu","Tsung-Min Pai","Ankita Pasad","Shih-Yun Shan Kuan","Suwon Shon","Yuxun Tang","Yun-Shao Tsai","Jui-Chiang Wei","Tzu-Chieh Wei","Chengxi Wu","Dien-Ruei Wu","Chao-Han Huck Yang","Chieh-Chi Yang","Jia Qi Yip","Shao-Xiang Yuan","Vahid Noroozi","Zhehuai Chen","Haibin Wu","Karen Livescu","David Harwath","Shinji Watanabe","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2411.05361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01251v3","updated":"2024-11-08T06:07:51Z","published":"2024-03-02T16:23:44Z","title":"Accelerating Greedy Coordinate Gradient and General Prompt Optimization\n  via Probe Sampling","summary":"  Safety of Large Language Models (LLMs) has become a critical issue given\ntheir rapid progresses. Greedy Coordinate Gradient (GCG) is shown to be\neffective in constructing adversarial prompts to break the aligned LLMs, but\noptimization of GCG is time-consuming. To reduce the time cost of GCG and\nenable more comprehensive studies of LLM safety, in this work, we study a new\nalgorithm called $\\texttt{Probe sampling}$. At the core of the algorithm is a\nmechanism that dynamically determines how similar a smaller draft model's\npredictions are to the target model's predictions for prompt candidates. When\nthe target model is similar to the draft model, we rely heavily on the draft\nmodel to filter out a large number of potential prompt candidates. Probe\nsampling achieves up to $5.6$ times speedup using Llama2-7b-chat and leads to\nequal or improved attack success rate (ASR) on the AdvBench. Furthermore, probe\nsampling is also able to accelerate other prompt optimization techniques and\nadversarial methods, leading to acceleration of $1.8\\times$ for AutoPrompt,\n$2.4\\times$ for APE and $2.4\\times$ for AutoDAN.\n","authors":["Yiran Zhao","Wenyue Zheng","Tianle Cai","Xuan Long Do","Kenji Kawaguchi","Anirudh Goyal","Michael Shieh"],"pdf_url":"https://arxiv.org/pdf/2403.01251v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05345v1","updated":"2024-11-08T05:54:05Z","published":"2024-11-08T05:54:05Z","title":"Reasoning Robustness of LLMs to Adversarial Typographical Errors","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities in\nreasoning using Chain-of-Thought (CoT) prompting. However, CoT can be biased by\nusers' instruction. In this work, we study the reasoning robustness of LLMs to\ntypographical errors, which can naturally occur in users' queries. We design an\nAdversarial Typo Attack ($\\texttt{ATA}$) algorithm that iteratively samples\ntypos for words that are important to the query and selects the edit that is\nmost likely to succeed in attacking. It shows that LLMs are sensitive to\nminimal adversarial typographical changes. Notably, with 1 character edit,\nMistral-7B-Instruct's accuracy drops from 43.7% to 38.6% on GSM8K, while with 8\ncharacter edits the performance further drops to 19.2%. To extend our\nevaluation to larger and closed-source LLMs, we develop the $\\texttt{R$^2$ATA}$\nbenchmark, which assesses models' $\\underline{R}$easoning\n$\\underline{R}$obustness to $\\underline{\\texttt{ATA}}$. It includes adversarial\ntypographical questions derived from three widely used reasoning\ndatasets-GSM8K, BBH, and MMLU-by applying $\\texttt{ATA}$ to open-source LLMs.\n$\\texttt{R$^2$ATA}$ demonstrates remarkable transferability and causes notable\nperformance drops across multiple super large and closed-source LLMs.\n","authors":["Esther Gan","Yiran Zhao","Liying Cheng","Yancan Mao","Anirudh Goyal","Kenji Kawaguchi","Min-Yen Kan","Michael Shieh"],"pdf_url":"https://arxiv.org/pdf/2411.05345v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05340v1","updated":"2024-11-08T05:43:40Z","published":"2024-11-08T05:43:40Z","title":"Improving Multi-Domain Task-Oriented Dialogue System with Offline\n  Reinforcement Learning","summary":"  Task-oriented dialogue (TOD) system is designed to accomplish user-defined\ntasks through dialogues. The TOD system has progressed towards end-to-end\nmodeling by leveraging pre-trained large language models. Fine-tuning the\npre-trained language models using only supervised learning leads to the\nexposure bias and token loss problem and it deviates the models from completing\nthe user's task. To address these issues, we propose a TOD system that\nleverages a unified pre-trained language model, GPT2, as a base model. It is\noptimized using supervised learning and reinforcement learning (RL). The issues\nin the TOD system are mitigated using a non-differentiable reward function. The\nreward is calculated using the weighted sum of the success rate and BLEU\nevaluation metrics. The success rate and BLEU metrics in reward calculation\nguide the language model for user task completion while ensuring a coherent and\nfluent response. Our model is acquired by fine-tuning a pre-trained model on\nthe dialogue-session level which comprises user utterance, belief state, system\nact, and system response. Experimental results on MultiWOZ2.1 demonstrate that\nour model increases the inform rate by 1.60% and the success rate by 3.17%\ncompared to the baseline.\n","authors":["Dharmendra Prajapat","Durga Toshniwal"],"pdf_url":"https://arxiv.org/pdf/2411.05340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05338v1","updated":"2024-11-08T05:28:22Z","published":"2024-11-08T05:28:22Z","title":"SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers","summary":"  Scientific literature is typically dense, requiring significant background\nknowledge and deep comprehension for effective engagement. We introduce SciDQA,\na new dataset for reading comprehension that challenges LLMs for a deep\nunderstanding of scientific articles, consisting of 2,937 QA pairs. Unlike\nother scientific QA datasets, SciDQA sources questions from peer reviews by\ndomain experts and answers by paper authors, ensuring a thorough examination of\nthe literature. We enhance the dataset's quality through a process that\ncarefully filters out lower quality questions, decontextualizes the content,\ntracks the source document across different versions, and incorporates a\nbibliography for multi-document question-answering. Questions in SciDQA\nnecessitate reasoning across figures, tables, equations, appendices, and\nsupplementary materials, and require multi-document reasoning. We evaluate\nseveral open-source and proprietary LLMs across various configurations to\nexplore their capabilities in generating relevant and factual responses. Our\ncomprehensive evaluation, based on metrics for surface-level similarity and LLM\njudgements, highlights notable performance discrepancies. SciDQA represents a\nrigorously curated, naturally derived scientific QA dataset, designed to\nfacilitate research on complex scientific text understanding.\n","authors":["Shruti Singh","Nandan Sarkar","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2411.05338v1.pdf","comment":"18 pages, Accepted to EMNLP 2024"},{"id":"http://arxiv.org/abs/2406.16524v2","updated":"2024-11-08T05:24:12Z","published":"2024-06-24T10:59:26Z","title":"The Privileged Students: On the Value of Initialization in Multilingual\n  Knowledge Distillation","summary":"  Knowledge distillation (KD) has proven to be a successful strategy to improve\nthe performance of smaller models in many NLP tasks. However, most of the work\nin KD only explores monolingual scenarios. In this paper, we investigate the\nvalue of KD in multilingual settings. We find the significance of KD and model\ninitialization by analyzing how well the student model acquires multilingual\nknowledge from the teacher model. Our proposed method emphasizes copying the\nteacher model's weights directly to the student model to enhance\ninitialization. Our findings show that model initialization using copy-weight\nfrom the fine-tuned teacher contributes the most compared to the distillation\nprocess itself across various multilingual settings. Furthermore, we\ndemonstrate that efficient weight initialization preserves multilingual\ncapabilities even in low-resource scenarios.\n","authors":["Haryo Akbarianto Wibowo","Thamar Solorio","Alham Fikri Aji"],"pdf_url":"https://arxiv.org/pdf/2406.16524v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2405.16964v2","updated":"2024-11-08T05:19:48Z","published":"2024-05-27T08:57:04Z","title":"Exploring the LLM Journey from Cognition to Expression with Linear\n  Representations","summary":"  This paper presents an in-depth examination of the evolution and interplay of\ncognitive and expressive capabilities in large language models (LLMs), with a\nspecific focus on Baichuan-7B and Baichuan-33B, an advanced bilingual (Chinese\nand English) LLM series. We define and explore the model's cognitive and\nexpressive capabilities through linear representations across three critical\nphases: Pretraining, Supervised Fine-Tuning (SFT), and Reinforcement Learning\nfrom Human Feedback (RLHF). Cognitive capability is defined as the quantity and\nquality of information conveyed by the neuron output vectors within the\nnetwork, similar to the neural signal processing in human cognition. Expressive\ncapability is defined as the model's capability to produce word-level output.\nOur findings unveil a sequential development pattern, where cognitive abilities\nare largely established during Pretraining, whereas expressive abilities\npredominantly advance during SFT and RLHF. Statistical analyses confirm a\nsignificant correlation between the two capabilities, suggesting that cognitive\ncapacity may limit expressive potential. The paper also explores the\ntheoretical underpinnings of these divergent developmental trajectories and\ntheir connection to the LLMs' architectural design. Moreover, we evaluate\nvarious optimization-independent strategies, such as few-shot learning and\nrepeated sampling, which bridge the gap between cognitive and expressive\ncapabilities. This research reveals the potential connection between the hidden\nspace and the output space, contributing valuable insights into the\ninterpretability and controllability of their training processes.\n","authors":["Yuzi Yan","Jialian Li","Yipin Zhang","Dong Yan"],"pdf_url":"https://arxiv.org/pdf/2405.16964v2.pdf","comment":"Published in ICML 2024"},{"id":"http://arxiv.org/abs/2402.15721v2","updated":"2024-11-08T05:08:43Z","published":"2024-02-24T05:14:52Z","title":"Hal-Eval: A Universal and Fine-grained Hallucination Evaluation\n  Framework for Large Vision Language Models","summary":"  Large Vision Language Models exhibit remarkable capabilities but struggle\nwith hallucinations inconsistencies between images and their descriptions.\nPrevious hallucination evaluation studies on LVLMs have identified\nhallucinations in terms of objects, attributes, and relations but overlooked\ncomplex hallucinations that create an entire narrative around a fictional\nentity. In this paper, we introduce a refined taxonomy of hallucinations,\nfeaturing a new category: Event Hallucination. We then utilize advanced LLMs to\ngenerate and filter fine grained hallucinatory data consisting of various types\nof hallucinations, with a particular focus on event hallucinations, laying the\ngroundwork for integrating discriminative and generative evaluation methods\nwithin our universal evaluation framework. The proposed benchmark distinctively\nassesses LVLMs ability to tackle a broad spectrum of hallucinations, making it\na reliable and comprehensive tool for gauging LVLMs efficacy in handling\nhallucinations. We will release our code and data.\n","authors":["Chaoya Jiang","Hongrui Jia","Wei Ye","Mengfan Dong","Haiyang Xu","Ming Yan","Ji Zhang","Shikun Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.15721v2.pdf","comment":"Accepted by ACM MM 2024"},{"id":"http://arxiv.org/abs/2411.00369v3","updated":"2024-11-08T03:09:37Z","published":"2024-11-01T05:14:03Z","title":"GRS-QA -- Graph Reasoning-Structured Question Answering Dataset","summary":"  Large Language Models (LLMs) have excelled in multi-hop question-answering\n(M-QA) due to their advanced reasoning abilities. However, the impact of the\ninherent reasoning structures on LLM M-QA performance remains unclear, largely\ndue to the absence of QA datasets that provide fine-grained reasoning\nstructures. To address this gap, we introduce the Graph Reasoning-Structured\nQuestion Answering Dataset (GRS-QA), which includes both semantic contexts and\nreasoning structures for QA pairs. Unlike existing M-QA datasets, where\ndifferent reasoning structures are entangled together, GRS-QA explicitly\ncaptures intricate reasoning pathways by constructing reasoning graphs, where\nnodes represent textual contexts and edges denote logical flows. These\nreasoning graphs of different structures enable a fine-grained evaluation of\nLLM reasoning capabilities across various reasoning structures. Our empirical\nanalysis reveals that LLMs perform differently when handling questions with\nvarying reasoning structures. This finding facilitates the exploration of\ntextual structures as compared with semantics.\n","authors":["Anish Pahilajani","Devasha Trivedi","Jincen Shuai","Khin S. Yone","Samyak Rajesh Jain","Namyong Park","Ryan A. Rossi","Nesreen K. Ahmed","Franck Dernoncourt","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2411.00369v3.pdf","comment":"15 pages, 24 figures, 10 tables"},{"id":"http://arxiv.org/abs/2411.05289v1","updated":"2024-11-08T02:47:07Z","published":"2024-11-08T02:47:07Z","title":"SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding","summary":"  Large Language Models (LLMs) have become essential in advancing natural\nlanguage processing (NLP) tasks, but their sequential token generation limits\ninference speed. Multi-Draft Speculative Decoding (MDSD) offers a promising\nsolution by using a smaller draft model to generate multiple token sequences,\nwhich the target LLM verifies in parallel. However, current heuristic\napproaches, such as Recursive Rejection Sampling (RRS), suffer from low\nacceptance rates in subsequent drafts, limiting the advantages of using\nmultiple drafts. Meanwhile, Optimal Transport with Membership Cost (OTM) can\ntheoretically improve acceptance rates, but its computational cost is too high\nfor real-time use. We present SpecHub, a novel, efficient sampling-verification\nmethod for MDSD that improves acceptance rates with only linear computational\noverhead. By simplifying the OTM problem into a compact Linear Programming\nmodel, SpecHub significantly reduces computational complexity. It further\naccelerates sampling by leveraging a sparse joint distribution, focusing\ncomputation on high-probability token sequences. In extensive experiments,\nSpechub consistently generates 0.05-0.27 and 0.02-0.16 more tokens per step\nthan RRS and RRS without replacement. We attach our code at\n\\url{https://github.com/MasterGodzilla/Speculative_decoding_OT}.\n","authors":["Ryan Sun","Tianyi Zhou","Xun Chen","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2411.05289v1.pdf","comment":"EMNLP 2024 (Main)"},{"id":"http://arxiv.org/abs/2411.05281v1","updated":"2024-11-08T02:24:29Z","published":"2024-11-08T02:24:29Z","title":"Fox-1 Technical Report","summary":"  We present Fox-1, a series of small language models (SLMs) consisting of\nFox-1-1.6B and Fox-1-1.6B-Instruct-v0.1. These models are pre-trained on 3\ntrillion tokens of web-scraped document data and fine-tuned with 5 billion\ntokens of instruction-following and multi-turn conversation data. Aiming to\nimprove the pre-training efficiency, Fox-1-1.6B model introduces a novel\n3-stage data curriculum across all the training data with 2K-8K sequence\nlength. In architecture design, Fox-1 features a deeper layer structure, an\nexpanded vocabulary, and utilizes Grouped Query Attention (GQA), offering a\nperformant and efficient architecture compared to other SLMs. Fox-1 achieves\nbetter or on-par performance in various benchmarks compared to StableLM-2-1.6B,\nGemma-2B, Qwen1.5-1.8B, and OpenELM1.1B, with competitive inference speed and\nthroughput. The model weights have been released under the Apache 2.0 license,\nwhere we aim to promote the democratization of LLMs and make them fully\naccessible to the whole open-source community.\n","authors":["Zijian Hu","Jipeng Zhang","Rui Pan","Zhaozhuo Xu","Salman Avestimehr","Chaoyang He","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05281v1.pdf","comment":"Base model is available at\n  https://huggingface.co/tensoropera/Fox-1-1.6B and the instruction-tuned\n  version is available at\n  https://huggingface.co/tensoropera/Fox-1-1.6B-Instruct-v0.1"},{"id":"http://arxiv.org/abs/2411.05277v1","updated":"2024-11-08T02:22:30Z","published":"2024-11-08T02:22:30Z","title":"Revisiting the Robustness of Watermarking to Paraphrasing Attacks","summary":"  Amidst rising concerns about the internet being proliferated with content\ngenerated from language models (LMs), watermarking is seen as a principled way\nto certify whether text was generated from a model. Many recent watermarking\ntechniques slightly modify the output probabilities of LMs to embed a signal in\nthe generated output that can later be detected. Since early proposals for text\nwatermarking, questions about their robustness to paraphrasing have been\nprominently discussed. Lately, some techniques are deliberately designed and\nclaimed to be robust to paraphrasing. However, such watermarking schemes do not\nadequately account for the ease with which they can be reverse-engineered. We\nshow that with access to only a limited number of generations from a black-box\nwatermarked model, we can drastically increase the effectiveness of\nparaphrasing attacks to evade watermark detection, thereby rendering the\nwatermark ineffective.\n","authors":["Saksham Rastogi","Danish Pruthi"],"pdf_url":"https://arxiv.org/pdf/2411.05277v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2406.16235v2","updated":"2024-11-08T02:17:22Z","published":"2024-06-23T22:53:47Z","title":"Preference Tuning For Toxicity Mitigation Generalizes Across Languages","summary":"  Detoxifying multilingual Large Language Models (LLMs) has become crucial due\nto their increasing global use. In this work, we explore zero-shot\ncross-lingual generalization of preference tuning in detoxifying LLMs. Unlike\nprevious studies that show limited cross-lingual generalization for other\nsafety tasks, we demonstrate that Direct Preference Optimization (DPO) training\nwith only English data can significantly reduce toxicity in multilingual\nopen-ended generations. For example, the probability of mGPT-1.3B generating\ntoxic continuations drops from 46.8% to 3.9% across 17 different languages\nafter training. Our results also extend to other multilingual LLMs, such as\nBLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal\nintervention and activation analysis, we identified the dual multilinguality\nproperty of MLP layers in LLMs, which explains the cross-lingual generalization\nof DPO. Finally, we show that bilingual sentence retrieval can predict the\ncross-lingual transferability of DPO preference tuning.\n","authors":["Xiaochen Li","Zheng-Xin Yong","Stephen H. Bach"],"pdf_url":"https://arxiv.org/pdf/2406.16235v2.pdf","comment":"Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05270v1","updated":"2024-11-08T02:06:41Z","published":"2024-11-08T02:06:41Z","title":"Seeing Through the Fog: A Cost-Effectiveness Analysis of Hallucination\n  Detection Systems","summary":"  This paper presents a comparative analysis of hallucination detection systems\nfor AI, focusing on automatic summarization and question answering tasks for\nLarge Language Models (LLMs). We evaluate different hallucination detection\nsystems using the diagnostic odds ratio (DOR) and cost-effectiveness metrics.\nOur results indicate that although advanced models can perform better they come\nat a much higher cost. We also demonstrate how an ideal hallucination detection\nsystem needs to maintain performance across different model sizes. Our findings\nhighlight the importance of choosing a detection system aligned with specific\napplication needs and resource constraints. Future research will explore hybrid\nsystems and automated identification of underperforming components to enhance\nAI reliability and efficiency in detecting and mitigating hallucinations.\n","authors":["Alexander Thomas","Seth Rosen","Vishnu Vettrivel"],"pdf_url":"https://arxiv.org/pdf/2411.05270v1.pdf","comment":"18 pags, 13 figures, 2 tables"},{"id":"http://arxiv.org/abs/2405.18822v2","updated":"2024-11-08T01:49:58Z","published":"2024-05-29T07:03:31Z","title":"Toxicity Detection for Free","summary":"  Current LLMs are generally aligned to follow safety requirements and tend to\nrefuse toxic prompts. However, LLMs can fail to refuse toxic prompts or be\novercautious and refuse benign examples. In addition, state-of-the-art toxicity\ndetectors have low TPRs at low FPR, incurring high costs in real-world\napplications where toxic examples are rare. In this paper, we introduce\nModeration Using LLM Introspection (MULI), which detects toxic prompts using\nthe information extracted directly from LLMs themselves. We found we can\ndistinguish between benign and toxic prompts from the distribution of the first\nresponse token's logits. Using this idea, we build a robust detector of toxic\nprompts using a sparse logistic regression model on the first response token\nlogits. Our scheme outperforms SOTA detectors under multiple metrics.\n","authors":["Zhanhao Hu","Julien Piet","Geng Zhao","Jiantao Jiao","David Wagner"],"pdf_url":"https://arxiv.org/pdf/2405.18822v2.pdf","comment":"Accepted by Neurips 2024"},{"id":"http://arxiv.org/abs/2411.05261v1","updated":"2024-11-08T01:46:11Z","published":"2024-11-08T01:46:11Z","title":"Decoding Report Generators: A Cyclic Vision-Language Adapter for\n  Counterfactual Explanations","summary":"  Despite significant advancements in report generation methods, a critical\nlimitation remains: the lack of interpretability in the generated text. This\npaper introduces an innovative approach to enhance the explainability of text\ngenerated by report generation models. Our method employs cyclic text\nmanipulation and visual comparison to identify and elucidate the features in\nthe original content that influence the generated text. By manipulating the\ngenerated reports and producing corresponding images, we create a comparative\nframework that highlights key attributes and their impact on the text\ngeneration process. This approach not only identifies the image features\naligned to the generated text but also improves transparency but also provides\ndeeper insights into the decision-making mechanisms of the report generation\nmodels. Our findings demonstrate the potential of this method to significantly\nenhance the interpretability and transparency of AI-generated reports.\n","authors":["Yingying Fang","Zihao Jin","Shaojie Guo","Jinda Liu","Yijian Gao","Junzhi Ning","Zhiling Yue","Zhi Li","Simon LF Walsh","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2411.05261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05253v1","updated":"2024-11-08T00:46:24Z","published":"2024-11-08T00:46:24Z","title":"What talking you?: Translating Code-Mixed Messaging Texts to English","summary":"  Translation of code-mixed texts to formal English allow a wider audience to\nunderstand these code-mixed languages, and facilitate downstream analysis\napplications such as sentiment analysis. In this work, we look at translating\nSinglish, which is colloquial Singaporean English, to formal standard English.\nSinglish is formed through the code-mixing of multiple Asian languages and\ndialects. We analysed the presence of other Asian languages and variants which\ncan facilitate translation. Our dataset is short message texts, written as\ninformal communication between Singlish speakers. We use a multi-step prompting\nscheme on five Large Language Models (LLMs) for language detection and\ntranslation. Our analysis show that LLMs do not perform well in this task, and\nwe describe the challenges involved in translation of code-mixed languages. We\nalso release our dataset in this link https://github.com/luoqichan/singlish.\n","authors":["Lynnette Hui Xian Ng","Luo Qi Chan"],"pdf_url":"https://arxiv.org/pdf/2411.05253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16156v2","updated":"2024-11-08T00:40:05Z","published":"2024-10-21T16:21:45Z","title":"Limpeh ga li gong: Challenges in Singlish Annotations","summary":"  Singlish, or Colloquial Singapore English, is a language formed from oral and\nsocial communication within multicultural Singapore. In this work, we work on a\nfundamental Natural Language Processing (NLP) task: Parts-Of-Speech (POS)\ntagging of Singlish sentences. For our analysis, we build a parallel Singlish\ndataset containing direct English translations and POS tags, with translation\nand POS annotation done by native Singlish speakers. Our experiments show that\nautomatic transition- and transformer- based taggers perform with only $\\sim\n80\\%$ accuracy when evaluated against human-annotated POS labels, suggesting\nthat there is indeed room for improvement on computation analysis of the\nlanguage. We provide an exposition of challenges in Singlish annotation: its\ninconsistencies in form and semantics, the highly context-dependent particles\nof the language, its structural unique expressions, and the variation of the\nlanguage on different mediums. Our task definition, resultant labels and\nresults reflects the challenges in analysing colloquial languages formulated\nfrom a variety of dialects, and paves the way for future studies beyond POS\ntagging.\n","authors":["Luo Qi Chan","Lynnette Hui Xian Ng"],"pdf_url":"https://arxiv.org/pdf/2410.16156v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00980v2","updated":"2024-11-08T00:36:10Z","published":"2024-11-01T19:11:54Z","title":"Enhancing AAC Software for Dysarthric Speakers in e-Health Settings: An\n  Evaluation Using TORGO","summary":"  Individuals with cerebral palsy (CP) and amyotrophic lateral sclerosis (ALS)\nfrequently face challenges with articulation, leading to dysarthria and\nresulting in atypical speech patterns. In healthcare settings, communication\nbreakdowns reduce the quality of care. While building an augmentative and\nalternative communication (AAC) tool to enable fluid communication we found\nthat state-of-the-art (SOTA) automatic speech recognition (ASR) technology like\nWhisper and Wav2vec2.0 marginalizes atypical speakers largely due to the lack\nof training data. Our work looks to leverage SOTA ASR followed by domain\nspecific error-correction. English dysarthric ASR performance is often\nevaluated on the TORGO dataset. Prompt-overlap is a well-known issue with this\ndataset where phrases overlap between training and test speakers. Our work\nproposes an algorithm to break this prompt-overlap. After reducing\nprompt-overlap, results with SOTA ASR models produce extremely high word error\nrates for speakers with mild and severe dysarthria. Furthermore, to improve\nASR, our work looks at the impact of n-gram language models and large-language\nmodel (LLM) based multi-modal generative error-correction algorithms like\nWhispering-LLaMA for a second pass ASR. Our work highlights how much more needs\nto be done to improve ASR for atypical speakers to enable equitable healthcare\naccess both in-person and in e-health settings.\n","authors":["Macarious Hui","Jinda Zhang","Aanchan Mohan"],"pdf_url":"https://arxiv.org/pdf/2411.00980v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2411.05783v1","updated":"2024-11-08T18:50:37Z","published":"2024-11-08T18:50:37Z","title":"ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles","summary":"  Deaf and hard-of-hearing (DHH) students face significant barriers in\naccessing science, technology, engineering, and mathematics (STEM) education,\nnotably due to the scarcity of STEM resources in signed languages. To help\naddress this, we introduce ASL STEM Wiki: a parallel corpus of 254 Wikipedia\narticles on STEM topics in English, interpreted into over 300 hours of American\nSign Language (ASL). ASL STEM Wiki is the first continuous signing dataset\nfocused on STEM, facilitating the development of AI resources for STEM\neducation in ASL. We identify several use cases of ASL STEM Wiki with\nhuman-centered applications. For example, because this dataset highlights the\nfrequent use of fingerspelling for technical concepts, which inhibits DHH\nstudents' ability to learn, we develop models to identify fingerspelled words\n-- which can later be used to query for appropriate ASL signs to suggest to\ninterpreters.\n","authors":["Kayo Yin","Chinmay Singh","Fyodor O. Minakov","Vanessa Milan","Hal Daumé III","Cyril Zhang","Alex X. Lu","Danielle Bragg"],"pdf_url":"https://arxiv.org/pdf/2411.05783v1.pdf","comment":"Accepted to EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05780v1","updated":"2024-11-08T18:47:08Z","published":"2024-11-08T18:47:08Z","title":"GazeSearch: Radiology Findings Search Benchmark","summary":"  Medical eye-tracking data is an important information source for\nunderstanding how radiologists visually interpret medical images. This\ninformation not only improves the accuracy of deep learning models for X-ray\nanalysis but also their interpretability, enhancing transparency in\ndecision-making. However, the current eye-tracking data is dispersed,\nunprocessed, and ambiguous, making it difficult to derive meaningful insights.\nTherefore, there is a need to create a new dataset with more focus and\npurposeful eyetracking data, improving its utility for diagnostic applications.\nIn this work, we propose a refinement method inspired by the target-present\nvisual search challenge: there is a specific finding and fixations are guided\nto locate it. After refining the existing eye-tracking datasets, we transform\nthem into a curated visual search dataset, called GazeSearch, specifically for\nradiology findings, where each fixation sequence is purposefully aligned to the\ntask of locating a particular finding. Subsequently, we introduce a scan path\nprediction baseline, called ChestSearch, specifically tailored to GazeSearch.\nFinally, we employ the newly introduced GazeSearch as a benchmark to evaluate\nthe performance of current state-of-the-art methods, offering a comprehensive\nassessment for visual search in the medical imaging domain.\n","authors":["Trong Thang Pham","Tien-Phat Nguyen","Yuki Ikebe","Akash Awasthi","Zhigang Deng","Carol C. Wu","Hien Nguyen","Ngan Le"],"pdf_url":"https://arxiv.org/pdf/2411.05780v1.pdf","comment":"Aceepted WACV 2025"},{"id":"http://arxiv.org/abs/2411.05779v1","updated":"2024-11-08T18:46:40Z","published":"2024-11-08T18:46:40Z","title":"Curriculum Learning for Few-Shot Domain Adaptation in CT-based Airway\n  Tree Segmentation","summary":"  Despite advances with deep learning (DL), automated airway segmentation from\nchest CT scans continues to face challenges in segmentation quality and\ngeneralization across cohorts. To address these, we propose integrating\nCurriculum Learning (CL) into airway segmentation networks, distributing the\ntraining set into batches according to ad-hoc complexity scores derived from CT\nscans and corresponding ground-truth tree features. We specifically investigate\nfew-shot domain adaptation, targeting scenarios where manual annotation of a\nfull fine-tuning dataset is prohibitively expensive. Results are reported on\ntwo large open-cohorts (ATM22 and AIIB23) with high performance using CL for\nfull training (Source domain) and few-shot fine-tuning (Target domain), but\nwith also some insights on potential detrimental effects if using a classic\nBootstrapping scoring function or if not using proper scan sequencing.\n","authors":["Maxime Jacovella","Ali Keshavarzi","Elsa Angelini"],"pdf_url":"https://arxiv.org/pdf/2411.05779v1.pdf","comment":"Under review for 22nd IEEE International Symposium on Biomedical\n  Imaging (ISBI), Houston, TX, USA"},{"id":"http://arxiv.org/abs/2411.05771v1","updated":"2024-11-08T18:33:03Z","published":"2024-11-08T18:33:03Z","title":"Sketched Equivariant Imaging Regularization and Deep Internal Learning\n  for Inverse Problems","summary":"  Equivariant Imaging (EI) regularization has become the de-facto technique for\nunsupervised training of deep imaging networks, without any need of\nground-truth data. Observing that the EI-based unsupervised training paradigm\ncurrently has significant computational redundancy leading to inefficiency in\nhigh-dimensional applications, we propose a sketched EI regularization which\nleverages the randomized sketching techniques for acceleration. We then extend\nour sketched EI regularization to develop an accelerated deep internal learning\nframework -- Sketched Equivariant Deep Image Prior (Sk.EI-DIP), which can be\nefficiently applied for single-image and task-adapted reconstruction. Our\nnumerical study on X-ray CT image reconstruction tasks demonstrate that our\napproach can achieve order-of-magnitude computational acceleration over\nstandard EI-based counterpart in single-input setting, and network adaptation\nat test time.\n","authors":["Guixian Xu","Jinglai Li","Junqi Tang"],"pdf_url":"https://arxiv.org/pdf/2411.05771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05007v2","updated":"2024-11-08T18:32:59Z","published":"2024-11-07T18:59:58Z","title":"SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion\n  Models","summary":"  Diffusion models have been proven highly effective at generating high-quality\nimages. However, as these models grow larger, they require significantly more\nmemory and suffer from higher latency, posing substantial challenges for\ndeployment. In this work, we aim to accelerate diffusion models by quantizing\ntheir weights and activations to 4 bits. At such an aggressive level, both\nweights and activations are highly sensitive, where conventional post-training\nquantization methods for large language models like smoothing become\ninsufficient. To overcome this limitation, we propose SVDQuant, a new 4-bit\nquantization paradigm. Different from smoothing which redistributes outliers\nbetween weights and activations, our approach absorbs these outliers using a\nlow-rank branch. We first consolidate the outliers by shifting them from\nactivations to weights, then employ a high-precision low-rank branch to take in\nthe weight outliers with Singular Value Decomposition (SVD). This process eases\nthe quantization on both sides. However, na\\\"{\\i}vely running the low-rank\nbranch independently incurs significant overhead due to extra data movement of\nactivations, negating the quantization speedup. To address this, we co-design\nan inference engine Nunchaku that fuses the kernels of the low-rank branch into\nthose of the low-bit branch to cut off redundant memory access. It can also\nseamlessly support off-the-shelf low-rank adapters (LoRAs) without the need for\nre-quantization. Extensive experiments on SDXL, PixArt-$\\Sigma$, and FLUX.1\nvalidate the effectiveness of SVDQuant in preserving image quality. We reduce\nthe memory usage for the 12B FLUX.1 models by 3.5$\\times$, achieving\n3.0$\\times$ speedup over the 4-bit weight-only quantized baseline on the 16GB\nlaptop 4090 GPU, paving the way for more interactive applications on PCs. Our\nquantization library and inference engine are open-sourced.\n","authors":["Muyang Li","Yujun Lin","Zhekai Zhang","Tianle Cai","Xiuyu Li","Junxian Guo","Enze Xie","Chenlin Meng","Jun-Yan Zhu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2411.05007v2.pdf","comment":"Quantization Library: https://github.com/mit-han-lab/deepcompressor\n  Inference Engine: https://github.com/mit-han-lab/nunchaku Website:\n  https://hanlab.mit.edu/projects/svdquant Demo: https://svdquant.mit.edu Blog:\n  https://hanlab.mit.edu/blog/svdquant"},{"id":"http://arxiv.org/abs/2411.05755v1","updated":"2024-11-08T18:16:58Z","published":"2024-11-08T18:16:58Z","title":"End-to-End Navigation with Vision Language Models: Transforming Spatial\n  Reasoning into Question-Answering","summary":"  We present VLMnav, an embodied framework to transform a Vision-Language Model\n(VLM) into an end-to-end navigation policy. In contrast to prior work, we do\nnot rely on a separation between perception, planning, and control; instead, we\nuse a VLM to directly select actions in one step. Surprisingly, we find that a\nVLM can be used as an end-to-end policy zero-shot, i.e., without any\nfine-tuning or exposure to navigation data. This makes our approach open-ended\nand generalizable to any downstream navigation task. We run an extensive study\nto evaluate the performance of our approach in comparison to baseline prompting\nmethods. In addition, we perform a design analysis to understand the most\nimpactful design decisions. Visual examples and code for our project can be\nfound at https://jirl-upenn.github.io/VLMnav/\n","authors":["Dylan Goetting","Himanshu Gaurav Singh","Antonio Loquercio"],"pdf_url":"https://arxiv.org/pdf/2411.05755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05752v1","updated":"2024-11-08T18:10:46Z","published":"2024-11-08T18:10:46Z","title":"FisherMask: Enhancing Neural Network Labeling Efficiency in Image\n  Classification Using Fisher Information","summary":"  Deep learning (DL) models are popular across various domains due to their\nremarkable performance and efficiency. However, their effectiveness relies\nheavily on large amounts of labeled data, which are often time-consuming and\nlabor-intensive to generate manually. To overcome this challenge, it is\nessential to develop strategies that reduce reliance on extensive labeled data\nwhile preserving model performance. In this paper, we propose FisherMask, a\nFisher information-based active learning (AL) approach that identifies key\nnetwork parameters by masking them based on their Fisher information values.\nFisherMask enhances batch AL by using Fisher information to select the most\ncritical parameters, allowing the identification of the most impactful samples\nduring AL training. Moreover, Fisher information possesses favorable\nstatistical properties, offering valuable insights into model behavior and\nproviding a better understanding of the performance characteristics within the\nAL pipeline. Our extensive experiments demonstrate that FisherMask\nsignificantly outperforms state-of-the-art methods on diverse datasets,\nincluding CIFAR-10 and FashionMNIST, especially under imbalanced settings.\nThese improvements lead to substantial gains in labeling efficiency. Hence\nserving as an effective tool to measure the sensitivity of model parameters to\ndata samples. Our code is available on\n\\url{https://github.com/sgchr273/FisherMask}.\n","authors":["Shreen Gul","Mohamed Elmahallawy","Sanjay Madria","Ardhendu Tripathy"],"pdf_url":"https://arxiv.org/pdf/2411.05752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05747v1","updated":"2024-11-08T18:08:33Z","published":"2024-11-08T18:08:33Z","title":"WavShadow: Wavelet Based Shadow Segmentation and Removal","summary":"  Shadow removal and segmentation remain challenging tasks in computer vision,\nparticularly in complex real-world scenarios. This study presents a novel\napproach that enhances the ShadowFormer model by incorporating Masked\nAutoencoder (MAE) priors and Fast Fourier Convolution (FFC) blocks, leading to\nsignificantly faster convergence and improved performance. We introduce key\ninnovations: (1) integration of MAE priors trained on Places2 dataset for\nbetter context understanding, (2) adoption of Haar wavelet features for\nenhanced edge detection and multi-scale analysis, and (3) implementation of a\nmodified SAM Adapter for robust shadow segmentation. Extensive experiments on\nthe challenging DESOBA dataset demonstrate that our approach achieves\nstate-of-the-art results, with notable improvements in both convergence speed\nand shadow removal quality.\n","authors":["Shreyans Jain","Aadya Arora","Viraj Vekaria","Karan Gandhi"],"pdf_url":"https://arxiv.org/pdf/2411.05747v1.pdf","comment":"ICVGIP’24, December 2024, Bangaluru, India"},{"id":"http://arxiv.org/abs/2411.05738v1","updated":"2024-11-08T17:54:18Z","published":"2024-11-08T17:54:18Z","title":"StdGEN: Semantic-Decomposed 3D Character Generation from Single Images","summary":"  We present StdGEN, an innovative pipeline for generating semantically\ndecomposed high-quality 3D characters from single images, enabling broad\napplications in virtual reality, gaming, and filmmaking, etc. Unlike previous\nmethods which struggle with limited decomposability, unsatisfactory quality,\nand long optimization times, StdGEN features decomposability, effectiveness and\nefficiency; i.e., it generates intricately detailed 3D characters with\nseparated semantic components such as the body, clothes, and hair, in three\nminutes. At the core of StdGEN is our proposed Semantic-aware Large\nReconstruction Model (S-LRM), a transformer-based generalizable model that\njointly reconstructs geometry, color and semantics from multi-view images in a\nfeed-forward manner. A differentiable multi-layer semantic surface extraction\nscheme is introduced to acquire meshes from hybrid implicit fields\nreconstructed by our S-LRM. Additionally, a specialized efficient multi-view\ndiffusion model and an iterative multi-layer surface refinement module are\nintegrated into the pipeline to facilitate high-quality, decomposable 3D\ncharacter generation. Extensive experiments demonstrate our state-of-the-art\nperformance in 3D anime character generation, surpassing existing baselines by\na significant margin in geometry, texture and decomposability. StdGEN offers\nready-to-use semantic-decomposed 3D characters and enables flexible\ncustomization for a wide range of applications. Project page:\nhttps://stdgen.github.io\n","authors":["Yuze He","Yanning Zhou","Wang Zhao","Zhongkai Wu","Kaiwen Xiao","Wei Yang","Yong-Jin Liu","Xiao Han"],"pdf_url":"https://arxiv.org/pdf/2411.05738v1.pdf","comment":"13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.05734v1","updated":"2024-11-08T17:48:20Z","published":"2024-11-08T17:48:20Z","title":"Poze: Sports Technique Feedback under Data Constraints","summary":"  Access to expert coaching is essential for developing technique in sports,\nyet economic barriers often place it out of reach for many enthusiasts. To\nbridge this gap, we introduce Poze, an innovative video processing framework\nthat provides feedback on human motion, emulating the insights of a\nprofessional coach. Poze combines pose estimation with sequence comparison and\nis optimized to function effectively with minimal data. Poze surpasses\nstate-of-the-art vision-language models in video question-answering frameworks,\nachieving 70% and 196% increase in accuracy over GPT4V and LLaVAv1.6 7b,\nrespectively.\n","authors":["Agamdeep Singh","Sujit PB","Mayank Vatsa"],"pdf_url":"https://arxiv.org/pdf/2411.05734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05731v1","updated":"2024-11-08T17:42:02Z","published":"2024-11-08T17:42:02Z","title":"PEP-GS: Perceptually-Enhanced Precise Structured 3D Gaussians for\n  View-Adaptive Rendering","summary":"  Recent advances in structured 3D Gaussians for view-adaptive rendering,\nparticularly through methods like Scaffold-GS, have demonstrated promising\nresults in neural scene representation. However, existing approaches still face\nchallenges in perceptual consistency and precise view-dependent effects. We\npresent PEP-GS, a novel framework that enhances structured 3D Gaussians through\nthree key innovations: (1) a Local-Enhanced Multi-head Self-Attention (LEMSA)\nmechanism that replaces spherical harmonics for more accurate view-dependent\ncolor decoding, and (2) Kolmogorov-Arnold Networks (KAN) that optimize Gaussian\nopacity and covariance functions for enhanced interpretability and splatting\nprecision. (3) a Neural Laplacian Pyramid Decomposition (NLPD) that improves\nperceptual similarity across views. Our comprehensive evaluation across\nmultiple datasets indicates that, compared to the current state-of-the-art\nmethods, these improvements are particularly evident in challenging scenarios\nsuch as view-dependent effects, specular reflections, fine-scale details and\nfalse geometry generation.\n","authors":["Junxi Jin","Xiulai Li","Haiping Huang","Lianjun Liu","Yujie Sun"],"pdf_url":"https://arxiv.org/pdf/2411.05731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01914v2","updated":"2024-11-08T17:33:31Z","published":"2024-06-04T02:51:26Z","title":"HPE-CogVLM: Advancing Vision Language Models with a Head Pose Grounding\n  Task","summary":"  Head pose estimation (HPE) requires a sophisticated understanding of 3D\nspatial relationships to generate precise yaw, pitch, and roll angles. Previous\nHPE models, primarily CNN-based, rely on cropped close-up human head images as\ninputs and often lack robustness in real-world scenario. Vision Language Models\n(VLMs) can analyze entire images while focusing on specific objects through\ntheir attention mechanisms. In this paper, we propose a novel framework to\nimprove the HPE accuracy by leveraging the object detection grounding\ncapability of a VLM, referred to as CogVLM. We empirically find that directly\nLoRA fine-tuning of this VLM for the HPE task fails to achieve desirable HPE\naccuracy, while some model merging methods can improve accuracy but frequently\nproduce blended invalid response formats, struggling to handle both object\ndetection and HPE tasks simultaneously. To integrate HPE capability into CogVLM\neffectively, we develop a novel LoRA layer-based model merging method. This\nmerging approach applies a high cosine similarity threshold and a\nwinner-takes-all layer selection strategy, aligning attention to the HPE task\nwhile preserving original object detection knowledge. It successfully resolves\nissues with blended invalid response formats and improves accuracy. Results\nshow that our HPE-CogVLM achieves a 31.5\\% reduction in Mean Absolute Error\nover the current state-of-the-art CNN model, 6DRepNet, in cross-dataset\nevaluation. Furthermore, HPE-CogVLM outperforms both directly LoRA fine-tuned\nand task arithmetic-based merged VLMs across all HPE metrics.\n","authors":["Yu Tian","Tianqi Shao","Tsukasa Demizu","Xuyang Wu","Hsin-Tai Wu"],"pdf_url":"https://arxiv.org/pdf/2406.01914v2.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2409.03945v2","updated":"2024-11-08T17:29:40Z","published":"2024-09-05T23:54:32Z","title":"TropNNC: Structured Neural Network Compression Using Tropical Geometry","summary":"  We present TropNNC, a framework for compressing neural networks with linear\nand convolutional layers and ReLU activations. TropNNC is a structured\ncompression framework based on a geometrical approach to machine/deep learning,\nusing tropical geometry and extending the work of Misiakos et al. (2022). We\nuse the Hausdorff distance of zonotopes in its standard continuous form to\nachieve a tighter approximation bound for tropical polynomials compared to\nprevious work. This enhancement leads to the development of an effective\ncompression algorithm that achieves superior functional approximations of\nneural networks. Our method is significantly easier to implement compared to\nother frameworks, and does not depend on the availability of training data\nsamples. We validate our framework through extensive empirical evaluations on\nthe MNIST, CIFAR, and ImageNet datasets. Our results demonstrate that TropNNC\nachieves performance on par with state-of-the-art methods like ThiNet (even\nsurpassing it in compressing linear layers) and CUP. To the best of our\nknowledge, it is the first method that achieves this using tropical geometry.\n","authors":["Konstantinos Fotopoulos","Petros Maragos","Panagiotis Misiakos"],"pdf_url":"https://arxiv.org/pdf/2409.03945v2.pdf","comment":"v2: minor improvements to the algorithm, updated one of the\n  experiments, same claims as in v1, changed the abstract, added some\n  references"},{"id":"http://arxiv.org/abs/2411.00922v2","updated":"2024-11-08T17:23:05Z","published":"2024-11-01T14:32:58Z","title":"Lung tumor segmentation in MRI mice scans using 3D nnU-Net with minimum\n  annotations","summary":"  In drug discovery, accurate lung tumor segmentation is an important step for\nassessing tumor size and its progression using \\textit{in-vivo} imaging such as\nMRI. While deep learning models have been developed to automate this process,\nthe focus has predominantly been on human subjects, neglecting the pivotal role\nof animal models in pre-clinical drug development. In this work, we focus on\noptimizing lung tumor segmentation in mice. First, we demonstrate that the\nnnU-Net model outperforms the U-Net, U-Net3+, and DeepMeta models. Most\nimportantly, we achieve better results with nnU-Net 3D models than 2D models,\nindicating the importance of spatial context for segmentation tasks in MRI mice\nscans. This study demonstrates the importance of 3D input over 2D input images\nfor lung tumor segmentation in MRI scans. Finally, we outperform the prior\nstate-of-the-art approach that involves the combined segmentation of lungs and\ntumors within the lungs. Our work achieves comparable results using only lung\ntumor annotations requiring fewer annotations, saving time and annotation\nefforts. This work\n(https://anonymous.4open.science/r/lung-tumour-mice-mri-64BB) is an important\nstep in automating pre-clinical animal studies to quantify the efficacy of\nexperimental drugs, particularly in assessing tumor changes.\n","authors":["Piotr Kaniewski","Fariba Yousefi","Yeman Brhane Hagos","Talha Qaiser","Nikolay Burlutskiy"],"pdf_url":"https://arxiv.org/pdf/2411.00922v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05714v1","updated":"2024-11-08T17:16:02Z","published":"2024-11-08T17:16:02Z","title":"STARS: Sensor-agnostic Transformer Architecture for Remote Sensing","summary":"  We present a sensor-agnostic spectral transformer as the basis for spectral\nfoundation models. To that end, we introduce a Universal Spectral\nRepresentation (USR) that leverages sensor meta-data, such as sensing kernel\nspecifications and sensing wavelengths, to encode spectra obtained from any\nspectral instrument into a common representation, such that a single model can\ningest data from any sensor. Furthermore, we develop a methodology for\npre-training such models in a self-supervised manner using a novel random\nsensor-augmentation and reconstruction pipeline to learn spectral features\nindependent of the sensing paradigm. We demonstrate that our architecture can\nlearn sensor independent spectral features that generalize effectively to\nsensors not seen during training. This work sets the stage for training\nfoundation models that can both leverage and be effective for the growing\ndiversity of spectral data.\n","authors":["Ethan King","Jaime Rodriguez","Diego Llanes","Timothy Doster","Tegan Emerson","James Koch"],"pdf_url":"https://arxiv.org/pdf/2411.05714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05712v1","updated":"2024-11-08T17:13:53Z","published":"2024-11-08T17:13:53Z","title":"Scaling Laws for Task-Optimized Models of the Primate Visual Ventral\n  Stream","summary":"  When trained on large-scale object classification datasets, certain\nartificial neural network models begin to approximate core object recognition\n(COR) behaviors and neural response patterns in the primate visual ventral\nstream (VVS). While recent machine learning advances suggest that scaling model\nsize, dataset size, and compute resources improve task performance, the impact\nof scaling on brain alignment remains unclear. In this study, we explore\nscaling laws for modeling the primate VVS by systematically evaluating over 600\nmodels trained under controlled conditions on benchmarks spanning V1, V2, V4,\nIT and COR behaviors. We observe that while behavioral alignment continues to\nscale with larger models, neural alignment saturates. This observation remains\ntrue across model architectures and training datasets, even though models with\nstronger inductive bias and datasets with higher-quality images are more\ncompute-efficient. Increased scaling is especially beneficial for higher-level\nvisual areas, where small models trained on few samples exhibit only poor\nalignment. Finally, we develop a scaling recipe, indicating that a greater\nproportion of compute should be allocated to data samples over model size. Our\nresults suggest that while scaling alone might suffice for alignment with human\ncore object recognition behavior, it will not yield improved models of the\nbrain's visual ventral stream with current architectures and datasets,\nhighlighting the need for novel strategies in building brain-like models.\n","authors":["Abdulkadir Gokce","Martin Schrimpf"],"pdf_url":"https://arxiv.org/pdf/2411.05712v1.pdf","comment":"9 pages for the main paper, 20 pages in total. 6 main figures and 10\n  supplementary figures. Code, model weights, and benchmark results can be\n  accessed at https://github.com/epflneuroailab/scaling-primate-vvs"},{"id":"http://arxiv.org/abs/2411.04707v2","updated":"2024-11-08T17:10:23Z","published":"2024-11-07T13:45:23Z","title":"From CNN to ConvRNN: Adapting Visualization Techniques for Time-Series\n  Anomaly Detection","summary":"  Nowadays, neural networks are commonly used to solve various problems.\nUnfortunately, despite their effectiveness, they are often perceived as black\nboxes capable of providing answers without explaining their decisions, which\nraises numerous ethical and legal concerns. Fortunately, the field of\nexplainability helps users understand these results. This aspect of machine\nlearning allows users to grasp the decision-making process of a model and\nverify the relevance of its outcomes. In this article, we focus on the learning\nprocess carried out by a ``time distributed`` convRNN, which performs anomaly\ndetection from video data.\n","authors":["Fabien Poirier"],"pdf_url":"https://arxiv.org/pdf/2411.04707v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05706v1","updated":"2024-11-08T17:07:01Z","published":"2024-11-08T17:07:01Z","title":"Image2Text2Image: A Novel Framework for Label-Free Evaluation of\n  Image-to-Text Generation with Text-to-Image Diffusion Models","summary":"  Evaluating the quality of automatically generated image descriptions is a\ncomplex task that requires metrics capturing various dimensions, such as\ngrammaticality, coverage, accuracy, and truthfulness. Although human evaluation\nprovides valuable insights, its cost and time-consuming nature pose\nlimitations. Existing automated metrics like BLEU, ROUGE, METEOR, and CIDEr\nattempt to fill this gap, but they often exhibit weak correlations with human\njudgment. To address this challenge, we propose a novel evaluation framework\ncalled Image2Text2Image, which leverages diffusion models, such as Stable\nDiffusion or DALL-E, for text-to-image generation. In the Image2Text2Image\nframework, an input image is first processed by a selected image captioning\nmodel, chosen for evaluation, to generate a textual description. Using this\ngenerated description, a diffusion model then creates a new image. By comparing\nfeatures extracted from the original and generated images, we measure their\nsimilarity using a designated similarity metric. A high similarity score\nsuggests that the model has produced a faithful textual description, while a\nlow score highlights discrepancies, revealing potential weaknesses in the\nmodel's performance. Notably, our framework does not rely on human-annotated\nreference captions, making it a valuable tool for assessing image captioning\nmodels. Extensive experiments and human evaluations validate the efficacy of\nour proposed Image2Text2Image evaluation framework. The code and dataset will\nbe published to support further research in the community.\n","authors":["Jia-Hong Huang","Hongyi Zhu","Yixian Shen","Stevan Rudinac","Evangelos Kanoulas"],"pdf_url":"https://arxiv.org/pdf/2411.05706v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2408.01723"},{"id":"http://arxiv.org/abs/2411.05705v1","updated":"2024-11-08T17:04:05Z","published":"2024-11-08T17:04:05Z","title":"Image inpainting enhancement by replacing the original mask with a\n  self-attended region from the input image","summary":"  Image inpainting, the process of restoring missing or corrupted regions of an\nimage by reconstructing pixel information, has recently seen considerable\nadvancements through deep learning-based approaches. In this paper, we\nintroduce a novel deep learning-based pre-processing methodology for image\ninpainting utilizing the Vision Transformer (ViT). Our approach involves\nreplacing masked pixel values with those generated by the ViT, leveraging\ndiverse visual patches within the attention matrix to capture discriminative\nspatial features. To the best of our knowledge, this is the first instance of\nsuch a pre-processing model being proposed for image inpainting tasks.\nFurthermore, we show that our methodology can be effectively applied using the\npre-trained ViT model with pre-defined patch size. To evaluate the\ngeneralization capability of the proposed methodology, we provide experimental\nresults comparing our approach with four standard models across four public\ndatasets, demonstrating the efficacy of our pre-processing technique in\nenhancing inpainting performance.\n","authors":["Kourosh Kiani","Razieh Rastgoo","Alireza Chaji","Sergio Escalera"],"pdf_url":"https://arxiv.org/pdf/2411.05705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05698v1","updated":"2024-11-08T16:52:52Z","published":"2024-11-08T16:52:52Z","title":"Visual-TCAV: Concept-based Attribution and Saliency Maps for Post-hoc\n  Explainability in Image Classification","summary":"  Convolutional Neural Networks (CNNs) have seen significant performance\nimprovements in recent years. However, due to their size and complexity, they\nfunction as black-boxes, leading to transparency concerns. State-of-the-art\nsaliency methods generate local explanations that highlight the area in the\ninput image where a class is identified but cannot explain how a concept of\ninterest contributes to the prediction, which is essential for bias mitigation.\nOn the other hand, concept-based methods, such as TCAV (Testing with Concept\nActivation Vectors), provide insights into how sensitive is the network to a\nconcept, but cannot compute its attribution in a specific prediction nor show\nits location within the input image. This paper introduces a novel post-hoc\nexplainability framework, Visual-TCAV, which aims to bridge the gap between\nthese methods by providing both local and global explanations for CNN-based\nimage classification. Visual-TCAV uses Concept Activation Vectors (CAVs) to\ngenerate saliency maps that show where concepts are recognized by the network.\nMoreover, it can estimate the attribution of these concepts to the output of\nany class using a generalization of Integrated Gradients. This framework is\nevaluated on popular CNN architectures, with its validity further confirmed via\nexperiments where ground truth for explanations is known, and a comparison with\nTCAV. Our code will be made available soon.\n","authors":["Antonio De Santis","Riccardo Campi","Matteo Bianchi","Marco Brambilla"],"pdf_url":"https://arxiv.org/pdf/2411.05698v1.pdf","comment":"Preprint currently under review"},{"id":"http://arxiv.org/abs/2411.05692v1","updated":"2024-11-08T16:45:52Z","published":"2024-11-08T16:45:52Z","title":"Autoregressive Adaptive Hypergraph Transformer for Skeleton-based\n  Activity Recognition","summary":"  Extracting multiscale contextual information and higher-order correlations\namong skeleton sequences using Graph Convolutional Networks (GCNs) alone is\ninadequate for effective action classification. Hypergraph convolution\naddresses the above issues but cannot harness the long-range dependencies.\nTransformer proves to be effective in capturing these dependencies and making\ncomplex contextual features accessible. We propose an Autoregressive Adaptive\nHyperGraph Transformer (AutoregAd-HGformer) model for in-phase (autoregressive\nand discrete) and out-phase (adaptive) hypergraph generation. The vector\nquantized in-phase hypergraph equipped with powerful autoregressive learned\npriors produces a more robust and informative representation suitable for\nhyperedge formation. The out-phase hypergraph generator provides a\nmodel-agnostic hyperedge learning technique to align the attributes with input\nskeleton embedding. The hybrid (supervised and unsupervised) learning in\nAutoregAd-HGformer explores the action-dependent feature along spatial,\ntemporal, and channel dimensions. The extensive experimental results and\nablation study indicate the superiority of our model over state-of-the-art\nhypergraph architectures on NTU RGB+D, NTU RGB+D 120, and NW-UCLA datasets.\n","authors":["Abhisek Ray","Ayush Raj","Maheshkumar H. Kolekar"],"pdf_url":"https://arxiv.org/pdf/2411.05692v1.pdf","comment":"Accepted to WACV 2025"},{"id":"http://arxiv.org/abs/2411.05679v1","updated":"2024-11-08T16:29:07Z","published":"2024-11-08T16:29:07Z","title":"Tell What You Hear From What You See -- Video to Audio Generation\n  Through Text","summary":"  The content of visual and audio scenes is multi-faceted such that a video can\nbe paired with various audio and vice-versa. Thereby, in video-to-audio\ngeneration task, it is imperative to introduce steering approaches for\ncontrolling the generated audio. While Video-to-Audio generation is a\nwell-established generative task, existing methods lack such controllability.\nIn this work, we propose VATT, a multi-modal generative framework that takes a\nvideo and an optional text prompt as input, and generates audio and optional\ntextual description of the audio. Such a framework has two advantages: i)\nVideo-to-Audio generation process can be refined and controlled via text which\ncomplements the context of visual information, and ii) The model can suggest\nwhat audio to generate for the video by generating audio captions. VATT\nconsists of two key modules: VATT Converter, a LLM that is fine-tuned for\ninstructions and includes a projection layer that maps video features to the\nLLM vector space; and VATT Audio, a transformer that generates audio tokens\nfrom visual frames and from optional text prompt using iterative parallel\ndecoding. The audio tokens are converted to a waveform by pretrained neural\ncodec. Experiments show that when VATT is compared to existing video-to-audio\ngeneration methods in objective metrics, it achieves competitive performance\nwhen the audio caption is not provided. When the audio caption is provided as a\nprompt, VATT achieves even more refined performance (lowest KLD score of 1.41).\nFurthermore, subjective studies show that VATT Audio has been chosen as\npreferred generated audio than audio generated by existing methods. VATT\nenables controllable video-to-audio generation through text as well as\nsuggesting text prompts for videos through audio captions, unlocking novel\napplications such as text-guided video-to-audio generation and video-to-audio\ncaptioning.\n","authors":["Xiulong Liu","Kun Su","Eli Shlizerman"],"pdf_url":"https://arxiv.org/pdf/2411.05679v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05663v1","updated":"2024-11-08T16:04:16Z","published":"2024-11-08T16:04:16Z","title":"Online-LoRA: Task-free Online Continual Learning via Low Rank Adaptation","summary":"  Catastrophic forgetting is a significant challenge in online continual\nlearning (OCL), especially for non-stationary data streams that do not have\nwell-defined task boundaries. This challenge is exacerbated by the memory\nconstraints and privacy concerns inherent in rehearsal buffers. To tackle\ncatastrophic forgetting, in this paper, we introduce Online-LoRA, a novel\nframework for task-free OCL. Online-LoRA allows to finetune pre-trained Vision\nTransformer (ViT) models in real-time to address the limitations of rehearsal\nbuffers and leverage pre-trained models' performance benefits. As the main\ncontribution, our approach features a novel online weight regularization\nstrategy to identify and consolidate important model parameters. Moreover,\nOnline-LoRA leverages the training dynamics of loss values to enable the\nautomatic recognition of the data distribution shifts. Extensive experiments\nacross many task-free OCL scenarios and benchmark datasets (including\nCIFAR-100, ImageNet-R, ImageNet-S, CUB-200 and CORe50) demonstrate that\nOnline-LoRA can be robustly adapted to various ViT architectures, while\nachieving better performance compared to SOTA methods. Our code will be\npublicly available at:\nhttps://github.com/Christina200/Online-LoRA-official.git.\n","authors":["Xiwen Wei","Guihong Li","Radu Marculescu"],"pdf_url":"https://arxiv.org/pdf/2411.05663v1.pdf","comment":"WACV 2025"},{"id":"http://arxiv.org/abs/2411.05636v1","updated":"2024-11-08T15:30:10Z","published":"2024-11-08T15:30:10Z","title":"Video RWKV:Video Action Recognition Based RWKV","summary":"  To address the challenges of high computational costs and long-distance\ndependencies in exist ing video understanding methods, such as CNNs and\nTransformers, this work introduces RWKV to the video domain in a novel way. We\npropose a LSTM CrossRWKV (LCR) framework, designed for spatiotemporal\nrepresentation learning to tackle the video understanding task. Specifically,\nthe proposed linear complexity LCR incorporates a novel Cross RWKV gate to\nfacilitate interaction be tween current frame edge information and past\nfeatures, enhancing the focus on the subject through edge features and globally\naggregating inter-frame features over time. LCR stores long-term mem ory for\nvideo processing through an enhanced LSTM recurrent execution mechanism. By\nleveraging the Cross RWKV gate and recurrent execution, LCR effectively\ncaptures both spatial and temporal features. Additionally, the edge information\nserves as a forgetting gate for LSTM, guiding long-term memory management.Tube\nmasking strategy reduces redundant information in food and reduces\noverfitting.These advantages enable LSTM CrossRWKV to set a new benchmark in\nvideo under standing, offering a scalable and efficient solution for\ncomprehensive video analysis. All code and models are publicly available.\n","authors":["Zhuowen Yin","Chengru Li","Xingbo Dong"],"pdf_url":"https://arxiv.org/pdf/2411.05636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05633v1","updated":"2024-11-08T15:22:49Z","published":"2024-11-08T15:22:49Z","title":"SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection","summary":"  Developing robust drone detection systems is often constrained by the limited\navailability of large-scale annotated training data and the high costs\nassociated with real-world data collection. However, leveraging synthetic data\ngenerated via game engine-based simulations provides a promising and\ncost-effective solution to overcome this issue. Therefore, we present\nSynDroneVision, a synthetic dataset specifically designed for RGB-based drone\ndetection in surveillance applications. Featuring diverse backgrounds, lighting\nconditions, and drone models, SynDroneVision offers a comprehensive training\nfoundation for deep learning algorithms. To evaluate the dataset's\neffectiveness, we perform a comparative analysis across a selection of recent\nYOLO detection models. Our findings demonstrate that SynDroneVision is a\nvaluable resource for real-world data enrichment, achieving notable\nenhancements in model performance and robustness, while significantly reducing\nthe time and costs of real-world data acquisition. SynDroneVision will be\npublicly released upon paper acceptance.\n","authors":["Tamara R. Lenhard","Andreas Weinmann","Kai Franke","Tobias Koch"],"pdf_url":"https://arxiv.org/pdf/2411.05633v1.pdf","comment":"Accepted at the 2025 IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV)"},{"id":"http://arxiv.org/abs/2308.00265v2","updated":"2024-11-08T15:10:11Z","published":"2023-08-01T03:56:50Z","title":"Benchmarking Ultra-High-Definition Image Reflection Removal","summary":"  Deep learning based methods have achieved significant success in the task of\nsingle image reflection removal (SIRR). However, the majority of these methods\nare focused on High-Definition/Standard-Definition (HD/SD) images, while\nignoring higher resolution images such as Ultra-High-Definition (UHD) images.\nWith the increasing prevalence of UHD images captured by modern devices, in\nthis paper, we aim to address the problem of UHD SIRR. Specifically, we first\nsynthesize two large-scale UHD datasets, UHDRR4K and UHDRR8K. The UHDRR4K\ndataset consists of $2,999$ and $168$ quadruplets of images for training and\ntesting respectively, and the UHDRR8K dataset contains $1,014$ and $105$\nquadruplets. To the best of our knowledge, these two datasets are the first\nlargest-scale UHD datasets for SIRR. Then, we conduct a comprehensive\nevaluation of six state-of-the-art SIRR methods using the proposed datasets.\nBased on the results, we provide detailed discussions regarding the strengths\nand limitations of these methods when applied to UHD images. Finally, we\npresent a transformer-based architecture named RRFormer for reflection removal.\nRRFormer comprises three modules, namely the Prepossessing Embedding Module,\nSelf-attention Feature Extraction Module, and Multi-scale Spatial Feature\nExtraction Module. These modules extract hypercolumn features, global and\npartial attention features, and multi-scale spatial features, respectively. To\nensure effective training, we utilize three terms in our loss function: pixel\nloss, feature loss, and adversarial loss. We demonstrate through experimental\nresults that RRFormer achieves state-of-the-art performance on both the non-UHD\ndataset and our proposed UHDRR datasets. The code and datasets are publicly\navailable at\nhttps://github.com/Liar-zzy/Benchmarking-Ultra-High-Definition-Single-Image-Reflection-Removal.\n","authors":["Zhenyuan Zhang","Zhenbo Song","Kaihao Zhang","Zhaoxin Fan","Jianfeng Lu"],"pdf_url":"https://arxiv.org/pdf/2308.00265v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12964v2","updated":"2024-11-08T14:58:29Z","published":"2024-03-19T17:59:39Z","title":"Enhancing Vision-Language Few-Shot Adaptation with Negative Learning","summary":"  Large-scale pre-trained Vision-Language Models (VLMs) have exhibited\nimpressive zero-shot performance and transferability, allowing them to adapt to\ndownstream tasks in a data-efficient manner. However, when only a few labeled\nsamples are available, adapting VLMs to distinguish subtle differences between\nsimilar classes in specific downstream tasks remains challenging. In this work,\nwe propose a Simple yet effective Negative Learning approach, SimNL, to more\nefficiently exploit the task-specific knowledge from few-shot labeled samples.\nUnlike previous methods that focus on identifying a set of representative\npositive features defining \"what is a {CLASS}\", SimNL discovers a complementary\nset of negative features that define \"what is not a {CLASS}\", providing\nadditional insights that supplement the positive features to enhance\ntask-specific recognition capability. Further, we identify that current\nadaptation approaches are particularly vulnerable to potential noise in the\nfew-shot sample set. To mitigate this issue, we introduce a plug-and-play\nfew-shot instance reweighting technique to suppress noisy outliers and amplify\nclean samples for more stable adaptation. Our extensive experimental results\nacross 15 datasets validate that the proposed SimNL outperforms existing\nstate-of-the-art methods on both few-shot learning and domain generalization\ntasks while achieving competitive computational efficiency. Code is available\nat https://github.com/zhangce01/SimNL.\n","authors":["Ce Zhang","Simon Stepputtis","Katia Sycara","Yaqi Xie"],"pdf_url":"https://arxiv.org/pdf/2403.12964v2.pdf","comment":"Accepted by WACV 2025. Code is available at\n  https://github.com/zhangce01/SimNL"},{"id":"http://arxiv.org/abs/2407.10921v2","updated":"2024-11-08T14:55:06Z","published":"2024-07-15T17:22:16Z","title":"Leveraging Bi-Focal Perspectives and Granular Feature Integration for\n  Accurate Reliable Early Alzheimer's Detection","summary":"  Alzheimer's disease (AD) is the most common form of neurodegeneration, which\nimpacts millions of people each year. Diagnosing and classifying AD accurately\nwith neuroimaging data is an ongoing challenge in the field of medicine.\nTraditional Convolutional Neural Networks (CNNs) are good at capturing\nlow-level information from images, but their capability to extract high-level\nminuscule particles is suboptimal, which is a significant challenge in\ndetecting AD from MRI scans. To overcome this, we propose a novel Granular\nFeature Integration method to combine information extraction at different\nscales combined with an efficient information flow. We also propose a Bi-Focal\nPerspective mechanism to highlight focus on subtle neurofibrillary tangles and\namyloid plaques in MRI scans. Our model yielded an F1-Score of 99.31%, a\nprecision of 99.24%, and a recall of 99.51%, which shows a major improvement in\ncomparison to existing state-of-the-art (SOTA) CNNs.\n","authors":["Pandiyaraju V","Shravan Venkatraman","Abeshek A","Aravintakshan S A","Pavan Kumar S","Kannan A"],"pdf_url":"https://arxiv.org/pdf/2407.10921v2.pdf","comment":"17 pages, 10 figures, 6 tables"},{"id":"http://arxiv.org/abs/2411.05609v1","updated":"2024-11-08T14:52:42Z","published":"2024-11-08T14:52:42Z","title":"A Two-Step Concept-Based Approach for Enhanced Interpretability and\n  Trust in Skin Lesion Diagnosis","summary":"  The main challenges hindering the adoption of deep learning-based systems in\nclinical settings are the scarcity of annotated data and the lack of\ninterpretability and trust in these systems. Concept Bottleneck Models (CBMs)\noffer inherent interpretability by constraining the final disease prediction on\na set of human-understandable concepts. However, this inherent interpretability\ncomes at the cost of greater annotation burden. Additionally, adding new\nconcepts requires retraining the entire system. In this work, we introduce a\nnovel two-step methodology that addresses both of these challenges. By\nsimulating the two stages of a CBM, we utilize a pretrained Vision Language\nModel (VLM) to automatically predict clinical concepts, and a Large Language\nModel (LLM) to generate disease diagnoses based on the predicted concepts. We\nvalidate our approach on three skin lesion datasets, demonstrating that it\noutperforms traditional CBMs and state-of-the-art explainable methods, all\nwithout requiring any training and utilizing only a few annotated examples. The\ncode is available at\nhttps://github.com/CristianoPatricio/2-step-concept-based-skin-diagnosis.\n","authors":["Cristiano Patrício","Luís F. Teixeira","João C. Neves"],"pdf_url":"https://arxiv.org/pdf/2411.05609v1.pdf","comment":"Preprint submitted for review"},{"id":"http://arxiv.org/abs/2411.05603v1","updated":"2024-11-08T14:47:28Z","published":"2024-11-08T14:47:28Z","title":"Efficient Audio-Visual Fusion for Video Classification","summary":"  We present Attend-Fusion, a novel and efficient approach for audio-visual\nfusion in video classification tasks. Our method addresses the challenge of\nexploiting both audio and visual modalities while maintaining a compact model\narchitecture. Through extensive experiments on the YouTube-8M dataset, we\ndemonstrate that our Attend-Fusion achieves competitive performance with\nsignificantly reduced model complexity compared to larger baseline models.\n","authors":["Mahrukh Awan","Asmar Nadeem","Armin Mustafa"],"pdf_url":"https://arxiv.org/pdf/2411.05603v1.pdf","comment":"CVMP Short Paper"},{"id":"http://arxiv.org/abs/2411.05597v1","updated":"2024-11-08T14:40:56Z","published":"2024-11-08T14:40:56Z","title":"Predicting Stroke through Retinal Graphs and Multimodal Self-supervised\n  Learning","summary":"  Early identification of stroke is crucial for intervention, requiring\nreliable models. We proposed an efficient retinal image representation together\nwith clinical information to capture a comprehensive overview of cardiovascular\nhealth, leveraging large multimodal datasets for new medical insights. Our\napproach is one of the first contrastive frameworks that integrates graph and\ntabular data, using vessel graphs derived from retinal images for efficient\nrepresentation. This method, combined with multimodal contrastive learning,\nsignificantly enhances stroke prediction accuracy by integrating data from\nmultiple sources and using contrastive learning for transfer learning. The\nself-supervised learning techniques employed allow the model to learn\neffectively from unlabeled data, reducing the dependency on large annotated\ndatasets. Our framework showed an AUROC improvement of 3.78% from supervised to\nself-supervised approaches. Additionally, the graph-level representation\napproach achieved superior performance to image encoders while significantly\nreducing pre-training and fine-tuning runtimes. These findings indicate that\nretinal images are a cost-effective method for improving cardiovascular disease\npredictions and pave the way for future research into retinal and cerebral\nvessel connections and the use of graph-based retinal vessel representations.\n","authors":["Yuqing Huang","Bastian Wittmann","Olga Demler","Bjoern Menze","Neda Davoudi"],"pdf_url":"https://arxiv.org/pdf/2411.05597v1.pdf","comment":"Accepted as oral paper at ML-CDS workshop, MICCAI 2024"},{"id":"http://arxiv.org/abs/2404.14565v2","updated":"2024-11-08T14:33:06Z","published":"2024-04-22T20:21:32Z","title":"\"Where am I?\" Scene Retrieval with Language","summary":"  Natural language interfaces to embodied AI are becoming more ubiquitous in\nour daily lives. This opens up further opportunities for language-based\ninteraction with embodied agents, such as a user verbally instructing an agent\nto execute some task in a specific location. For example, \"put the bowls back\nin the cupboard next to the fridge\" or \"meet me at the intersection under the\nred sign.\" As such, we need methods that interface between natural language and\nmap representations of the environment. To this end, we explore the question of\nwhether we can use an open-set natural language query to identify a scene\nrepresented by a 3D scene graph. We define this task as \"language-based\nscene-retrieval\" and it is closely related to \"coarse-localization,\" but we are\ninstead searching for a match from a collection of disjoint scenes and not\nnecessarily a large-scale continuous map. We present Text2SceneGraphMatcher, a\n\"scene-retrieval\" pipeline that learns joint embeddings between text\ndescriptions and scene graphs to determine if they are a match. The code,\ntrained models, and datasets will be made public.\n","authors":["Jiaqi Chen","Daniel Barath","Iro Armeni","Marc Pollefeys","Hermann Blum"],"pdf_url":"https://arxiv.org/pdf/2404.14565v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05769v2","updated":"2024-11-08T14:17:17Z","published":"2024-07-08T09:25:45Z","title":"Boosting 3D Object Detection with Semantic-Aware Multi-Branch Framework","summary":"  In autonomous driving, LiDAR sensors are vital for acquiring 3D point clouds,\nproviding reliable geometric information. However, traditional sampling methods\nof preprocessing often ignore semantic features, leading to detail loss and\nground point interference in 3D object detection. To address this, we propose a\nmulti-branch two-stage 3D object detection framework using a Semantic-aware\nMulti-branch Sampling (SMS) module and multi-view consistency constraints. The\nSMS module includes random sampling, Density Equalization Sampling (DES) for\nenhancing distant objects, and Ground Abandonment Sampling (GAS) to focus on\nnon-ground points. The sampled multi-view points are processed through a\nConsistent KeyPoint Selection (CKPS) module to generate consistent keypoint\nmasks for efficient proposal sampling. The first-stage detector uses\nmulti-branch parallel learning with multi-view consistency loss for feature\naggregation, while the second-stage detector fuses multi-view data through a\nMulti-View Fusion Pooling (MVFP) module to precisely predict 3D objects. The\nexperimental results on the KITTI dataset and Waymo Open Dataset show that our\nmethod achieves excellent detection performance improvement for a variety of\nbackbones, especially for low-performance backbones with the simple network\nstructures.\n","authors":["Hao Jing","Anhong Wang","Lijun Zhao","Yakun Yang","Donghan Bu","Jing Zhang","Yifan Zhang","Junhui Hou"],"pdf_url":"https://arxiv.org/pdf/2407.05769v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08229v2","updated":"2024-11-08T14:14:23Z","published":"2024-09-28T15:52:49Z","title":"Improvement of Spiking Neural Network with Bit Planes and Color Models","summary":"  Spiking neural network (SNN) has emerged as a promising paradigm in\ncomputational neuroscience and artificial intelligence, offering advantages\nsuch as low energy consumption and small memory footprint. However, their\npractical adoption is constrained by several challenges, prominently among them\nbeing performance optimization. In this study, we present a novel approach to\nenhance the performance of SNN for images through a new coding method that\nexploits bit plane representation. Our proposed technique is designed to\nimprove the accuracy of SNN without increasing model size. Also, we investigate\nthe impacts of color models of the proposed coding process. Through extensive\nexperimental validation, we demonstrate the effectiveness of our coding\nstrategy in achieving performance gain across multiple datasets. To the best of\nour knowledge, this is the first research that considers bit planes and color\nmodels in the context of SNN. By leveraging the unique characteristics of bit\nplanes, we hope to unlock new potentials in SNNs performance, potentially\npaving the way for more efficient and effective SNNs models in future\nresearches and applications.\n","authors":["Nhan T. Luu","Duong T. Luu","Nam N. Pham","Thang C. Truong"],"pdf_url":"https://arxiv.org/pdf/2410.08229v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17791v2","updated":"2024-11-08T13:45:38Z","published":"2024-07-25T05:58:58Z","title":"Untrained neural networks can demonstrate memorization-independent\n  abstract reasoning","summary":"  The nature of abstract reasoning is a matter of debate. Modern artificial\nneural network (ANN) models, like large language models, demonstrate impressive\nsuccess when tested on abstract reasoning problems. However, it has been argued\nthat their success reflects some form of memorization of similar problems (data\ncontamination) rather than a general-purpose abstract reasoning capability.\nThis concern is supported by evidence of brittleness, and the requirement of\nextensive training. In our study, we explored whether abstract reasoning can be\nachieved using the toolbox of ANNs, without prior training. Specifically, we\nstudied an ANN model in which the weights of a naive network are optimized\nduring the solution of the problem, using the problem data itself, rather than\nany prior knowledge. We tested this modeling approach on visual reasoning\nproblems and found that it performs relatively well. Crucially, this success\ndoes not rely on memorization of similar problems. We further suggest an\nexplanation of how it works. Finally, as problem solving is performed by\nchanging the ANN weights, we explored the connection between problem solving\nand the accumulation of knowledge in the ANNs.\n","authors":["Tomer Barak","Yonatan Loewenstein"],"pdf_url":"https://arxiv.org/pdf/2407.17791v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05564v1","updated":"2024-11-08T13:40:01Z","published":"2024-11-08T13:40:01Z","title":"Open-set object detection: towards unified problem formulation and\n  benchmarking","summary":"  In real-world applications where confidence is key, like autonomous driving,\nthe accurate detection and appropriate handling of classes differing from those\nused during training are crucial. Despite the proposal of various unknown\nobject detection approaches, we have observed widespread inconsistencies among\nthem regarding the datasets, metrics, and scenarios used, alongside a notable\nabsence of a clear definition for unknown objects, which hampers meaningful\nevaluation. To counter these issues, we introduce two benchmarks: a unified\nVOC-COCO evaluation, and the new OpenImagesRoad benchmark which provides clear\nhierarchical object definition besides new evaluation metrics. Complementing\nthe benchmark, we exploit recent self-supervised Vision Transformers\nperformance, to improve pseudo-labeling-based OpenSet Object Detection (OSOD),\nthrough OW-DETR++. State-of-the-art methods are extensively evaluated on the\nproposed benchmarks. This study provides a clear problem definition, ensures\nconsistent evaluations, and draws new conclusions about effectiveness of OSOD\nstrategies.\n","authors":["Hejer Ammar","Nikita Kiselov","Guillaume Lapouge","Romaric Audigier"],"pdf_url":"https://arxiv.org/pdf/2411.05564v1.pdf","comment":"Accepted at ECCV 2024 Workshop: \"The 3rd Workshop for\n  Out-of-Distribution Generalization in Computer Vision Foundation Models\""},{"id":"http://arxiv.org/abs/2411.05561v1","updated":"2024-11-08T13:35:45Z","published":"2024-11-08T13:35:45Z","title":"Training objective drives the consistency of representational similarity\n  across datasets","summary":"  The Platonic Representation Hypothesis claims that recent foundation models\nare converging to a shared representation space as a function of their\ndownstream task performance, irrespective of the objectives and data modalities\nused to train these models. Representational similarity is generally measured\nfor individual datasets and is not necessarily consistent across datasets.\nThus, one may wonder whether this convergence of model representations is\nconfounded by the datasets commonly used in machine learning. Here, we propose\na systematic way to measure how representational similarity between models\nvaries with the set of stimuli used to construct the representations. We find\nthat the objective function is the most crucial factor in determining the\nconsistency of representational similarities across datasets. Specifically,\nself-supervised vision models learn representations whose relative pairwise\nsimilarities generalize better from one dataset to another compared to those of\nimage classification or image-text models. Moreover, the correspondence between\nrepresentational similarities and the models' task behavior is\ndataset-dependent, being most strongly pronounced for single-domain datasets.\nOur work provides a framework for systematically measuring similarities of\nmodel representations across datasets and linking those similarities to\ndifferences in task behavior.\n","authors":["Laure Ciernik","Lorenz Linhardt","Marco Morik","Jonas Dippel","Simon Kornblith","Lukas Muttenthaler"],"pdf_url":"https://arxiv.org/pdf/2411.05561v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2411.05557v1","updated":"2024-11-08T13:26:07Z","published":"2024-11-08T13:26:07Z","title":"A Nerf-Based Color Consistency Method for Remote Sensing Images","summary":"  Due to different seasons, illumination, and atmospheric conditions, the\nphotometric of the acquired image varies greatly, which leads to obvious\nstitching seams at the edges of the mosaic image. Traditional methods can be\ndivided into two categories, one is absolute radiation correction and the other\nis relative radiation normalization. We propose a NeRF-based method of color\nconsistency correction for multi-view images, which weaves image features\ntogether using implicit expressions, and then re-illuminates feature space to\ngenerate a fusion image with a new perspective. We chose Superview-1 satellite\nimages and UAV images with large range and time difference for the experiment.\nExperimental results show that the synthesize image generated by our method has\nexcellent visual effect and smooth color transition at the edges.\n","authors":["Zongcheng Zuo","Yuanxiang Li","Tongtong Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05557v1.pdf","comment":"4 pages, 4 figures, The International Geoscience and Remote Sensing\n  Symposium (IGARSS2023)"},{"id":"http://arxiv.org/abs/2411.05552v1","updated":"2024-11-08T13:18:31Z","published":"2024-11-08T13:18:31Z","title":"DeepArUco++: Improved detection of square fiducial markers in\n  challenging lighting conditions","summary":"  Fiducial markers are a computer vision tool used for object pose estimation\nand detection. These markers are highly useful in fields such as industry,\nmedicine and logistics. However, optimal lighting conditions are not always\navailable,and other factors such as blur or sensor noise can affect image\nquality. Classical computer vision techniques that precisely locate and decode\nfiducial markers often fail under difficult illumination conditions (e.g.\nextreme variations of lighting within the same frame). Hence, we propose\nDeepArUco++, a deep learning-based framework that leverages the robustness of\nConvolutional Neural Networks to perform marker detection and decoding in\nchallenging lighting conditions. The framework is based on a pipeline using\ndifferent Neural Network models at each step, namely marker detection, corner\nrefinement and marker decoding. Additionally, we propose a simple method for\ngenerating synthetic data for training the different models that compose the\nproposed pipeline, and we present a second, real-life dataset of ArUco markers\nin challenging lighting conditions used to evaluate our system. The developed\nmethod outperforms other state-of-the-art methods in such tasks and remains\ncompetitive even when testing on the datasets used to develop those methods.\nCode available in GitHub: https://github.com/AVAuco/deeparuco/\n","authors":["Rafael Berral-Soler","Rafael Muñoz-Salinas","Rafael Medina-Carnicer","Manuel J. Marín-Jiménez"],"pdf_url":"https://arxiv.org/pdf/2411.05552v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05544v1","updated":"2024-11-08T12:58:48Z","published":"2024-11-08T12:58:48Z","title":"Towards Lifelong Few-Shot Customization of Text-to-Image Diffusion","summary":"  Lifelong few-shot customization for text-to-image diffusion aims to\ncontinually generalize existing models for new tasks with minimal data while\npreserving old knowledge. Current customization diffusion models excel in\nfew-shot tasks but struggle with catastrophic forgetting problems in lifelong\ngenerations. In this study, we identify and categorize the catastrophic\nforgetting problems into two folds: relevant concepts forgetting and previous\nconcepts forgetting. To address these challenges, we first devise a data-free\nknowledge distillation strategy to tackle relevant concepts forgetting. Unlike\nexisting methods that rely on additional real data or offline replay of\noriginal concept data, our approach enables on-the-fly knowledge distillation\nto retain the previous concepts while learning new ones, without accessing any\nprevious data. Second, we develop an In-Context Generation (ICGen) paradigm\nthat allows the diffusion model to be conditioned upon the input vision\ncontext, which facilitates the few-shot generation and mitigates the issue of\nprevious concepts forgetting. Extensive experiments show that the proposed\nLifelong Few-Shot Diffusion (LFS-Diffusion) method can produce high-quality and\naccurate images while maintaining previously learned knowledge.\n","authors":["Nan Song","Xiaofeng Yang","Ze Yang","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2411.05544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10580v2","updated":"2024-11-08T12:55:58Z","published":"2024-06-15T09:44:54Z","title":"IMDL-BenCo: A Comprehensive Benchmark and Codebase for Image\n  Manipulation Detection & Localization","summary":"  A comprehensive benchmark is yet to be established in the Image Manipulation\nDetection & Localization (IMDL) field. The absence of such a benchmark leads to\ninsufficient and misleading model evaluations, severely undermining the\ndevelopment of this field. However, the scarcity of open-sourced baseline\nmodels and inconsistent training and evaluation protocols make conducting\nrigorous experiments and faithful comparisons among IMDL models challenging. To\naddress these challenges, we introduce IMDL-BenCo, the first comprehensive IMDL\nbenchmark and modular codebase. IMDL-BenCo: i) decomposes the IMDL framework\ninto standardized, reusable components and revises the model construction\npipeline, improving coding efficiency and customization flexibility; ii) fully\nimplements or incorporates training code for state-of-the-art models to\nestablish a comprehensive IMDL benchmark; and iii) conducts deep analysis based\non the established benchmark and codebase, offering new insights into IMDL\nmodel architecture, dataset characteristics, and evaluation standards.\nSpecifically, IMDL-BenCo includes common processing algorithms, 8\nstate-of-the-art IMDL models (1 of which are reproduced from scratch), 2 sets\nof standard training and evaluation protocols, 15 GPU-accelerated evaluation\nmetrics, and 3 kinds of robustness evaluation. This benchmark and codebase\nrepresent a significant leap forward in calibrating the current progress in the\nIMDL field and inspiring future breakthroughs. Code is available at:\nhttps://github.com/scu-zjz/IMDLBenCo.\n","authors":["Xiaochen Ma","Xuekang Zhu","Lei Su","Bo Du","Zhuohang Jiang","Bingkui Tong","Zeyu Lei","Xinyu Yang","Chi-Man Pun","Jiancheng Lv","Jizhe Zhou"],"pdf_url":"https://arxiv.org/pdf/2406.10580v2.pdf","comment":"Technical report, NeurIPS Spotlight of Benchmark and Dataset Track\n  2024"},{"id":"http://arxiv.org/abs/2411.01683v2","updated":"2024-11-08T12:50:03Z","published":"2024-11-03T20:46:50Z","title":"ROAD-Waymo: Action Awareness at Scale for Autonomous Driving","summary":"  Autonomous Vehicle (AV) perception systems require more than simply seeing,\nvia e.g., object detection or scene segmentation. They need a holistic\nunderstanding of what is happening within the scene for safe interaction with\nother road users. Few datasets exist for the purpose of developing and training\nalgorithms to comprehend the actions of other road users. This paper presents\nROAD-Waymo, an extensive dataset for the development and benchmarking of\ntechniques for agent, action, location and event detection in road scenes,\nprovided as a layer upon the (US) Waymo Open dataset. Considerably larger and\nmore challenging than any existing dataset (and encompassing multiple cities),\nit comes with 198k annotated video frames, 54k agent tubes, 3.9M bounding boxes\nand a total of 12.4M labels. The integrity of the dataset has been confirmed\nand enhanced via a novel annotation pipeline designed for automatically\nidentifying violations of requirements specifically designed for this dataset.\nAs ROAD-Waymo is compatible with the original (UK) ROAD dataset, it provides\nthe opportunity to tackle domain adaptation between real-world road scenarios\nin different countries within a novel benchmark: ROAD++.\n","authors":["Salman Khan","Izzeddin Teeti","Reza Javanmard Alitappeh","Mihaela C. Stoian","Eleonora Giunchiglia","Gurkirt Singh","Andrew Bradley","Fabio Cuzzolin"],"pdf_url":"https://arxiv.org/pdf/2411.01683v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05524v1","updated":"2024-11-08T12:30:41Z","published":"2024-11-08T12:30:41Z","title":"Alignment of 3D woodblock geometrical models and 2D orthographic\n  projection image","summary":"  The accurate alignment of 3D woodblock geometrical models with 2D\northographic projection images presents a significant challenge in the digital\npreservation of Vietnamese cultural heritage. This paper proposes a unified\nimage processing algorithm to address this issue, enhancing the registration\nquality between 3D woodblock models and their 2D representations. The method\nincludes determining the plane of the 3D character model, establishing a\ntransformation matrix to align this plane with the 2D printed image plane, and\ncreating a parallel-projected depth map for precise alignment. This process\nminimizes disocclusions and ensures that character shapes and strokes are\ncorrectly positioned. Experimental results highlight the importance of\nstructure-based comparisons to optimize alignment for large-scale Han-Nom\ncharacter datasets. The proposed approach, combining density-based and\nstructure-based methods, demonstrates improved registration performance,\noffering an effective normalization scheme for digital heritage preservation.\n","authors":["Minh DUc Nguyen","Cong Thuong Le","Trong Lam Nguyen"],"pdf_url":"https://arxiv.org/pdf/2411.05524v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05514v1","updated":"2024-11-08T12:19:20Z","published":"2024-11-08T12:19:20Z","title":"Towards Scalable Foundation Models for Digital Dermatology","summary":"  The growing demand for accurate and equitable AI models in digital\ndermatology faces a significant challenge: the lack of diverse, high-quality\nlabeled data. In this work, we investigate the potential of domain-specific\nfoundation models for dermatology in addressing this challenge. We utilize\nself-supervised learning (SSL) techniques to pre-train models on a dataset of\nover 240,000 dermatological images from public and private collections. Our\nstudy considers several SSL methods and compares the resulting foundation\nmodels against domain-agnostic models like those pre-trained on ImageNet and\nstate-of-the-art models such as MONET across 12 downstream tasks. Unlike\nprevious research, we emphasize the development of smaller models that are more\nsuitable for resource-limited clinical settings, facilitating easier adaptation\nto a broad range of use cases. Results show that models pre-trained in this\nwork not only outperform general-purpose models but also approach the\nperformance of models 50 times larger on clinically relevant diagnostic tasks.\nTo promote further research in this direction, we publicly release both the\ntraining code and the foundation models, which can benefit clinicians in\ndermatological applications.\n","authors":["Fabian Gröger","Philippe Gottfrois","Ludovic Amruthalingam","Alvaro Gonzalez-Jimenez","Simone Lionetti","Luis R. Soenksen-Martinez","Alexander A. Navarini","Marc Pouly"],"pdf_url":"https://arxiv.org/pdf/2411.05514v1.pdf","comment":"Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 11 pages"},{"id":"http://arxiv.org/abs/2411.05500v1","updated":"2024-11-08T12:02:25Z","published":"2024-11-08T12:02:25Z","title":"FGGP: Fixed-Rate Gradient-First Gradual Pruning","summary":"  In recent years, the increasing size of deep learning models and their\ngrowing demand for computational resources have drawn significant attention to\nthe practice of pruning neural networks, while aiming to preserve their\naccuracy. In unstructured gradual pruning, which sparsifies a network by\ngradually removing individual network parameters until a targeted network\nsparsity is reached, recent works show that both gradient and weight magnitudes\nshould be considered. In this work, we show that such mechanism, e.g., the\norder of prioritization and selection criteria, is essential. We introduce a\ngradient-first magnitude-next strategy for choosing the parameters to prune,\nand show that a fixed-rate subselection criterion between these steps works\nbetter, in contrast to the annealing approach in the literature. We validate\nthis on CIFAR-10 dataset, with multiple randomized initializations on both\nVGG-19 and ResNet-50 network backbones, for pruning targets of 90, 95, and 98%\nsparsity and for both initially dense and 50% sparse networks. Our proposed\nfixed-rate gradient-first gradual pruning (FGGP) approach outperforms its\nstate-of-the-art alternatives in most of the above experimental settings, even\noccasionally surpassing the upperbound of corresponding dense network results,\nand having the highest ranking across the considered experimental settings.\n","authors":["Lingkai Zhu","Can Deniz Bezek","Orcun Goksel"],"pdf_url":"https://arxiv.org/pdf/2411.05500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02491v2","updated":"2024-11-08T11:56:04Z","published":"2024-02-04T13:37:21Z","title":"VM-UNet: Vision Mamba UNet for Medical Image Segmentation","summary":"  In the realm of medical image segmentation, both CNN-based and\nTransformer-based models have been extensively explored. However, CNNs exhibit\nlimitations in long-range modeling capabilities, whereas Transformers are\nhampered by their quadratic computational complexity. Recently, State Space\nModels (SSMs), exemplified by Mamba, have emerged as a promising approach. They\nnot only excel in modeling long-range interactions but also maintain a linear\ncomputational complexity. In this paper, leveraging state space models, we\npropose a U-shape architecture model for medical image segmentation, named\nVision Mamba UNet (VM-UNet). Specifically, the Visual State Space (VSS) block\nis introduced as the foundation block to capture extensive contextual\ninformation, and an asymmetrical encoder-decoder structure is constructed with\nfewer convolution layers to save calculation cost. We conduct comprehensive\nexperiments on the ISIC17, ISIC18, and Synapse datasets, and the results\nindicate that VM-UNet performs competitively in medical image segmentation\ntasks. To our best knowledge, this is the first medical image segmentation\nmodel constructed based on the pure SSM-based model. We aim to establish a\nbaseline and provide valuable insights for the future development of more\nefficient and effective SSM-based segmentation systems. Our code is available\nat https://github.com/JCruan519/VM-UNet.\n","authors":["Jiacheng Ruan","Jincheng Li","Suncheng Xiang"],"pdf_url":"https://arxiv.org/pdf/2402.02491v2.pdf","comment":"9 pages, 5 figures, 6 tables. Work in progress"},{"id":"http://arxiv.org/abs/2411.05497v1","updated":"2024-11-08T11:55:27Z","published":"2024-11-08T11:55:27Z","title":"Tightly-Coupled, Speed-aided Monocular Visual-Inertial Localization in\n  Topological Map","summary":"  This paper proposes a novel algorithm for vehicle speed-aided monocular\nvisual-inertial localization using a topological map. The proposed system aims\nto address the limitations of existing methods that rely heavily on expensive\nsensors like GPS and LiDAR by leveraging relatively inexpensive camera-based\npose estimation. The topological map is generated offline from LiDAR point\nclouds and includes depth images, intensity images, and corresponding camera\nposes. This map is then used for real-time localization through correspondence\nmatching between current camera images and the stored topological images. The\nsystem employs an Iterated Error State Kalman Filter (IESKF) for optimized pose\nestimation, incorporating correspondence among images and vehicle speed\nmeasurements to enhance accuracy. Experimental results using both open dataset\nand our collected data in challenging scenario, such as tunnel, demonstrate the\nproposed algorithm's superior performance in topological map generation and\nlocalization tasks.\n","authors":["Chanuk Yang","Hayeon O","Kunsoo Huh"],"pdf_url":"https://arxiv.org/pdf/2411.05497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05489v1","updated":"2024-11-08T11:39:03Z","published":"2024-11-08T11:39:03Z","title":"Do Histopathological Foundation Models Eliminate Batch Effects? A\n  Comparative Study","summary":"  Deep learning has led to remarkable advancements in computational\nhistopathology, e.g., in diagnostics, biomarker prediction, and outcome\nprognosis. Yet, the lack of annotated data and the impact of batch effects,\ne.g., systematic technical data differences across hospitals, hamper model\nrobustness and generalization. Recent histopathological foundation models --\npretrained on millions to billions of images -- have been reported to improve\ngeneralization performances on various downstream tasks. However, it has not\nbeen systematically assessed whether they fully eliminate batch effects. In\nthis study, we empirically show that the feature embeddings of the foundation\nmodels still contain distinct hospital signatures that can lead to biased\npredictions and misclassifications. We further find that the signatures are not\nremoved by stain normalization methods, dominate distances in feature space,\nand are evident across various principal components. Our work provides a novel\nperspective on the evaluation of medical foundation models, paving the way for\nmore robust pretraining strategies and downstream predictors.\n","authors":["Jonah Kömen","Hannah Marienwald","Jonas Dippel","Julius Hense"],"pdf_url":"https://arxiv.org/pdf/2411.05489v1.pdf","comment":"Accepted to AIM-FM Workshop @ NeurIPS'24"},{"id":"http://arxiv.org/abs/2411.04480v2","updated":"2024-11-08T11:29:36Z","published":"2024-11-07T07:19:28Z","title":"CFPNet: Improving Lightweight ToF Depth Completion via Cross-zone\n  Feature Propagation","summary":"  Depth completion using lightweight time-of-flight (ToF) depth sensors is\nattractive due to their low cost. However, lightweight ToF sensors usually have\na limited field of view (FOV) compared with cameras. Thus, only pixels in the\nzone area of the image can be associated with depth signals. Previous methods\nfail to propagate depth features from the zone area to the outside-zone area\neffectively, thus suffering from degraded depth completion performance outside\nthe zone. To this end, this paper proposes the CFPNet to achieve cross-zone\nfeature propagation from the zone area to the outside-zone area with two novel\nmodules. The first is a direct-attention-based propagation module (DAPM), which\nenforces direct cross-zone feature acquisition. The second is a\nlarge-kernel-based propagation module (LKPM), which realizes cross-zone feature\npropagation by utilizing convolution layers with kernel sizes up to 31. CFPNet\nachieves state-of-the-art (SOTA) depth completion performance by combining\nthese two modules properly, as verified by extensive experimental results on\nthe ZJU-L5 dataset. The code will be made public.\n","authors":["Laiyan Ding","Hualie Jiang","Rui Xu","Rui Huang"],"pdf_url":"https://arxiv.org/pdf/2411.04480v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05473v1","updated":"2024-11-08T10:58:09Z","published":"2024-11-08T10:58:09Z","title":"Improving image synthesis with diffusion-negative sampling","summary":"  For image generation with diffusion models (DMs), a negative prompt n can be\nused to complement the text prompt p, helping define properties not desired in\nthe synthesized image. While this improves prompt adherence and image quality,\nfinding good negative prompts is challenging. We argue that this is due to a\nsemantic gap between humans and DMs, which makes good negative prompts for DMs\nappear unintuitive to humans. To bridge this gap, we propose a new\ndiffusion-negative prompting (DNP) strategy. DNP is based on a new procedure to\nsample images that are least compliant with p under the distribution of the DM,\ndenoted as diffusion-negative sampling (DNS). Given p, one such image is\nsampled, which is then translated into natural language by the user or a\ncaptioning model, to produce the negative prompt n*. The pair (p, n*) is\nfinally used to prompt the DM. DNS is straightforward to implement and requires\nno training. Experiments and human evaluations show that DNP performs well both\nquantitatively and qualitatively and can be easily combined with several DM\nvariants.\n","authors":["Alakh Desai","Nuno Vasconcelos"],"pdf_url":"https://arxiv.org/pdf/2411.05473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06000v2","updated":"2024-11-08T10:52:08Z","published":"2024-07-08T14:52:03Z","title":"Bounding Boxes and Probabilistic Graphical Models: Video Anomaly\n  Detection Simplified","summary":"  In this study, we formulate the task of Video Anomaly Detection as a\nprobabilistic analysis of object bounding boxes. We hypothesize that the\nrepresentation of objects via their bounding boxes only, can be sufficient to\nsuccessfully identify anomalous events in a scene. The implied value of this\napproach is increased object anonymization, faster model training and fewer\ncomputational resources. This can particularly benefit applications within\nvideo surveillance running on edge devices such as cameras. We design our model\nbased on human reasoning which lends itself to explaining model output in\nhuman-understandable terms. Meanwhile, the slowest model trains within less\nthan 7 seconds on a 11th Generation Intel Core i9 Processor. While our approach\nconstitutes a drastic reduction of problem feature space in comparison with\nprior art, we show that this does not result in a reduction in performance: the\nresults we report are highly competitive on the benchmark datasets CUHK Avenue\nand ShanghaiTech, and significantly exceed on the latest State-of-the-Art\nresults on StreetScene, which has so far proven to be the most challenging VAD\ndataset.\n","authors":["Mia Siemon","Thomas B. Moeslund","Barry Norton","Kamal Nasrollahi"],"pdf_url":"https://arxiv.org/pdf/2407.06000v2.pdf","comment":"Accepted for publication at GCPR 2024, after peer review. Use of this\n  Accepted Version is subject to the publisher's Accepted Manuscript terms of\n  use\n  https://www.springer-nature.com/gp/open-research/policies/accepted-manuscript-terms.\n  Code available on GitHub:\n  https://github.com/milestonesys-research/VAD-with-PGMs/"},{"id":"http://arxiv.org/abs/2401.14718v5","updated":"2024-11-08T10:51:47Z","published":"2024-01-26T08:59:38Z","title":"A Survey on Future Frame Synthesis: Bridging Deterministic and\n  Generative Approaches","summary":"  Future Frame Synthesis (FFS) aims to enable models to generate sequences of\nfuture frames based on existing content. This survey comprehensively reviews\nhistorical and contemporary works in FFS, including widely used datasets and\nalgorithms. It scrutinizes the challenges and the evolving landscape of FFS\nwithin computer vision, with a focus on the transition from deterministic to\ngenerative synthesis methodologies. Our taxonomy highlights the significant\nadvancements and shifts in approach, underscoring the growing importance of\ngenerative models in achieving realistic and diverse future frame predictions.\n","authors":["Ruibo Ming","Zhewei Huang","Zhuoxuan Ju","Jianming Hu","Lihui Peng","Shuchang Zhou"],"pdf_url":"https://arxiv.org/pdf/2401.14718v5.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2401.17904v2","updated":"2024-11-08T10:45:12Z","published":"2024-01-31T15:10:29Z","title":"Hi-SAM: Marrying Segment Anything Model for Hierarchical Text\n  Segmentation","summary":"  The Segment Anything Model (SAM), a profound vision foundation model\npretrained on a large-scale dataset, breaks the boundaries of general\nsegmentation and sparks various downstream applications. This paper introduces\nHi-SAM, a unified model leveraging SAM for hierarchical text segmentation.\nHi-SAM excels in segmentation across four hierarchies, including pixel-level\ntext, word, text-line, and paragraph, while realizing layout analysis as well.\nSpecifically, we first turn SAM into a high-quality pixel-level text\nsegmentation (TS) model through a parameter-efficient fine-tuning approach. We\nuse this TS model to iteratively generate the pixel-level text labels in a\nsemi-automatical manner, unifying labels across the four text hierarchies in\nthe HierText dataset. Subsequently, with these complete labels, we launch the\nend-to-end trainable Hi-SAM based on the TS architecture with a customized\nhierarchical mask decoder. During inference, Hi-SAM offers both automatic mask\ngeneration (AMG) mode and promptable segmentation (PS) mode. In the AMG mode,\nHi-SAM segments pixel-level text foreground masks initially, then samples\nforeground points for hierarchical text mask generation and achieves layout\nanalysis in passing. As for the PS mode, Hi-SAM provides word, text-line, and\nparagraph masks with a single point click. Experimental results show the\nstate-of-the-art performance of our TS model: 84.86% fgIOU on Total-Text and\n88.96% fgIOU on TextSeg for pixel-level text segmentation. Moreover, compared\nto the previous specialist for joint hierarchical detection and layout analysis\non HierText, Hi-SAM achieves significant improvements: 4.73% PQ and 5.39% F1 on\nthe text-line level, 5.49% PQ and 7.39% F1 on the paragraph level layout\nanalysis, requiring $20\\times$ fewer training epochs. The code is available at\nhttps://github.com/ymy-k/Hi-SAM.\n","authors":["Maoyuan Ye","Jing Zhang","Juhua Liu","Chenyu Liu","Baocai Yin","Cong Liu","Bo Du","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2401.17904v2.pdf","comment":"Accepted by IEEE TPAMI. GitHub repository:\n  https://github.com/ymy-k/Hi-SAM"},{"id":"http://arxiv.org/abs/2411.05456v1","updated":"2024-11-08T10:07:03Z","published":"2024-11-08T10:07:03Z","title":"Comparative Study of Probabilistic Atlas and Deep Learning Approaches\n  for Automatic Brain Tissue Segmentation from MRI Using N4 Bias Field\n  Correction and Anisotropic Diffusion Pre-processing Techniques","summary":"  Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI)\nimages is vital for accurate diagnosis and further analysis in medical imaging.\nDespite advancements in segmentation techniques, a comprehensive comparison\nbetween traditional statistical methods and modern deep learning approaches\nusing pre-processing techniques like N4 Bias Field Correction and Anisotropic\nDiffusion remains underexplored. This study provides a comparative analysis of\nvarious segmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and\nLinkNet, enhanced with these pre-processing techniques to segment brain tissues\n(white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF)) on the\nInternet Brain Segmentation Repository (IBSR18) dataset. Our results\ndemonstrate that the 3D nnU-Net model outperforms others, achieving the highest\nmean Dice Coefficient score (0.937 +- 0.012), while the 2D nnU-Net model\nrecorded the lowest mean Hausdorff Distance (5.005 +- 0.343 mm) and the lowest\nmean Absolute Volumetric Difference (3.695 +- 2.931 mm) across five unseen test\nsamples. The findings highlight the superiority of nnU-Net models in brain\ntissue segmentation, particularly when combined with N4 Bias Field Correction\nand Anisotropic Diffusion pre-processing techniques. Our implemented code can\nbe accessed via GitHub.\n","authors":["Mohammad Imran Hossain","Muhammad Zain Amin","Daniel Tweneboah Anyimadu","Taofik Ahmed Suleiman"],"pdf_url":"https://arxiv.org/pdf/2411.05456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.10083v2","updated":"2024-11-08T09:39:32Z","published":"2023-03-17T16:08:56Z","title":"$α$Surf: Implicit Surface Reconstruction for Semi-Transparent and\n  Thin Objects with Decoupled Geometry and Opacity","summary":"  Implicit surface representations such as the signed distance function (SDF)\nhave emerged as a promising approach for image-based surface reconstruction.\nHowever, existing optimization methods assume solid surfaces and are therefore\nunable to properly reconstruct semi-transparent surfaces and thin structures,\nwhich also exhibit low opacity due to the blending effect with the background.\nWhile neural radiance field (NeRF) based methods can model semi-transparency\nand achieve photo-realistic quality in synthesized novel views, their\nvolumetric geometry representation tightly couples geometry and opacity, and\ntherefore cannot be easily converted into surfaces without introducing\nartifacts. We present $\\alpha$Surf, a novel surface representation with\ndecoupled geometry and opacity for the reconstruction of semi-transparent and\nthin surfaces where the colors mix. Ray-surface intersections on our\nrepresentation can be found in closed-form via analytical solutions of cubic\npolynomials, avoiding Monte-Carlo sampling and is fully differentiable by\nconstruction. Our qualitative and quantitative evaluations show that our\napproach can accurately reconstruct surfaces with semi-transparent and thin\nparts with fewer artifacts, achieving better reconstruction quality than\nstate-of-the-art SDF and NeRF methods. Website: https://alphasurf.netlify.app/\n","authors":["Tianhao Wu","Hanxue Liang","Fangcheng Zhong","Gernot Riegler","Shimon Vainer","Jiankang Deng","Cengiz Oztireli"],"pdf_url":"https://arxiv.org/pdf/2303.10083v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05423v1","updated":"2024-11-08T09:15:56Z","published":"2024-11-08T09:15:56Z","title":"VISTA: Visual Integrated System for Tailored Automation in Math Problem\n  Generation Using LLM","summary":"  Generating accurate and consistent visual aids is a critical challenge in\nmathematics education, where visual representations like geometric shapes and\nfunctions play a pivotal role in enhancing student comprehension. This paper\nintroduces a novel multi-agent framework that leverages Large Language Models\n(LLMs) to automate the creation of complex mathematical visualizations\nalongside coherent problem text. Our approach not only simplifies the\ngeneration of precise visual aids but also aligns these aids with the problem's\ncore mathematical concepts, improving both problem creation and assessment. By\nintegrating multiple agents, each responsible for distinct tasks such as\nnumeric calculation, geometry validation, and visualization, our system\ndelivers mathematically accurate and contextually relevant problems with visual\naids. Evaluation across Geometry and Function problem types shows that our\nmethod significantly outperforms basic LLMs in terms of text coherence,\nconsistency, relevance and similarity, while maintaining the essential\ngeometrical and functional integrity of the original problems. Although some\nchallenges remain in ensuring consistent visual outputs, our framework\ndemonstrates the immense potential of LLMs in transforming the way educators\ngenerate and utilize visual aids in math education.\n","authors":["Jeongwoo Lee","Kwangsuk Park","Jihyeon Park"],"pdf_url":"https://arxiv.org/pdf/2411.05423v1.pdf","comment":"Accepted at NeurIPS 2024 Workshop on Large Foundation Models for\n  Educational Assessment (FM-Assess)"},{"id":"http://arxiv.org/abs/2411.05420v1","updated":"2024-11-08T09:14:19Z","published":"2024-11-08T09:14:19Z","title":"WeatherGFM: Learning A Weather Generalist Foundation Model via\n  In-context Learning","summary":"  The Earth's weather system encompasses intricate weather data modalities and\ndiverse weather understanding tasks, which hold significant value to human\nlife. Existing data-driven models focus on single weather understanding tasks\n(e.g., weather forecasting). Although these models have achieved promising\nresults, they fail to tackle various complex tasks within a single and unified\nmodel. Moreover, the paradigm that relies on limited real observations for a\nsingle scenario hinders the model's performance upper bound. In response to\nthese limitations, we draw inspiration from the in-context learning paradigm\nemployed in state-of-the-art visual foundation models and large language\nmodels. In this paper, we introduce the first generalist weather foundation\nmodel (WeatherGFM), designed to address a wide spectrum of weather\nunderstanding tasks in a unified manner. More specifically, we initially unify\nthe representation and definition of the diverse weather understanding tasks.\nSubsequently, we devised weather prompt formats to manage different weather\ndata modalities, namely single, multiple, and temporal modalities. Finally, we\nadopt a visual prompting question-answering paradigm for the training of\nunified weather understanding tasks. Extensive experiments indicate that our\nWeatherGFM can effectively handle up to ten weather understanding tasks,\nincluding weather forecasting, super-resolution, weather image translation, and\npost-processing. Our method also showcases generalization ability on unseen\ntasks.\n","authors":["Xiangyu Zhao","Zhiwang Zhou","Wenlong Zhang","Yihao Liu","Xiangyu Chen","Junchao Gong","Hao Chen","Ben Fei","Shiqi Chen","Wanli Ouyang","Xiao-Ming Wu","Lei Bai"],"pdf_url":"https://arxiv.org/pdf/2411.05420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05419v1","updated":"2024-11-08T09:13:20Z","published":"2024-11-08T09:13:20Z","title":"POC-SLT: Partial Object Completion with SDF Latent Transformers","summary":"  3D geometric shape completion hinges on representation learning and a deep\nunderstanding of geometric data. Without profound insights into the\nthree-dimensional nature of the data, this task remains unattainable. Our work\naddresses this challenge of 3D shape completion given partial observations by\nproposing a transformer operating on the latent space representing Signed\nDistance Fields (SDFs). Instead of a monolithic volume, the SDF of an object is\npartitioned into smaller high-resolution patches leading to a sequence of\nlatent codes. The approach relies on a smooth latent space encoding learned via\na variational autoencoder (VAE), trained on millions of 3D patches. We employ\nan efficient masked autoencoder transformer to complete partial sequences into\ncomprehensive shapes in latent space. Our approach is extensively evaluated on\npartial observations from ShapeNet and the ABC dataset where only fractions of\nthe objects are given. The proposed POC-SLT architecture compares favorably\nwith several baseline state-of-the-art methods, demonstrating a significant\nimprovement in 3D shape completion, both qualitatively and quantitatively.\n","authors":["Faezeh Zakeri","Raphael Braun","Lukas Ruppert","Henrik P. A. Lensch"],"pdf_url":"https://arxiv.org/pdf/2411.05419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00916v2","updated":"2024-11-08T09:09:27Z","published":"2024-11-01T13:58:15Z","title":"Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning\n  Framework with Feature Fusion and Variable Clustering","summary":"  Osteoporosis is a common condition that increases fracture risk, especially\nin older adults. Early diagnosis is vital for preventing fractures, reducing\ntreatment costs, and preserving mobility. However, healthcare providers face\nchallenges like limited labeled data and difficulties in processing medical\nimages. This study presents a novel multi-modal learning framework that\nintegrates clinical and imaging data to improve diagnostic accuracy and model\ninterpretability. The model utilizes three pre-trained networks-VGG19,\nInceptionV3, and ResNet50-to extract deep features from X-ray images. These\nfeatures are transformed using PCA to reduce dimensionality and focus on the\nmost relevant components. A clustering-based selection process identifies the\nmost representative components, which are then combined with preprocessed\nclinical data and processed through a fully connected network (FCN) for final\nclassification. A feature importance plot highlights key variables, showing\nthat Medical History, BMI, and Height were the main contributors, emphasizing\nthe significance of patient-specific data. While imaging features were\nvaluable, they had lower importance, indicating that clinical data are crucial\nfor accurate predictions. This framework promotes precise and interpretable\npredictions, enhancing transparency and building trust in AI-driven diagnoses\nfor clinical integration.\n","authors":["Mehdi Hosseini Chagahi","Saeed Mohammadi Dashtaki","Niloufar Delfan","Nadia Mohammadi","Alireza Samari","Behzad Moshiri","Md. Jalil Piran","Oliver Faust"],"pdf_url":"https://arxiv.org/pdf/2411.00916v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02249v2","updated":"2024-11-08T08:32:40Z","published":"2024-10-03T06:41:10Z","title":"Spiking Neural Network as Adaptive Event Stream Slicer","summary":"  Event-based cameras are attracting significant interest as they provide rich\nedge information, high dynamic range, and high temporal resolution. Many\nstate-of-the-art event-based algorithms rely on splitting the events into fixed\ngroups, resulting in the omission of crucial temporal information, particularly\nwhen dealing with diverse motion scenarios (\\eg, high/low speed).In this work,\nwe propose SpikeSlicer, a novel-designed plug-and-play event processing method\ncapable of splitting events stream adaptively.SpikeSlicer utilizes a low-energy\nspiking neural network (SNN) to trigger event slicing. To guide the SNN to fire\nspikes at optimal time steps, we propose the Spiking Position-aware Loss\n(SPA-Loss) to modulate the neuron's state. Additionally, we develop a\nFeedback-Update training strategy that refines the slicing decisions using\nfeedback from the downstream artificial neural network (ANN). Extensive\nexperiments demonstrate that our method yields significant performance\nimprovements in event-based object tracking and recognition. Notably,\nSpikeSlicer provides a brand-new SNN-ANN cooperation paradigm, where the SNN\nacts as an efficient, low-energy data processor to assist the ANN in improving\ndownstream performance, injecting new perspectives and potential avenues of\nexploration.\n","authors":["Jiahang Cao","Mingyuan Sun","Ziqing Wang","Hao Cheng","Qiang Zhang","Shibo Zhou","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2410.02249v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05395v1","updated":"2024-11-08T08:21:08Z","published":"2024-11-08T08:21:08Z","title":"AuthFormer: Adaptive Multimodal biometric authentication transformer for\n  middle-aged and elderly people","summary":"  Multimodal biometric authentication methods address the limitations of\nunimodal biometric technologies in security, robustness, and user adaptability.\nHowever, most existing methods depend on fixed combinations and numbers of\nbiometric modalities, which restricts flexibility and adaptability in\nreal-world applications. To overcome these challenges, we propose an adaptive\nmultimodal biometric authentication model, AuthFormer, tailored for elderly\nusers. AuthFormer is trained on the LUTBIO multimodal biometric database,\ncontaining biometric data from elderly individuals. By incorporating a\ncross-attention mechanism and a Gated Residual Network (GRN), the model\nimproves adaptability to physiological variations in elderly users. Experiments\nshow that AuthFormer achieves an accuracy of 99.73%. Additionally, its encoder\nrequires only two layers to perform optimally, reducing complexity compared to\ntraditional Transformer-based models.\n","authors":["Yang rui","Meng ling-tao","Zhang qiu-yu"],"pdf_url":"https://arxiv.org/pdf/2411.05395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05384v1","updated":"2024-11-08T07:46:50Z","published":"2024-11-08T07:46:50Z","title":"Advancing Meteorological Forecasting: AI-based Approach to Synoptic\n  Weather Map Analysis","summary":"  As global warming increases the complexity of weather patterns; the precision\nof weather forecasting becomes increasingly important. Our study proposes a\nnovel preprocessing method and convolutional autoencoder model developed to\nimprove the interpretation of synoptic weather maps. These are critical for\nmeteorologists seeking a thorough understanding of weather conditions. This\nmodel could recognize historical synoptic weather maps that nearly match\ncurrent atmospheric conditions, marking a significant step forward in modern\ntechnology in meteorological forecasting. This comprises unsupervised learning\nmodels like VQ-VQE, as well as supervised learning models like VGG16, VGG19,\nXception, InceptionV3, and ResNet50 trained on the ImageNet dataset, as well as\nresearch into newer models like EfficientNet and ConvNeXt. Our findings proved\nthat, while these models perform well in various settings, their ability to\nidentify comparable synoptic weather maps has certain limits. Our research,\nmotivated by the primary goal of significantly increasing meteorologists'\nefficiency in labor-intensive tasks, discovered that cosine similarity is the\nmost effective metric, as determined by a combination of quantitative and\nqualitative assessments to accurately identify relevant historical weather\npatterns. This study broadens our understanding by shifting the emphasis from\nnumerical precision to practical application, ensuring that our model is\neffective in theory practical, and accessible in the complex and dynamic field\nof meteorology.\n","authors":["Yo-Hwan Choi","Seon-Yu Kang","Minjong Cheon"],"pdf_url":"https://arxiv.org/pdf/2411.05384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16633v5","updated":"2024-11-08T07:37:11Z","published":"2024-06-24T13:30:55Z","title":"MLAAN: Scaling Supervised Local Learning with Multilaminar Leap\n  Augmented Auxiliary Network","summary":"  Deep neural networks (DNNs) typically employ an end-to-end (E2E) training\nparadigm which presents several challenges, including high GPU memory\nconsumption, inefficiency, and difficulties in model parallelization during\ntraining. Recent research has sought to address these issues, with one\npromising approach being local learning. This method involves partitioning the\nbackbone network into gradient-isolated modules and manually designing\nauxiliary networks to train these local modules. Existing methods often neglect\nthe interaction of information between local modules, leading to myopic issues\nand a performance gap compared to E2E training. To address these limitations,\nwe propose the Multilaminar Leap Augmented Auxiliary Network (MLAAN).\nSpecifically, MLAAN comprises Multilaminar Local Modules (MLM) and Leap\nAugmented Modules (LAM). MLM captures both local and global features through\nindependent and cascaded auxiliary networks, alleviating performance issues\ncaused by insufficient global features. However, overly simplistic auxiliary\nnetworks can impede MLM's ability to capture global information. To address\nthis, we further design LAM, an enhanced auxiliary network that uses the\nExponential Moving Average (EMA) method to facilitate information exchange\nbetween local modules, thereby mitigating the shortsightedness resulting from\ninadequate interaction. The synergy between MLM and LAM has demonstrated\nexcellent performance. Our experiments on the CIFAR-10, STL-10, SVHN, and\nImageNet datasets show that MLAAN can be seamlessly integrated into existing\nlocal learning frameworks, significantly enhancing their performance and even\nsurpassing end-to-end (E2E) training methods, while also reducing GPU memory\nconsumption.\n","authors":["Yuming Zhang","Shouxin Zhang","Peizhe Wang","Feiyu Zhu","Dongzhi Guan","Junhao Su","Jiabin Liu","Changpeng Cai"],"pdf_url":"https://arxiv.org/pdf/2406.16633v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04865v2","updated":"2024-11-08T07:24:15Z","published":"2024-11-07T16:58:18Z","title":"ZAHA: Introducing the Level of Facade Generalization and the Large-Scale\n  Point Cloud Facade Semantic Segmentation Benchmark Dataset","summary":"  Facade semantic segmentation is a long-standing challenge in photogrammetry\nand computer vision. Although the last decades have witnessed the influx of\nfacade segmentation methods, there is a lack of comprehensive facade classes\nand data covering the architectural variability. In ZAHA, we introduce Level of\nFacade Generalization (LoFG), novel hierarchical facade classes designed based\non international urban modeling standards, ensuring compatibility with\nreal-world challenging classes and uniform methods' comparison. Realizing the\nLoFG, we present to date the largest semantic 3D facade segmentation dataset,\nproviding 601 million annotated points at five and 15 classes of LoFG2 and\nLoFG3, respectively. Moreover, we analyze the performance of baseline semantic\nsegmentation methods on our introduced LoFG classes and data, complementing it\nwith a discussion on the unresolved challenges for facade segmentation. We\nfirmly believe that ZAHA shall facilitate further development of 3D facade\nsemantic segmentation methods, enabling robust segmentation indispensable in\ncreating urban digital twins.\n","authors":["Olaf Wysocki","Yue Tan","Thomas Froech","Yan Xia","Magdalena Wysocki","Ludwig Hoegner","Daniel Cremers","Christoph Holst"],"pdf_url":"https://arxiv.org/pdf/2411.04865v2.pdf","comment":"Accepted to WACV 2025 (IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV))"},{"id":"http://arxiv.org/abs/2401.17263v5","updated":"2024-11-08T06:57:05Z","published":"2024-01-30T18:56:08Z","title":"Robust Prompt Optimization for Defending Language Models Against\n  Jailbreaking Attacks","summary":"  Despite advances in AI alignment, large language models (LLMs) remain\nvulnerable to adversarial attacks or jailbreaking, in which adversaries can\nmodify prompts to induce unwanted behavior. While some defenses have been\nproposed, they have not been adapted to newly proposed attacks and more\nchallenging threat models. To address this, we propose an optimization-based\nobjective for defending LLMs against jailbreaking attacks and an algorithm,\nRobust Prompt Optimization (RPO) to create robust system-level defenses. Our\napproach directly incorporates the adversary into the defensive objective and\noptimizes a lightweight and transferable suffix, enabling RPO to adapt to\nworst-case adaptive attacks. Our theoretical and experimental results show\nimproved robustness to both jailbreaks seen during optimization and unknown\njailbreaks, reducing the attack success rate (ASR) on GPT-4 to 6% and Llama-2\nto 0% on JailbreakBench, setting the state-of-the-art. Code can be found at\nhttps://github.com/lapisrocks/rpo\n","authors":["Andy Zhou","Bo Li","Haohan Wang"],"pdf_url":"https://arxiv.org/pdf/2401.17263v5.pdf","comment":"NeurIPS 2024 Spotlight; code available at\n  https://github.com/lapisrocks/rpo"},{"id":"http://arxiv.org/abs/2411.02974v2","updated":"2024-11-08T06:55:36Z","published":"2024-11-05T10:21:21Z","title":"Region-Guided Attack on the Segment Anything Model (SAM)","summary":"  The Segment Anything Model (SAM) is a cornerstone of image segmentation,\ndemonstrating exceptional performance across various applications, particularly\nin autonomous driving and medical imaging, where precise segmentation is\ncrucial. However, SAM is vulnerable to adversarial attacks that can\nsignificantly impair its functionality through minor input perturbations.\nTraditional techniques, such as FGSM and PGD, are often ineffective in\nsegmentation tasks due to their reliance on global perturbations that overlook\nspatial nuances. Recent methods like Attack-SAM-K and UAD have begun to address\nthese challenges, but they frequently depend on external cues and do not fully\nleverage the structural interdependencies within segmentation processes. This\nlimitation underscores the need for a novel adversarial strategy that exploits\nthe unique characteristics of segmentation tasks. In response, we introduce the\nRegion-Guided Attack (RGA), designed specifically for SAM. RGA utilizes a\nRegion-Guided Map (RGM) to manipulate segmented regions, enabling targeted\nperturbations that fragment large segments and expand smaller ones, resulting\nin erroneous outputs from SAM. Our experiments demonstrate that RGA achieves\nhigh success rates in both white-box and black-box scenarios, emphasizing the\nneed for robust defenses against such sophisticated attacks. RGA not only\nreveals SAM's vulnerabilities but also lays the groundwork for developing more\nresilient defenses against adversarial threats in image segmentation.\n","authors":["Xiaoliang Liu","Furao Shen","Jian Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.02974v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05362v1","updated":"2024-11-08T06:36:31Z","published":"2024-11-08T06:36:31Z","title":"From Transparent to Opaque: Rethinking Neural Implicit Surfaces with\n  $α$-NeuS","summary":"  Traditional 3D shape reconstruction techniques from multi-view images, such\nas structure from motion and multi-view stereo, primarily focus on opaque\nsurfaces. Similarly, recent advances in neural radiance fields and its variants\nalso primarily address opaque objects, encountering difficulties with the\ncomplex lighting effects caused by transparent materials. This paper introduces\n$\\alpha$-NeuS, a new method for simultaneously reconstructing thin transparent\nobjects and opaque objects based on neural implicit surfaces (NeuS). Our method\nleverages the observation that transparent surfaces induce local extreme values\nin the learned distance fields during neural volumetric rendering, contrasting\nwith opaque surfaces that align with zero level sets. Traditional iso-surfacing\nalgorithms such as marching cubes, which rely on fixed iso-values, are\nill-suited for this data. We address this by taking the absolute value of the\ndistance field and developing an optimization method that extracts level sets\ncorresponding to both non-negative local minima and zero iso-values. We prove\nthat the reconstructed surfaces are unbiased for both transparent and opaque\nobjects. To validate our approach, we construct a benchmark that includes both\nreal-world and synthetic scenes, demonstrating its practical utility and\neffectiveness. Our data and code are publicly available at\nhttps://github.com/728388808/alpha-NeuS.\n","authors":["Haoran Zhang","Junkai Deng","Xuhui Chen","Fei Hou","Wencheng Wang","Hong Qin","Chen Qian","Ying He"],"pdf_url":"https://arxiv.org/pdf/2411.05362v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05359v1","updated":"2024-11-08T06:29:02Z","published":"2024-11-08T06:29:02Z","title":"Agricultural Landscape Understanding At Country-Scale","summary":"  Agricultural landscapes are quite complex, especially in the Global South\nwhere fields are smaller, and agricultural practices are more varied. In this\npaper we report on our progress in digitizing the agricultural landscape\n(natural and man-made) in our study region of India. We use high resolution\nimagery and a UNet style segmentation model to generate the first of its kind\nnational-scale multi-class panoptic segmentation output. Through this work we\nhave been able to identify individual fields across 151.7M hectares, and\ndelineating key features such as water resources and vegetation. We share how\nthis output was validated by our team and externally by downstream users,\nincluding some sample use cases that can lead to targeted data driven decision\nmaking. We believe this dataset will contribute towards digitizing agriculture\nby generating the foundational baselayer.\n","authors":["Radhika Dua","Nikita Saxena","Aditi Agarwal","Alex Wilson","Gaurav Singh","Hoang Tran","Ishan Deshpande","Amandeep Kaur","Gaurav Aggarwal","Chandan Nath","Arnab Basu","Vishal Batchu","Sharath Holla","Bindiya Kurle","Olana Missura","Rahul Aggarwal","Shubhika Garg","Nishi Shah","Avneet Singh","Dinesh Tewari","Agata Dondzik","Bharat Adsul","Milind Sohoni","Asim Rama Praveen","Aaryan Dangi","Lisan Kadivar","E Abhishek","Niranjan Sudhansu","Kamlakar Hattekar","Sameer Datar","Musty Krishna Chaithanya","Anumas Ranjith Reddy","Aashish Kumar","Betala Laxmi Tirumala","Alok Talekar"],"pdf_url":"https://arxiv.org/pdf/2411.05359v1.pdf","comment":"34 pages, 7 tables, 15 figs"},{"id":"http://arxiv.org/abs/2411.05357v1","updated":"2024-11-08T06:28:02Z","published":"2024-11-08T06:28:02Z","title":"Enhancing Visual Classification using Comparative Descriptors","summary":"  The performance of vision-language models (VLMs), such as CLIP, in visual\nclassification tasks, has been enhanced by leveraging semantic knowledge from\nlarge language models (LLMs), including GPT. Recent studies have shown that in\nzero-shot classification tasks, descriptors incorporating additional cues,\nhigh-level concepts, or even random characters often outperform those using\nonly the category name. In many classification tasks, while the top-1 accuracy\nmay be relatively low, the top-5 accuracy is often significantly higher. This\ngap implies that most misclassifications occur among a few similar classes,\nhighlighting the model's difficulty in distinguishing between classes with\nsubtle differences. To address this challenge, we introduce a novel concept of\ncomparative descriptors. These descriptors emphasize the unique features of a\ntarget class against its most similar classes, enhancing differentiation. By\ngenerating and integrating these comparative descriptors into the\nclassification framework, we refine the semantic focus and improve\nclassification accuracy. An additional filtering process ensures that these\ndescriptors are closer to the image embeddings in the CLIP space, further\nenhancing performance. Our approach demonstrates improved accuracy and\nrobustness in visual classification tasks by addressing the specific challenge\nof subtle inter-class differences.\n","authors":["Hankyeol Lee","Gawon Seo","Wonseok Choi","Geunyoung Jung","Kyungwoo Song","Jiyoung Jung"],"pdf_url":"https://arxiv.org/pdf/2411.05357v1.pdf","comment":"Accepted to WACV 2025. Main paper with 8 pages"},{"id":"http://arxiv.org/abs/2303.07909v3","updated":"2024-11-08T06:19:33Z","published":"2023-03-14T13:49:54Z","title":"Text-to-image Diffusion Models in Generative AI: A Survey","summary":"  This survey reviews the progress of diffusion models in generating images\nfrom text, ~\\textit{i.e.} text-to-image diffusion models. As a self-contained\nwork, this survey starts with a brief introduction of how diffusion models work\nfor image synthesis, followed by the background for text-conditioned image\nsynthesis. Based on that, we present an organized review of pioneering methods\nand their improvements on text-to-image generation. We further summarize\napplications beyond image generation, such as text-guided generation for\nvarious modalities like videos, and text-guided image editing. Beyond the\nprogress made so far, we discuss existing challenges and promising future\ndirections.\n","authors":["Chenshuang Zhang","Chaoning Zhang","Mengchun Zhang","In So Kweon","Junmo Kim"],"pdf_url":"https://arxiv.org/pdf/2303.07909v3.pdf","comment":"First survey on the recent progress of text-to-image generation based\n  on the diffusion model"},{"id":"http://arxiv.org/abs/2405.04682v4","updated":"2024-11-08T05:45:45Z","published":"2024-05-07T21:52:39Z","title":"TALC: Time-Aligned Captions for Multi-Scene Text-to-Video Generation","summary":"  Most of these text-to-video (T2V) generative models often produce\nsingle-scene video clips that depict an entity performing a particular action\n(e.g., 'a red panda climbing a tree'). However, it is pertinent to generate\nmulti-scene videos since they are ubiquitous in the real-world (e.g., 'a red\npanda climbing a tree' followed by 'the red panda sleeps on the top of the\ntree'). To generate multi-scene videos from the pretrained T2V model, we\nintroduce a simple and effective Time-Aligned Captions (TALC) framework.\nSpecifically, we enhance the text-conditioning mechanism in the T2V\narchitecture to recognize the temporal alignment between the video scenes and\nscene descriptions. For instance, we condition the visual features of the\nearlier and later scenes of the generated video with the representations of the\nfirst scene description (e.g., 'a red panda climbing a tree') and second scene\ndescription (e.g., 'the red panda sleeps on the top of the tree'),\nrespectively. As a result, we show that the T2V model can generate multi-scene\nvideos that adhere to the multi-scene text descriptions and be visually\nconsistent (e.g., entity and background). Further, we finetune the pretrained\nT2V model with multi-scene video-text data using the TALC framework. We show\nthat the TALC-finetuned model outperforms the baseline by achieving a relative\ngain of 29% in the overall score, which averages visual consistency and text\nadherence using human evaluation.\n","authors":["Hritik Bansal","Yonatan Bitton","Michal Yarom","Idan Szpektor","Aditya Grover","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2405.04682v4.pdf","comment":"22 pages, 14 figures, 11 tables"},{"id":"http://arxiv.org/abs/2410.21556v3","updated":"2024-11-08T05:35:04Z","published":"2024-10-28T21:35:08Z","title":"Super-resolution in disordered media using neural networks","summary":"  We propose a methodology that exploits large and diverse data sets to\naccurately estimate the ambient medium's Green's functions in strongly\nscattering media. Given these estimates, obtained with and without the use of\nneural networks, excellent imaging results are achieved, with a resolution that\nis better than that of a homogeneous medium. This phenomenon, also known as\nsuper-resolution, occurs because the ambient scattering medium effectively\nenhances the physical imaging aperture. This work has been submitted to the\nIEEE for possible publication. Copyright may be transferred without notice,\nafter which this version may no longer be accessible.\n","authors":["Alexander Christie","Matan Leibovich","Miguel Moscoso","Alexei Novikov","George Papanicolaou","Chrysoula Tsogka"],"pdf_url":"https://arxiv.org/pdf/2410.21556v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05335v1","updated":"2024-11-08T05:14:46Z","published":"2024-11-08T05:14:46Z","title":"A Quality-Centric Framework for Generic Deepfake Detection","summary":"  This paper addresses the generalization issue in deepfake detection by\nharnessing forgery quality in training data. Generally, the forgery quality of\ndifferent deepfakes varies: some have easily recognizable forgery clues, while\nothers are highly realistic. Existing works often train detectors on a mix of\ndeepfakes with varying forgery qualities, potentially leading detectors to\nshort-cut the easy-to-spot artifacts from low-quality forgery samples, thereby\nhurting generalization performance. To tackle this issue, we propose a novel\nquality-centric framework for generic deepfake detection, which is composed of\na Quality Evaluator, a low-quality data enhancement module, and a learning\npacing strategy that explicitly incorporates forgery quality into the training\nprocess. The framework is inspired by curriculum learning, which is designed to\ngradually enable the detector to learn more challenging deepfake samples,\nstarting with easier samples and progressing to more realistic ones. We employ\nboth static and dynamic assessments to assess the forgery quality, combining\ntheir scores to produce a final rating for each training sample. The rating\nscore guides the selection of deepfake samples for training, with higher-rated\nsamples having a higher probability of being chosen. Furthermore, we propose a\nnovel frequency data augmentation method specifically designed for low-quality\nforgery samples, which helps to reduce obvious forgery traces and improve their\noverall realism. Extensive experiments show that our method can be applied in a\nplug-and-play manner and significantly enhance the generalization performance.\n","authors":["Wentang Song","Zhiyuan Yan","Yuzhen Lin","Taiping Yao","Changsheng Chen","Shen Chen","Yandan Zhao","Shouhong Ding","Bin Li"],"pdf_url":"https://arxiv.org/pdf/2411.05335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.13097v2","updated":"2024-11-08T05:13:52Z","published":"2023-08-24T21:43:04Z","title":"CompaCT: Fractal-Based Heuristic Pixel Segmentation for Lossless\n  Compression of High-Color DICOM Medical Images","summary":"  Medical image compression is a widely studied field of data processing due to\nits prevalence in modern digital databases. This domain requires a high color\ndepth of 12 bits per pixel component for accurate analysis by physicians,\nprimarily in the DICOM format. Standard raster-based compression of images via\nfiltering is well-known; however, it remains suboptimal in the medical domain\ndue to non-specialized implementations. This study proposes a lossless medical\nimage compression algorithm, CompaCT, that aims to target spatial features and\npatterns of pixel concentration for dynamically enhanced data processing. The\nalgorithm employs fractal pixel traversal coupled with a novel approach of\nsegmentation and meshing between pixel blocks for preprocessing. Furthermore,\ndelta and entropy coding are applied to this concept for a complete compression\npipeline. The proposal demonstrates that the data compression achieved via\nfractal segmentation preprocessing yields enhanced image compression results\nwhile remaining lossless in its reconstruction accuracy. CompaCT is evaluated\nin its compression ratios on 3954 high-color CT scans against the efficiency of\nindustry-standard compression techniques (i.e., JPEG2000, RLE, ZIP, PNG). Its\nreconstruction performance is assessed with error metrics to verify lossless\nimage recovery after decompression. The results demonstrate that CompaCT can\ncompress and losslessly reconstruct medical images, being 37% more\nspace-efficient than industry-standard compression systems.\n","authors":["Taaha Khan"],"pdf_url":"https://arxiv.org/pdf/2308.13097v2.pdf","comment":"20 pages, 10 figures, Word PDF"},{"id":"http://arxiv.org/abs/2411.04933v2","updated":"2024-11-08T04:56:53Z","published":"2024-11-07T18:12:49Z","title":"SaSR-Net: Source-Aware Semantic Representation Network for Enhancing\n  Audio-Visual Question Answering","summary":"  Audio-Visual Question Answering (AVQA) is a challenging task that involves\nanswering questions based on both auditory and visual information in videos. A\nsignificant challenge is interpreting complex multi-modal scenes, which include\nboth visual objects and sound sources, and connecting them to the given\nquestion. In this paper, we introduce the Source-aware Semantic Representation\nNetwork (SaSR-Net), a novel model designed for AVQA. SaSR-Net utilizes\nsource-wise learnable tokens to efficiently capture and align audio-visual\nelements with the corresponding question. It streamlines the fusion of audio\nand visual information using spatial and temporal attention mechanisms to\nidentify answers in multi-modal scenes. Extensive experiments on the Music-AVQA\nand AVQA-Yang datasets show that SaSR-Net outperforms state-of-the-art AVQA\nmethods.\n","authors":["Tianyu Yang","Yiyang Nan","Lisen Dai","Zhenwen Liang","Yapeng Tian","Xiangliang Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.04933v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05324v1","updated":"2024-11-08T04:37:55Z","published":"2024-11-08T04:37:55Z","title":"SASWISE-UE: Segmentation and Synthesis with Interpretable Scalable\n  Ensembles for Uncertainty Estimation","summary":"  This paper introduces an efficient sub-model ensemble framework aimed at\nenhancing the interpretability of medical deep learning models, thus increasing\ntheir clinical applicability. By generating uncertainty maps, this framework\nenables end-users to evaluate the reliability of model outputs. We developed a\nstrategy to develop diverse models from a single well-trained checkpoint,\nfacilitating the training of a model family. This involves producing multiple\noutputs from a single input, fusing them into a final output, and estimating\nuncertainty based on output disagreements. Implemented using U-Net and UNETR\nmodels for segmentation and synthesis tasks, this approach was tested on CT\nbody segmentation and MR-CT synthesis datasets. It achieved a mean Dice\ncoefficient of 0.814 in segmentation and a Mean Absolute Error of 88.17 HU in\nsynthesis, improved from 89.43 HU by pruning. Additionally, the framework was\nevaluated under corruption and undersampling, maintaining correlation between\nuncertainty and error, which highlights its robustness. These results suggest\nthat the proposed approach not only maintains the performance of well-trained\nmodels but also enhances interpretability through effective uncertainty\nestimation, applicable to both convolutional and transformer models in a range\nof imaging tasks.\n","authors":["Weijie Chen","Alan McMillan"],"pdf_url":"https://arxiv.org/pdf/2411.05324v1.pdf","comment":"16 pages, 12 figures, 5 tables"},{"id":"http://arxiv.org/abs/2411.05322v1","updated":"2024-11-08T04:29:14Z","published":"2024-11-08T04:29:14Z","title":"Rate-aware Compression for NeRF-based Volumetric Video","summary":"  The neural radiance fields (NeRF) have advanced the development of 3D\nvolumetric video technology, but the large data volumes they involve pose\nsignificant challenges for storage and transmission. To address these problems,\nthe existing solutions typically compress these NeRF representations after the\ntraining stage, leading to a separation between representation training and\ncompression. In this paper, we try to directly learn a compact NeRF\nrepresentation for volumetric video in the training stage based on the proposed\nrate-aware compression framework. Specifically, for volumetric video, we use a\nsimple yet effective modeling strategy to reduce temporal redundancy for the\nNeRF representation. Then, during the training phase, an implicit entropy model\nis utilized to estimate the bitrate of the NeRF representation. This entropy\nmodel is then encoded into the bitstream to assist in the decoding of the NeRF\nrepresentation. This approach enables precise bitrate estimation, thereby\nleading to a compact NeRF representation. Furthermore, we propose an adaptive\nquantization strategy and learn the optimal quantization step for the NeRF\nrepresentations. Finally, the NeRF representation can be optimized by using the\nrate-distortion trade-off. Our proposed compression framework can be used for\ndifferent representations and experimental results demonstrate that our\napproach significantly reduces the storage size with marginal distortion and\nachieves state-of-the-art rate-distortion performance for volumetric video on\nthe HumanRF and ReRF datasets. Compared to the previous state-of-the-art method\nTeTriRF, we achieved an approximately -80% BD-rate on the HumanRF dataset and\n-60% BD-rate on the ReRF dataset.\n","authors":["Zhiyu Zhang","Guo Lu","Huanxiong Liang","Zhengxue Cheng","Anni Tang","Li Song"],"pdf_url":"https://arxiv.org/pdf/2411.05322v1.pdf","comment":"Accepted by ACM MM 2024 (Oral)"},{"id":"http://arxiv.org/abs/2411.05312v1","updated":"2024-11-08T04:00:05Z","published":"2024-11-08T04:00:05Z","title":"A Real-time Face Mask Detection and Social Distancing System for\n  COVID-19 using Attention-InceptionV3 Model","summary":"  One of the deadliest pandemics is now happening in the current world due to\nCOVID-19. This contagious virus is spreading like wildfire around the whole\nworld. To minimize the spreading of this virus, World Health Organization (WHO)\nhas made protocols mandatory for wearing face masks and maintaining 6 feet\nphysical distance. In this paper, we have developed a system that can detect\nthe proper maintenance of that distance and people are properly using masks or\nnot. We have used the customized attention-inceptionv3 model in this system for\nthe identification of those two components. We have used two different datasets\nalong with 10,800 images including both with and without Face Mask images. The\ntraining accuracy has been achieved 98% and validation accuracy 99.5%. The\nsystem can conduct a precision value of around 98.2% and the frame rate per\nsecond (FPS) was 25.0. So, with this system, we can identify high-risk areas\nwith the highest possibility of the virus spreading zone. This may help\nauthorities to take necessary steps to locate those risky areas and alert the\nlocal people to ensure proper precautions in no time.\n","authors":["Abdullah Al Asif","Farhana Chowdhury Tisha"],"pdf_url":"https://arxiv.org/pdf/2411.05312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06122v2","updated":"2024-11-08T03:55:37Z","published":"2023-11-10T15:36:57Z","title":"Fight Fire with Fire: Combating Adversarial Patch Attacks using\n  Pattern-randomized Defensive Patches","summary":"  Object detection has found extensive applications in various tasks, but it is\nalso susceptible to adversarial patch attacks. The ideal defense should be\neffective, efficient, easy to deploy, and capable of withstanding adaptive\nattacks. In this paper, we adopt a counterattack strategy to propose a novel\nand general methodology for defending adversarial attacks. Two types of\ndefensive patches, canary and woodpecker, are specially-crafted and injected\ninto the model input to proactively probe or counteract potential adversarial\npatches. In this manner, adversarial patch attacks can be effectively detected\nby simply analyzing the model output, without the need to alter the target\nmodel. Moreover, we employ randomized canary and woodpecker injection patterns\nto defend against defense-aware attacks. The effectiveness and practicality of\nthe proposed method are demonstrated through comprehensive experiments. The\nresults illustrate that canary and woodpecker achieve high performance, even\nwhen confronted with unknown attack methods, while incurring limited time\noverhead. Furthermore, our method also exhibits sufficient robustness against\ndefense-aware attacks, as evidenced by adaptive attack experiments.\n","authors":["Jianan Feng","Jiachun Li","Changqing Miao","Jianjun Huang","Wei You","Wenchang Shi","Bin Liang"],"pdf_url":"https://arxiv.org/pdf/2311.06122v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05311v1","updated":"2024-11-08T03:52:32Z","published":"2024-11-08T03:52:32Z","title":"ZOPP: A Framework of Zero-shot Offboard Panoptic Perception for\n  Autonomous Driving","summary":"  Offboard perception aims to automatically generate high-quality 3D labels for\nautonomous driving (AD) scenes. Existing offboard methods focus on 3D object\ndetection with closed-set taxonomy and fail to match human-level recognition\ncapability on the rapidly evolving perception tasks. Due to heavy reliance on\nhuman labels and the prevalence of data imbalance and sparsity, a unified\nframework for offboard auto-labeling various elements in AD scenes that meets\nthe distinct needs of perception tasks is not being fully explored. In this\npaper, we propose a novel multi-modal Zero-shot Offboard Panoptic Perception\n(ZOPP) framework for autonomous driving scenes. ZOPP integrates the powerful\nzero-shot recognition capabilities of vision foundation models and 3D\nrepresentations derived from point clouds. To the best of our knowledge, ZOPP\nrepresents a pioneering effort in the domain of multi-modal panoptic perception\nand auto labeling for autonomous driving scenes. We conduct comprehensive\nempirical studies and evaluations on Waymo open dataset to validate the\nproposed ZOPP on various perception tasks. To further explore the usability and\nextensibility of our proposed ZOPP, we also conduct experiments in downstream\napplications. The results further demonstrate the great potential of our ZOPP\nfor real-world scenarios.\n","authors":["Tao Ma","Hongbin Zhou","Qiusheng Huang","Xuemeng Yang","Jianfei Guo","Bo Zhang","Min Dou","Yu Qiao","Botian Shi","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2411.05311v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.01801v2","updated":"2024-11-08T03:30:52Z","published":"2024-11-04T05:00:49Z","title":"Bootstrapping Top-down Information for Self-modulating Slot Attention","summary":"  Object-centric learning (OCL) aims to learn representations of individual\nobjects within visual scenes without manual supervision, facilitating efficient\nand effective visual reasoning. Traditional OCL methods primarily employ\nbottom-up approaches that aggregate homogeneous visual features to represent\nobjects. However, in complex visual environments, these methods often fall\nshort due to the heterogeneous nature of visual features within an object. To\naddress this, we propose a novel OCL framework incorporating a top-down\npathway. This pathway first bootstraps the semantics of individual objects and\nthen modulates the model to prioritize features relevant to these semantics. By\ndynamically modulating the model based on its own output, our top-down pathway\nenhances the representational quality of objects. Our framework achieves\nstate-of-the-art performance across multiple synthetic and real-world\nobject-discovery benchmarks.\n","authors":["Dongwon Kim","Seoyeon Kim","Suha Kwak"],"pdf_url":"https://arxiv.org/pdf/2411.01801v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05307v1","updated":"2024-11-08T03:23:39Z","published":"2024-11-08T03:23:39Z","title":"Revisiting Network Perturbation for Semi-Supervised Semantic\n  Segmentation","summary":"  In semi-supervised semantic segmentation (SSS), weak-to-strong consistency\nregularization techniques are widely utilized in recent works, typically\ncombined with input-level and feature-level perturbations. However, the\nintegration between weak-to-strong consistency regularization and network\nperturbation has been relatively rare. We note several problems with existing\nnetwork perturbations in SSS that may contribute to this phenomenon. By\nrevisiting network perturbations, we introduce a new approach for network\nperturbation to expand the existing weak-to-strong consistency regularization\nfor unlabeled data. Additionally, we present a volatile learning process for\nlabeled data, which is uncommon in existing research. Building upon previous\nwork that includes input-level and feature-level perturbations, we present\nMLPMatch (Multi-Level-Perturbation Match), an easy-to-implement and efficient\nframework for semi-supervised semantic segmentation. MLPMatch has been\nvalidated on the Pascal VOC and Cityscapes datasets, achieving state-of-the-art\nperformance. Code is available from https://github.com/LlistenL/MLPMatch.\n","authors":["Sien Li","Tao Wang","Ruizhe Hu","Wenxi Liu"],"pdf_url":"https://arxiv.org/pdf/2411.05307v1.pdf","comment":"Accepted by PRCV2024"},{"id":"http://arxiv.org/abs/2405.09828v3","updated":"2024-11-08T03:19:03Z","published":"2024-05-16T06:05:08Z","title":"*: Improving the 3D detector by introducing Voxel2Pillar feature\n  encoding and extracting multi-scale features","summary":"  The multi-line LiDAR is widely used in autonomous vehicles, so point\ncloud-based 3D detectors are essential for autonomous driving. Extracting rich\nmulti-scale features is crucial for point cloud-based 3D detectors in\nautonomous driving due to significant differences in the size of different\ntypes of objects. However, because of the real-time requirements, large-size\nconvolution kernels are rarely used to extract large-scale features in the\nbackbone. Current 3D detectors commonly use feature pyramid networks to obtain\nlarge-scale features; however, some objects containing fewer point clouds are\nfurther lost during down-sampling, resulting in degraded performance. Since\npillar-based schemes require much less computation than voxel-based schemes,\nthey are more suitable for constructing real-time 3D detectors. Hence, we\npropose the *, a pillar-based scheme. We redesigned the feature encoding, the\nbackbone, and the neck of the 3D detector. We propose the Voxel2Pillar feature\nencoding, which uses a sparse convolution constructor to construct pillars with\nricher point cloud features, especially height features. The Voxel2Pillar adds\nmore learnable parameters to the feature encoding, enabling the initial pillars\nto have higher performance ability. We extract multi-scale and large-scale\nfeatures in the proposed fully sparse backbone, which does not utilize\nlarge-size convolutional kernels; the backbone consists of the proposed\nmulti-scale feature extraction module. The neck consists of the proposed sparse\nConvNeXt, whose simple structure significantly improves the performance. We\nvalidate the effectiveness of the proposed * on the Waymo Open Dataset, and the\nobject detection accuracy for vehicles, pedestrians, and cyclists is improved.\nWe also verify the effectiveness of each proposed module in detail through\nablation studies.\n","authors":["Xusheng Li","Chengliang Wang","Shumao Wang","Zhuo Zeng","Ji Liu"],"pdf_url":"https://arxiv.org/pdf/2405.09828v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05302v1","updated":"2024-11-08T03:06:47Z","published":"2024-11-08T03:06:47Z","title":"Adaptive Whole-Body PET Image Denoising Using 3D Diffusion Models with\n  ControlNet","summary":"  Positron Emission Tomography (PET) is a vital imaging modality widely used in\nclinical diagnosis and preclinical research but faces limitations in image\nresolution and signal-to-noise ratio due to inherent physical degradation\nfactors. Current deep learning-based denoising methods face challenges in\nadapting to the variability of clinical settings, influenced by factors such as\nscanner types, tracer choices, dose levels, and acquisition times. In this\nwork, we proposed a novel 3D ControlNet-based denoising method for whole-body\nPET imaging. We first pre-trained a 3D Denoising Diffusion Probabilistic Model\n(DDPM) using a large dataset of high-quality normal-dose PET images. Following\nthis, we fine-tuned the model on a smaller set of paired low- and normal-dose\nPET images, integrating low-dose inputs through a 3D ControlNet architecture,\nthereby making the model adaptable to denoising tasks in diverse clinical\nsettings. Experimental results based on clinical PET datasets show that the\nproposed framework outperformed other state-of-the-art PET image denoising\nmethods both in visual quality and quantitative metrics. This plug-and-play\napproach allows large diffusion models to be fine-tuned and adapted to PET\nimages from diverse acquisition protocols.\n","authors":["Boxiao Yu","Kuang Gong"],"pdf_url":"https://arxiv.org/pdf/2411.05302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01380v2","updated":"2024-11-08T03:05:11Z","published":"2024-02-02T13:03:20Z","title":"Efficient Dynamic-NeRF Based Volumetric Video Coding with Rate\n  Distortion Optimization","summary":"  Volumetric videos, benefiting from immersive 3D realism and interactivity,\nhold vast potential for various applications, while the tremendous data volume\nposes significant challenges for compression. Recently, NeRF has demonstrated\nremarkable potential in volumetric video compression thanks to its simple\nrepresentation and powerful 3D modeling capabilities, where a notable work is\nReRF. However, ReRF separates the modeling from compression process, resulting\nin suboptimal compression efficiency. In contrast, in this paper, we propose a\nvolumetric video compression method based on dynamic NeRF in a more compact\nmanner. Specifically, we decompose the NeRF representation into the coefficient\nfields and the basis fields, incrementally updating the basis fields in the\ntemporal domain to achieve dynamic modeling. Additionally, we perform\nend-to-end joint optimization on the modeling and compression process to\nfurther improve the compression efficiency. Extensive experiments demonstrate\nthat our method achieves higher compression efficiency compared to ReRF on\nvarious datasets.\n","authors":["Zhiyu Zhang","Guo Lu","Huanxiong Liang","Anni Tang","Qiang Hu","Li Song"],"pdf_url":"https://arxiv.org/pdf/2402.01380v2.pdf","comment":"Accepted by IEEE ICME 2024"},{"id":"http://arxiv.org/abs/2411.03807v3","updated":"2024-11-08T03:02:02Z","published":"2024-11-06T10:07:46Z","title":"GS2Pose: Two-stage 6D Object Pose Estimation Guided by Gaussian\n  Splatting","summary":"  This paper proposes a new method for accurate and robust 6D pose estimation\nof novel objects, named GS2Pose. By introducing 3D Gaussian splatting, GS2Pose\ncan utilize the reconstruction results without requiring a high-quality CAD\nmodel, which means it only requires segmented RGBD images as input.\nSpecifically, GS2Pose employs a two-stage structure consisting of coarse\nestimation followed by refined estimation. In the coarse stage, a lightweight\nU-Net network with a polarization attention mechanism, called Pose-Net, is\ndesigned. By using the 3DGS model for supervised training, Pose-Net can\ngenerate NOCS images to compute a coarse pose. In the refinement stage, GS2Pose\nformulates a pose regression algorithm following the idea of reprojection or\nBundle Adjustment (BA), referred to as GS-Refiner. By leveraging Lie algebra to\nextend 3DGS, GS-Refiner obtains a pose-differentiable rendering pipeline that\nrefines the coarse pose by comparing the input images with the rendered images.\nGS-Refiner also selectively updates parameters in the 3DGS model to achieve\nenvironmental adaptation, thereby enhancing the algorithm's robustness and\nflexibility to illuminative variation, occlusion, and other challenging\ndisruptive factors. GS2Pose was evaluated through experiments conducted on the\nLineMod dataset, where it was compared with similar algorithms, yielding highly\ncompetitive results. The code for GS2Pose will soon be released on GitHub.\n","authors":["Jilan Mei","Junbo Li","Cai Meng"],"pdf_url":"https://arxiv.org/pdf/2411.03807v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05292v1","updated":"2024-11-08T02:51:39Z","published":"2024-11-08T02:51:39Z","title":"SimpleBEV: Improved LiDAR-Camera Fusion Architecture for 3D Object\n  Detection","summary":"  More and more research works fuse the LiDAR and camera information to improve\nthe 3D object detection of the autonomous driving system. Recently, a simple\nyet effective fusion framework has achieved an excellent detection performance,\nfusing the LiDAR and camera features in a unified bird's-eye-view (BEV) space.\nIn this paper, we propose a LiDAR-camera fusion framework, named SimpleBEV, for\naccurate 3D object detection, which follows the BEV-based fusion framework and\nimproves the camera and LiDAR encoders, respectively. Specifically, we perform\nthe camera-based depth estimation using a cascade network and rectify the depth\nresults with the depth information derived from the LiDAR points. Meanwhile, an\nauxiliary branch that implements the 3D object detection using only the\ncamera-BEV features is introduced to exploit the camera information during the\ntraining phase. Besides, we improve the LiDAR feature extractor by fusing the\nmulti-scaled sparse convolutional features. Experimental results demonstrate\nthe effectiveness of our proposed method. Our method achieves 77.6\\% NDS\naccuracy on the nuScenes dataset, showcasing superior performance in the 3D\nobject detection track.\n","authors":["Yun Zhao","Zhan Gong","Peiru Zheng","Hong Zhu","Shaohua Wu"],"pdf_url":"https://arxiv.org/pdf/2411.05292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05269v1","updated":"2024-11-08T02:04:21Z","published":"2024-11-08T02:04:21Z","title":"Cancer-Net SCa-Synth: An Open Access Synthetically Generated 2D Skin\n  Lesion Dataset for Skin Cancer Classification","summary":"  In the United States, skin cancer ranks as the most commonly diagnosed\ncancer, presenting a significant public health issue due to its high rates of\noccurrence and the risk of serious complications if not caught early. Recent\nadvancements in dataset curation and deep learning have shown promise in quick\nand accurate detection of skin cancer. However, current open-source datasets\nhave significant class imbalances which impedes the effectiveness of these deep\nlearning models. In healthcare, generative artificial intelligence (AI) models\nhave been employed to create synthetic data, addressing data imbalance in\ndatasets by augmenting underrepresented classes and enhancing the overall\nquality and performance of machine learning models. In this paper, we build on\ntop of previous work by leveraging new advancements in generative AI, notably\nStable Diffusion and DreamBooth. We introduce Cancer-Net SCa-Synth, an open\naccess synthetically generated 2D skin lesion dataset for skin cancer\nclassification. Further analysis on the data effectiveness by comparing the\nISIC 2020 test set performance for training with and without these synthetic\nimages for a simple model highlights the benefits of leveraging synthetic data\nto improve performance. Cancer-Net SCa-Synth is publicly available at\nhttps://github.com/catai9/Cancer-Net-SCa-Synth as part of a global open-source\ninitiative for accelerating machine learning for cancer care.\n","authors":["Chi-en Amy Tai","Oustan Ding","Alexander Wong"],"pdf_url":"https://arxiv.org/pdf/2411.05269v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01167v2","updated":"2024-11-08T02:01:00Z","published":"2024-08-02T10:34:23Z","title":"Rethinking Pre-trained Feature Extractor Selection in Multiple Instance\n  Learning for Whole Slide Image Classification","summary":"  Multiple instance learning (MIL) has become a preferred method for gigapixel\nwhole slide image (WSI) classification without requiring patch-level\nannotations. Current MIL research primarily relies on embedding-based\napproaches, which extract patch features using a pre-trained feature extractor\nand aggregate them for slide-level prediction. Despite the critical role of\nfeature extraction, there is limited guidance on selecting optimal feature\nextractors to maximize WSI performance. This study addresses this gap by\nsystematically evaluating MIL feature extractors across three dimensions:\npre-training dataset, backbone model, and pre-training method. Extensive\nexperiments were conducted on two public WSI datasets (TCGA-NSCLC and\nCamelyon16) using four state-of-the-art (SOTA) MIL models. Our findings reveal\nthat selecting a robust self-supervised learning (SSL) method has a greater\nimpact on performance than relying solely on an in-domain pre-training dataset.\nAdditionally, prioritizing Transformer-based backbones with deeper\narchitectures over CNN-based models and using larger, more diverse pre-training\ndatasets significantly enhances classification outcomes. We believe these\ninsights provide practical guidance for optimizing WSI classification and\nexplain the reasons behind the performance advantages of current SOTA pathology\nfoundation models. Furthermore, this work may inform the development of more\neffective foundation models. Our code is publicly available at\nhttps://anonymous.4open.science/r/MIL-Feature-Extractor-Selection\n","authors":["Bryan Wong","Mun Yong Yi"],"pdf_url":"https://arxiv.org/pdf/2408.01167v2.pdf","comment":"Under submission to ISBI 2025"},{"id":"http://arxiv.org/abs/2411.05265v1","updated":"2024-11-08T01:47:53Z","published":"2024-11-08T01:47:53Z","title":"Image Decomposition: Theory, Numerical Schemes, and Performance\n  Evaluation","summary":"  This paper describes the many image decomposition models that allow to\nseparate structures and textures or structures, textures, and noise. These\nmodels combined a total variation approach with different adapted functional\nspaces such as Besov or Contourlet spaces or a special oscillating function\nspace based on the work of Yves Meyer. We propose a method to evaluate the\nperformance of such algorithms to enhance understanding of the behavior of\nthese models.\n","authors":["Jerome Gilles"],"pdf_url":"https://arxiv.org/pdf/2411.05265v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05261v1","updated":"2024-11-08T01:46:11Z","published":"2024-11-08T01:46:11Z","title":"Decoding Report Generators: A Cyclic Vision-Language Adapter for\n  Counterfactual Explanations","summary":"  Despite significant advancements in report generation methods, a critical\nlimitation remains: the lack of interpretability in the generated text. This\npaper introduces an innovative approach to enhance the explainability of text\ngenerated by report generation models. Our method employs cyclic text\nmanipulation and visual comparison to identify and elucidate the features in\nthe original content that influence the generated text. By manipulating the\ngenerated reports and producing corresponding images, we create a comparative\nframework that highlights key attributes and their impact on the text\ngeneration process. This approach not only identifies the image features\naligned to the generated text but also improves transparency but also provides\ndeeper insights into the decision-making mechanisms of the report generation\nmodels. Our findings demonstrate the potential of this method to significantly\nenhance the interpretability and transparency of AI-generated reports.\n","authors":["Yingying Fang","Zihao Jin","Shaojie Guo","Jinda Liu","Yijian Gao","Junzhi Ning","Zhiling Yue","Zhi Li","Simon LF Walsh","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2411.05261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14856v3","updated":"2024-11-08T01:34:58Z","published":"2024-06-21T04:02:19Z","title":"Accessible, At-Home Detection of Parkinson's Disease via Multi-task\n  Video Analysis","summary":"  Limited accessibility to neurological care leads to underdiagnosed\nParkinson's Disease (PD), preventing early intervention. Existing AI-based PD\ndetection methods primarily focus on unimodal analysis of motor or speech\ntasks, overlooking the multifaceted nature of the disease. To address this, we\nintroduce a large-scale, multi-task video dataset consisting of 1102 sessions\n(each containing videos of finger tapping, facial expression, and speech tasks\ncaptured via webcam) from 845 participants (272 with PD). We propose a novel\nUncertainty-calibrated Fusion Network (UFNet) that leverages this multimodal\ndata to enhance diagnostic accuracy. UFNet employs independent task-specific\nnetworks, trained with Monte Carlo Dropout for uncertainty quantification,\nfollowed by self-attended fusion of features, with attention weights\ndynamically adjusted based on task-specific uncertainties. To ensure\npatient-centered evaluation, the participants were randomly split into three\nsets: 60% for training, 20% for model selection, and 20% for final performance\nevaluation. UFNet significantly outperformed single-task models in terms of\naccuracy, area under the ROC curve (AUROC), and sensitivity while maintaining\nnon-inferior specificity. Withholding uncertain predictions further boosted the\nperformance, achieving 88.0+-0.3%$ accuracy, 93.0+-0.2% AUROC, 79.3+-0.9%\nsensitivity, and 92.6+-0.3% specificity, at the expense of not being able to\npredict for 2.3+-0.3% data (+- denotes 95% confidence interval). Further\nanalysis suggests that the trained model does not exhibit any detectable bias\nacross sex and ethnic subgroups and is most effective for individuals aged\nbetween 50 and 80. Requiring only a webcam and microphone, our approach\nfacilitates accessible home-based PD screening, especially in regions with\nlimited healthcare resources.\n","authors":["Md Saiful Islam","Tariq Adnan","Jan Freyberg","Sangwu Lee","Abdelrahman Abdelkader","Meghan Pawlik","Cathe Schwartz","Karen Jaffe","Ruth B. Schneider","E Ray Dorsey","Ehsan Hoque"],"pdf_url":"https://arxiv.org/pdf/2406.14856v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.01778v2","updated":"2024-11-08T01:17:17Z","published":"2023-07-04T15:31:03Z","title":"Physically Realizable Natural-Looking Clothing Textures Evade Person\n  Detectors via 3D Modeling","summary":"  Recent works have proposed to craft adversarial clothes for evading person\ndetectors, while they are either only effective at limited viewing angles or\nvery conspicuous to humans. We aim to craft adversarial texture for clothes\nbased on 3D modeling, an idea that has been used to craft rigid adversarial\nobjects such as a 3D-printed turtle. Unlike rigid objects, humans and clothes\nare non-rigid, leading to difficulties in physical realization. In order to\ncraft natural-looking adversarial clothes that can evade person detectors at\nmultiple viewing angles, we propose adversarial camouflage textures (AdvCaT)\nthat resemble one kind of the typical textures of daily clothes, camouflage\ntextures. We leverage the Voronoi diagram and Gumbel-softmax trick to\nparameterize the camouflage textures and optimize the parameters via 3D\nmodeling. Moreover, we propose an efficient augmentation pipeline on 3D meshes\ncombining topologically plausible projection (TopoProj) and Thin Plate Spline\n(TPS) to narrow the gap between digital and real-world objects. We printed the\ndeveloped 3D texture pieces on fabric materials and tailored them into T-shirts\nand trousers. Experiments show high attack success rates of these clothes\nagainst multiple detectors.\n","authors":["Zhanhao Hu","Wenda Chu","Xiaopei Zhu","Hui Zhang","Bo Zhang","Xiaolin Hu"],"pdf_url":"https://arxiv.org/pdf/2307.01778v2.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2410.00321v5","updated":"2024-11-08T01:07:53Z","published":"2024-10-01T01:41:23Z","title":"A Cat Is A Cat (Not A Dog!): Unraveling Information Mix-ups in\n  Text-to-Image Encoders through Causal Analysis and Embedding Optimization","summary":"  This paper analyzes the impact of causal manner in the text encoder of\ntext-to-image (T2I) diffusion models, which can lead to information bias and\nloss. Previous works have focused on addressing the issues through the\ndenoising process. However, there is no research discussing how text embedding\ncontributes to T2I models, especially when generating more than one object. In\nthis paper, we share a comprehensive analysis of text embedding: i) how text\nembedding contributes to the generated images and ii) why information gets lost\nand biases towards the first-mentioned object. Accordingly, we propose a simple\nbut effective text embedding balance optimization method, which is\ntraining-free, with an improvement of 125.42% on information balance in stable\ndiffusion. Furthermore, we propose a new automatic evaluation metric that\nquantifies information loss more accurately than existing methods, achieving\n81% concordance with human assessments. This metric effectively measures the\npresence and accuracy of objects, addressing the limitations of current\ndistribution scores like CLIP's text-image similarities.\n","authors":["Chieh-Yun Chen","Chiang Tseng","Li-Wu Tsao","Hong-Han Shuai"],"pdf_url":"https://arxiv.org/pdf/2410.00321v5.pdf","comment":"Accepted to NeurIPS 2024\n  (https://neurips.cc/virtual/2024/poster/94705)"},{"id":"http://arxiv.org/abs/2411.05254v1","updated":"2024-11-08T00:58:12Z","published":"2024-11-08T00:58:12Z","title":"Hierarchical Visual Feature Aggregation for OCR-Free Document\n  Understanding","summary":"  We present a novel OCR-free document understanding framework based on\npretrained Multimodal Large Language Models (MLLMs). Our approach employs\nmulti-scale visual features to effectively handle various font sizes within\ndocument images. To address the increasing costs of considering the multi-scale\nvisual inputs for MLLMs, we propose the Hierarchical Visual Feature Aggregation\n(HVFA) module, designed to reduce the number of input tokens to LLMs.\nLeveraging a feature pyramid with cross-attentive pooling, our approach\neffectively manages the trade-off between information loss and efficiency\nwithout being affected by varying document image sizes. Furthermore, we\nintroduce a novel instruction tuning task, which facilitates the model's\ntext-reading capability by learning to predict the relative positions of input\ntext, eventually minimizing the risk of truncated text caused by the limited\ncapacity of LLMs. Comprehensive experiments validate the effectiveness of our\napproach, demonstrating superior performance in various document understanding\ntasks.\n","authors":["Jaeyoo Park","Jin Young Choi","Jeonghyung Park","Bohyung Han"],"pdf_url":"https://arxiv.org/pdf/2411.05254v1.pdf","comment":"NeurIPS 2024"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2404.04264v4","updated":"2024-11-08T18:35:49Z","published":"2024-03-17T17:01:45Z","title":"Logic Query of Thoughts: Guiding Large Language Models to Answer Complex\n  Logic Queries with Knowledge Graphs","summary":"  Despite the superb performance in many tasks, large language models (LLMs)\nbear the risk of generating hallucination or even wrong answers when confronted\nwith tasks that demand the accuracy of knowledge. The issue becomes even more\nnoticeable when addressing logic queries that require multiple logic reasoning\nsteps. On the other hand, knowledge graph (KG) based question answering methods\nare capable of accurately identifying the correct answers with the help of\nknowledge graph, yet its accuracy could quickly deteriorate when the knowledge\ngraph itself is sparse and incomplete. It remains a critical challenge on how\nto integrate knowledge graph reasoning with LLMs in a mutually beneficial way\nso as to mitigate both the hallucination problem of LLMs as well as the\nincompleteness issue of knowledge graphs. In this paper, we propose\n'Logic-Query-of-Thoughts' (LGOT) which is the first of its kind to combine LLMs\nwith knowledge graph based logic query reasoning. LGOT seamlessly combines\nknowledge graph reasoning and LLMs, effectively breaking down complex logic\nqueries into easy to answer subquestions. Through the utilization of both\nknowledge graph reasoning and LLMs, it successfully derives answers for each\nsubquestion. By aggregating these results and selecting the highest quality\ncandidate answers for each step, LGOT achieves accurate results to complex\nquestions. Our experimental findings demonstrate substantial performance\nenhancements, with up to 20% improvement over ChatGPT.\n","authors":["Lihui Liu","Zihao Wang","Ruizhong Qiu","Yikun Ban","Eunice Chan","Yangqiu Song","Jingrui He","Hanghang Tong"],"pdf_url":"https://arxiv.org/pdf/2404.04264v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05649v1","updated":"2024-11-08T15:45:33Z","published":"2024-11-08T15:45:33Z","title":"Harnessing High-Level Song Descriptors towards Natural Language-Based\n  Music Recommendation","summary":"  Recommender systems relying on Language Models (LMs) have gained popularity\nin assisting users to navigate large catalogs. LMs often exploit item\nhigh-level descriptors, i.e. categories or consumption contexts, from training\ndata or user preferences. This has been proven effective in domains like movies\nor products. However, in the music domain, understanding how effectively LMs\nutilize song descriptors for natural language-based music recommendation is\nrelatively limited. In this paper, we assess LMs effectiveness in recommending\nsongs based on user natural language descriptions and items with descriptors\nlike genres, moods, and listening contexts. We formulate the recommendation\ntask as a dense retrieval problem and assess LMs as they become increasingly\nfamiliar with data pertinent to the task and domain. Our findings reveal\nimproved performance as LMs are fine-tuned for general language similarity,\ninformation retrieval, and mapping longer descriptions to shorter, high-level\ndescriptors in music.\n","authors":["Elena V. Epure","Gabriel Meseguer Brocal","Darius Afchar","Romain Hennequin"],"pdf_url":"https://arxiv.org/pdf/2411.05649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05572v1","updated":"2024-11-08T13:51:37Z","published":"2024-11-08T13:51:37Z","title":"Why These Documents? Explainable Generative Retrieval with Hierarchical\n  Category Paths","summary":"  Generative retrieval has recently emerged as a new alternative of traditional\ninformation retrieval approaches. However, existing generative retrieval\nmethods directly decode docid when a query is given, making it impossible to\nprovide users with explanations as an answer for \"Why this document is\nretrieved?\". To address this limitation, we propose Hierarchical Category\nPath-Enhanced Generative Retrieval(HyPE), which enhances explainability by\ngenerating hierarchical category paths step-by-step before decoding docid. HyPE\nleverages hierarchical category paths as explanation, progressing from broad to\nspecific semantic categories. This approach enables diverse explanations for\nthe same document depending on the query by using shared category paths between\nthe query and the document, and provides reasonable explanation by reflecting\nthe document's semantic structure through a coarse-to-fine manner. HyPE\nconstructs category paths with external high-quality semantic hierarchy,\nleverages LLM to select appropriate candidate paths for each document, and\noptimizes the generative retrieval model with path-augmented dataset. During\ninference, HyPE utilizes path-aware reranking strategy to aggregate diverse\ntopic information, allowing the most relevant documents to be prioritized in\nthe final ranked list of docids. Our extensive experiments demonstrate that\nHyPE not only offers a high level of explainability but also improves the\nretrieval performance in the document retrieval task.\n","authors":["Sangam Lee","Ryang Heo","SeongKu Kang","Susik Yoon","Jinyoung Yeo","Dongha Lee"],"pdf_url":"https://arxiv.org/pdf/2411.05572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10321v2","updated":"2024-11-08T13:29:47Z","published":"2024-04-16T07:05:16Z","title":"Cluster-based Graph Collaborative Filtering","summary":"  Graph Convolution Networks (GCNs) have significantly succeeded in learning\nuser and item representations for recommendation systems. The core of their\nefficacy is the ability to explicitly exploit the collaborative signals from\nboth the first- and high-order neighboring nodes. However, most existing\nGCN-based methods overlook the multiple interests of users while performing\nhigh-order graph convolution. Thus, the noisy information from unreliable\nneighbor nodes (e.g., users with dissimilar interests) negatively impacts the\nrepresentation learning of the target node. Additionally, conducting graph\nconvolution operations without differentiating high-order neighbors suffers the\nover-smoothing issue when stacking more layers, resulting in performance\ndegradation. In this paper, we aim to capture more valuable information from\nhigh-order neighboring nodes while avoiding noise for better representation\nlearning of the target node. To achieve this goal, we propose a novel GCN-based\nrecommendation model, termed Cluster-based Graph Collaborative Filtering\n(ClusterGCF). This model performs high-order graph convolution on\ncluster-specific graphs, which are constructed by capturing the multiple\ninterests of users and identifying the common interests among them.\nSpecifically, we design an unsupervised and optimizable soft node clustering\napproach to classify user and item nodes into multiple clusters. Based on the\nsoft node clustering results and the topology of the user-item interaction\ngraph, we assign the nodes with probabilities for different clusters to\nconstruct the cluster-specific graphs. To evaluate the effectiveness of\nClusterGCF, we conducted extensive experiments on four publicly available\ndatasets. Experimental results demonstrate that our model can significantly\nimprove recommendation performance.\n","authors":["Fan Liu","Shuai Zhao","Zhiyong Cheng","Liqiang Nie","Mohan Kankanhalli"],"pdf_url":"https://arxiv.org/pdf/2404.10321v2.pdf","comment":"Accepted by ACM TOIS"},{"id":"http://arxiv.org/abs/2411.05508v1","updated":"2024-11-08T12:08:17Z","published":"2024-11-08T12:08:17Z","title":"An Early FIRST Reproduction and Improvements to Single-Token Decoding\n  for Fast Listwise Reranking","summary":"  Recent advances have demonstrated that large language models (LLMs) excel as\nlistwise rerankers, but their high computational demands remain a barrier to\nwidespread adoption. Further, the traditional language modeling (LM) objective\nis not ideally suited for reranking tasks. FIRST is a novel approach that\naddresses these challenges by integrating a learning-to-rank objective and\nleveraging the logits of only the first generated token, thereby significantly\nreducing inference latency compared to traditional LLM rerankers. In this\nstudy, we extend the evaluation of FIRST to the TREC Deep Learning datasets\n(DL19-22), validating its robustness across diverse domains. We investigate the\ninfluence of different first-stage retrievers on FIRST rerankers, observing\ndiminishing returns and patterns consistent with traditional LLM rerankers.\nThrough applying the FIRST objective to a broader range of backbone models, we\nachieve effectiveness surpassing the original implementation. Our experiments\nconfirm that fast reranking with single-token logits does not compromise\nout-of-domain reranking quality. To better quantify the computational savings\nin the original study, we measure and compare latency to find a 21%-42% gain\nacross various models and benchmarks. Moreover, while LM training implicitly\nimproves zero-shot single-token reranking, our experiments also raise questions\nabout whether LM pre-training may hinder subsequent fine-tuning with the FIRST\nobjective. These findings pave the way for more efficient and effective\nlistwise reranking in future applications.\n","authors":["Zijian Chen","Ronak Pradeep","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.05508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05442v1","updated":"2024-11-08T09:40:53Z","published":"2024-11-08T09:40:53Z","title":"IntellBot: Retrieval Augmented LLM Chatbot for Cyber Threat Knowledge\n  Delivery","summary":"  In the rapidly evolving landscape of cyber security, intelligent chatbots are\ngaining prominence. Artificial Intelligence, Machine Learning, and Natural\nLanguage Processing empower these chatbots to handle user inquiries and deliver\nthreat intelligence. This helps cyber security knowledge readily available to\nboth professionals and the public. Traditional rule-based chatbots often lack\nflexibility and struggle to adapt to user interactions. In contrast, Large\nLanguage Model-based chatbots offer contextually relevant information across\nmultiple domains and adapt to evolving conversational contexts. In this work,\nwe develop IntellBot, an advanced cyber security Chatbot built on top of\ncutting-edge technologies like Large Language Models and Langchain alongside a\nRetrieval-Augmented Generation model to deliver superior capabilities. This\nchatbot gathers information from diverse data sources to create a comprehensive\nknowledge base covering known vulnerabilities, recent cyber attacks, and\nemerging threats. It delivers tailored responses, serving as a primary hub for\ncyber security insights. By providing instant access to relevant information\nand resources, this IntellBot enhances threat intelligence, incident response,\nand overall security posture, saving time and empowering users with knowledge\nof cyber security best practices. Moreover, we analyzed the performance of our\ncopilot using a two-stage evaluation strategy. We achieved BERT score above 0.8\nby indirect approach and a cosine similarity score ranging from 0.8 to 1, which\naffirms the accuracy of our copilot. Additionally, we utilized RAGAS to\nevaluate the RAG model, and all evaluation metrics consistently produced scores\nabove 0.77, highlighting the efficacy of our system.\n","authors":["Dincy R. Arikkat","Abhinav M.","Navya Binu","Parvathi M.","Navya Biju","K. S. Arunima","Vinod P.","Rafidha Rehiman K. A.","Mauro Conti"],"pdf_url":"https://arxiv.org/pdf/2411.05442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05375v1","updated":"2024-11-08T07:05:06Z","published":"2024-11-08T07:05:06Z","title":"Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking","summary":"  Current automated fact-checking (AFC) approaches commonly evaluate evidence\neither implicitly via the predicted verdicts or by comparing retrieved evidence\nwith a predefined closed knowledge source, such as Wikipedia. However, these\nmethods suffer from limitations, resulting from their reliance on evaluation\nmetrics developed for different purposes and constraints imposed by closed\nknowledge sources. Recent advances in natural language generation (NLG)\nevaluation offer new possibilities for evidence assessment. In this work, we\nintroduce Ev2R, an evaluation framework for AFC that comprises three types of\napproaches for evidence evaluation: reference-based, proxy-reference, and\nreference-less. We evaluate their effectiveness through agreement with human\nratings and adversarial tests, and demonstrate that prompt-based scorers,\nparticularly those leveraging LLMs and reference evidence, outperform\ntraditional evaluation approaches.\n","authors":["Mubashara Akhtar","Michael Schlichtkrull","Andreas Vlachos"],"pdf_url":"https://arxiv.org/pdf/2411.05375v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2411.05340v1","updated":"2024-11-08T05:43:40Z","published":"2024-11-08T05:43:40Z","title":"Improving Multi-Domain Task-Oriented Dialogue System with Offline\n  Reinforcement Learning","summary":"  Task-oriented dialogue (TOD) system is designed to accomplish user-defined\ntasks through dialogues. The TOD system has progressed towards end-to-end\nmodeling by leveraging pre-trained large language models. Fine-tuning the\npre-trained language models using only supervised learning leads to the\nexposure bias and token loss problem and it deviates the models from completing\nthe user's task. To address these issues, we propose a TOD system that\nleverages a unified pre-trained language model, GPT2, as a base model. It is\noptimized using supervised learning and reinforcement learning (RL). The issues\nin the TOD system are mitigated using a non-differentiable reward function. The\nreward is calculated using the weighted sum of the success rate and BLEU\nevaluation metrics. The success rate and BLEU metrics in reward calculation\nguide the language model for user task completion while ensuring a coherent and\nfluent response. Our model is acquired by fine-tuning a pre-trained model on\nthe dialogue-session level which comprises user utterance, belief state, system\nact, and system response. Experimental results on MultiWOZ2.1 demonstrate that\nour model increases the inform rate by 1.60% and the success rate by 3.17%\ncompared to the baseline.\n","authors":["Dharmendra Prajapat","Durga Toshniwal"],"pdf_url":"https://arxiv.org/pdf/2411.05340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10108v3","updated":"2024-11-08T03:58:00Z","published":"2023-10-16T06:41:16Z","title":"On Generative Agents in Recommendation","summary":"  Recommender systems are the cornerstone of today's information dissemination,\nyet a disconnect between offline metrics and online performance greatly hinders\ntheir development. Addressing this challenge, we envision a recommendation\nsimulator, capitalizing on recent breakthroughs in human-level intelligence\nexhibited by Large Language Models (LLMs). We propose Agent4Rec, a user\nsimulator in recommendation, leveraging LLM-empowered generative agents\nequipped with user profile, memory, and actions modules specifically tailored\nfor the recommender system. In particular, these agents' profile modules are\ninitialized using real-world datasets (e.g. MovieLens, Steam, Amazon-Book),\ncapturing users' unique tastes and social traits; memory modules log both\nfactual and emotional memories and are integrated with an emotion-driven\nreflection mechanism; action modules support a wide variety of behaviors,\nspanning both taste-driven and emotion-driven actions. Each agent interacts\nwith personalized recommender models in a page-by-page manner, relying on a\npre-implemented collaborative filtering-based recommendation algorithm. We\ndelve into both the capabilities and limitations of Agent4Rec, aiming to\nexplore an essential research question: ``To what extent can LLM-empowered\ngenerative agents faithfully simulate the behavior of real, autonomous humans\nin recommender systems?'' Extensive and multi-faceted evaluations of Agent4Rec\nhighlight both the alignment and deviation between agents and user-personalized\npreferences. Beyond mere performance comparison, we explore insightful\nexperiments, such as emulating the filter bubble effect and discovering the\nunderlying causal relationships in recommendation tasks. Our codes are\navailable at https://github.com/LehengTHU/Agent4Rec.\n","authors":["An Zhang","Yuxin Chen","Leheng Sheng","Xiang Wang","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2310.10108v3.pdf","comment":"SIGIR 2024 perspective paper"},{"id":"http://arxiv.org/abs/2308.02580v3","updated":"2024-11-08T02:21:38Z","published":"2023-08-03T16:13:46Z","title":"Feature Noise Resilient for QoS Prediction with Probabilistic Deep\n  Supervision","summary":"  Accurate Quality of Service (QoS) prediction is essential for enhancing user\nsatisfaction in web recommendation systems, yet existing prediction models\noften overlook feature noise, focusing predominantly on label noise. In this\npaper, we present the Probabilistic Deep Supervision Network (PDS-Net), a\nrobust framework designed to effectively identify and mitigate feature noise,\nthereby improving QoS prediction accuracy. PDS-Net operates with a dual-branch\narchitecture: the main branch utilizes a decoder network to learn a\nGaussian-based prior distribution from known features, while the second branch\nderives a posterior distribution based on true labels. A key innovation of\nPDS-Net is its condition-based noise recognition loss function, which enables\nprecise identification of noisy features in objects (users or services). Once\nnoisy features are identified, PDS-Net refines the feature's prior\ndistribution, aligning it with the posterior distribution, and propagates this\nadjusted distribution to intermediate layers, effectively reducing noise\ninterference. Extensive experiments conducted on two real-world QoS datasets\ndemonstrate that PDS-Net consistently outperforms existing models, achieving an\naverage improvement of 8.91% in MAE on Dataset D1 and 8.32% on Dataset D2\ncompared to the ate-of-the-art. These results highlight PDS-Net's ability to\naccurately capture complex user-service relationships and handle feature noise,\nunderscoring its robustness and versatility across diverse QoS prediction\nenvironments.\n","authors":["Ziliang Wang","Xiaohong Zhang","Ze Shi Li","Sheng Huang","Meng Yan"],"pdf_url":"https://arxiv.org/pdf/2308.02580v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16156v2","updated":"2024-11-08T00:40:05Z","published":"2024-10-21T16:21:45Z","title":"Limpeh ga li gong: Challenges in Singlish Annotations","summary":"  Singlish, or Colloquial Singapore English, is a language formed from oral and\nsocial communication within multicultural Singapore. In this work, we work on a\nfundamental Natural Language Processing (NLP) task: Parts-Of-Speech (POS)\ntagging of Singlish sentences. For our analysis, we build a parallel Singlish\ndataset containing direct English translations and POS tags, with translation\nand POS annotation done by native Singlish speakers. Our experiments show that\nautomatic transition- and transformer- based taggers perform with only $\\sim\n80\\%$ accuracy when evaluated against human-annotated POS labels, suggesting\nthat there is indeed room for improvement on computation analysis of the\nlanguage. We provide an exposition of challenges in Singlish annotation: its\ninconsistencies in form and semantics, the highly context-dependent particles\nof the language, its structural unique expressions, and the variation of the\nlanguage on different mediums. Our task definition, resultant labels and\nresults reflects the challenges in analysing colloquial languages formulated\nfrom a variety of dialects, and paves the way for future studies beyond POS\ntagging.\n","authors":["Luo Qi Chan","Lynnette Hui Xian Ng"],"pdf_url":"https://arxiv.org/pdf/2410.16156v2.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2404.08627v2","updated":"2024-11-08T18:56:42Z","published":"2024-04-12T17:41:05Z","title":"Is ChatGPT Transforming Academics' Writing Style?","summary":"  Based on one million arXiv papers submitted from May 2018 to January 2024, we\nassess the textual density of ChatGPT's writing style in their abstracts\nthrough a statistical analysis of word frequency changes. Our model is\ncalibrated and validated on a mixture of real abstracts and ChatGPT-modified\nabstracts (simulated data) after a careful noise analysis. The words used for\nestimation are not fixed but adaptive, including those with decreasing\nfrequency. We find that large language models (LLMs), represented by ChatGPT,\nare having an increasing impact on arXiv abstracts, especially in the field of\ncomputer science, where the fraction of LLM-style abstracts is estimated to be\napproximately 35%, if we take the responses of GPT-3.5 to one simple prompt,\n\"revise the following sentences\", as a baseline. We conclude with an analysis\nof both positive and negative aspects of the penetration of LLMs into\nacademics' writing style.\n","authors":["Mingmeng Geng","Roberto Trotta"],"pdf_url":"https://arxiv.org/pdf/2404.08627v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2403.09539v3","updated":"2024-11-08T18:56:41Z","published":"2024-03-14T16:27:49Z","title":"Logits of API-Protected LLMs Leak Proprietary Information","summary":"  Large language model (LLM) providers often hide the architectural details and\nparameters of their proprietary models by restricting public access to a\nlimited API. In this work we show that, with only a conservative assumption\nabout the model architecture, it is possible to learn a surprisingly large\namount of non-public information about an API-protected LLM from a relatively\nsmall number of API queries (e.g., costing under $1000 USD for OpenAI's\ngpt-3.5-turbo). Our findings are centered on one key observation: most modern\nLLMs suffer from a softmax bottleneck, which restricts the model outputs to a\nlinear subspace of the full output space. We exploit this fact to unlock\nseveral capabilities, including (but not limited to) obtaining cheap\nfull-vocabulary outputs, auditing for specific types of model updates,\nidentifying the source LLM given a single full LLM output, and even efficiently\ndiscovering the LLM's hidden size. Our empirical investigations show the\neffectiveness of our methods, which allow us to estimate the embedding size of\nOpenAI's gpt-3.5-turbo to be about 4096. Lastly, we discuss ways that LLM\nproviders can guard against these attacks, as well as how these capabilities\ncan be viewed as a feature (rather than a bug) by allowing for greater\ntransparency and accountability.\n","authors":["Matthew Finlayson","Xiang Ren","Swabha Swayamdipta"],"pdf_url":"https://arxiv.org/pdf/2403.09539v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05779v1","updated":"2024-11-08T18:46:40Z","published":"2024-11-08T18:46:40Z","title":"Curriculum Learning for Few-Shot Domain Adaptation in CT-based Airway\n  Tree Segmentation","summary":"  Despite advances with deep learning (DL), automated airway segmentation from\nchest CT scans continues to face challenges in segmentation quality and\ngeneralization across cohorts. To address these, we propose integrating\nCurriculum Learning (CL) into airway segmentation networks, distributing the\ntraining set into batches according to ad-hoc complexity scores derived from CT\nscans and corresponding ground-truth tree features. We specifically investigate\nfew-shot domain adaptation, targeting scenarios where manual annotation of a\nfull fine-tuning dataset is prohibitively expensive. Results are reported on\ntwo large open-cohorts (ATM22 and AIIB23) with high performance using CL for\nfull training (Source domain) and few-shot fine-tuning (Target domain), but\nwith also some insights on potential detrimental effects if using a classic\nBootstrapping scoring function or if not using proper scan sequencing.\n","authors":["Maxime Jacovella","Ali Keshavarzi","Elsa Angelini"],"pdf_url":"https://arxiv.org/pdf/2411.05779v1.pdf","comment":"Under review for 22nd IEEE International Symposium on Biomedical\n  Imaging (ISBI), Houston, TX, USA"},{"id":"http://arxiv.org/abs/2411.05771v1","updated":"2024-11-08T18:33:03Z","published":"2024-11-08T18:33:03Z","title":"Sketched Equivariant Imaging Regularization and Deep Internal Learning\n  for Inverse Problems","summary":"  Equivariant Imaging (EI) regularization has become the de-facto technique for\nunsupervised training of deep imaging networks, without any need of\nground-truth data. Observing that the EI-based unsupervised training paradigm\ncurrently has significant computational redundancy leading to inefficiency in\nhigh-dimensional applications, we propose a sketched EI regularization which\nleverages the randomized sketching techniques for acceleration. We then extend\nour sketched EI regularization to develop an accelerated deep internal learning\nframework -- Sketched Equivariant Deep Image Prior (Sk.EI-DIP), which can be\nefficiently applied for single-image and task-adapted reconstruction. Our\nnumerical study on X-ray CT image reconstruction tasks demonstrate that our\napproach can achieve order-of-magnitude computational acceleration over\nstandard EI-based counterpart in single-input setting, and network adaptation\nat test time.\n","authors":["Guixian Xu","Jinglai Li","Junqi Tang"],"pdf_url":"https://arxiv.org/pdf/2411.05771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05007v2","updated":"2024-11-08T18:32:59Z","published":"2024-11-07T18:59:58Z","title":"SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion\n  Models","summary":"  Diffusion models have been proven highly effective at generating high-quality\nimages. However, as these models grow larger, they require significantly more\nmemory and suffer from higher latency, posing substantial challenges for\ndeployment. In this work, we aim to accelerate diffusion models by quantizing\ntheir weights and activations to 4 bits. At such an aggressive level, both\nweights and activations are highly sensitive, where conventional post-training\nquantization methods for large language models like smoothing become\ninsufficient. To overcome this limitation, we propose SVDQuant, a new 4-bit\nquantization paradigm. Different from smoothing which redistributes outliers\nbetween weights and activations, our approach absorbs these outliers using a\nlow-rank branch. We first consolidate the outliers by shifting them from\nactivations to weights, then employ a high-precision low-rank branch to take in\nthe weight outliers with Singular Value Decomposition (SVD). This process eases\nthe quantization on both sides. However, na\\\"{\\i}vely running the low-rank\nbranch independently incurs significant overhead due to extra data movement of\nactivations, negating the quantization speedup. To address this, we co-design\nan inference engine Nunchaku that fuses the kernels of the low-rank branch into\nthose of the low-bit branch to cut off redundant memory access. It can also\nseamlessly support off-the-shelf low-rank adapters (LoRAs) without the need for\nre-quantization. Extensive experiments on SDXL, PixArt-$\\Sigma$, and FLUX.1\nvalidate the effectiveness of SVDQuant in preserving image quality. We reduce\nthe memory usage for the 12B FLUX.1 models by 3.5$\\times$, achieving\n3.0$\\times$ speedup over the 4-bit weight-only quantized baseline on the 16GB\nlaptop 4090 GPU, paving the way for more interactive applications on PCs. Our\nquantization library and inference engine are open-sourced.\n","authors":["Muyang Li","Yujun Lin","Zhekai Zhang","Tianle Cai","Xiuyu Li","Junxian Guo","Enze Xie","Chenlin Meng","Jun-Yan Zhu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2411.05007v2.pdf","comment":"Quantization Library: https://github.com/mit-han-lab/deepcompressor\n  Inference Engine: https://github.com/mit-han-lab/nunchaku Website:\n  https://hanlab.mit.edu/projects/svdquant Demo: https://svdquant.mit.edu Blog:\n  https://hanlab.mit.edu/blog/svdquant"},{"id":"http://arxiv.org/abs/2411.05764v1","updated":"2024-11-08T18:26:17Z","published":"2024-11-08T18:26:17Z","title":"FinDVer: Explainable Claim Verification over Long and Hybrid-Content\n  Financial Documents","summary":"  We introduce FinDVer, a comprehensive benchmark specifically designed to\nevaluate the explainable claim verification capabilities of LLMs in the context\nof understanding and analyzing long, hybrid-content financial documents.\nFinDVer contains 2,400 expert-annotated examples, divided into three subsets:\ninformation extraction, numerical reasoning, and knowledge-intensive reasoning,\neach addressing common scenarios encountered in real-world financial contexts.\nWe assess a broad spectrum of LLMs under long-context and RAG settings. Our\nresults show that even the current best-performing system, GPT-4o, still lags\nbehind human experts. We further provide in-depth analysis on long-context and\nRAG setting, Chain-of-Thought reasoning, and model reasoning errors, offering\ninsights to drive future advancements. We believe that FinDVer can serve as a\nvaluable benchmark for evaluating LLMs in claim verification over complex,\nexpert-domain documents.\n","authors":["Yilun Zhao","Yitao Long","Yuru Jiang","Chengye Wang","Weiyuan Chen","Hongjun Liu","Yiming Zhang","Xiangru Tang","Chen Zhao","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2411.05764v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2408.10162v2","updated":"2024-11-08T18:22:46Z","published":"2024-08-19T17:16:35Z","title":"Physics-Aware Combinatorial Assembly Sequence Planning using Data-free\n  Action Masking","summary":"  Combinatorial assembly uses standardized unit primitives to build objects\nthat satisfy user specifications. This paper studies assembly sequence planning\n(ASP) for physical combinatorial assembly. Given the shape of the desired\nobject, the goal is to find a sequence of actions for placing unit primitives\nto build the target object. In particular, we aim to ensure the planned\nassembly sequence is physically executable. However, ASP for combinatorial\nassembly is particularly challenging due to its combinatorial nature. To\naddress the challenge, we employ deep reinforcement learning to learn a\nconstruction policy for placing unit primitives sequentially to build the\ndesired object. Specifically, we design an online physics-aware action mask\nthat filters out invalid actions, which effectively guides policy learning and\nensures violation-free deployment. In the end, we apply the proposed method to\nLego assembly with more than 250 3D structures. The experiment results\ndemonstrate that the proposed method plans physically valid assembly sequences\nto build all structures, achieving a $100\\%$ success rate, whereas the best\ncomparable baseline fails more than $40$ structures. Our implementation is\navailable at\n\\url{https://github.com/intelligent-control-lab/PhysicsAwareCombinatorialASP}.\n","authors":["Ruixuan Liu","Alan Chen","Weiye Zhao","Changliu Liu"],"pdf_url":"https://arxiv.org/pdf/2408.10162v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.08657v2","updated":"2024-11-08T18:18:23Z","published":"2023-05-15T14:02:35Z","title":"Meta-models for transfer learning in source localisation","summary":"  In practice, non-destructive testing (NDT) procedures tend to consider\nexperiments (and their respective models) as distinct, conducted in isolation\nand associated with independent data. In contrast, this work looks to capture\nthe interdependencies between acoustic emission (AE) experiments (as\nmeta-models) and then use the resulting functions to predict the model\nhyperparameters for previously unobserved systems. We utilise a Bayesian\nmultilevel approach (similar to deep Gaussian Processes) where a higher level\nmeta-model captures the inter-task relationships. Our key contribution is how\nknowledge of the experimental campaign can be encoded between tasks as well as\nwithin tasks. We present an example of AE time-of-arrival mapping for source\nlocalisation, to illustrate how multilevel models naturally lend themselves to\nrepresenting aggregate systems in engineering. We constrain the meta-model\nbased on domain knowledge, then use the inter-task functions for transfer\nlearning, predicting hyperparameters for models of previously unobserved\nexperiments (for a specific design).\n","authors":["Lawrence A. Bull","Matthew R. Jones","Elizabeth J. Cross","Andrew Duncan","Mark Girolami"],"pdf_url":"https://arxiv.org/pdf/2305.08657v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05757v1","updated":"2024-11-08T18:18:18Z","published":"2024-11-08T18:18:18Z","title":"Tract-RLFormer: A Tract-Specific RL policy based Decoder-only\n  Transformer Network","summary":"  Fiber tractography is a cornerstone of neuroimaging, enabling the detailed\nmapping of the brain's white matter pathways through diffusion MRI. This is\ncrucial for understanding brain connectivity and function, making it a valuable\ntool in neurological applications. Despite its importance, tractography faces\nchallenges due to its complexity and susceptibility to false positives,\nmisrepresenting vital pathways. To address these issues, recent strategies have\nshifted towards deep learning, utilizing supervised learning, which depends on\nprecise ground truth, or reinforcement learning, which operates without it. In\nthis work, we propose Tract-RLFormer, a network utilizing both supervised and\nreinforcement learning, in a two-stage policy refinement process that markedly\nimproves the accuracy and generalizability across various data-sets. By\nemploying a tract-specific approach, our network directly delineates the tracts\nof interest, bypassing the traditional segmentation process. Through rigorous\nvalidation on datasets such as TractoInferno, HCP, and ISMRM-2015, our\nmethodology demonstrates a leap forward in tractography, showcasing its ability\nto accurately map the brain's white matter tracts.\n","authors":["Ankita Joshi","Ashutosh Sharma","Anoushkrit Goel","Ranjeet Ranjan Jha","Chirag Ahuja","Arnav Bhavsar","Aditya Nigam"],"pdf_url":"https://arxiv.org/pdf/2411.05757v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01702v3","updated":"2024-11-08T18:17:39Z","published":"2024-05-02T19:55:30Z","title":"Optimization without Retraction on the Random Generalized Stiefel\n  Manifold","summary":"  Optimization over the set of matrices $X$ that satisfy $X^\\top B X = I_p$,\nreferred to as the generalized Stiefel manifold, appears in many applications\ninvolving sampled covariance matrices such as the canonical correlation\nanalysis (CCA), independent component analysis (ICA), and the generalized\neigenvalue problem (GEVP). Solving these problems is typically done by\niterative methods that require a fully formed $B$. We propose a cheap\nstochastic iterative method that solves the optimization problem while having\naccess only to random estimates of $B$. Our method does not enforce the\nconstraint in every iteration; instead, it produces iterations that converge to\ncritical points on the generalized Stiefel manifold defined in expectation. The\nmethod has lower per-iteration cost, requires only matrix multiplications, and\nhas the same convergence rates as its Riemannian optimization counterparts that\nrequire the full matrix $B$. Experiments demonstrate its effectiveness in\nvarious machine learning applications involving generalized orthogonality\nconstraints, including CCA, ICA, and the GEVP.\n","authors":["Simon Vary","Pierre Ablin","Bin Gao","P. -A. Absil"],"pdf_url":"https://arxiv.org/pdf/2405.01702v3.pdf","comment":"This v3 is a corrected version of the ICML 2024 paper (PMLR\n  235:49226-49248); see the errata at the end"},{"id":"http://arxiv.org/abs/2411.05752v1","updated":"2024-11-08T18:10:46Z","published":"2024-11-08T18:10:46Z","title":"FisherMask: Enhancing Neural Network Labeling Efficiency in Image\n  Classification Using Fisher Information","summary":"  Deep learning (DL) models are popular across various domains due to their\nremarkable performance and efficiency. However, their effectiveness relies\nheavily on large amounts of labeled data, which are often time-consuming and\nlabor-intensive to generate manually. To overcome this challenge, it is\nessential to develop strategies that reduce reliance on extensive labeled data\nwhile preserving model performance. In this paper, we propose FisherMask, a\nFisher information-based active learning (AL) approach that identifies key\nnetwork parameters by masking them based on their Fisher information values.\nFisherMask enhances batch AL by using Fisher information to select the most\ncritical parameters, allowing the identification of the most impactful samples\nduring AL training. Moreover, Fisher information possesses favorable\nstatistical properties, offering valuable insights into model behavior and\nproviding a better understanding of the performance characteristics within the\nAL pipeline. Our extensive experiments demonstrate that FisherMask\nsignificantly outperforms state-of-the-art methods on diverse datasets,\nincluding CIFAR-10 and FashionMNIST, especially under imbalanced settings.\nThese improvements lead to substantial gains in labeling efficiency. Hence\nserving as an effective tool to measure the sensitivity of model parameters to\ndata samples. Our code is available on\n\\url{https://github.com/sgchr273/FisherMask}.\n","authors":["Shreen Gul","Mohamed Elmahallawy","Sanjay Madria","Ardhendu Tripathy"],"pdf_url":"https://arxiv.org/pdf/2411.05752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05750v1","updated":"2024-11-08T18:10:07Z","published":"2024-11-08T18:10:07Z","title":"On Differentially Private String Distances","summary":"  Given a database of bit strings $A_1,\\ldots,A_m\\in \\{0,1\\}^n$, a fundamental\ndata structure task is to estimate the distances between a given query $B\\in\n\\{0,1\\}^n$ with all the strings in the database. In addition, one might further\nwant to ensure the integrity of the database by releasing these distance\nstatistics in a secure manner. In this work, we propose differentially private\n(DP) data structures for this type of tasks, with a focus on Hamming and edit\ndistance. On top of the strong privacy guarantees, our data structures are also\ntime- and space-efficient. In particular, our data structure is $\\epsilon$-DP\nagainst any sequence of queries of arbitrary length, and for any query $B$ such\nthat the maximum distance to any string in the database is at most $k$, we\noutput $m$ distance estimates. Moreover,\n  - For Hamming distance, our data structure answers any query in $\\widetilde\nO(mk+n)$ time and each estimate deviates from the true distance by at most\n$\\widetilde O(k/e^{\\epsilon/\\log k})$;\n  - For edit distance, our data structure answers any query in $\\widetilde\nO(mk^2+n)$ time and each estimate deviates from the true distance by at most\n$\\widetilde O(k/e^{\\epsilon/(\\log k \\log n)})$.\n  For moderate $k$, both data structures support sublinear query operations. We\nobtain these results via a novel adaptation of the randomized response\ntechnique as a bit flipping procedure, applied to the sketched strings.\n","authors":["Jerry Yao-Chieh Hu","Erzhi Liu","Han Liu","Zhao Song","Lichen Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05746v1","updated":"2024-11-08T18:07:55Z","published":"2024-11-08T18:07:55Z","title":"Continuous-Time Analysis of Adaptive Optimization and Normalization","summary":"  Adaptive optimization algorithms, particularly Adam and its variant AdamW,\nare fundamental components of modern deep learning. However, their training\ndynamics lack comprehensive theoretical understanding, with limited insight\ninto why common practices - such as specific hyperparameter choices and\nnormalization layers - contribute to successful generalization. This work\npresents a continuous-time formulation of Adam and AdamW, facilitating a\ntractable analysis of training dynamics that can shed light on such practical\nquestions. We theoretically derive a stable region for Adam's hyperparameters\n$(\\beta, \\gamma)$ that ensures bounded updates, empirically verifying these\npredictions by observing unstable exponential growth of parameter updates\noutside this region. Furthermore, we theoretically justify the success of\nnormalization layers by uncovering an implicit meta-adaptive effect of\nscale-invariant architectural components. This insight leads to an explicit\noptimizer, $2$-Adam, which we generalize to $k$-Adam - an optimizer that\napplies an adaptive normalization procedure $k$ times, encompassing Adam\n(corresponding to $k=1$) and Adam with a normalization layer (corresponding to\n$k=2$). Overall, our continuous-time formulation of Adam facilitates a\nprincipled analysis, offering deeper understanding of optimal hyperparameter\nchoices and architectural decisions in modern deep learning.\n","authors":["Rhys Gould","Hidenori Tanaka"],"pdf_url":"https://arxiv.org/pdf/2411.05746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05743v1","updated":"2024-11-08T18:04:41Z","published":"2024-11-08T18:04:41Z","title":"Free Record-Level Privacy Risk Evaluation Through Artifact-Based Methods","summary":"  Membership inference attacks (MIAs) are widely used to empirically assess the\nprivacy risks of samples used to train a target machine learning model.\nState-of-the-art methods however require training hundreds of shadow models,\nwith the same size and architecture of the target model, solely to evaluate the\nprivacy risk. While one might be able to afford this for small models, the cost\noften becomes prohibitive for medium and large models.\n  We here instead propose a novel approach to identify the at-risk samples\nusing only artifacts available during training, with little to no additional\ncomputational overhead. Our method analyzes individual per-sample loss traces\nand uses them to identify the vulnerable data samples. We demonstrate the\neffectiveness of our artifact-based approach through experiments on the CIFAR10\ndataset, showing high precision in identifying vulnerable samples as determined\nby a SOTA shadow model-based MIA (LiRA). Impressively, our method reaches the\nsame precision as another SOTA MIA when measured against LiRA, despite it being\norders of magnitude cheaper. We then show LT-IQR to outperform alternative loss\naggregation methods, perform ablation studies on hyperparameters, and validate\nthe robustness of our method to the target metric. Finally, we study the\nevolution of the vulnerability score distribution throughout training as a\nmetric for model-level risk assessment.\n","authors":["Joseph Pollock","Igor Shilov","Euodia Dodd","Yves-Alexandre de Montjoye"],"pdf_url":"https://arxiv.org/pdf/2411.05743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05742v1","updated":"2024-11-08T18:01:05Z","published":"2024-11-08T18:01:05Z","title":"Topology-aware Reinforcement Feature Space Reconstruction for Graph Data","summary":"  Feature space is an environment where data points are vectorized to represent\nthe original dataset. Reconstructing a good feature space is essential to\naugment the AI power of data, improve model generalization, and increase the\navailability of downstream ML models. Existing literature, such as feature\ntransformation and feature selection, is labor-intensive (e.g., heavy reliance\non empirical experience) and mostly designed for tabular data. Moreover, these\nmethods regard data samples as independent, which ignores the unique\ntopological structure when applied to graph data, thus resulting in a\nsuboptimal reconstruction feature space. Can we consider the topological\ninformation to automatically reconstruct feature space for graph data without\nheavy experiential knowledge? To fill this gap, we leverage topology-aware\nreinforcement learning to automate and optimize feature space reconstruction\nfor graph data. Our approach combines the extraction of core subgraphs to\ncapture essential structural information with a graph neural network (GNN) to\nencode topological features and reduce computing complexity. Then we introduce\nthree reinforcement agents within a hierarchical structure to systematically\ngenerate meaningful features through an iterative process, effectively\nreconstructing the feature space. This framework provides a principled solution\nfor attributed graph feature space reconstruction. The extensive experiments\ndemonstrate the effectiveness and efficiency of including topological\nawareness.\n","authors":["Wangyang Ying","Haoyue Bai","Kunpeng Liu","Yanjie Fu"],"pdf_url":"https://arxiv.org/pdf/2411.05742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.17396v2","updated":"2024-11-08T18:00:00Z","published":"2024-08-30T16:30:00Z","title":"Fairness-Aware Estimation of Graphical Models","summary":"  This paper examines the issue of fairness in the estimation of graphical\nmodels (GMs), particularly Gaussian, Covariance, and Ising models. These models\nplay a vital role in understanding complex relationships in high-dimensional\ndata. However, standard GMs can result in biased outcomes, especially when the\nunderlying data involves sensitive characteristics or protected groups. To\naddress this, we introduce a comprehensive framework designed to reduce bias in\nthe estimation of GMs related to protected attributes. Our approach involves\nthe integration of the pairwise graph disparity error and a tailored loss\nfunction into a nonsmooth multi-objective optimization problem, striving to\nachieve fairness across different sensitive groups while maintaining the\neffectiveness of the GMs. Experimental evaluations on synthetic and real-world\ndatasets demonstrate that our framework effectively mitigates bias without\nundermining GMs' performance.\n","authors":["Zhuoping Zhou","Davoud Ataee Tarzanagh","Bojian Hou","Qi Long","Li Shen"],"pdf_url":"https://arxiv.org/pdf/2408.17396v2.pdf","comment":"Accepted for publication at NeurIPS 2024, 34 Pages, 9 Figures"},{"id":"http://arxiv.org/abs/2411.03320v2","updated":"2024-11-08T17:50:33Z","published":"2024-10-20T18:35:56Z","title":"log-RRIM: Yield Prediction via Local-to-global Reaction Representation\n  Learning and Interaction Modeling","summary":"  Accurate prediction of chemical reaction yields is crucial for optimizing\norganic synthesis, potentially reducing time and resources spent on\nexperimentation. With the rise of artificial intelligence (AI), there is\ngrowing interest in leveraging AI-based methods to accelerate yield predictions\nwithout conducting in vitro experiments. We present log-RRIM, an innovative\ngraph transformer-based framework designed for predicting chemical reaction\nyields. Our approach implements a unique local-to-global reaction\nrepresentation learning strategy. This approach initially captures detailed\nmolecule-level information and then models and aggregates intermolecular\ninteractions, ensuring that the impact of varying-sizes molecular fragments on\nyield is accurately accounted for. Another key feature of log-RRIM is its\nintegration of a cross-attention mechanism that focuses on the interplay\nbetween reagents and reaction centers. This design reflects a fundamental\nprinciple in chemical reactions: the crucial role of reagents in influencing\nbond-breaking and formation processes, which ultimately affect reaction yields.\nlog-RRIM outperforms existing methods in our experiments, especially for medium\nto high-yielding reactions, proving its reliability as a predictor. Its\nadvanced modeling of reactant-reagent interactions and sensitivity to small\nmolecular fragments make it a valuable tool for reaction planning and\noptimization in chemical synthesis. The data and codes of log-RRIM are\naccessible through https://github.com/ninglab/Yield_log_RRIM.\n","authors":["Xiao Hu","Ziqi Chen","Bo Peng","Daniel Adu-Ampratwum","Xia Ning"],"pdf_url":"https://arxiv.org/pdf/2411.03320v2.pdf","comment":"18 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.05735v1","updated":"2024-11-08T17:50:24Z","published":"2024-11-08T17:50:24Z","title":"Aioli: A Unified Optimization Framework for Language Model Data Mixing","summary":"  Language model performance depends on identifying the optimal mixture of data\ngroups to train on (e.g., law, code, math). Prior work has proposed a diverse\nset of methods to efficiently learn mixture proportions, ranging from fitting\nregression models over training runs to dynamically updating proportions\nthroughout training. Surprisingly, we find that no existing method consistently\noutperforms a simple stratified sampling baseline in terms of average test\nperplexity per group. In this paper, we study the cause of this inconsistency\nby unifying existing methods into a standard optimization framework. We show\nthat all methods set proportions to minimize total loss, subject to a\nmethod-specific mixing law -- an assumption on how loss is a function of\nmixture proportions. We find that existing parameterizations of mixing laws can\nexpress the true loss-proportion relationship empirically, but the methods\nthemselves often set the mixing law parameters inaccurately, resulting in poor\nand inconsistent performance. Finally, we leverage the insights from our\nframework to derive a new online method named Aioli, which directly estimates\nthe mixing law parameters throughout training and uses them to dynamically\nadjust proportions. Empirically, Aioli outperforms stratified sampling on 6 out\nof 6 datasets by an average of 0.28 test perplexity points, whereas existing\nmethods fail to consistently beat stratified sampling, doing up to 6.9 points\nworse. Moreover, in a practical setting where proportions are learned on\nshorter runs due to computational constraints, Aioli can dynamically adjust\nthese proportions over the full training run, consistently improving\nperformance over existing methods by up to 12.01 test perplexity points.\n","authors":["Mayee F. Chen","Michael Y. Hu","Nicholas Lourie","Kyunghyun Cho","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2411.05735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20067v2","updated":"2024-11-08T17:49:46Z","published":"2024-07-29T14:53:45Z","title":"xAI-Drop: Don't Use What You Cannot Explain","summary":"  Graph Neural Networks (GNNs) have emerged as the predominant paradigm for\nlearning from graph-structured data, offering a wide range of applications from\nsocial network analysis to bioinformatics. Despite their versatility, GNNs face\nchallenges such as lack of generalization and poor interpretability, which\nhinder their wider adoption and reliability in critical applications. Dropping\nhas emerged as an effective paradigm for improving the generalization\ncapabilities of GNNs. However, existing approaches often rely on random or\nheuristic-based selection criteria, lacking a principled method to identify and\nexclude nodes that contribute to noise and over-complexity in the model. In\nthis work, we argue that explainability should be a key indicator of a model's\nquality throughout its training phase. To this end, we introduce xAI-Drop, a\nnovel topological-level dropping regularizer that leverages explainability to\npinpoint noisy network elements to be excluded from the GNN propagation\nmechanism. An empirical evaluation on diverse real-world datasets demonstrates\nthat our method outperforms current state-of-the-art dropping approaches in\naccuracy, and improves explanation quality.\n","authors":["Vincenzo Marco De Luca","Antonio Longa","Andrea Passerini","Pietro Liò"],"pdf_url":"https://arxiv.org/pdf/2407.20067v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05733v1","updated":"2024-11-08T17:46:56Z","published":"2024-11-08T17:46:56Z","title":"Differential Privacy Under Class Imbalance: Methods and Empirical\n  Insights","summary":"  Imbalanced learning occurs in classification settings where the distribution\nof class-labels is highly skewed in the training data, such as when predicting\nrare diseases or in fraud detection. This class imbalance presents a\nsignificant algorithmic challenge, which can be further exacerbated when\nprivacy-preserving techniques such as differential privacy are applied to\nprotect sensitive training data. Our work formalizes these challenges and\nprovides a number of algorithmic solutions. We consider DP variants of\npre-processing methods that privately augment the original dataset to reduce\nthe class imbalance; these include oversampling, SMOTE, and private synthetic\ndata generation. We also consider DP variants of in-processing techniques,\nwhich adjust the learning algorithm to account for the imbalance; these include\nmodel bagging, class-weighted empirical risk minimization and class-weighted\ndeep learning. For each method, we either adapt an existing imbalanced learning\ntechnique to the private setting or demonstrate its incompatibility with\ndifferential privacy. Finally, we empirically evaluate these privacy-preserving\nimbalanced learning methods under various data and distributional settings. We\nfind that private synthetic data methods perform well as a data pre-processing\nstep, while class-weighted ERMs are an alternative in higher-dimensional\nsettings where private synthetic data suffers from the curse of dimensionality.\n","authors":["Lucas Rosenblatt","Yuliia Lut","Eitan Turok","Marco Avella-Medina","Rachel Cummings"],"pdf_url":"https://arxiv.org/pdf/2411.05733v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2411.05730v1","updated":"2024-11-08T17:41:51Z","published":"2024-11-08T17:41:51Z","title":"Learning Subsystem Dynamics in Nonlinear Systems via Port-Hamiltonian\n  Neural Networks","summary":"  Port-Hamiltonian neural networks (pHNNs) are emerging as a powerful modeling\ntool that integrates physical laws with deep learning techniques. While most\nresearch has focused on modeling the entire dynamics of interconnected systems,\nthe potential for identifying and modeling individual subsystems while\noperating as part of a larger system has been overlooked. This study addresses\nthis gap by introducing a novel method for using pHNNs to identify such\nsubsystems based solely on input-output measurements. By utilizing the inherent\ncompositional property of the port-Hamiltonian systems, we developed an\nalgorithm that learns the dynamics of individual subsystems, without requiring\ndirect access to their internal states. On top of that, by choosing an output\nerror (OE) model structure, we have been able to handle measurement noise\neffectively. The effectiveness of the proposed approach is demonstrated through\ntests on interconnected systems, including multi-physics scenarios,\ndemonstrating its potential for identifying subsystem dynamics and facilitating\ntheir integration into new interconnected models.\n","authors":["G. J. E. van Otterdijk","S. Moradi","S. Weiland","R. Tóth","N. O. Jaensson","M. Schoukens"],"pdf_url":"https://arxiv.org/pdf/2411.05730v1.pdf","comment":"Preprint submitted to ECC 2025"},{"id":"http://arxiv.org/abs/2411.05729v1","updated":"2024-11-08T17:40:43Z","published":"2024-11-08T17:40:43Z","title":"Graph-Dictionary Signal Model for Sparse Representations of Multivariate\n  Data","summary":"  Representing and exploiting multivariate signals require capturing complex\nrelations between variables. We define a novel Graph-Dictionary signal model,\nwhere a finite set of graphs characterizes relationships in data distribution\nthrough a weighted sum of their Laplacians. We propose a framework to infer the\ngraph dictionary representation from observed data, along with a bilinear\ngeneralization of the primal-dual splitting algorithm to solve the learning\nproblem. Our new formulation allows to include a priori knowledge on signal\nproperties, as well as on underlying graphs and their coefficients. We show the\ncapability of our method to reconstruct graphs from signals in multiple\nsynthetic settings, where our model outperforms previous baselines. Then, we\nexploit graph-dictionary representations in a motor imagery decoding task on\nbrain activity data, where we classify imagined motion better than standard\nmethods relying on many more features.\n","authors":["William Cappelletti","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2411.05729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.01977v2","updated":"2024-11-08T17:40:09Z","published":"2024-09-03T15:21:10Z","title":"Counterfactual Fairness by Combining Factual and Counterfactual\n  Predictions","summary":"  In high-stake domains such as healthcare and hiring, the role of machine\nlearning (ML) in decision-making raises significant fairness concerns. This\nwork focuses on Counterfactual Fairness (CF), which posits that an ML model's\noutcome on any individual should remain unchanged if they had belonged to a\ndifferent demographic group. Previous works have proposed methods that\nguarantee CF. Notwithstanding, their effects on the model's predictive\nperformance remains largely unclear. To fill in this gap, we provide a\ntheoretical study on the inherent trade-off between CF and predictive\nperformance in a model-agnostic manner. We first propose a simple but effective\nmethod to cast an optimal but potentially unfair predictor into a fair one\nwithout losing the optimality. By analyzing its excess risk in order to achieve\nCF, we quantify this inherent trade-off. Further analysis on our method's\nperformance with access to only incomplete causal knowledge is also conducted.\nBuilt upon it, we propose a performant algorithm that can be applied in such\nscenarios. Experiments on both synthetic and semi-synthetic datasets\ndemonstrate the validity of our analysis and methods.\n","authors":["Zeyu Zhou","Tianci Liu","Ruqi Bai","Jing Gao","Murat Kocaoglu","David I. Inouye"],"pdf_url":"https://arxiv.org/pdf/2409.01977v2.pdf","comment":"In NeurIPS 2024"},{"id":"http://arxiv.org/abs/2312.14106v3","updated":"2024-11-08T17:33:39Z","published":"2023-12-21T18:31:33Z","title":"Learning Human-like Representations to Enable Learning Human Values","summary":"  How can we build AI systems that can learn any set of individual human values\nboth quickly and safely, avoiding causing harm or violating societal standards\nfor acceptable behavior during the learning process? We explore the effects of\nrepresentational alignment between humans and AI agents on learning human\nvalues. Making AI systems learn human-like representations of the world has\nmany known benefits, including improving generalization, robustness to domain\nshifts, and few-shot learning performance. We demonstrate that this kind of\nrepresentational alignment can also support safely learning and exploring human\nvalues in the context of personalization. We begin with a theoretical\nprediction, show that it applies to learning human morality judgments, then\nshow that our results generalize to ten different aspects of human values --\nincluding ethics, honesty, and fairness -- training AI agents on each set of\nvalues in a multi-armed bandit setting, where rewards reflect human value\njudgments over the chosen action. Using a set of textual action descriptions,\nwe collect value judgments from humans, as well as similarity judgments from\nboth humans and multiple language models, and demonstrate that representational\nalignment enables both safe exploration and improved generalization when\nlearning human values.\n","authors":["Andrea Wynn","Ilia Sucholutsky","Thomas L. Griffiths"],"pdf_url":"https://arxiv.org/pdf/2312.14106v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.00922v2","updated":"2024-11-08T17:23:05Z","published":"2024-11-01T14:32:58Z","title":"Lung tumor segmentation in MRI mice scans using 3D nnU-Net with minimum\n  annotations","summary":"  In drug discovery, accurate lung tumor segmentation is an important step for\nassessing tumor size and its progression using \\textit{in-vivo} imaging such as\nMRI. While deep learning models have been developed to automate this process,\nthe focus has predominantly been on human subjects, neglecting the pivotal role\nof animal models in pre-clinical drug development. In this work, we focus on\noptimizing lung tumor segmentation in mice. First, we demonstrate that the\nnnU-Net model outperforms the U-Net, U-Net3+, and DeepMeta models. Most\nimportantly, we achieve better results with nnU-Net 3D models than 2D models,\nindicating the importance of spatial context for segmentation tasks in MRI mice\nscans. This study demonstrates the importance of 3D input over 2D input images\nfor lung tumor segmentation in MRI scans. Finally, we outperform the prior\nstate-of-the-art approach that involves the combined segmentation of lungs and\ntumors within the lungs. Our work achieves comparable results using only lung\ntumor annotations requiring fewer annotations, saving time and annotation\nefforts. This work\n(https://anonymous.4open.science/r/lung-tumour-mice-mri-64BB) is an important\nstep in automating pre-clinical animal studies to quantify the efficacy of\nexperimental drugs, particularly in assessing tumor changes.\n","authors":["Piotr Kaniewski","Fariba Yousefi","Yeman Brhane Hagos","Talha Qaiser","Nikolay Burlutskiy"],"pdf_url":"https://arxiv.org/pdf/2411.00922v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05718v1","updated":"2024-11-08T17:20:47Z","published":"2024-11-08T17:20:47Z","title":"A Retrospective on the Robot Air Hockey Challenge: Benchmarking Robust,\n  Reliable, and Safe Learning Techniques for Real-world Robotics","summary":"  Machine learning methods have a groundbreaking impact in many application\ndomains, but their application on real robotic platforms is still limited.\nDespite the many challenges associated with combining machine learning\ntechnology with robotics, robot learning remains one of the most promising\ndirections for enhancing the capabilities of robots. When deploying\nlearning-based approaches on real robots, extra effort is required to address\nthe challenges posed by various real-world factors. To investigate the key\nfactors influencing real-world deployment and to encourage original solutions\nfrom different researchers, we organized the Robot Air Hockey Challenge at the\nNeurIPS 2023 conference. We selected the air hockey task as a benchmark,\nencompassing low-level robotics problems and high-level tactics. Different from\nother machine learning-centric benchmarks, participants need to tackle\npractical challenges in robotics, such as the sim-to-real gap, low-level\ncontrol issues, safety problems, real-time requirements, and the limited\navailability of real-world data. Furthermore, we focus on a dynamic\nenvironment, removing the typical assumption of quasi-static motions of other\nreal-world benchmarks. The competition's results show that solutions combining\nlearning-based approaches with prior knowledge outperform those relying solely\non data when real-world deployment is challenging. Our ablation study reveals\nwhich real-world factors may be overlooked when building a learning-based\nsolution. The successful real-world air hockey deployment of best-performing\nagents sets the foundation for future competitions and follow-up research\ndirections.\n","authors":["Puze Liu","Jonas Günster","Niklas Funk","Simon Gröger","Dong Chen","Haitham Bou-Ammar","Julius Jankowski","Ante Marić","Sylvain Calinon","Andrej Orsula","Miguel Olivares-Mendez","Hongyi Zhou","Rudolf Lioutikov","Gerhard Neumann","Amarildo Likmeta Amirhossein Zhalehmehrabi","Thomas Bonenfant","Marcello Restelli","Davide Tateo","Ziyuan Liu","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2411.05718v1.pdf","comment":"Accept at NeurIPS 2024 Dataset and Benchmark Track"},{"id":"http://arxiv.org/abs/2407.19115v2","updated":"2024-11-08T17:20:07Z","published":"2024-07-26T22:38:11Z","title":"Towards Scalable and Stable Parallelization of Nonlinear RNNs","summary":"  Conventional nonlinear RNNs are not naturally parallelizable across the\nsequence length, unlike transformers and linear RNNs. Lim et. al. (2024)\ntherefore tackle parallelized evaluation of nonlinear RNNs, posing it as a\nfixed point problem solved with Newton's method. By deriving and applying a\nparallelized form of Newton's method, they achieve large speedups over\nsequential evaluation. However, their approach inherits cubic computational\ncomplexity and numerical instability. We tackle these weaknesses. To reduce the\ncomputational complexity, we apply quasi-Newton approximations and show they\nconverge comparably, use less memory, and are faster, compared to full-Newton.\nTo stabilize Newton's method, we leverage a connection between Newton's method\ndamped with trust regions and Kalman smoothing. This connection allows us to\nstabilize the iteration, per the trust region, and use efficient parallelized\nKalman algorithms to retain performance. We compare these methods empirically\nand highlight use cases where each algorithm excels.\n","authors":["Xavier Gonzalez","Andrew Warrington","Jimmy T. H. Smith","Scott W. Linderman"],"pdf_url":"https://arxiv.org/pdf/2407.19115v2.pdf","comment":"25 pages, 8 figures, NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.04242v2","updated":"2024-11-08T17:16:29Z","published":"2024-11-06T20:11:19Z","title":"Multimodal Structure-Aware Quantum Data Processing","summary":"  While large language models (LLMs) have advanced the field of natural\nlanguage processing (NLP), their \"black box\" nature obscures their\ndecision-making processes. To address this, researchers developed structured\napproaches using higher order tensors. These are able to model linguistic\nrelations, but stall when training on classical computers due to their\nexcessive size. Tensors are natural inhabitants of quantum systems and training\non quantum computers provides a solution by translating text to variational\nquantum circuits. In this paper, we develop MultiQ-NLP: a framework for\nstructure-aware data processing with multimodal text+image data. Here,\n\"structure\" refers to syntactic and grammatical relationships in language, as\nwell as the hierarchical organization of visual elements in images. We enrich\nthe translation with new types and type homomorphisms and develop novel\narchitectures to represent structure. When tested on a main stream image\nclassification task (SVO Probes), our best model showed a par performance with\nthe state of the art classical models; moreover the best model was fully\nstructured.\n","authors":["Hala Hawashin","Mehrnoosh Sadrzadeh"],"pdf_url":"https://arxiv.org/pdf/2411.04242v2.pdf","comment":"10 Pages, 16 Figures"},{"id":"http://arxiv.org/abs/2411.05714v1","updated":"2024-11-08T17:16:02Z","published":"2024-11-08T17:16:02Z","title":"STARS: Sensor-agnostic Transformer Architecture for Remote Sensing","summary":"  We present a sensor-agnostic spectral transformer as the basis for spectral\nfoundation models. To that end, we introduce a Universal Spectral\nRepresentation (USR) that leverages sensor meta-data, such as sensing kernel\nspecifications and sensing wavelengths, to encode spectra obtained from any\nspectral instrument into a common representation, such that a single model can\ningest data from any sensor. Furthermore, we develop a methodology for\npre-training such models in a self-supervised manner using a novel random\nsensor-augmentation and reconstruction pipeline to learn spectral features\nindependent of the sensing paradigm. We demonstrate that our architecture can\nlearn sensor independent spectral features that generalize effectively to\nsensors not seen during training. This work sets the stage for training\nfoundation models that can both leverage and be effective for the growing\ndiversity of spectral data.\n","authors":["Ethan King","Jaime Rodriguez","Diego Llanes","Timothy Doster","Tegan Emerson","James Koch"],"pdf_url":"https://arxiv.org/pdf/2411.05714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05712v1","updated":"2024-11-08T17:13:53Z","published":"2024-11-08T17:13:53Z","title":"Scaling Laws for Task-Optimized Models of the Primate Visual Ventral\n  Stream","summary":"  When trained on large-scale object classification datasets, certain\nartificial neural network models begin to approximate core object recognition\n(COR) behaviors and neural response patterns in the primate visual ventral\nstream (VVS). While recent machine learning advances suggest that scaling model\nsize, dataset size, and compute resources improve task performance, the impact\nof scaling on brain alignment remains unclear. In this study, we explore\nscaling laws for modeling the primate VVS by systematically evaluating over 600\nmodels trained under controlled conditions on benchmarks spanning V1, V2, V4,\nIT and COR behaviors. We observe that while behavioral alignment continues to\nscale with larger models, neural alignment saturates. This observation remains\ntrue across model architectures and training datasets, even though models with\nstronger inductive bias and datasets with higher-quality images are more\ncompute-efficient. Increased scaling is especially beneficial for higher-level\nvisual areas, where small models trained on few samples exhibit only poor\nalignment. Finally, we develop a scaling recipe, indicating that a greater\nproportion of compute should be allocated to data samples over model size. Our\nresults suggest that while scaling alone might suffice for alignment with human\ncore object recognition behavior, it will not yield improved models of the\nbrain's visual ventral stream with current architectures and datasets,\nhighlighting the need for novel strategies in building brain-like models.\n","authors":["Abdulkadir Gokce","Martin Schrimpf"],"pdf_url":"https://arxiv.org/pdf/2411.05712v1.pdf","comment":"9 pages for the main paper, 20 pages in total. 6 main figures and 10\n  supplementary figures. Code, model weights, and benchmark results can be\n  accessed at https://github.com/epflneuroailab/scaling-primate-vvs"},{"id":"http://arxiv.org/abs/2411.05708v1","updated":"2024-11-08T17:10:38Z","published":"2024-11-08T17:10:38Z","title":"Sample and Computationally Efficient Robust Learning of Gaussian\n  Single-Index Models","summary":"  A single-index model (SIM) is a function of the form\n$\\sigma(\\mathbf{w}^{\\ast} \\cdot \\mathbf{x})$, where $\\sigma: \\mathbb{R} \\to\n\\mathbb{R}$ is a known link function and $\\mathbf{w}^{\\ast}$ is a hidden unit\nvector. We study the task of learning SIMs in the agnostic (a.k.a. adversarial\nlabel noise) model with respect to the $L^2_2$-loss under the Gaussian\ndistribution. Our main result is a sample and computationally efficient\nagnostic proper learner that attains $L^2_2$-error of\n$O(\\mathrm{OPT})+\\epsilon$, where $\\mathrm{OPT}$ is the optimal loss. The\nsample complexity of our algorithm is $\\tilde{O}(d^{\\lceil\nk^{\\ast}/2\\rceil}+d/\\epsilon)$, where $k^{\\ast}$ is the information-exponent of\n$\\sigma$ corresponding to the degree of its first non-zero Hermite coefficient.\nThis sample bound nearly matches known CSQ lower bounds, even in the realizable\nsetting. Prior algorithmic work in this setting had focused on learning in the\nrealizable case or in the presence of semi-random noise. Prior computationally\nefficient robust learners required significantly stronger assumptions on the\nlink function.\n","authors":["Puqian Wang","Nikos Zarifis","Ilias Diakonikolas","Jelena Diakonikolas"],"pdf_url":"https://arxiv.org/pdf/2411.05708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16749v3","updated":"2024-11-08T17:07:23Z","published":"2024-06-24T15:57:49Z","title":"Inferring stochastic low-rank recurrent neural networks from neural data","summary":"  A central aim in computational neuroscience is to relate the activity of\nlarge populations of neurons to an underlying dynamical system. Models of these\nneural dynamics should ideally be both interpretable and fit the observed data\nwell. Low-rank recurrent neural networks (RNNs) exhibit such interpretability\nby having tractable dynamics. However, it is unclear how to best fit low-rank\nRNNs to data consisting of noisy observations of an underlying stochastic\nsystem. Here, we propose to fit stochastic low-rank RNNs with variational\nsequential Monte Carlo methods. We validate our method on several datasets\nconsisting of both continuous and spiking neural data, where we obtain lower\ndimensional latent dynamics than current state of the art methods.\nAdditionally, for low-rank models with piecewise linear nonlinearities, we show\nhow to efficiently identify all fixed points in polynomial rather than\nexponential cost in the number of units, making analysis of the inferred\ndynamics tractable for large RNNs. Our method both elucidates the dynamical\nsystems underlying experimental recordings and provides a generative model\nwhose trajectories match observed variability.\n","authors":["Matthijs Pals","A Erdem Sağtekin","Felix Pei","Manuel Gloeckler","Jakob H Macke"],"pdf_url":"https://arxiv.org/pdf/2406.16749v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10160v3","updated":"2024-11-08T17:05:09Z","published":"2023-02-20T18:46:12Z","title":"Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift","summary":"  We develop and analyze a principled approach to kernel ridge regression under\ncovariate shift. The goal is to learn a regression function with small mean\nsquared error over a target distribution, based on unlabeled data from there\nand labeled data that may have a different feature distribution. We propose to\nsplit the labeled data into two subsets, and conduct kernel ridge regression on\nthem separately to obtain a collection of candidate models and an imputation\nmodel. We use the latter to fill the missing labels and then select the best\ncandidate accordingly. Our non-asymptotic excess risk bounds demonstrate that\nour estimator adapts effectively to both the structure of the target\ndistribution and the covariate shift. This adaptation is quantified through a\nnotion of effective sample size that reflects the value of labeled source data\nfor the target regression task. Our estimator achieves the minimax optimal\nerror rate up to a polylogarithmic factor, and we find that using pseudo-labels\nfor model selection does not significantly hinder performance.\n","authors":["Kaizheng Wang"],"pdf_url":"https://arxiv.org/pdf/2302.10160v3.pdf","comment":"45 pages, 2 figures"},{"id":"http://arxiv.org/abs/2404.07955v2","updated":"2024-11-08T17:04:45Z","published":"2024-03-21T14:41:12Z","title":"Triple Component Matrix Factorization: Untangling Global, Local, and\n  Noisy Components","summary":"  In this work, we study the problem of common and unique feature extraction\nfrom noisy data. When we have N observation matrices from N different and\nassociated sources corrupted by sparse and potentially gross noise, can we\nrecover the common and unique components from these noisy observations? This is\na challenging task as the number of parameters to estimate is approximately\nthrice the number of observations. Despite the difficulty, we propose an\nintuitive alternating minimization algorithm called triple component matrix\nfactorization (TCMF) to recover the three components exactly. TCMF is\ndistinguished from existing works in literature thanks to two salient features.\nFirst, TCMF is a principled method to separate the three components given noisy\nobservations provably. Second, the bulk of the computation in TCMF can be\ndistributed. On the technical side, we formulate the problem as a constrained\nnonconvex nonsmooth optimization problem. Despite the intricate nature of the\nproblem, we provide a Taylor series characterization of its solution by solving\nthe corresponding Karush-Kuhn-Tucker conditions. Using this characterization,\nwe can show that the alternating minimization algorithm makes significant\nprogress at each iteration and converges into the ground truth at a linear\nrate. Numerical experiments in video segmentation and anomaly detection\nhighlight the superior feature extraction abilities of TCMF.\n","authors":["Naichen Shi","Salar Fattahi","Raed Al Kontar"],"pdf_url":"https://arxiv.org/pdf/2404.07955v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17632v3","updated":"2024-11-08T17:01:49Z","published":"2024-03-26T12:08:05Z","title":"Data-driven Energy Consumption Modelling for Electric Micromobility\n  using an Open Dataset","summary":"  The escalating challenges of traffic congestion and environmental degradation\nunderscore the critical importance of embracing E-Mobility solutions in urban\nspaces. In particular, micro E-Mobility tools such as E-scooters and E-bikes,\nplay a pivotal role in this transition, offering sustainable alternatives for\nurban commuters. However, the energy consumption patterns for these tools are a\ncritical aspect that impacts their effectiveness in real-world scenarios and is\nessential for trip planning and boosting user confidence in using these. To\nthis effect, recent studies have utilised physical models customised for\nspecific mobility tools and conditions, but these models struggle with\ngeneralization and effectiveness in real-world scenarios due to a notable\nabsence of open datasets for thorough model evaluation and verification. To\nfill this gap, our work presents an open dataset, collected in Dublin, Ireland,\nspecifically designed for energy modelling research related to E-Scooters and\nE-Bikes. Furthermore, we provide a comprehensive analysis of energy consumption\nmodelling based on the dataset using a set of representative machine learning\nalgorithms and compare their performance against the contemporary mathematical\nmodels as a baseline. Our results demonstrate a notable advantage for\ndata-driven models in comparison to the corresponding mathematical models for\nestimating energy consumption. Specifically, data-driven models outperform\nphysical models in accuracy by up to 83.83% for E-Bikes and 82.16% for\nE-Scooters based on an in-depth analysis of the dataset under certain\nassumptions.\n","authors":["Yue Ding","Sen Yan","Maqsood Hussain Shah","Hongyuan Fang","Ji Li","Mingming Liu"],"pdf_url":"https://arxiv.org/pdf/2403.17632v3.pdf","comment":"7 pages, 5 figures, 4 tables. This manuscript has been accepted by\n  the IEEE ITEC 2024"},{"id":"http://arxiv.org/abs/2411.05698v1","updated":"2024-11-08T16:52:52Z","published":"2024-11-08T16:52:52Z","title":"Visual-TCAV: Concept-based Attribution and Saliency Maps for Post-hoc\n  Explainability in Image Classification","summary":"  Convolutional Neural Networks (CNNs) have seen significant performance\nimprovements in recent years. However, due to their size and complexity, they\nfunction as black-boxes, leading to transparency concerns. State-of-the-art\nsaliency methods generate local explanations that highlight the area in the\ninput image where a class is identified but cannot explain how a concept of\ninterest contributes to the prediction, which is essential for bias mitigation.\nOn the other hand, concept-based methods, such as TCAV (Testing with Concept\nActivation Vectors), provide insights into how sensitive is the network to a\nconcept, but cannot compute its attribution in a specific prediction nor show\nits location within the input image. This paper introduces a novel post-hoc\nexplainability framework, Visual-TCAV, which aims to bridge the gap between\nthese methods by providing both local and global explanations for CNN-based\nimage classification. Visual-TCAV uses Concept Activation Vectors (CAVs) to\ngenerate saliency maps that show where concepts are recognized by the network.\nMoreover, it can estimate the attribution of these concepts to the output of\nany class using a generalization of Integrated Gradients. This framework is\nevaluated on popular CNN architectures, with its validity further confirmed via\nexperiments where ground truth for explanations is known, and a comparison with\nTCAV. Our code will be made available soon.\n","authors":["Antonio De Santis","Riccardo Campi","Matteo Bianchi","Marco Brambilla"],"pdf_url":"https://arxiv.org/pdf/2411.05698v1.pdf","comment":"Preprint currently under review"},{"id":"http://arxiv.org/abs/2411.05697v1","updated":"2024-11-08T16:52:23Z","published":"2024-11-08T16:52:23Z","title":"IPMN Risk Assessment under Federated Learning Paradigm","summary":"  Accurate classification of Intraductal Papillary Mucinous Neoplasms (IPMN) is\nessential for identifying high-risk cases that require timely intervention. In\nthis study, we develop a federated learning framework for multi-center IPMN\nclassification utilizing a comprehensive pancreas MRI dataset. This dataset\nincludes 653 T1-weighted and 656 T2-weighted MRI images, accompanied by\ncorresponding IPMN risk scores from 7 leading medical institutions, making it\nthe largest and most diverse dataset for IPMN classification to date. We assess\nthe performance of DenseNet-121 in both centralized and federated settings for\ntraining on distributed data. Our results demonstrate that the federated\nlearning approach achieves high classification accuracy comparable to\ncentralized learning while ensuring data privacy across institutions. This work\nmarks a significant advancement in collaborative IPMN classification,\nfacilitating secure and high-accuracy model training across multiple centers.\n","authors":["Hongyi Pan","Ziliang Hong","Gorkem Durak","Elif Keles","Halil Ertugrul Aktas","Yavuz Taktak","Alpay Medetalibeyoglu","Zheyuan Zhang","Yury Velichko","Concetto Spampinato","Ivo Schoots","Marco J. Bruno","Pallavi Tiwari","Candice Bolan","Tamas Gonda","Frank Miller","Rajesh N. Keswani","Michael B. Wallace","Ziyue Xu","Ulas Bagci"],"pdf_url":"https://arxiv.org/pdf/2411.05697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21349v2","updated":"2024-11-08T16:50:05Z","published":"2024-10-28T12:18:22Z","title":"FALCON: Feedback-driven Adaptive Long/short-term memory reinforced\n  Coding Optimization system","summary":"  Recently, large language models (LLMs) have achieved significant progress in\nautomated code generation. Despite their strong instruction-following\ncapabilities, these models frequently struggled to align with user intent in\ncoding scenarios. In particular, they were hampered by datasets that lacked\ndiversity and failed to address specialized tasks or edge cases. Furthermore,\nchallenges in supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) led to failures in generating precise,\nhuman-intent-aligned code. To tackle these challenges and improve the code\ngeneration performance for automated programming systems, we propose\nFeedback-driven Adaptive Long/short-term memory reinforced Coding Optimization\n(i.e., FALCON). FALCON is structured into two hierarchical levels. From the\nglobal level, long-term memory improves code quality by retaining and applying\nlearned knowledge. At the local level, short-term memory allows for the\nincorporation of immediate feedback from compilers and AI systems.\nAdditionally, we introduce meta-reinforcement learning with feedback rewards to\nsolve the global-local bi-level optimization problem and enhance the model's\nadaptability across diverse code generation tasks. Extensive experiments\ndemonstrate that our technique achieves state-of-the-art performance, leading\nother reinforcement learning methods by more than 4.5 percentage points on the\nMBPP benchmark and 6.1 percentage points on the Humaneval benchmark. The\nopen-sourced code is publicly available at https://github.com/titurte/FALCON.\n","authors":["Zeyuan Li","Yangfan He","Lewei He","Jianhui Wang","Tianyu Shi","Bin Lei","Yuchen Li","Qiuwu Chen"],"pdf_url":"https://arxiv.org/pdf/2410.21349v2.pdf","comment":"20 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.05693v1","updated":"2024-11-08T16:47:51Z","published":"2024-11-08T16:47:51Z","title":"YOSO: You-Only-Sample-Once via Compressed Sensing for Graph Neural\n  Network Training","summary":"  Graph neural networks (GNNs) have become essential tools for analyzing\nnon-Euclidean data across various domains. During training stage, sampling\nplays an important role in reducing latency by limiting the number of nodes\nprocessed, particularly in large-scale applications. However, as the demand for\nbetter prediction performance grows, existing sampling algorithms become\nincreasingly complex, leading to significant overhead. To mitigate this, we\npropose YOSO (You-Only-Sample-Once), an algorithm designed to achieve efficient\ntraining while preserving prediction accuracy. YOSO introduces a compressed\nsensing (CS)-based sampling and reconstruction framework, where nodes are\nsampled once at input layer, followed by a lossless reconstruction at the\noutput layer per epoch. By integrating the reconstruction process with the loss\nfunction of specific learning tasks, YOSO not only avoids costly computations\nin traditional compressed sensing (CS) methods, such as orthonormal basis\ncalculations, but also ensures high-probability accuracy retention which\nequivalent to full node participation. Experimental results on node\nclassification and link prediction demonstrate the effectiveness and efficiency\nof YOSO, reducing GNN training by an average of 75\\% compared to\nstate-of-the-art methods, while maintaining accuracy on par with top-performing\nbaselines.\n","authors":["Yi Li","Zhichun Guo","Guanpeng Li","Bingzhe Li"],"pdf_url":"https://arxiv.org/pdf/2411.05693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02343v2","updated":"2024-11-08T16:44:59Z","published":"2024-11-04T18:12:59Z","title":"Boulder2Vec: Modeling Climber Performances in Professional Bouldering\n  Competitions","summary":"  Using data from professional bouldering competitions from 2008 to 2022, we\ntrain a logistic regression to predict climber results and measure climber\nskill. However, this approach is limited, as a single numeric coefficient per\nclimber cannot adequately capture the intricacies of climbers' varying\nstrengths and weaknesses in different boulder problems. For example, some\nclimbers might prefer more static, technical routes while other climbers may\nspecialize in powerful, dynamic problems.\n  To this end, we apply Probabilistic Matrix Factorization (PMF), a framework\ncommonly used in recommender systems, to represent the unique characteristics\nof climbers and problems with latent, multi-dimensional vectors. In this\nframework, a climber's performance on a given problem is predicted by taking\nthe dot product of the corresponding climber vector and problem vectors. PMF\neffectively handles sparse datasets, such as our dataset where only a subset of\nclimbers attempt each particular problem, by extrapolating patterns from\nsimilar climbers.\n  We contrast the empirical performance of PMF to the logistic regression\napproach and investigate the multivariate representations produced by PMF to\ngain insights into climber characteristics. Our results show that the\nmultivariate PMF representations improve predictive performance of professional\nbouldering competitions by capturing both the overall strength of climbers and\ntheir specialized skill sets. We provide our code open-source at\nhttps://github.com/baronet2/boulder2vec.\n","authors":["Ethan Baron","Victor Hau","Zeke Weng"],"pdf_url":"https://arxiv.org/pdf/2411.02343v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.05646v2","updated":"2024-11-08T16:29:33Z","published":"2024-08-10T22:47:12Z","title":"Eigen Attention: Attention in Low-Rank Space for KV Cache Compression","summary":"  Large language models (LLMs) represent a groundbreaking advancement in the\ndomain of natural language processing due to their impressive reasoning\nabilities. Recently, there has been considerable interest in increasing the\ncontext lengths for these models to enhance their applicability to complex\ntasks. However, at long context lengths and large batch sizes, the key-value\n(KV) cache, which stores the attention keys and values, emerges as the new\nbottleneck in memory usage during inference. To address this, we propose Eigen\nAttention, which performs the attention operation in a low-rank space, thereby\nreducing the KV cache memory overhead. Our proposed approach is orthogonal to\nexisting KV cache compression techniques and can be used synergistically with\nthem. Through extensive experiments over OPT, MPT, and Llama model families, we\ndemonstrate that Eigen Attention results in up to 40% reduction in KV cache\nsizes and up to 60% reduction in attention operation latency with minimal drop\nin performance. Code is available at\nhttps://github.com/UtkarshSaxena1/EigenAttn.\n","authors":["Utkarsh Saxena","Gobinda Saha","Sakshi Choudhary","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2408.05646v2.pdf","comment":"12 page, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2411.05679v1","updated":"2024-11-08T16:29:07Z","published":"2024-11-08T16:29:07Z","title":"Tell What You Hear From What You See -- Video to Audio Generation\n  Through Text","summary":"  The content of visual and audio scenes is multi-faceted such that a video can\nbe paired with various audio and vice-versa. Thereby, in video-to-audio\ngeneration task, it is imperative to introduce steering approaches for\ncontrolling the generated audio. While Video-to-Audio generation is a\nwell-established generative task, existing methods lack such controllability.\nIn this work, we propose VATT, a multi-modal generative framework that takes a\nvideo and an optional text prompt as input, and generates audio and optional\ntextual description of the audio. Such a framework has two advantages: i)\nVideo-to-Audio generation process can be refined and controlled via text which\ncomplements the context of visual information, and ii) The model can suggest\nwhat audio to generate for the video by generating audio captions. VATT\nconsists of two key modules: VATT Converter, a LLM that is fine-tuned for\ninstructions and includes a projection layer that maps video features to the\nLLM vector space; and VATT Audio, a transformer that generates audio tokens\nfrom visual frames and from optional text prompt using iterative parallel\ndecoding. The audio tokens are converted to a waveform by pretrained neural\ncodec. Experiments show that when VATT is compared to existing video-to-audio\ngeneration methods in objective metrics, it achieves competitive performance\nwhen the audio caption is not provided. When the audio caption is provided as a\nprompt, VATT achieves even more refined performance (lowest KLD score of 1.41).\nFurthermore, subjective studies show that VATT Audio has been chosen as\npreferred generated audio than audio generated by existing methods. VATT\nenables controllable video-to-audio generation through text as well as\nsuggesting text prompts for videos through audio captions, unlocking novel\napplications such as text-guided video-to-audio generation and video-to-audio\ncaptioning.\n","authors":["Xiulong Liu","Kun Su","Eli Shlizerman"],"pdf_url":"https://arxiv.org/pdf/2411.05679v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05676v1","updated":"2024-11-08T16:27:27Z","published":"2024-11-08T16:27:27Z","title":"Improving Molecular Graph Generation with Flow Matching and Optimal\n  Transport","summary":"  Generating molecular graphs is crucial in drug design and discovery but\nremains challenging due to the complex interdependencies between nodes and\nedges. While diffusion models have demonstrated their potentiality in molecular\ngraph design, they often suffer from unstable training and inefficient\nsampling. To enhance generation performance and training stability, we propose\nGGFlow, a discrete flow matching generative model incorporating optimal\ntransport for molecular graphs and it incorporates an edge-augmented graph\ntransformer to enable the direct communications among chemical bounds.\nAdditionally, GGFlow introduces a novel goal-guided generation framework to\ncontrol the generative trajectory of our model, aiming to design novel\nmolecular structures with the desired properties. GGFlow demonstrates superior\nperformance on both unconditional and conditional molecule generation tasks,\noutperforming existing baselines and underscoring its effectiveness and\npotential for wider application.\n","authors":["Xiaoyang Hou","Tian Zhu","Milong Ren","Dongbo Bu","Xin Gao","Chunming Zhang","Shiwei Sun"],"pdf_url":"https://arxiv.org/pdf/2411.05676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23893v3","updated":"2024-11-08T16:21:02Z","published":"2024-10-31T12:53:53Z","title":"DiffBatt: A Diffusion Model for Battery Degradation Prediction and\n  Synthesis","summary":"  Battery degradation remains a critical challenge in the pursuit of green\ntechnologies and sustainable energy solutions. Despite significant research\nefforts, predicting battery capacity loss accurately remains a formidable task\ndue to its complex nature, influenced by both aging and cycling behaviors. To\naddress this challenge, we introduce a novel general-purpose model for battery\ndegradation prediction and synthesis, DiffBatt. Leveraging an innovative\ncombination of conditional and unconditional diffusion models with\nclassifier-free guidance and transformer architecture, DiffBatt achieves high\nexpressivity and scalability. DiffBatt operates as a probabilistic model to\ncapture uncertainty in aging behaviors and a generative model to simulate\nbattery degradation. The performance of the model excels in prediction tasks\nwhile also enabling the generation of synthetic degradation curves,\nfacilitating enhanced model training by data augmentation. In the remaining\nuseful life prediction task, DiffBatt provides accurate results with a mean\nRMSE of 196 cycles across all datasets, outperforming all other models and\ndemonstrating superior generalizability. This work represents an important step\ntowards developing foundational models for battery degradation.\n","authors":["Hamidreza Eivazi","André Hebenbrock","Raphael Ginster","Steffen Blömeke","Stefan Wittek","Christoph Herrmann","Thomas S. Spengler","Thomas Turek","Andreas Rausch"],"pdf_url":"https://arxiv.org/pdf/2410.23893v3.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2310.20598v3","updated":"2024-11-08T16:17:50Z","published":"2023-10-31T16:34:49Z","title":"Online Conversion with Switching Costs: Robust and Learning-Augmented\n  Algorithms","summary":"  We introduce and study online conversion with switching costs, a family of\nonline problems that capture emerging problems at the intersection of energy\nand sustainability. In this problem, an online player attempts to purchase\n(alternatively, sell) fractional shares of an asset during a fixed time horizon\nwith length $T$. At each time step, a cost function (alternatively, price\nfunction) is revealed, and the player must irrevocably decide an amount of\nasset to convert. The player also incurs a switching cost whenever their\ndecision changes in consecutive time steps, i.e., when they increase or\ndecrease their purchasing amount. We introduce competitive (robust)\nthreshold-based algorithms for both the minimization and maximization variants\nof this problem, and show they are optimal among deterministic online\nalgorithms. We then propose learning-augmented algorithms that take advantage\nof untrusted black-box advice (such as predictions from a machine learning\nmodel) to achieve significantly better average-case performance without\nsacrificing worst-case competitive guarantees. Finally, we empirically evaluate\nour proposed algorithms using a carbon-aware EV charging case study, showing\nthat our algorithms substantially improve on baseline methods for this problem.\n","authors":["Adam Lechowicz","Nicolas Christianson","Bo Sun","Noman Bashir","Mohammad Hajiesmaili","Adam Wierman","Prashant Shenoy"],"pdf_url":"https://arxiv.org/pdf/2310.20598v3.pdf","comment":"Appeared as a conference paper at SIGMETRICS / Performance '24. 47\n  pages, 9 figures"},{"id":"http://arxiv.org/abs/2402.17176v2","updated":"2024-11-08T16:09:02Z","published":"2024-02-27T03:24:54Z","title":"DeepDRK: Deep Dependency Regularized Knockoff for Feature Selection","summary":"  Model-X knockoff has garnered significant attention among various feature\nselection methods due to its guarantees for controlling the false discovery\nrate (FDR). Since its introduction in parametric design, knockoff techniques\nhave evolved to handle arbitrary data distributions using deep learning-based\ngenerative models. However, we have observed limitations in the current\nimplementations of the deep Model-X knockoff framework. Notably, the \"swap\nproperty\" that knockoffs require often faces challenges at the sample level,\nresulting in diminished selection power. To address these issues, we develop\n\"Deep Dependency Regularized Knockoff (DeepDRK),\" a distribution-free deep\nlearning method that effectively balances FDR and power. In DeepDRK, we\nintroduce a novel formulation of the knockoff model as a learning problem under\nmulti-source adversarial attacks. By employing an innovative perturbation\ntechnique, we achieve lower FDR and higher power. Our model outperforms\nexisting benchmarks across synthetic, semi-synthetic, and real-world datasets,\nparticularly when sample sizes are small and data distributions are\nnon-Gaussian.\n","authors":["Hongyu Shen","Yici Yan","Zhizhen Zhao"],"pdf_url":"https://arxiv.org/pdf/2402.17176v2.pdf","comment":"33 pages, 15 figures, 9 tables"},{"id":"http://arxiv.org/abs/2407.17032v3","updated":"2024-11-08T16:08:51Z","published":"2024-07-24T06:35:05Z","title":"Gymnasium: A Standard Interface for Reinforcement Learning Environments","summary":"  Reinforcement Learning (RL) is a continuously growing field that has the\npotential to revolutionize many areas of artificial intelligence. However,\ndespite its promise, RL research is often hindered by the lack of\nstandardization in environment and algorithm implementations. This makes it\ndifficult for researchers to compare and build upon each other's work, slowing\ndown progress in the field. Gymnasium is an open-source library that provides a\nstandard API for RL environments, aiming to tackle this issue. Gymnasium's main\nfeature is a set of abstractions that allow for wide interoperability between\nenvironments and training algorithms, making it easier for researchers to\ndevelop and test RL algorithms. In addition, Gymnasium provides a collection of\neasy-to-use environments, tools for easily customizing environments, and tools\nto ensure the reproducibility and robustness of RL research. Through this\nunified framework, Gymnasium significantly streamlines the process of\ndeveloping and testing RL algorithms, enabling researchers to focus more on\ninnovation and less on implementation details. By providing a standardized\nplatform for RL research, Gymnasium helps to drive forward the field of\nreinforcement learning and unlock its full potential. Gymnasium is available\nonline at https://github.com/Farama-Foundation/Gymnasium\n","authors":["Mark Towers","Ariel Kwiatkowski","Jordan Terry","John U. Balis","Gianluca De Cola","Tristan Deleu","Manuel Goulão","Andreas Kallinteris","Markus Krimmel","Arjun KG","Rodrigo Perez-Vicente","Andrea Pierré","Sander Schulhoff","Jun Jet Tai","Hannah Tan","Omar G. Younis"],"pdf_url":"https://arxiv.org/pdf/2407.17032v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05663v1","updated":"2024-11-08T16:04:16Z","published":"2024-11-08T16:04:16Z","title":"Online-LoRA: Task-free Online Continual Learning via Low Rank Adaptation","summary":"  Catastrophic forgetting is a significant challenge in online continual\nlearning (OCL), especially for non-stationary data streams that do not have\nwell-defined task boundaries. This challenge is exacerbated by the memory\nconstraints and privacy concerns inherent in rehearsal buffers. To tackle\ncatastrophic forgetting, in this paper, we introduce Online-LoRA, a novel\nframework for task-free OCL. Online-LoRA allows to finetune pre-trained Vision\nTransformer (ViT) models in real-time to address the limitations of rehearsal\nbuffers and leverage pre-trained models' performance benefits. As the main\ncontribution, our approach features a novel online weight regularization\nstrategy to identify and consolidate important model parameters. Moreover,\nOnline-LoRA leverages the training dynamics of loss values to enable the\nautomatic recognition of the data distribution shifts. Extensive experiments\nacross many task-free OCL scenarios and benchmark datasets (including\nCIFAR-100, ImageNet-R, ImageNet-S, CUB-200 and CORe50) demonstrate that\nOnline-LoRA can be robustly adapted to various ViT architectures, while\nachieving better performance compared to SOTA methods. Our code will be\npublicly available at:\nhttps://github.com/Christina200/Online-LoRA-official.git.\n","authors":["Xiwen Wei","Guihong Li","Radu Marculescu"],"pdf_url":"https://arxiv.org/pdf/2411.05663v1.pdf","comment":"WACV 2025"},{"id":"http://arxiv.org/abs/2411.05661v1","updated":"2024-11-08T16:02:39Z","published":"2024-11-08T16:02:39Z","title":"Multi-armed Bandits with Missing Outcome","summary":"  While significant progress has been made in designing algorithms that\nminimize regret in online decision-making, real-world scenarios often introduce\nadditional complexities, perhaps the most challenging of which is missing\noutcomes. Overlooking this aspect or simply assuming random missingness\ninvariably leads to biased estimates of the rewards and may result in linear\nregret. Despite the practical relevance of this challenge, no rigorous\nmethodology currently exists for systematically handling missingness,\nespecially when the missingness mechanism is not random. In this paper, we\naddress this gap in the context of multi-armed bandits (MAB) with missing\noutcomes by analyzing the impact of different missingness mechanisms on\nachievable regret bounds. We introduce algorithms that account for missingness\nunder both missing at random (MAR) and missing not at random (MNAR) models.\nThrough both analytical and simulation studies, we demonstrate the drastic\nimprovements in decision-making by accounting for missingness in these\nsettings.\n","authors":["Ilia Mahrooghi","Mahshad Moradi","Sina Akbari","Negar Kiyavash"],"pdf_url":"https://arxiv.org/pdf/2411.05661v1.pdf","comment":"38 pages, 5 figures, multi-armed bandits, missing data"},{"id":"http://arxiv.org/abs/2410.06884v2","updated":"2024-11-08T16:02:20Z","published":"2024-10-09T13:46:08Z","title":"Adaptive Refinement Protocols for Distributed Distribution Estimation\n  under $\\ell^p$-Losses","summary":"  Consider the communication-constrained estimation of discrete distributions\nunder $\\ell^p$ losses, where each distributed terminal holds multiple\nindependent samples and uses limited number of bits to describe the samples. We\nobtain the minimax optimal rates of the problem in most parameter regimes. An\nelbow effect of the optimal rates at $p=2$ is clearly identified. To show the\noptimal rates, we first design estimation protocols to achieve them. The key\ningredient of these protocols is to introduce adaptive refinement mechanisms,\nwhich first generate rough estimate by partial information and then establish\nrefined estimate in subsequent steps guided by the rough estimate. The\nprotocols leverage successive refinement, sample compression, thresholding and\nrandom hashing methods to achieve the optimal rates in different parameter\nregimes. The optimality of the protocols is shown by deriving compatible\nminimax lower bounds.\n","authors":["Deheng Yuan","Tao Guo","Zhongyi Huang"],"pdf_url":"https://arxiv.org/pdf/2410.06884v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01029v3","updated":"2024-11-08T15:59:46Z","published":"2024-02-01T21:38:10Z","title":"Response Theory via Generative Score Modeling","summary":"  We introduce an approach for analyzing the responses of dynamical systems to\nexternal perturbations that combines score-based generative modeling with the\nGeneralized Fluctuation-Dissipation Theorem (GFDT). The methodology enables\naccurate estimation of system responses, including those with non-Gaussian\nstatistics. We numerically validate our approach using time-series data from\nthree different stochastic partial differential equations of increasing\ncomplexity: an Ornstein-Uhlenbeck process with spatially correlated noise, a\nmodified stochastic Allen-Cahn equation, and the 2D Navier-Stokes equations. We\ndemonstrate the improved accuracy of the methodology over conventional methods\nand discuss its potential as a versatile tool for predicting the statistical\nbehavior of complex dynamical systems.\n","authors":["Ludovico Theo Giorgini","Katherine Deck","Tobias Bischoff","Andre Souza"],"pdf_url":"https://arxiv.org/pdf/2402.01029v3.pdf","comment":"In press. Includes supplementary material in the file\n  supp_material.pdf"},{"id":"http://arxiv.org/abs/2204.02291v2","updated":"2024-11-08T15:58:22Z","published":"2022-04-05T15:42:51Z","title":"Aggregating distribution forecasts from deep ensembles","summary":"  The importance of accurately quantifying forecast uncertainty has motivated\nmuch recent research on probabilistic forecasting. In particular, a variety of\ndeep learning approaches has been proposed, with forecast distributions\nobtained as output of neural networks. These neural network-based methods are\noften used in the form of an ensemble, e.g., based on multiple model runs from\ndifferent random initializations or more sophisticated ensembling strategies\nsuch as dropout, resulting in a collection of forecast distributions that need\nto be aggregated into a final probabilistic prediction. With the aim of\nconsolidating findings from the machine learning literature on ensemble methods\nand the statistical literature on forecast combination, we address the question\nof how to aggregate distribution forecasts based on such `deep ensembles'.\nUsing theoretical arguments and a comprehensive analysis on twelve benchmark\ndata sets, we systematically compare probability- and quantile-based\naggregation methods for three neural network-based approaches with different\nforecast distribution types as output. Our results show that combining forecast\ndistributions from deep ensembles can substantially improve the predictive\nperformance. We propose a general quantile aggregation framework for deep\nensembles that allows for corrections of systematic deficiencies and performs\nwell in a variety of settings, often superior compared to a linear combination\nof the forecast densities. Finally, we investigate the effects of the ensemble\nsize and derive recommendations of aggregating distribution forecasts from deep\nensembles in practice.\n","authors":["Benedikt Schulz","Lutz Köhler","Sebastian Lerch"],"pdf_url":"https://arxiv.org/pdf/2204.02291v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.15865v2","updated":"2024-11-08T15:51:52Z","published":"2023-10-24T14:23:10Z","title":"Using Time-Aware Graph Neural Networks to Predict Temporal Centralities\n  in Dynamic Graphs","summary":"  Node centralities play a pivotal role in network science, social network\nanalysis, and recommender systems. In temporal data, static path-based\ncentralities like closeness or betweenness can give misleading results about\nthe true importance of nodes in a temporal graph. To address this issue,\ntemporal generalizations of betweenness and closeness have been defined that\nare based on the shortest time-respecting paths between pairs of nodes.\nHowever, a major issue of those generalizations is that the calculation of such\npaths is computationally expensive. Addressing this issue, we study the\napplication of De Bruijn Graph Neural Networks (DBGNN), a time-aware graph\nneural network architecture, to predict temporal path-based centralities in\ntime series data. We experimentally evaluate our approach in 13 temporal graphs\nfrom biological and social systems and show that it considerably improves the\nprediction of betweenness and closeness centrality compared to (i) a static\nGraph Convolutional Neural Network, (ii) an efficient sampling-based\napproximation technique for temporal betweenness, and (iii) two\nstate-of-the-art time-aware graph learning techniques for dynamic graphs.\n","authors":["Franziska Heeg","Ingo Scholtes"],"pdf_url":"https://arxiv.org/pdf/2310.15865v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05648v1","updated":"2024-11-08T15:43:01Z","published":"2024-11-08T15:43:01Z","title":"Enhancing Model Fairness and Accuracy with Similarity Networks: A\n  Methodological Approach","summary":"  In this paper, we propose an innovative approach to thoroughly explore\ndataset features that introduce bias in downstream machine-learning tasks.\nDepending on the data format, we use different techniques to map instances into\na similarity feature space. Our method's ability to adjust the resolution of\npairwise similarity provides clear insights into the relationship between the\ndataset classification complexity and model fairness. Experimental results\nconfirm the promising applicability of the similarity network in promoting fair\nmodels. Moreover, leveraging our methodology not only seems promising in\nproviding a fair downstream task such as classification, it also performs well\nin imputation and augmentation of the dataset satisfying the fairness criteria\nsuch as demographic parity and imbalanced classes.\n","authors":["Samira Maghool","Paolo Ceravolo"],"pdf_url":"https://arxiv.org/pdf/2411.05648v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.05636v1","updated":"2024-11-08T15:30:10Z","published":"2024-11-08T15:30:10Z","title":"Video RWKV:Video Action Recognition Based RWKV","summary":"  To address the challenges of high computational costs and long-distance\ndependencies in exist ing video understanding methods, such as CNNs and\nTransformers, this work introduces RWKV to the video domain in a novel way. We\npropose a LSTM CrossRWKV (LCR) framework, designed for spatiotemporal\nrepresentation learning to tackle the video understanding task. Specifically,\nthe proposed linear complexity LCR incorporates a novel Cross RWKV gate to\nfacilitate interaction be tween current frame edge information and past\nfeatures, enhancing the focus on the subject through edge features and globally\naggregating inter-frame features over time. LCR stores long-term mem ory for\nvideo processing through an enhanced LSTM recurrent execution mechanism. By\nleveraging the Cross RWKV gate and recurrent execution, LCR effectively\ncaptures both spatial and temporal features. Additionally, the edge information\nserves as a forgetting gate for LSTM, guiding long-term memory management.Tube\nmasking strategy reduces redundant information in food and reduces\noverfitting.These advantages enable LSTM CrossRWKV to set a new benchmark in\nvideo under standing, offering a scalable and efficient solution for\ncomprehensive video analysis. All code and models are publicly available.\n","authors":["Zhuowen Yin","Chengru Li","Xingbo Dong"],"pdf_url":"https://arxiv.org/pdf/2411.05636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15178v2","updated":"2024-11-08T15:22:26Z","published":"2024-10-19T18:46:17Z","title":"Enhancing Robot Navigation Policies with Task-Specific Uncertainty\n  Management","summary":"  Robots performing navigation tasks in complex environments face significant\nchallenges due to uncertainty in state estimation. Effectively managing this\nuncertainty is crucial, but the optimal approach varies depending on the\nspecific details of the task: different tasks require varying levels of\nprecision in different regions of the environment. For instance, a robot\nnavigating a crowded space might need precise localization near obstacles but\ncan operate effectively with less precise state estimates in open areas. This\nvarying need for certainty in different parts of the environment, depending on\nthe task, calls for policies that can adapt their uncertainty management\nstrategies based on task-specific requirements. In this paper, we present a\nframework for integrating task-specific uncertainty requirements directly into\nnavigation policies. We introduce Task-Specific Uncertainty Map (TSUM), which\nrepresents acceptable levels of state estimation uncertainty across different\nregions of the operating environment for a given task. Using TSUM, we propose\nGeneralized Uncertainty Integration for Decision-Making and Execution (GUIDE),\na policy conditioning framework that incorporates these uncertainty\nrequirements into the robot's decision-making process. We find that\nconditioning policies on TSUMs provides an effective way to express\ntask-specific uncertainty requirements and enables the robot to reason about\nthe context-dependent value of certainty. We show how integrating GUIDE into\nreinforcement learning frameworks allows the agent to learn navigation policies\nwithout the need for explicit reward engineering to balance task completion and\nuncertainty management. We evaluate GUIDE on a variety of real-world navigation\ntasks and find that it demonstrates significant improvements in task completion\nrates compared to baselines. Evaluation videos can be found at\nhttps://guided-agents.github.io.\n","authors":["Gokul Puthumanaillam","Paulo Padrao","Jose Fuentes","Leonardo Bobadilla","Melkior Ornik"],"pdf_url":"https://arxiv.org/pdf/2410.15178v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05631v1","updated":"2024-11-08T15:22:20Z","published":"2024-11-08T15:22:20Z","title":"Physics-constrained coupled neural differential equations for one\n  dimensional blood flow modeling","summary":"  Computational cardiovascular flow modeling plays a crucial role in\nunderstanding blood flow dynamics. While 3D models provide acute details, they\nare computationally expensive, especially with fluid-structure interaction\n(FSI) simulations. 1D models offer a computationally efficient alternative, by\nsimplifying the 3D Navier-Stokes equations through axisymmetric flow assumption\nand cross-sectional averaging. However, traditional 1D models based on finite\nelement methods (FEM) often lack accuracy compared to 3D averaged solutions.\nThis study introduces a novel physics-constrained machine learning technique\nthat enhances the accuracy of 1D blood flow models while maintaining\ncomputational efficiency. Our approach, utilizing a physics-constrained coupled\nneural differential equation (PCNDE) framework, demonstrates superior\nperformance compared to conventional FEM-based 1D models across a wide range of\ninlet boundary condition waveforms and stenosis blockage ratios. A key\ninnovation lies in the spatial formulation of the momentum conservation\nequation, departing from the traditional temporal approach and capitalizing on\nthe inherent temporal periodicity of blood flow. This spatial neural\ndifferential equation formulation switches space and time and overcomes issues\nrelated to coupling stability and smoothness, while simplifying boundary\ncondition implementation. The model accurately captures flow rate, area, and\npressure variations for unseen waveforms and geometries. We evaluate the\nmodel's robustness to input noise and explore the loss landscapes associated\nwith the inclusion of different physics terms. This advanced 1D modeling\ntechnique offers promising potential for rapid cardiovascular simulations,\nachieving computational efficiency and accuracy. By combining the strengths of\nphysics-based and data-driven modeling, this approach enables fast and accurate\ncardiovascular simulations.\n","authors":["Hunor Csala","Arvind Mohan","Daniel Livescu","Amirhossein Arzani"],"pdf_url":"https://arxiv.org/pdf/2411.05631v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05625v1","updated":"2024-11-08T15:15:34Z","published":"2024-11-08T15:15:34Z","title":"Cross-validating causal discovery via Leave-One-Variable-Out","summary":"  We propose a new approach to falsify causal discovery algorithms without\nground truth, which is based on testing the causal model on a pair of variables\nthat has been dropped when learning the causal model. To this end, we use the\n\"Leave-One-Variable-Out (LOVO)\" prediction where $Y$ is inferred from $X$\nwithout any joint observations of $X$ and $Y$, given only training data from\n$X,Z_1,\\dots,Z_k$ and from $Z_1,\\dots,Z_k,Y$. We demonstrate that causal models\non the two subsets, in the form of Acyclic Directed Mixed Graphs (ADMGs), often\nentail conclusions on the dependencies between $X$ and $Y$, enabling this type\nof prediction. The prediction error can then be estimated since the joint\ndistribution $P(X, Y)$ is assumed to be available, and $X$ and $Y$ have only\nbeen omitted for the purpose of falsification. After presenting this graphical\nmethod, which is applicable to general causal discovery algorithms, we\nillustrate how to construct a LOVO predictor tailored towards algorithms\nrelying on specific a priori assumptions, such as linear additive noise models.\nSimulations indicate that the LOVO prediction error is indeed correlated with\nthe accuracy of the causal outputs, affirming the method's effectiveness.\n","authors":["Daniela Schkoda","Philipp Faller","Patrick Blöbaum","Dominik Janzing"],"pdf_url":"https://arxiv.org/pdf/2411.05625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05619v1","updated":"2024-11-08T15:01:27Z","published":"2024-11-08T15:01:27Z","title":"WHALE: Towards Generalizable and Scalable World Models for Embodied\n  Decision-making","summary":"  World models play a crucial role in decision-making within embodied\nenvironments, enabling cost-free explorations that would otherwise be expensive\nin the real world. To facilitate effective decision-making, world models must\nbe equipped with strong generalizability to support faithful imagination in\nout-of-distribution (OOD) regions and provide reliable uncertainty estimation\nto assess the credibility of the simulated experiences, both of which present\nsignificant challenges for prior scalable approaches. This paper introduces\nWHALE, a framework for learning generalizable world models, consisting of two\nkey techniques: behavior-conditioning and retracing-rollout.\nBehavior-conditioning addresses the policy distribution shift, one of the\nprimary sources of the world model generalization error, while\nretracing-rollout enables efficient uncertainty estimation without the\nnecessity of model ensembles. These techniques are universal and can be\ncombined with any neural network architecture for world model learning.\nIncorporating these two techniques, we present Whale-ST, a scalable\nspatial-temporal transformer-based world model with enhanced generalizability.\nWe demonstrate the superiority of Whale-ST in simulation tasks by evaluating\nboth value estimation accuracy and video generation fidelity. Additionally, we\nexamine the effectiveness of our uncertainty estimation technique, which\nenhances model-based policy optimization in fully offline scenarios.\nFurthermore, we propose Whale-X, a 414M parameter world model trained on 970K\ntrajectories from Open X-Embodiment datasets. We show that Whale-X exhibits\npromising scalability and strong generalizability in real-world manipulation\nscenarios using minimal demonstrations.\n","authors":["Zhilong Zhang","Ruifeng Chen","Junyin Ye","Yihao Sun","Pengyuan Wang","Jingcheng Pang","Kaiyuan Li","Tianshuo Liu","Haoxin Lin","Yang Yu","Zhi-Hua Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.05619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05618v1","updated":"2024-11-08T14:57:59Z","published":"2024-11-08T14:57:59Z","title":"Knowledge Distillation Neural Network for Predicting Car-following\n  Behaviour of Human-driven and Autonomous Vehicles","summary":"  As we move towards a mixed-traffic scenario of Autonomous vehicles (AVs) and\nHuman-driven vehicles (HDVs), understanding the car-following behaviour is\nimportant to improve traffic efficiency and road safety. Using a real-world\ntrajectory dataset, this study uses descriptive and statistical analysis to\ninvestigate the car-following behaviours of three vehicle pairs: HDV-AV, AV-HDV\nand HDV-HDV in mixed traffic. The ANOVA test showed that car-following\nbehaviours across different vehicle pairs are statistically significant\n(p-value < 0.05).\n  We also introduce a data-driven Knowledge Distillation Neural Network (KDNN)\nmodel for predicting car-following behaviour in terms of speed. The KDNN model\ndemonstrates comparable predictive accuracy to its teacher network, a Long\nShort-Term Memory (LSTM) network, and outperforms both the standalone student\nnetwork, a Multilayer Perceptron (MLP), and traditional physics-based models\nlike the Gipps model. Notably, the KDNN model better prevents collisions,\nmeasured by minimum Time-to-Collision (TTC), and operates with lower\ncomputational power, making it ideal for AVs or driving simulators requiring\nefficient computing.\n","authors":["Ayobami Adewale","Chris Lee","Amnir Hadachi","Nicolly Lima da Silva"],"pdf_url":"https://arxiv.org/pdf/2411.05618v1.pdf","comment":"27th IEEE International Conference on Intelligent Transportation\n  Systems"},{"id":"http://arxiv.org/abs/2411.05614v1","updated":"2024-11-08T14:55:32Z","published":"2024-11-08T14:55:32Z","title":"Acceleration for Deep Reinforcement Learning using Parallel and\n  Distributed Computing: A Survey","summary":"  Deep reinforcement learning has led to dramatic breakthroughs in the field of\nartificial intelligence for the past few years. As the amount of rollout\nexperience data and the size of neural networks for deep reinforcement learning\nhave grown continuously, handling the training process and reducing the time\nconsumption using parallel and distributed computing is becoming an urgent and\nessential desire. In this paper, we perform a broad and thorough investigation\non training acceleration methodologies for deep reinforcement learning based on\nparallel and distributed computing, providing a comprehensive survey in this\nfield with state-of-the-art methods and pointers to core references. In\nparticular, a taxonomy of literature is provided, along with a discussion of\nemerging topics and open issues. This incorporates learning system\narchitectures, simulation parallelism, computing parallelism, distributed\nsynchronization mechanisms, and deep evolutionary reinforcement learning.\nFurther, we compare 16 current open-source libraries and platforms with\ncriteria of facilitating rapid development. Finally, we extrapolate future\ndirections that deserve further research.\n","authors":["Zhihong Liu","Xin Xu","Peng Qiao","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2411.05614v1.pdf","comment":"This paper has been accepted by ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2407.10921v2","updated":"2024-11-08T14:55:06Z","published":"2024-07-15T17:22:16Z","title":"Leveraging Bi-Focal Perspectives and Granular Feature Integration for\n  Accurate Reliable Early Alzheimer's Detection","summary":"  Alzheimer's disease (AD) is the most common form of neurodegeneration, which\nimpacts millions of people each year. Diagnosing and classifying AD accurately\nwith neuroimaging data is an ongoing challenge in the field of medicine.\nTraditional Convolutional Neural Networks (CNNs) are good at capturing\nlow-level information from images, but their capability to extract high-level\nminuscule particles is suboptimal, which is a significant challenge in\ndetecting AD from MRI scans. To overcome this, we propose a novel Granular\nFeature Integration method to combine information extraction at different\nscales combined with an efficient information flow. We also propose a Bi-Focal\nPerspective mechanism to highlight focus on subtle neurofibrillary tangles and\namyloid plaques in MRI scans. Our model yielded an F1-Score of 99.31%, a\nprecision of 99.24%, and a recall of 99.51%, which shows a major improvement in\ncomparison to existing state-of-the-art (SOTA) CNNs.\n","authors":["Pandiyaraju V","Shravan Venkatraman","Abeshek A","Aravintakshan S A","Pavan Kumar S","Kannan A"],"pdf_url":"https://arxiv.org/pdf/2407.10921v2.pdf","comment":"17 pages, 10 figures, 6 tables"},{"id":"http://arxiv.org/abs/2411.05609v1","updated":"2024-11-08T14:52:42Z","published":"2024-11-08T14:52:42Z","title":"A Two-Step Concept-Based Approach for Enhanced Interpretability and\n  Trust in Skin Lesion Diagnosis","summary":"  The main challenges hindering the adoption of deep learning-based systems in\nclinical settings are the scarcity of annotated data and the lack of\ninterpretability and trust in these systems. Concept Bottleneck Models (CBMs)\noffer inherent interpretability by constraining the final disease prediction on\na set of human-understandable concepts. However, this inherent interpretability\ncomes at the cost of greater annotation burden. Additionally, adding new\nconcepts requires retraining the entire system. In this work, we introduce a\nnovel two-step methodology that addresses both of these challenges. By\nsimulating the two stages of a CBM, we utilize a pretrained Vision Language\nModel (VLM) to automatically predict clinical concepts, and a Large Language\nModel (LLM) to generate disease diagnoses based on the predicted concepts. We\nvalidate our approach on three skin lesion datasets, demonstrating that it\noutperforms traditional CBMs and state-of-the-art explainable methods, all\nwithout requiring any training and utilizing only a few annotated examples. The\ncode is available at\nhttps://github.com/CristianoPatricio/2-step-concept-based-skin-diagnosis.\n","authors":["Cristiano Patrício","Luís F. Teixeira","João C. Neves"],"pdf_url":"https://arxiv.org/pdf/2411.05609v1.pdf","comment":"Preprint submitted for review"},{"id":"http://arxiv.org/abs/2410.23889v2","updated":"2024-11-08T14:45:55Z","published":"2024-10-31T12:51:40Z","title":"GEPS: Boosting Generalization in Parametric PDE Neural Solvers through\n  Adaptive Conditioning","summary":"  Solving parametric partial differential equations (PDEs) presents significant\nchallenges for data-driven methods due to the sensitivity of spatio-temporal\ndynamics to variations in PDE parameters. Machine learning approaches often\nstruggle to capture this variability. To address this, data-driven approaches\nlearn parametric PDEs by sampling a very large variety of trajectories with\nvarying PDE parameters. We first show that incorporating conditioning\nmechanisms for learning parametric PDEs is essential and that among them,\n$\\textit{adaptive conditioning}$, allows stronger generalization. As existing\nadaptive conditioning methods do not scale well with respect to the number of\nparameters to adapt in the neural solver, we propose GEPS, a simple adaptation\nmechanism to boost GEneralization in Pde Solvers via a first-order optimization\nand low-rank rapid adaptation of a small set of context parameters. We\ndemonstrate the versatility of our approach for both fully data-driven and for\nphysics-aware neural solvers. Validation performed on a whole range of\nspatio-temporal forecasting problems demonstrates excellent performance for\ngeneralizing to unseen conditions including initial conditions, PDE\ncoefficients, forcing terms and solution domain. $\\textit{Project page}$:\nhttps://geps-project.github.io\n","authors":["Armand Kassaï Koupaï","Jorge Mifsut Benet","Yuan Yin","Jean-Noël Vittaut","Patrick Gallinari"],"pdf_url":"https://arxiv.org/pdf/2410.23889v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15376v2","updated":"2024-11-08T14:42:07Z","published":"2024-05-24T09:23:43Z","title":"Fast training and sampling of Restricted Boltzmann Machines","summary":"  Restricted Boltzmann Machines (RBMs) are effective tools for modeling complex\nsystems and deriving insights from data. However, training these models with\nhighly structured data presents significant challenges due to the slow mixing\ncharacteristics of Markov Chain Monte Carlo processes. In this study, we build\nupon recent theoretical advancements in RBM training, to significantly reduce\nthe computational cost of training (in very clustered datasets), evaluating and\nsampling in RBMs in general. The learning process is analogous to thermodynamic\ncontinuous phase transitions observed in ferromagnetic models, where new modes\nin the probability measure emerge in a continuous manner. Such continuous\ntransitions are associated with the critical slowdown effect, which adversely\naffects the accuracy of gradient estimates, particularly during the initial\nstages of training with clustered data. To mitigate this issue, we propose a\npre-training phase that encodes the principal components into a low-rank RBM\nthrough a convex optimization process. This approach enables efficient static\nMonte Carlo sampling and accurate computation of the partition function. We\nexploit the continuous and smooth nature of the parameter annealing trajectory\nto achieve reliable and computationally efficient log-likelihood estimations,\nenabling online assessment during the training, and propose a novel sampling\nstrategy named parallel trajectory tempering (PTT) which outperforms previously\noptimized MCMC methods. Our results show that this training strategy enables\nRBMs to effectively address highly structured datasets that conventional\nmethods struggle with. We also provide evidence that our log-likelihood\nestimation is more accurate than traditional, more computationally intensive\napproaches in controlled scenarios. The PTT algorithm significantly accelerates\nMCMC processes compared to existing and conventional methods.\n","authors":["Nicolas Béreux","Aurélien Decelle","Cyril Furtlehner","Lorenzo Rosset","Beatriz Seoane"],"pdf_url":"https://arxiv.org/pdf/2405.15376v2.pdf","comment":"31 pages, 16 figures"},{"id":"http://arxiv.org/abs/2411.05597v1","updated":"2024-11-08T14:40:56Z","published":"2024-11-08T14:40:56Z","title":"Predicting Stroke through Retinal Graphs and Multimodal Self-supervised\n  Learning","summary":"  Early identification of stroke is crucial for intervention, requiring\nreliable models. We proposed an efficient retinal image representation together\nwith clinical information to capture a comprehensive overview of cardiovascular\nhealth, leveraging large multimodal datasets for new medical insights. Our\napproach is one of the first contrastive frameworks that integrates graph and\ntabular data, using vessel graphs derived from retinal images for efficient\nrepresentation. This method, combined with multimodal contrastive learning,\nsignificantly enhances stroke prediction accuracy by integrating data from\nmultiple sources and using contrastive learning for transfer learning. The\nself-supervised learning techniques employed allow the model to learn\neffectively from unlabeled data, reducing the dependency on large annotated\ndatasets. Our framework showed an AUROC improvement of 3.78% from supervised to\nself-supervised approaches. Additionally, the graph-level representation\napproach achieved superior performance to image encoders while significantly\nreducing pre-training and fine-tuning runtimes. These findings indicate that\nretinal images are a cost-effective method for improving cardiovascular disease\npredictions and pave the way for future research into retinal and cerebral\nvessel connections and the use of graph-based retinal vessel representations.\n","authors":["Yuqing Huang","Bastian Wittmann","Olga Demler","Bjoern Menze","Neda Davoudi"],"pdf_url":"https://arxiv.org/pdf/2411.05597v1.pdf","comment":"Accepted as oral paper at ML-CDS workshop, MICCAI 2024"},{"id":"http://arxiv.org/abs/2411.05596v1","updated":"2024-11-08T14:31:50Z","published":"2024-11-08T14:31:50Z","title":"Machine learning-driven Anomaly Detection and Forecasting for Euclid\n  Space Telescope Operations","summary":"  State-of-the-art space science missions increasingly rely on automation due\nto spacecraft complexity and the costs of human oversight. The high volume of\ndata, including scientific and telemetry data, makes manual inspection\nchallenging. Machine learning offers significant potential to meet these\ndemands.\n  The Euclid space telescope, in its survey phase since February 2024,\nexemplifies this shift. Euclid's success depends on accurate monitoring and\ninterpretation of housekeeping telemetry and science-derived data. Thousands of\ntelemetry parameters, monitored as time series, may or may not impact the\nquality of scientific data. These parameters have complex interdependencies,\noften due to physical relationships (e.g., proximity of temperature sensors).\nOptimising science operations requires careful anomaly detection and\nidentification of hidden parameter states. Moreover, understanding the\ninteractions between known anomalies and physical quantities is crucial yet\ncomplex, as related parameters may display anomalies with varied timing and\nintensity.\n  We address these challenges by analysing temperature anomalies in Euclid's\ntelemetry from February to August 2024, focusing on eleven temperature\nparameters and 35 covariates. We use a predictive XGBoost model to forecast\ntemperatures based on historical values, detecting anomalies as deviations from\npredictions. A second XGBoost model predicts anomalies from covariates,\ncapturing their relationships to temperature anomalies. We identify the top\nthree anomalies per parameter and analyse their interactions with covariates\nusing SHAP (Shapley Additive Explanations), enabling rapid, automated analysis\nof complex parameter relationships.\n  Our method demonstrates how machine learning can enhance telemetry\nmonitoring, offering scalable solutions for other missions with similar data\nchallenges.\n","authors":["Pablo Gómez","Roland D. Vavrek","Guillermo Buenadicha","John Hoar","Sandor Kruk","Jan Reerink"],"pdf_url":"https://arxiv.org/pdf/2411.05596v1.pdf","comment":"Presented at IAC 2024"},{"id":"http://arxiv.org/abs/2306.00809v6","updated":"2024-11-08T14:27:36Z","published":"2023-06-01T15:37:32Z","title":"Initial Guessing Bias: How Untrained Networks Favor Some Classes","summary":"  Understanding and controlling biasing effects in neural networks is crucial\nfor ensuring accurate and fair model performance. In the context of\nclassification problems, we provide a theoretical analysis demonstrating that\nthe structure of a deep neural network (DNN) can condition the model to assign\nall predictions to the same class, even before the beginning of training, and\nin the absence of explicit biases. We prove that, besides dataset properties,\nthe presence of this phenomenon, which we call \\textit{Initial Guessing Bias}\n(IGB), is influenced by model choices including dataset preprocessing methods,\nand architectural decisions, such as activation functions, max-pooling layers,\nand network depth. Our analysis of IGB provides information for architecture\nselection and model initialization. We also highlight theoretical consequences,\nsuch as the breakdown of node-permutation symmetry, the violation of\nself-averaging and the non-trivial effects that depth has on the phenomenon.\n","authors":["Emanuele Francazi","Aurelien Lucchi","Marco Baity-Jesi"],"pdf_url":"https://arxiv.org/pdf/2306.00809v6.pdf","comment":"Fixed notation typos in Figure3 and Figure4"},{"id":"http://arxiv.org/abs/2411.05591v1","updated":"2024-11-08T14:25:46Z","published":"2024-11-08T14:25:46Z","title":"Network EM Algorithm for Gaussian Mixture Model in Decentralized\n  Federated Learning","summary":"  We systematically study various network Expectation-Maximization (EM)\nalgorithms for the Gaussian mixture model within the framework of decentralized\nfederated learning. Our theoretical investigation reveals that directly\nextending the classical decentralized supervised learning method to the EM\nalgorithm exhibits poor estimation accuracy with heterogeneous data across\nclients and struggles to converge numerically when Gaussian components are\npoorly-separated. To address these issues, we propose two novel solutions.\nFirst, to handle heterogeneous data, we introduce a momentum network EM (MNEM)\nalgorithm, which uses a momentum parameter to combine information from both the\ncurrent and historical estimators. Second, to tackle the challenge of\npoorly-separated Gaussian components, we develop a semi-supervised MNEM\n(semi-MNEM) algorithm, which leverages partially labeled data. Rigorous\ntheoretical analysis demonstrates that MNEM can achieve statistical efficiency\ncomparable to that of the whole sample estimator when the mixture components\nsatisfy certain separation conditions, even in heterogeneous scenarios.\nMoreover, the semi-MNEM estimator enhances the convergence speed of the MNEM\nalgorithm, effectively addressing the numerical convergence challenges in\npoorly-separated scenarios. Extensive simulation and real data analyses are\nconducted to justify our theoretical findings.\n","authors":["Shuyuan Wu","Bin Du","Xuetong Li","Hansheng Wang"],"pdf_url":"https://arxiv.org/pdf/2411.05591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11407v2","updated":"2024-11-08T14:21:51Z","published":"2023-10-17T17:14:07Z","title":"Group-blind optimal transport to group parity and its constrained\n  variants","summary":"  Fairness holds a pivotal role in the realm of machine learning, particularly\nwhen it comes to addressing groups categorised by protected attributes, e.g.,\ngender, race. Prevailing algorithms in fair learning predominantly hinge on\naccessibility or estimations of these protected attributes, at least in the\ntraining process. We design a single group-blind projection map that aligns the\nfeature distributions of both groups in the source data, achieving\n(demographic) group parity, without requiring values of the protected attribute\nfor individual samples in the computation of the map, as well as its use.\nInstead, our approach utilises the feature distributions of the privileged and\nunprivileged groups in a boarder population and the essential assumption that\nthe source data are unbiased representation of the population. We present\nnumerical results on synthetic data and real data.\n","authors":["Quan Zhou","Jakub Marecek"],"pdf_url":"https://arxiv.org/pdf/2310.11407v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.15368v2","updated":"2024-11-08T14:06:33Z","published":"2024-04-19T18:16:37Z","title":"Unmasking the Role of Remote Sensors in Comfort, Energy and Demand\n  Response","summary":"  In single-zone multi-node systems (SZMRSs), temperature controls rely on a\nsingle probe near the thermostat, resulting in temperature discrepancies that\ncause thermal discomfort and energy waste. Augmenting smart thermostats (STs)\nwith per-room sensors has gained acceptance by major ST manufacturers. This\npaper leverages additional sensory information to empirically characterize the\nservices provided by buildings, including thermal comfort, energy efficiency,\nand demand response (DR). Utilizing room-level time-series data from 1,000\nhouses, metadata from 110,000 houses across the United States, and data from\ntwo real-world testbeds, we examine the limitations of SZMNSs and explore the\npotential of remote sensors. We discovered that comfortable DR durations\n(CDRDs) for rooms are typically 70% longer or 40% shorter than for the room\nwith the thermostat. When averaging, rooms at the control temperature's bounds\nare typically deviated around -3{\\deg}F to 2.5{\\deg}F from the average.\nMoreover, in 95% of houses, we identified rooms experiencing notably higher\nsolar gains compared to the rest of the rooms, while 85% and 70% of houses\ndemonstrated lower heat input and poor insulation, respectively. Lastly, it\nbecame evident that the consumption of cooling energy escalates with the\nincrease in the number of sensors, whereas heating usage experiences\nfluctuations ranging from -19% to +25%. This study serves as a benchmark for\nassessing the thermal comfort and DR services in the existing housing stock,\nwhile also highlighting the energy efficiency impacts of sensing technologies.\nOur approach sets the stage for more granular, precise control strategies of\nSZMNSs.\n","authors":["Ozan Baris Mulayim","Edson Severnini","Mario Bergés"],"pdf_url":"https://arxiv.org/pdf/2404.15368v2.pdf","comment":"13 Figures, 8 Tables, 25 Pages. Published in Data-Centric Engineering\n  Journal"},{"id":"http://arxiv.org/abs/2411.05575v1","updated":"2024-11-08T14:04:17Z","published":"2024-11-08T14:04:17Z","title":"Towards a Real-Time Simulation of Elastoplastic Deformation Using\n  Multi-Task Neural Networks","summary":"  This study introduces a surrogate modeling framework merging proper\northogonal decomposition, long short-term memory networks, and multi-task\nlearning, to accurately predict elastoplastic deformations in real-time.\nSuperior to single-task neural networks, this approach achieves a mean absolute\nerror below 0.40\\% across various state variables, with the multi-task model\nshowing enhanced generalization by mitigating overfitting through shared\nlayers. Moreover, in our use cases, a pre-trained multi-task model can\neffectively train additional variables with as few as 20 samples, demonstrating\nits deep understanding of complex scenarios. This is notably efficient compared\nto single-task models, which typically require around 100 samples.\n  Significantly faster than traditional finite element analysis, our model\naccelerates computations by approximately a million times, making it a\nsubstantial advancement for real-time predictive modeling in engineering\napplications. While it necessitates further testing on more intricate models,\nthis framework shows substantial promise in elevating both efficiency and\naccuracy in engineering applications, particularly for real-time scenarios.\n","authors":["Ruben Schmeitz","Joris Remmers","Olga Mula","Olaf van der Sluis"],"pdf_url":"https://arxiv.org/pdf/2411.05575v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02867v3","updated":"2024-11-08T13:55:18Z","published":"2023-12-05T16:27:51Z","title":"Semi-Supervised Health Index Monitoring with Feature Generation and\n  Fusion","summary":"  The Health Index (HI) is crucial for evaluating system health and is\nimportant for tasks like anomaly detection and Remaining Useful Life (RUL)\nprediction of safety-critical systems. Real-time, meticulous monitoring of\nsystem conditions is essential, especially in manufacturing high-quality and\nsafety-critical components such as spray coatings. However, acquiring accurate\nhealth status information (HI labels) in real scenarios can be difficult or\ncostly because it requires continuous, precise measurements that fully capture\nthe system's health. As a result, using datasets from systems run-to-failure,\nwhich provide limited HI labels only at the healthy and end-of-life phases,\nbecomes a practical approach. We employ Deep Semi-supervised Anomaly Detection\n(DeepSAD) embeddings to tackle the challenge of extracting features associated\nwith the system's health state. Additionally, we introduce a diversity loss to\nfurther enrich the DeepSAD embeddings. We also propose applying an alternating\nprojection algorithm with isotonic constraints to transform the embedding into\na normalized HI with an increasing trend. Validation on the PHME2010 milling\ndataset, a recognized benchmark with ground truth HIs, confirms the efficacy of\nour proposed HI estimations. Our methodology is further applied to monitor the\nwear states of thermal spray coatings using high-frequency voltage. These\ncontributions facilitate more accessible and reliable HI estimation,\nparticularly in scenarios where obtaining ground truth HI labels is impossible.\n","authors":["Gaëtan Frusque","Ismail Nejjar","Majid Nabavi","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2312.02867v3.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.05564v1","updated":"2024-11-08T13:40:01Z","published":"2024-11-08T13:40:01Z","title":"Open-set object detection: towards unified problem formulation and\n  benchmarking","summary":"  In real-world applications where confidence is key, like autonomous driving,\nthe accurate detection and appropriate handling of classes differing from those\nused during training are crucial. Despite the proposal of various unknown\nobject detection approaches, we have observed widespread inconsistencies among\nthem regarding the datasets, metrics, and scenarios used, alongside a notable\nabsence of a clear definition for unknown objects, which hampers meaningful\nevaluation. To counter these issues, we introduce two benchmarks: a unified\nVOC-COCO evaluation, and the new OpenImagesRoad benchmark which provides clear\nhierarchical object definition besides new evaluation metrics. Complementing\nthe benchmark, we exploit recent self-supervised Vision Transformers\nperformance, to improve pseudo-labeling-based OpenSet Object Detection (OSOD),\nthrough OW-DETR++. State-of-the-art methods are extensively evaluated on the\nproposed benchmarks. This study provides a clear problem definition, ensures\nconsistent evaluations, and draws new conclusions about effectiveness of OSOD\nstrategies.\n","authors":["Hejer Ammar","Nikita Kiselov","Guillaume Lapouge","Romaric Audigier"],"pdf_url":"https://arxiv.org/pdf/2411.05564v1.pdf","comment":"Accepted at ECCV 2024 Workshop: \"The 3rd Workshop for\n  Out-of-Distribution Generalization in Computer Vision Foundation Models\""},{"id":"http://arxiv.org/abs/2410.15617v2","updated":"2024-11-08T13:38:04Z","published":"2024-10-21T03:36:34Z","title":"Long-time Integration of Nonlinear Wave Equations with Neural Operators","summary":"  Neural operators have shown promise in solving many types of Partial\nDifferential Equations (PDEs). They are significantly faster compared to\ntraditional numerical solvers once they have been trained with a certain amount\nof observed data. However, their numerical performance in solving\ntime-dependent PDEs, particularly in long-time prediction of dynamic systems,\nstill needs improvement. In this paper, we focus on solving the long-time\nintegration of nonlinear wave equations via neural operators by replacing the\ninitial condition with the prediction in a recurrent manner. Given limited\nobserved temporal trajectory data, we utilize some intrinsic features of these\nnonlinear wave equations, such as conservation laws and well-posedness, to\nimprove the algorithm design and reduce accumulated error. Our numerical\nexperiments examine these improvements in the Korteweg-de Vries (KdV) equation,\nthe sine-Gordon equation, and the Klein-Gordon wave equation on the irregular\ndomain.\n","authors":["Guanhang Lei","Zhen Lei","Lei Shi"],"pdf_url":"https://arxiv.org/pdf/2410.15617v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05561v1","updated":"2024-11-08T13:35:45Z","published":"2024-11-08T13:35:45Z","title":"Training objective drives the consistency of representational similarity\n  across datasets","summary":"  The Platonic Representation Hypothesis claims that recent foundation models\nare converging to a shared representation space as a function of their\ndownstream task performance, irrespective of the objectives and data modalities\nused to train these models. Representational similarity is generally measured\nfor individual datasets and is not necessarily consistent across datasets.\nThus, one may wonder whether this convergence of model representations is\nconfounded by the datasets commonly used in machine learning. Here, we propose\na systematic way to measure how representational similarity between models\nvaries with the set of stimuli used to construct the representations. We find\nthat the objective function is the most crucial factor in determining the\nconsistency of representational similarities across datasets. Specifically,\nself-supervised vision models learn representations whose relative pairwise\nsimilarities generalize better from one dataset to another compared to those of\nimage classification or image-text models. Moreover, the correspondence between\nrepresentational similarities and the models' task behavior is\ndataset-dependent, being most strongly pronounced for single-domain datasets.\nOur work provides a framework for systematically measuring similarities of\nmodel representations across datasets and linking those similarities to\ndifferences in task behavior.\n","authors":["Laure Ciernik","Lorenz Linhardt","Marco Morik","Jonas Dippel","Simon Kornblith","Lukas Muttenthaler"],"pdf_url":"https://arxiv.org/pdf/2411.05561v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2310.17705v3","updated":"2024-11-08T13:31:57Z","published":"2023-10-26T18:05:22Z","title":"A Wireless AI-Generated Content (AIGC) Provisioning Framework Empowered\n  by Semantic Communication","summary":"  With the significant advances in AI-generated content (AIGC) and the\nproliferation of mobile devices, providing high-quality AIGC services via\nwireless networks is becoming the future direction. However, the primary\nchallenges of AIGC services provisioning in wireless networks lie in unstable\nchannels, limited bandwidth resources, and unevenly distributed computational\nresources. To this end, this paper proposes a semantic communication\n(SemCom)-empowered AIGC (SemAIGC) generation and transmission framework, where\nonly semantic information of the content rather than all the binary bits should\nbe generated and transmitted by using SemCom. Specifically, SemAIGC integrates\ndiffusion models within the semantic encoder and decoder to design a\nworkload-adjustable transceiver thereby allowing adjustment of computational\nresource utilization in edge and local. In addition, a Resource-aware wOrklOad\nTrade-off (ROOT) scheme is devised to intelligently make workload adaptation\ndecisions for the transceiver, thus efficiently generating, transmitting, and\nfine-tuning content as per dynamic wireless channel conditions and service\nrequirements. Simulations verify the superiority of our proposed SemAIGC\nframework in terms of latency and content quality compared to conventional\napproaches.\n","authors":["Runze Cheng","Yao Sun","Dusit Niyato","Lan Zhang","Lei Zhang","Muhammad Ali Imran"],"pdf_url":"https://arxiv.org/pdf/2310.17705v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21333v3","updated":"2024-11-08T13:11:58Z","published":"2024-10-27T18:30:41Z","title":"Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on\n  Tasks where Thinking Makes Humans Worse","summary":"  Chain-of-thought (CoT) prompting has become a widely used strategy for\nworking with large language and multimodal models. While CoT has been shown to\nimprove performance across many tasks, determining the settings in which it is\neffective remains an ongoing effort. In particular, it is still an open\nquestion in what settings CoT systematically reduces model performance. In this\npaper, we seek to identify the characteristics of tasks where CoT reduces\nperformance by drawing inspiration from cognitive psychology, looking at cases\nwhere (i) verbal thinking or deliberation hurts performance in humans, and (ii)\nthe constraints governing human performance generalize to language models.\nThree such cases are implicit statistical learning, visual recognition, and\nclassifying with patterns containing exceptions. In extensive experiments\nacross all three settings, we find that a diverse collection of\nstate-of-the-art models exhibit significant drop-offs in performance (e.g., up\nto 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using\ninference-time reasoning compared to zero-shot counterparts. We also identify\nthree tasks that satisfy condition (i) but not (ii), and find that while verbal\nthinking reduces human performance in these tasks, CoT retains or increases\nmodel performance. Overall, our results show that while there is not an exact\nparallel between the cognitive processes of models and those of humans,\nconsidering cases where thinking has negative consequences for human\nperformance can help us identify settings where it negatively impacts models.\nBy connecting the literature on human deliberation with evaluations of CoT, we\noffer a new tool that can be used in understanding the impact of prompt choices\nand inference-time reasoning.\n","authors":["Ryan Liu","Jiayi Geng","Addison J. Wu","Ilia Sucholutsky","Tania Lombrozo","Thomas L. Griffiths"],"pdf_url":"https://arxiv.org/pdf/2410.21333v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05544v1","updated":"2024-11-08T12:58:48Z","published":"2024-11-08T12:58:48Z","title":"Towards Lifelong Few-Shot Customization of Text-to-Image Diffusion","summary":"  Lifelong few-shot customization for text-to-image diffusion aims to\ncontinually generalize existing models for new tasks with minimal data while\npreserving old knowledge. Current customization diffusion models excel in\nfew-shot tasks but struggle with catastrophic forgetting problems in lifelong\ngenerations. In this study, we identify and categorize the catastrophic\nforgetting problems into two folds: relevant concepts forgetting and previous\nconcepts forgetting. To address these challenges, we first devise a data-free\nknowledge distillation strategy to tackle relevant concepts forgetting. Unlike\nexisting methods that rely on additional real data or offline replay of\noriginal concept data, our approach enables on-the-fly knowledge distillation\nto retain the previous concepts while learning new ones, without accessing any\nprevious data. Second, we develop an In-Context Generation (ICGen) paradigm\nthat allows the diffusion model to be conditioned upon the input vision\ncontext, which facilitates the few-shot generation and mitigates the issue of\nprevious concepts forgetting. Extensive experiments show that the proposed\nLifelong Few-Shot Diffusion (LFS-Diffusion) method can produce high-quality and\naccurate images while maintaining previously learned knowledge.\n","authors":["Nan Song","Xiaofeng Yang","Ze Yang","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2411.05544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16254v2","updated":"2024-11-08T12:54:16Z","published":"2024-06-24T01:31:03Z","title":"Confidence Regulation Neurons in Language Models","summary":"  Despite their widespread use, the mechanisms by which large language models\n(LLMs) represent and regulate uncertainty in next-token predictions remain\nlargely unexplored. This study investigates two critical components believed to\ninfluence this uncertainty: the recently discovered entropy neurons and a new\nset of components that we term token frequency neurons. Entropy neurons are\ncharacterized by an unusually high weight norm and influence the final layer\nnormalization (LayerNorm) scale to effectively scale down the logits. Our work\nshows that entropy neurons operate by writing onto an unembedding null space,\nallowing them to impact the residual stream norm with minimal direct effect on\nthe logits themselves. We observe the presence of entropy neurons across a\nrange of models, up to 7 billion parameters. On the other hand, token frequency\nneurons, which we discover and describe here for the first time, boost or\nsuppress each token's logit proportionally to its log frequency, thereby\nshifting the output distribution towards or away from the unigram distribution.\nFinally, we present a detailed case study where entropy neurons actively manage\nconfidence in the setting of induction, i.e. detecting and continuing repeated\nsubsequences.\n","authors":["Alessandro Stolfo","Ben Wu","Wes Gurnee","Yonatan Belinkov","Xingyi Song","Mrinmaya Sachan","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2406.16254v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05536v1","updated":"2024-11-08T12:49:24Z","published":"2024-11-08T12:49:24Z","title":"Towards Active Flow Control Strategies Through Deep Reinforcement\n  Learning","summary":"  This paper presents a deep reinforcement learning (DRL) framework for active\nflow control (AFC) to reduce drag in aerodynamic bodies. Tested on a 3D\ncylinder at Re = 100, the DRL approach achieved a 9.32% drag reduction and a\n78.4% decrease in lift oscillations by learning advanced actuation strategies.\nThe methodology integrates a CFD solver with a DRL model using an in-memory\ndatabase for efficient communication between\n","authors":["Ricard Montalà","Bernat Font","Pol Suárez","Jean Rabault","Oriol Lehmkuhl","Ivette Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2411.05536v1.pdf","comment":"ECOMMAS 2024 conference proceeding paper"},{"id":"http://arxiv.org/abs/2402.09166v2","updated":"2024-11-08T12:45:38Z","published":"2024-02-14T13:32:23Z","title":"Deinterleaving of Discrete Renewal Process Mixtures with Application to\n  Electronic Support Measures","summary":"  In this paper, we propose a new deinterleaving method for mixtures of\ndiscrete renewal Markov chains. This method relies on the maximization of a\npenalized likelihood score. It exploits all available information about both\nthe sequence of the different symbols and their arrival times. A theoretical\nanalysis is carried out to prove that minimizing this score allows to recover\nthe true partition of symbols in the large sample limit, under mild conditions\non the component processes. This theoretical analysis is then validated by\nexperiments on synthetic data. Finally, the method is applied to deinterleave\npulse trains received from different emitters in a RESM (Radar Electronic\nSupport Measurements) context and we show that the proposed method competes\nfavorably with state-of-the-art methods on simulated warfare datasets.\n","authors":["Jean Pinsolle","Olivier Goudet","Cyrille Enderli","Sylvain Lamprier","Jin-Kao Hao"],"pdf_url":"https://arxiv.org/pdf/2402.09166v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17044v2","updated":"2024-11-08T12:44:49Z","published":"2024-09-25T15:54:29Z","title":"How to Connect Speech Foundation Models and Large Language Models? What\n  Matters and What Does Not","summary":"  The remarkable performance achieved by Large Language Models (LLM) has driven\nresearch efforts to leverage them for a wide range of tasks and input\nmodalities. In speech-to-text (S2T) tasks, the emerging solution consists of\nprojecting the output of the encoder of a Speech Foundational Model (SFM) into\nthe LLM embedding space through an adapter module. However, no work has yet\ninvestigated how much the downstream-task performance depends on each component\n(SFM, adapter, LLM) nor whether the best design of the adapter depends on the\nchosen SFM and LLM. To fill this gap, we evaluate the combination of 5 adapter\nmodules, 2 LLMs (Mistral and Llama), and 2 SFMs (Whisper and SeamlessM4T) on\ntwo widespread S2T tasks, namely Automatic Speech Recognition and Speech\nTranslation. Our results demonstrate that the SFM plays a pivotal role in\ndownstream performance, while the adapter choice has moderate impact and\ndepends on the SFM and LLM.\n","authors":["Francesco Verdini","Pierfrancesco Melucci","Stefano Perna","Francesco Cariaggi","Marco Gaido","Sara Papi","Szymon Mazurek","Marek Kasztelnik","Luisa Bentivogli","Sébastien Bratières","Paolo Merialdo","Simone Scardapane"],"pdf_url":"https://arxiv.org/pdf/2409.17044v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03880v3","updated":"2024-11-08T12:26:43Z","published":"2024-03-06T17:40:26Z","title":"Almost Surely Asymptotically Constant Graph Neural Networks","summary":"  We present a new angle on the expressive power of graph neural networks\n(GNNs) by studying how the predictions of real-valued GNN classifiers, such as\nthose classifying graphs probabilistically, evolve as we apply them on larger\ngraphs drawn from some random graph model. We show that the output converges to\na constant function, which upper-bounds what these classifiers can uniformly\nexpress. This strong convergence phenomenon applies to a very wide class of\nGNNs, including state of the art models, with aggregates including mean and the\nattention-based mechanism of graph transformers. Our results apply to a broad\nclass of random graph models, including sparse and dense variants of the\nErd\\H{o}s-R\\'enyi model, the stochastic block model, and the Barab\\'asi-Albert\nmodel. We empirically validate these findings, observing that the convergence\nphenomenon appears not only on random graphs but also on some real-world\ngraphs.\n","authors":["Sam Adam-Day","Michael Benedikt","İsmail İlkan Ceylan","Ben Finkelshtein"],"pdf_url":"https://arxiv.org/pdf/2403.03880v3.pdf","comment":"NeurIPS '24 camera-ready version; 10 body pages, 29 appendix pages,\n  11 figures"},{"id":"http://arxiv.org/abs/2411.05500v1","updated":"2024-11-08T12:02:25Z","published":"2024-11-08T12:02:25Z","title":"FGGP: Fixed-Rate Gradient-First Gradual Pruning","summary":"  In recent years, the increasing size of deep learning models and their\ngrowing demand for computational resources have drawn significant attention to\nthe practice of pruning neural networks, while aiming to preserve their\naccuracy. In unstructured gradual pruning, which sparsifies a network by\ngradually removing individual network parameters until a targeted network\nsparsity is reached, recent works show that both gradient and weight magnitudes\nshould be considered. In this work, we show that such mechanism, e.g., the\norder of prioritization and selection criteria, is essential. We introduce a\ngradient-first magnitude-next strategy for choosing the parameters to prune,\nand show that a fixed-rate subselection criterion between these steps works\nbetter, in contrast to the annealing approach in the literature. We validate\nthis on CIFAR-10 dataset, with multiple randomized initializations on both\nVGG-19 and ResNet-50 network backbones, for pruning targets of 90, 95, and 98%\nsparsity and for both initially dense and 50% sparse networks. Our proposed\nfixed-rate gradient-first gradual pruning (FGGP) approach outperforms its\nstate-of-the-art alternatives in most of the above experimental settings, even\noccasionally surpassing the upperbound of corresponding dense network results,\nand having the highest ranking across the considered experimental settings.\n","authors":["Lingkai Zhu","Can Deniz Bezek","Orcun Goksel"],"pdf_url":"https://arxiv.org/pdf/2411.05500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05489v1","updated":"2024-11-08T11:39:03Z","published":"2024-11-08T11:39:03Z","title":"Do Histopathological Foundation Models Eliminate Batch Effects? A\n  Comparative Study","summary":"  Deep learning has led to remarkable advancements in computational\nhistopathology, e.g., in diagnostics, biomarker prediction, and outcome\nprognosis. Yet, the lack of annotated data and the impact of batch effects,\ne.g., systematic technical data differences across hospitals, hamper model\nrobustness and generalization. Recent histopathological foundation models --\npretrained on millions to billions of images -- have been reported to improve\ngeneralization performances on various downstream tasks. However, it has not\nbeen systematically assessed whether they fully eliminate batch effects. In\nthis study, we empirically show that the feature embeddings of the foundation\nmodels still contain distinct hospital signatures that can lead to biased\npredictions and misclassifications. We further find that the signatures are not\nremoved by stain normalization methods, dominate distances in feature space,\nand are evident across various principal components. Our work provides a novel\nperspective on the evaluation of medical foundation models, paving the way for\nmore robust pretraining strategies and downstream predictors.\n","authors":["Jonah Kömen","Hannah Marienwald","Jonas Dippel","Julius Hense"],"pdf_url":"https://arxiv.org/pdf/2411.05489v1.pdf","comment":"Accepted to AIM-FM Workshop @ NeurIPS'24"},{"id":"http://arxiv.org/abs/2411.05486v1","updated":"2024-11-08T11:32:33Z","published":"2024-11-08T11:32:33Z","title":"Handling geometrical variability in nonlinear reduced order modeling\n  through Continuous Geometry-Aware DL-ROMs","summary":"  Deep Learning-based Reduced Order Models (DL-ROMs) provide nowadays a\nwell-established class of accurate surrogate models for complex physical\nsystems described by parametrized PDEs, by nonlinearly compressing the solution\nmanifold into a handful of latent coordinates. Until now, design and\napplication of DL-ROMs mainly focused on physically parameterized problems.\nWithin this work, we provide a novel extension of these architectures to\nproblems featuring geometrical variability and parametrized domains, namely, we\npropose Continuous Geometry-Aware DL-ROMs (CGA-DL-ROMs). In particular, the\nspace-continuous nature of the proposed architecture matches the need to deal\nwith multi-resolution datasets, which are quite common in the case of\ngeometrically parametrized problems. Moreover, CGA-DL-ROMs are endowed with a\nstrong inductive bias that makes them aware of geometrical parametrizations,\nthus enhancing both the compression capability and the overall performance of\nthe architecture. Within this work, we justify our findings through a thorough\ntheoretical analysis, and we practically validate our claims by means of a\nseries of numerical tests encompassing physically-and-geometrically\nparametrized PDEs, ranging from the unsteady Navier-Stokes equations for fluid\ndynamics to advection-diffusion-reaction equations for mathematical biology.\n","authors":["Simone Brivio","Stefania Fresca","Andrea Manzoni"],"pdf_url":"https://arxiv.org/pdf/2411.05486v1.pdf","comment":"30 pages, 15 figures"},{"id":"http://arxiv.org/abs/2408.10126v2","updated":"2024-11-08T11:30:20Z","published":"2024-08-19T16:13:35Z","title":"Learning Brave Assumption-Based Argumentation Frameworks via ASP","summary":"  Assumption-based Argumentation (ABA) is advocated as a unifying formalism for\nvarious forms of non-monotonic reasoning, including logic programming. It\nallows capturing defeasible knowledge, subject to argumentative debate. While,\nin much existing work, ABA frameworks are given up-front, in this paper we\nfocus on the problem of automating their learning from background knowledge and\npositive/negative examples. Unlike prior work, we newly frame the problem in\nterms of brave reasoning under stable extensions for ABA. We present a novel\nalgorithm based on transformation rules (such as Rote Learning, Folding,\nAssumption Introduction and Fact Subsumption) and an implementation thereof\nthat makes use of Answer Set Programming. Finally, we compare our technique to\nstate-of-the-art ILP systems that learn defeasible knowledge.\n","authors":["Emanuele De Angelis","Maurizio Proietti","Francesca Toni"],"pdf_url":"https://arxiv.org/pdf/2408.10126v2.pdf","comment":"Extended version of the paper published in: Proceedings 27th European\n  Conference on Artificial Intelligence, Frontiers in Artificial Intelligence\n  and Applications, Volume 392: ECAI 2024, pp. 3445 - 3452. DOI:\n  10.3233/FAIA240896"},{"id":"http://arxiv.org/abs/2411.05483v1","updated":"2024-11-08T11:21:31Z","published":"2024-11-08T11:21:31Z","title":"The Limits of Differential Privacy in Online Learning","summary":"  Differential privacy (DP) is a formal notion that restricts the privacy\nleakage of an algorithm when running on sensitive data, in which\nprivacy-utility trade-off is one of the central problems in private data\nanalysis. In this work, we investigate the fundamental limits of differential\nprivacy in online learning algorithms and present evidence that separates three\ntypes of constraints: no DP, pure DP, and approximate DP. We first describe a\nhypothesis class that is online learnable under approximate DP but not online\nlearnable under pure DP under the adaptive adversarial setting. This indicates\nthat approximate DP must be adopted when dealing with adaptive adversaries. We\nthen prove that any private online learner must make an infinite number of\nmistakes for almost all hypothesis classes. This essentially generalizes\nprevious results and shows a strong separation between private and non-private\nsettings since a finite mistake bound is always attainable (as long as the\nclass is online learnable) when there is no privacy requirement.\n","authors":["Bo Li","Wei Wang","Peng Ye"],"pdf_url":"https://arxiv.org/pdf/2411.05483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05472v1","updated":"2024-11-08T10:53:39Z","published":"2024-11-08T10:53:39Z","title":"Bridging the Gap between Learning and Inference for Diffusion-Based\n  Molecule Generation","summary":"  The efficacy of diffusion models in generating a spectrum of data modalities,\nincluding images, text, and videos, has spurred inquiries into their utility in\nmolecular generation, yielding significant advancements in the field. However,\nthe molecular generation process with diffusion models involves multiple\nautoregressive steps over a finite time horizon, leading to exposure bias\nissues inherently. To address the exposure bias issue, we propose a training\nframework named GapDiff. The core idea of GapDiff is to utilize model-predicted\nconformations as ground truth probabilistically during training, aiming to\nmitigate the data distributional disparity between training and inference,\nthereby enhancing the affinity of generated molecules. We conduct experiments\nusing a 3D molecular generation model on the CrossDocked2020 dataset, and the\nvina energy and diversity demonstrate the potency of our framework with\nsuperior affinity. GapDiff is available at\n\\url{https://github.com/HUGHNew/gapdiff}.\n","authors":["Peidong Liu","Wenbo Zhang","Xue Zhe","Jiancheng Lv","Xianggen Liu"],"pdf_url":"https://arxiv.org/pdf/2411.05472v1.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2405.09597v3","updated":"2024-11-08T10:51:40Z","published":"2024-05-15T13:50:23Z","title":"When AI Eats Itself: On the Caveats of AI Autophagy","summary":"  Generative Artificial Intelligence (AI) technologies and large models are\nproducing realistic outputs across various domains, such as images, text,\nspeech, and music. Creating these advanced generative models requires\nsignificant resources, particularly large and high-quality datasets. To\nminimise training expenses, many algorithm developers use data created by the\nmodels themselves as a cost-effective training solution. However, not all\nsynthetic data effectively improve model performance, necessitating a strategic\nbalance in the use of real versus synthetic data to optimise outcomes.\nCurrently, the previously well-controlled integration of real and synthetic\ndata is becoming uncontrollable. The widespread and unregulated dissemination\nof synthetic data online leads to the contamination of datasets traditionally\ncompiled through web scraping, now mixed with unlabeled synthetic data. This\ntrend, known as the AI autophagy phenomenon, suggests a future where generative\nAI systems may increasingly consume their own outputs without discernment,\nraising concerns about model performance, reliability, and ethical\nimplications. What will happen if generative AI continuously consumes itself\nwithout discernment? What measures can we take to mitigate the potential\nadverse effects? To address these research questions, this study examines the\nexisting literature, delving into the consequences of AI autophagy, analyzing\nthe associated risks, and exploring strategies to mitigate its impact. Our aim\nis to provide a comprehensive perspective on this phenomenon advocating for a\nbalanced approach that promotes the sustainable development of generative AI\ntechnologies in the era of large models.\n","authors":["Xiaodan Xing","Fadong Shi","Jiahao Huang","Yinzhe Wu","Yang Nan","Sheng Zhang","Yingying Fang","Mike Roberts","Carola-Bibiane Schönlieb","Javier Del Ser","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2405.09597v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19928v2","updated":"2024-11-08T10:46:09Z","published":"2024-05-30T10:44:45Z","title":"BAN: Detecting Backdoors Activated by Adversarial Neuron Noise","summary":"  Backdoor attacks on deep learning represent a recent threat that has gained\nsignificant attention in the research community. Backdoor defenses are mainly\nbased on backdoor inversion, which has been shown to be generic,\nmodel-agnostic, and applicable to practical threat scenarios. State-of-the-art\nbackdoor inversion recovers a mask in the feature space to locate prominent\nbackdoor features, where benign and backdoor features can be disentangled.\nHowever, it suffers from high computational overhead, and we also find that it\noverly relies on prominent backdoor features that are highly distinguishable\nfrom benign features. To tackle these shortcomings, this paper improves\nbackdoor feature inversion for backdoor detection by incorporating extra neuron\nactivation information. In particular, we adversarially increase the loss of\nbackdoored models with respect to weights to activate the backdoor effect,\nbased on which we can easily differentiate backdoored and clean models.\nExperimental results demonstrate our defense, BAN, is 1.37$\\times$ (on\nCIFAR-10) and 5.11$\\times$ (on ImageNet200) more efficient with an average\n9.99\\% higher detect success rate than the state-of-the-art defense BTI-DBF.\nOur code and trained models are publicly available\nat~\\url{https://github.com/xiaoyunxxy/ban}.\n","authors":["Xiaoyun Xu","Zhuoran Liu","Stefanos Koffas","Shujian Yu","Stjepan Picek"],"pdf_url":"https://arxiv.org/pdf/2405.19928v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04088v2","updated":"2024-11-08T10:38:26Z","published":"2024-06-06T13:58:41Z","title":"Deterministic Uncertainty Propagation for Improved Model-Based Offline\n  Reinforcement Learning","summary":"  Current approaches to model-based offline reinforcement learning often\nincorporate uncertainty-based reward penalization to address the distributional\nshift problem. These approaches, commonly known as pessimistic value iteration,\nuse Monte Carlo sampling to estimate the Bellman target to perform temporal\ndifference based policy evaluation. We find out that the randomness caused by\nthis sampling step significantly delays convergence. We present a theoretical\nresult demonstrating the strong dependency of suboptimality on the number of\nMonte Carlo samples taken per Bellman target calculation. Our main contribution\nis a deterministic approximation to the Bellman target that uses progressive\nmoment matching, a method developed originally for deterministic variational\ninference. The resulting algorithm, which we call Moment Matching Offline\nModel-Based Policy Optimization (MOMBO), propagates the uncertainty of the next\nstate through a nonlinear Q-network in a deterministic fashion by approximating\nthe distributions of hidden layer activations by a normal distribution. We show\nthat it is possible to provide tighter guarantees for the suboptimality of\nMOMBO than the existing Monte Carlo sampling approaches. We also observe MOMBO\nto converge faster than these approaches in a large set of benchmark tasks.\n","authors":["Abdullah Akgül","Manuel Haußmann","Melih Kandemir"],"pdf_url":"https://arxiv.org/pdf/2406.04088v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05464v1","updated":"2024-11-08T10:34:24Z","published":"2024-11-08T10:34:24Z","title":"Generalization, Expressivity, and Universality of Graph Neural Networks\n  on Attributed Graphs","summary":"  We analyze the universality and generalization of graph neural networks\n(GNNs) on attributed graphs, i.e., with node attributes. To this end, we\npropose pseudometrics over the space of all attributed graphs that describe the\nfine-grained expressivity of GNNs. Namely, GNNs are both Lipschitz continuous\nwith respect to our pseudometrics and can separate attributed graphs that are\ndistant in the metric. Moreover, we prove that the space of all attributed\ngraphs is relatively compact with respect to our metrics. Based on these\nproperties, we prove a universal approximation theorem for GNNs and\ngeneralization bounds for GNNs on any data distribution of attributed graphs.\nThe proposed metrics compute the similarity between the structures of\nattributed graphs via a hierarchical optimal transport between computation\ntrees. Our work extends and unites previous approaches which either derived\ntheory only for graphs with no attributes, derived compact metrics under which\nGNNs are continuous but without separation power, or derived metrics under\nwhich GNNs are continuous and separate points but the space of graphs is not\nrelatively compact, which prevents universal approximation and generalization\nanalysis.\n","authors":["Levi Rauchwerger","Stefanie Jegelka","Ron Levie"],"pdf_url":"https://arxiv.org/pdf/2411.05464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02199v3","updated":"2024-11-08T10:30:59Z","published":"2024-11-04T15:54:32Z","title":"Provably Transformers Harness Multi-Concept Word Semantics for Efficient\n  In-Context Learning","summary":"  Transformer-based large language models (LLMs) have displayed remarkable\ncreative prowess and emergence capabilities. Existing empirical studies have\nrevealed a strong connection between these LLMs' impressive emergence abilities\nand their in-context learning (ICL) capacity, allowing them to solve new tasks\nusing only task-specific prompts without further fine-tuning. On the other\nhand, existing empirical and theoretical studies also show that there is a\nlinear regularity of the multi-concept encoded semantic representation behind\ntransformer-based LLMs. However, existing theoretical work fail to build up an\nunderstanding of the connection between this regularity and the innovative\npower of ICL. Additionally, prior work often focuses on simplified, unrealistic\nscenarios involving linear transformers or unrealistic loss functions, and they\nachieve only linear or sub-linear convergence rates. In contrast, this work\nprovides a fine-grained mathematical analysis to show how transformers leverage\nthe multi-concept semantics of words to enable powerful ICL and excellent\nout-of-distribution ICL abilities, offering insights into how transformers\ninnovate solutions for certain unseen tasks encoded with multiple cross-concept\nsemantics. Inspired by empirical studies on the linear latent geometry of LLMs,\nthe analysis is based on a concept-based low-noise sparse coding prompt model.\nLeveraging advanced techniques, this work showcases the exponential 0-1 loss\nconvergence over the highly non-convex training dynamics, which pioneeringly\nincorporates the challenges of softmax self-attention, ReLU-activated MLPs, and\ncross-entropy loss. Empirical simulations corroborate the theoretical findings.\n","authors":["Dake Bu","Wei Huang","Andi Han","Atsushi Nitanda","Taiji Suzuki","Qingfu Zhang","Hau-San Wong"],"pdf_url":"https://arxiv.org/pdf/2411.02199v3.pdf","comment":"Accepted by the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2405.17372v2","updated":"2024-11-08T10:25:43Z","published":"2024-05-27T17:28:25Z","title":"BehaviorGPT: Smart Agent Simulation for Autonomous Driving with\n  Next-Patch Prediction","summary":"  Simulating realistic interactions among traffic agents is crucial for\nefficiently validating the safety of autonomous driving systems. Existing\nleading simulators primarily use an encoder-decoder structure to encode the\nhistorical trajectories for future simulation. However, such a paradigm\ncomplicates the model architecture, and the manual separation of history and\nfuture trajectories leads to low data utilization. To address these challenges,\nwe propose Behavior Generative Pre-trained Transformers (BehaviorGPT), a\ndecoder-only, autoregressive architecture designed to simulate the sequential\nmotion of multiple agents. Crucially, our approach discards the traditional\nseparation between \"history\" and \"future,\" treating each time step as the\n\"current\" one, resulting in a simpler, more parameter- and data-efficient\ndesign that scales seamlessly with data and computation. Additionally, we\nintroduce the Next-Patch Prediction Paradigm (NP3), which enables models to\nreason at the patch level of trajectories and capture long-range\nspatial-temporal interactions. BehaviorGPT ranks first across several metrics\non the Waymo Sim Agents Benchmark, demonstrating its exceptional performance in\nmulti-agent and agent-map interactions. We outperformed state-of-the-art models\nwith a realism score of 0.741 and improved the minADE metric to 1.540, with an\napproximately 91.6% reduction in model parameters.\n","authors":["Zikang Zhou","Haibo Hu","Xinhong Chen","Jianping Wang","Nan Guan","Kui Wu","Yung-Hui Li","Yu-Kai Huang","Chun Jason Xue"],"pdf_url":"https://arxiv.org/pdf/2405.17372v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04832v2","updated":"2024-11-08T10:19:15Z","published":"2024-11-07T16:13:54Z","title":"Plasticity Loss in Deep Reinforcement Learning: A Survey","summary":"  Akin to neuroplasticity in human brains, the plasticity of deep neural\nnetworks enables their quick adaption to new data. This makes plasticity\nparticularly crucial for deep Reinforcement Learning (RL) agents: Once\nplasticity is lost, an agent's performance will inevitably plateau because it\ncannot improve its policy to account for changes in the data distribution,\nwhich are a necessary consequence of its learning process. Thus, developing\nwell-performing and sample-efficient agents hinges on their ability to remain\nplastic during training. Furthermore, the loss of plasticity can be connected\nto many other issues plaguing deep RL, such as training instabilities, scaling\nfailures, overestimation bias, and insufficient exploration. With this survey,\nwe aim to provide an overview of the emerging research on plasticity loss for\nacademics and practitioners of deep reinforcement learning. First, we propose a\nunified definition of plasticity loss based on recent works, relate it to\ndefinitions from the literature, and discuss metrics for measuring plasticity\nloss. Then, we categorize and discuss numerous possible causes of plasticity\nloss before reviewing currently employed mitigation strategies. Our taxonomy is\nthe first systematic overview of the current state of the field. Lastly, we\ndiscuss prevalent issues within the literature, such as a necessity for broader\nevaluation, and provide recommendations for future research, like gaining a\nbetter understanding of an agent's neural activity and behavior.\n","authors":["Timo Klein","Lukas Miklautz","Kevin Sidak","Claudia Plant","Sebastian Tschiatschek"],"pdf_url":"https://arxiv.org/pdf/2411.04832v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12789v3","updated":"2024-11-08T10:17:29Z","published":"2024-02-20T07:57:38Z","title":"Fairness Without Harm: An Influence-Guided Active Sampling Approach","summary":"  The pursuit of fairness in machine learning (ML), ensuring that the models do\nnot exhibit biases toward protected demographic groups, typically results in a\ncompromise scenario. This compromise can be explained by a Pareto frontier\nwhere given certain resources (e.g., data), reducing the fairness violations\noften comes at the cost of lowering the model accuracy. In this work, we aim to\ntrain models that mitigate group fairness disparity without causing harm to\nmodel accuracy. Intuitively, acquiring more data is a natural and promising\napproach to achieve this goal by reaching a better Pareto frontier of the\nfairness-accuracy tradeoff. The current data acquisition methods, such as fair\nactive learning approaches, typically require annotating sensitive attributes.\nHowever, these sensitive attribute annotations should be protected due to\nprivacy and safety concerns. In this paper, we propose a tractable active data\nsampling algorithm that does not rely on training group annotations, instead\nonly requiring group annotations on a small validation set. Specifically, the\nalgorithm first scores each new example by its influence on fairness and\naccuracy evaluated on the validation dataset, and then selects a certain number\nof examples for training. We theoretically analyze how acquiring more data can\nimprove fairness without causing harm, and validate the possibility of our\nsampling approach in the context of risk disparity. We also provide the upper\nbound of generalization error and risk disparity as well as the corresponding\nconnections. Extensive experiments on real-world data demonstrate the\neffectiveness of our proposed algorithm. Our code is available at\nhttps://github.com/UCSC-REAL/FairnessWithoutHarm.\n","authors":["Jinlong Pang","Jialu Wang","Zhaowei Zhu","Yuanshun Yao","Chen Qian","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2402.12789v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05456v1","updated":"2024-11-08T10:07:03Z","published":"2024-11-08T10:07:03Z","title":"Comparative Study of Probabilistic Atlas and Deep Learning Approaches\n  for Automatic Brain Tissue Segmentation from MRI Using N4 Bias Field\n  Correction and Anisotropic Diffusion Pre-processing Techniques","summary":"  Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI)\nimages is vital for accurate diagnosis and further analysis in medical imaging.\nDespite advancements in segmentation techniques, a comprehensive comparison\nbetween traditional statistical methods and modern deep learning approaches\nusing pre-processing techniques like N4 Bias Field Correction and Anisotropic\nDiffusion remains underexplored. This study provides a comparative analysis of\nvarious segmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and\nLinkNet, enhanced with these pre-processing techniques to segment brain tissues\n(white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF)) on the\nInternet Brain Segmentation Repository (IBSR18) dataset. Our results\ndemonstrate that the 3D nnU-Net model outperforms others, achieving the highest\nmean Dice Coefficient score (0.937 +- 0.012), while the 2D nnU-Net model\nrecorded the lowest mean Hausdorff Distance (5.005 +- 0.343 mm) and the lowest\nmean Absolute Volumetric Difference (3.695 +- 2.931 mm) across five unseen test\nsamples. The findings highlight the superiority of nnU-Net models in brain\ntissue segmentation, particularly when combined with N4 Bias Field Correction\nand Anisotropic Diffusion pre-processing techniques. Our implemented code can\nbe accessed via GitHub.\n","authors":["Mohammad Imran Hossain","Muhammad Zain Amin","Daniel Tweneboah Anyimadu","Taofik Ahmed Suleiman"],"pdf_url":"https://arxiv.org/pdf/2411.05456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10119v4","updated":"2024-11-08T10:06:06Z","published":"2024-01-18T16:50:55Z","title":"Towards Principled Graph Transformers","summary":"  Graph learning architectures based on the k-dimensional Weisfeiler-Leman\n(k-WL) hierarchy offer a theoretically well-understood expressive power.\nHowever, such architectures often fail to deliver solid predictive performance\non real-world tasks, limiting their practical impact. In contrast, global\nattention-based models such as graph transformers demonstrate strong\nperformance in practice, but comparing their expressive power with the k-WL\nhierarchy remains challenging, particularly since these architectures rely on\npositional or structural encodings for their expressivity and predictive\nperformance. To address this, we show that the recently proposed Edge\nTransformer, a global attention model operating on node pairs instead of nodes,\nhas at least 3-WL expressive power. Empirically, we demonstrate that the Edge\nTransformer surpasses other theoretically aligned architectures regarding\npredictive performance while not relying on positional or structural encodings.\nOur code is available at https://github.com/luis-mueller/towards-principled-gts\n","authors":["Luis Müller","Daniel Kusuma","Blai Bonet","Christopher Morris"],"pdf_url":"https://arxiv.org/pdf/2401.10119v4.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05453v1","updated":"2024-11-08T10:00:40Z","published":"2024-11-08T10:00:40Z","title":"The sampling complexity of learning invertible residual neural networks","summary":"  In recent work it has been shown that determining a feedforward ReLU neural\nnetwork to within high uniform accuracy from point samples suffers from the\ncurse of dimensionality in terms of the number of samples needed. As a\nconsequence, feedforward ReLU neural networks are of limited use for\napplications where guaranteed high uniform accuracy is required.\n  We consider the question of whether the sampling complexity can be improved\nby restricting the specific neural network architecture. To this end, we\ninvestigate invertible residual neural networks which are foundational\narchitectures in deep learning and are widely employed in models that power\nmodern generative methods. Our main result shows that the residual neural\nnetwork architecture and invertibility do not help overcome the complexity\nbarriers encountered with simpler feedforward architectures. Specifically, we\ndemonstrate that the computational complexity of approximating invertible\nresidual neural networks from point samples in the uniform norm suffers from\nthe curse of dimensionality. Similar results are established for invertible\nconvolutional Residual neural networks.\n","authors":["Yuanyuan Li","Philipp Grohs","Philipp Petersen"],"pdf_url":"https://arxiv.org/pdf/2411.05453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14250v4","updated":"2024-11-08T09:57:56Z","published":"2024-05-23T07:28:56Z","title":"Diffusion models for Gaussian distributions: Exact solutions and\n  Wasserstein errors","summary":"  Diffusion or score-based models recently showed high performance in image\ngeneration. They rely on a forward and a backward stochastic differential\nequations (SDE). The sampling of a data distribution is achieved by solving\nnumerically the backward SDE or its associated flow ODE. Studying the\nconvergence of these models necessitates to control four different types of\nerror: the initialization error, the truncation error, the discretization and\nthe score approximation. In this paper, we study theoretically the behavior of\ndiffusion models and their numerical implementation when the data distribution\nis Gaussian. In this restricted framework where the score function is a linear\noperator, we derive the analytical solutions of the backward SDE and the\nprobability flow ODE. We prove that these solutions and their discretizations\nare all Gaussian processes, which allows us to compute exact Wasserstein errors\ninduced by each error type for any sampling scheme. Monitoring convergence\ndirectly in the data space instead of relying on Inception features, our\nexperiments show that the recommended numerical schemes from the diffusion\nmodels literature are also the best sampling schemes for Gaussian\ndistributions.\n","authors":["Emile Pierret","Bruno Galerne"],"pdf_url":"https://arxiv.org/pdf/2405.14250v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14689v3","updated":"2024-11-08T09:37:14Z","published":"2024-05-23T15:25:56Z","title":"Cascade of phase transitions in the training of Energy-based models","summary":"  In this paper, we investigate the feature encoding process in a prototypical\nenergy-based generative model, the Restricted Boltzmann Machine (RBM). We start\nwith an analytical investigation using simplified architectures and data\nstructures, and end with numerical analysis of real trainings on real datasets.\nOur study tracks the evolution of the model's weight matrix through its\nsingular value decomposition, revealing a series of phase transitions\nassociated to a progressive learning of the principal modes of the empirical\nprobability distribution. The model first learns the center of mass of the\nmodes and then progressively resolve all modes through a cascade of phase\ntransitions. We first describe this process analytically in a controlled setup\nthat allows us to study analytically the training dynamics. We then validate\nour theoretical results by training the Bernoulli-Bernoulli RBM on real data\nsets. By using data sets of increasing dimension, we show that learning indeed\nleads to sharp phase transitions in the high-dimensional limit. Moreover, we\npropose and test a mean-field finite-size scaling hypothesis. This shows that\nthe first phase transition is in the same universality class of the one we\nstudied analytically, and which is reminiscent of the mean-field\nparamagnetic-to-ferromagnetic phase transition.\n","authors":["Dimitrios Bachtis","Giulio Biroli","Aurélien Decelle","Beatriz Seoane"],"pdf_url":"https://arxiv.org/pdf/2405.14689v3.pdf","comment":"19 pages, 6 figures, accepted to Neurips2024"},{"id":"http://arxiv.org/abs/2402.17089v2","updated":"2024-11-08T09:33:04Z","published":"2024-02-26T23:56:11Z","title":"Learnability of high-dimensional targets by two-parameter models and\n  gradient flow","summary":"  We explore the theoretical possibility of learning $d$-dimensional targets\nwith $W$-parameter models by gradient flow (GF) when $W<d$. Our main result\nshows that if the targets are described by a particular $d$-dimensional\nprobability distribution, then there exist models with as few as two parameters\nthat can learn the targets with arbitrarily high success probability. On the\nother hand, we show that for $W<d$ there is necessarily a large subset of\nGF-non-learnable targets. In particular, the set of learnable targets is not\ndense in $\\mathbb R^d$, and any subset of $\\mathbb R^d$ homeomorphic to the\n$W$-dimensional sphere contains non-learnable targets. Finally, we observe that\nthe model in our main theorem on almost guaranteed two-parameter learning is\nconstructed using a hierarchical procedure and as a result is not expressible\nby a single elementary function. We show that this limitation is essential in\nthe sense that most models written in terms of elementary functions cannot\nachieve the learnability demonstrated in this theorem.\n","authors":["Dmitry Yarotsky"],"pdf_url":"https://arxiv.org/pdf/2402.17089v2.pdf","comment":"Camera-ready NeurIPS 2024 version; some extra comments and figures"},{"id":"http://arxiv.org/abs/2411.05424v1","updated":"2024-11-08T09:16:05Z","published":"2024-11-08T09:16:05Z","title":"ICE-T: A Multi-Faceted Concept for Teaching Machine Learning","summary":"  The topics of Artificial intelligence (AI) and especially Machine Learning\n(ML) are increasingly making their way into educational curricula. To\nfacilitate the access for students, a variety of platforms, visual tools, and\ndigital games are already being used to introduce ML concepts and strengthen\nthe understanding of how AI works. We take a look at didactic principles that\nare employed for teaching computer science, define criteria, and, based on\nthose, evaluate a selection of prominent existing platforms, tools, and games.\nAdditionally, we criticize the approach of portraying ML mostly as a black-box\nand the resulting missing focus on creating an understanding of data,\nalgorithms, and models that come with it. To tackle this issue, we present a\nconcept that covers intermodal transfer, computational and explanatory\nthinking, ICE-T, as an extension of known didactic principles. With our\nmulti-faceted concept, we believe that planners of learning units, creators of\nlearning platforms and educators can improve on teaching ML.\n","authors":["Hendrik Krone","Pierre Haritz","Thomas Liebig"],"pdf_url":"https://arxiv.org/pdf/2411.05424v1.pdf","comment":"Accepted and presented at the 17th International Conference on\n  Informatics in Schools (ISSEP 2024)"},{"id":"http://arxiv.org/abs/2411.05420v1","updated":"2024-11-08T09:14:19Z","published":"2024-11-08T09:14:19Z","title":"WeatherGFM: Learning A Weather Generalist Foundation Model via\n  In-context Learning","summary":"  The Earth's weather system encompasses intricate weather data modalities and\ndiverse weather understanding tasks, which hold significant value to human\nlife. Existing data-driven models focus on single weather understanding tasks\n(e.g., weather forecasting). Although these models have achieved promising\nresults, they fail to tackle various complex tasks within a single and unified\nmodel. Moreover, the paradigm that relies on limited real observations for a\nsingle scenario hinders the model's performance upper bound. In response to\nthese limitations, we draw inspiration from the in-context learning paradigm\nemployed in state-of-the-art visual foundation models and large language\nmodels. In this paper, we introduce the first generalist weather foundation\nmodel (WeatherGFM), designed to address a wide spectrum of weather\nunderstanding tasks in a unified manner. More specifically, we initially unify\nthe representation and definition of the diverse weather understanding tasks.\nSubsequently, we devised weather prompt formats to manage different weather\ndata modalities, namely single, multiple, and temporal modalities. Finally, we\nadopt a visual prompting question-answering paradigm for the training of\nunified weather understanding tasks. Extensive experiments indicate that our\nWeatherGFM can effectively handle up to ten weather understanding tasks,\nincluding weather forecasting, super-resolution, weather image translation, and\npost-processing. Our method also showcases generalization ability on unseen\ntasks.\n","authors":["Xiangyu Zhao","Zhiwang Zhou","Wenlong Zhang","Yihao Liu","Xiangyu Chen","Junchao Gong","Hao Chen","Ben Fei","Shiqi Chen","Wanli Ouyang","Xiao-Ming Wu","Lei Bai"],"pdf_url":"https://arxiv.org/pdf/2411.05420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07230v2","updated":"2024-11-08T08:55:00Z","published":"2024-03-12T00:58:19Z","title":"Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked\n  Preferences","summary":"  Direct Preference Optimization (DPO) is an effective technique that leverages\npairwise preference data (usually one chosen and rejected response pair per\nuser prompt) to align LLMs to human preferences. In practice, multiple\nresponses can exist for a given prompt with varying quality relative to each\nother. With availability of such quality ratings for multiple responses, we\npropose utilizing these responses to create multiple preference pairs for a\ngiven prompt. Our work focuses on systematically using the constructed multiple\npreference pair in DPO training via curriculum learning methodology. In\nparticular, we order these multiple pairs of preference data from easy to hard\n(emulating curriculum training) according to various criteria. We show detailed\ncomparisons of our proposed approach to the standard single-pair DPO setting.\nOur method, which we call Curry-DPO consistently shows increased performance\ngains on MTbench, Vicuna, WizardLM, and the UltraFeedback test set,\nhighlighting its effectiveness. More specifically, Curry-DPO achieves a score\nof 7.43 on MT-bench with Zephy-7B model outperforming majority of existing LLMs\nwith similar parameter size. Curry-DPO also achieves the highest adjusted win\nrates on Vicuna, WizardLM, and UltraFeedback test datasets (90.7%, 87.1%, and\n87.9% respectively) in our experiments, with notable gains of upto 7.5% when\ncompared to standard DPO technique. We release the preference pairs used in\nalignment at:\nhttps://huggingface.co/datasets/ServiceNow-AI/Curriculum_DPO_preferences\n","authors":["Pulkit Pattnaik","Rishabh Maheshwary","Kelechi Ogueji","Vikas Yadav","Sathwik Tejaswi Madhusudhan"],"pdf_url":"https://arxiv.org/pdf/2403.07230v2.pdf","comment":"Published at EMNLP 2024 as long (findings) conference paper"},{"id":"http://arxiv.org/abs/2411.02540v2","updated":"2024-11-08T08:29:10Z","published":"2024-11-04T19:21:06Z","title":"GraphXAIN: Narratives to Explain Graph Neural Networks","summary":"  Graph Neural Networks (GNNs) are a powerful technique for machine learning on\ngraph-structured data, yet they pose interpretability challenges, especially\nfor non-expert users. Existing GNN explanation methods often yield technical\noutputs such as subgraphs and feature importance scores, which are not easily\nunderstood. Building on recent insights from social science and other\nExplainable AI (XAI) methods, we propose GraphXAIN, a natural language\nnarrative that explains individual predictions made by GNNs. We present a\nmodel-agnostic and explainer-agnostic XAI approach that complements graph\nexplainers by generating GraphXAINs, using Large Language Models (LLMs) and\nintegrating graph data, individual predictions from GNNs, explanatory\nsubgraphs, and feature importances. We define XAI Narratives and XAI\nDescriptions, highlighting their distinctions and emphasizing the importance of\nnarrative principles in effective explanations. By incorporating natural\nlanguage narratives, our approach supports graph practitioners and non-expert\nusers, aligning with social science research on explainability and enhancing\nuser understanding and trust in complex GNN models. We demonstrate GraphXAIN's\ncapabilities on a real-world graph dataset, illustrating how its generated\nnarratives can aid understanding compared to traditional graph explainer\noutputs or other descriptive explanation methods.\n","authors":["Mateusz Cedro","David Martens"],"pdf_url":"https://arxiv.org/pdf/2411.02540v2.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.05399v1","updated":"2024-11-08T08:26:42Z","published":"2024-11-08T08:26:42Z","title":"Post-Hoc Robustness Enhancement in Graph Neural Networks with\n  Conditional Random Fields","summary":"  Graph Neural Networks (GNNs), which are nowadays the benchmark approach in\ngraph representation learning, have been shown to be vulnerable to adversarial\nattacks, raising concerns about their real-world applicability. While existing\ndefense techniques primarily concentrate on the training phase of GNNs,\ninvolving adjustments to message passing architectures or pre-processing\nmethods, there is a noticeable gap in methods focusing on increasing robustness\nduring inference. In this context, this study introduces RobustCRF, a post-hoc\napproach aiming to enhance the robustness of GNNs at the inference stage. Our\nproposed method, founded on statistical relational learning using a Conditional\nRandom Field, is model-agnostic and does not require prior knowledge about the\nunderlying model architecture. We validate the efficacy of this approach across\nvarious models, leveraging benchmark node classification datasets.\n","authors":["Yassine Abbahaddou","Sofiane Ennadir","Johannes F. Lutzeyer","Fragkiskos D. Malliaros","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2411.05399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05384v1","updated":"2024-11-08T07:46:50Z","published":"2024-11-08T07:46:50Z","title":"Advancing Meteorological Forecasting: AI-based Approach to Synoptic\n  Weather Map Analysis","summary":"  As global warming increases the complexity of weather patterns; the precision\nof weather forecasting becomes increasingly important. Our study proposes a\nnovel preprocessing method and convolutional autoencoder model developed to\nimprove the interpretation of synoptic weather maps. These are critical for\nmeteorologists seeking a thorough understanding of weather conditions. This\nmodel could recognize historical synoptic weather maps that nearly match\ncurrent atmospheric conditions, marking a significant step forward in modern\ntechnology in meteorological forecasting. This comprises unsupervised learning\nmodels like VQ-VQE, as well as supervised learning models like VGG16, VGG19,\nXception, InceptionV3, and ResNet50 trained on the ImageNet dataset, as well as\nresearch into newer models like EfficientNet and ConvNeXt. Our findings proved\nthat, while these models perform well in various settings, their ability to\nidentify comparable synoptic weather maps has certain limits. Our research,\nmotivated by the primary goal of significantly increasing meteorologists'\nefficiency in labor-intensive tasks, discovered that cosine similarity is the\nmost effective metric, as determined by a combination of quantitative and\nqualitative assessments to accurately identify relevant historical weather\npatterns. This study broadens our understanding by shifting the emphasis from\nnumerical precision to practical application, ensuring that our model is\neffective in theory practical, and accessible in the complex and dynamic field\nof meteorology.\n","authors":["Yo-Hwan Choi","Seon-Yu Kang","Minjong Cheon"],"pdf_url":"https://arxiv.org/pdf/2411.05384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04358v2","updated":"2024-11-08T07:31:26Z","published":"2024-11-07T01:31:48Z","title":"Robust and Efficient Fine-tuning of LLMs with Bayesian\n  Reparameterization of Low-Rank Adaptation","summary":"  Large Language Models (LLMs) are highly resource-intensive to fine-tune due\nto their enormous size. While low-rank adaptation is a prominent\nparameter-efficient fine-tuning approach, it suffers from sensitivity to\nhyperparameter choices, leading to instability in model performance on\nfine-tuning downstream tasks. This paper highlights the importance of effective\nparameterization in low-rank fine-tuning to reduce estimator variance and\nenhance the stability of final model outputs. We propose MonteCLoRA, an\nefficient fine-tuning technique, employing Monte Carlo estimation to learn an\nunbiased posterior estimation of low-rank parameters with low expected\nvariance, which stabilizes fine-tuned LLMs with only O(1) additional\nparameters. MonteCLoRA shows significant improvements in accuracy and\nrobustness, achieving up to 3.8% higher accuracy and 8.6% greater robustness\nthan existing efficient fine-tuning methods on natural language understanding\ntasks with pre-trained RoBERTa-base. Furthermore, in generative tasks with\npre-trained LLaMA-1-7B, MonteCLoRA demonstrates robust zero-shot performance\nwith 50% lower variance than the contemporary efficient fine-tuning methods.\nThe theoretical and empirical results presented in the paper underscore how\nparameterization and hyperpriors balance exploration-exploitation in the\nlow-rank parametric space, therefore leading to more optimal and robust\nparameter estimation during efficient fine-tuning.\n","authors":["Ayan Sengupta","Vaibhav Seth","Arinjay Pathak","Natraj Raman","Sriram Gopalakrishnan","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2411.04358v2.pdf","comment":"48 pages, 10 figures, 10 tables, Code:\n  https://github.com/LCS2-IIITD/MonteCLoRA"},{"id":"http://arxiv.org/abs/2401.16407v2","updated":"2024-11-08T07:30:25Z","published":"2024-01-29T18:46:53Z","title":"Is K-fold cross validation the best model selection method for Machine\n  Learning?","summary":"  As a technique that can compactly represent complex patterns, machine\nlearning has significant potential for predictive inference. K-fold\ncross-validation (CV) is the most common approach to ascertaining the\nlikelihood that a machine learning outcome is generated by chance, and it\nfrequently outperforms conventional hypothesis testing. This improvement uses\nmeasures directly obtained from machine learning classifications, such as\naccuracy, that do not have a parametric description. To approach a frequentist\nanalysis within machine learning pipelines, a permutation test or simple\nstatistics from data partitions (i.e., folds) can be added to estimate\nconfidence intervals. Unfortunately, neither parametric nor non-parametric\ntests solve the inherent problems of partitioning small sample-size datasets\nand learning from heterogeneous data sources. The fact that machine learning\nstrongly depends on the learning parameters and the distribution of data across\nfolds recapitulates familiar difficulties around excess false positives and\nreplication. A novel statistical test based on K-fold CV and the Upper Bound of\nthe actual risk (K-fold CUBV) is proposed, where uncertain predictions of\nmachine learning with CV are bounded by the worst case through the evaluation\nof concentration inequalities. Probably Approximately Correct-Bayesian upper\nbounds for linear classifiers in combination with K-fold CV are derived and\nused to estimate the actual risk. The performance with simulated and\nneuroimaging datasets suggests that K-fold CUBV is a robust criterion for\ndetecting effects and validating accuracy values obtained from machine learning\nand classical CV schemes, while avoiding excess false positives.\n","authors":["Juan M Gorriz","R. Martin Clemente","F Segovia","J Ramirez","A Ortiz","J. Suckling"],"pdf_url":"https://arxiv.org/pdf/2401.16407v2.pdf","comment":"40 pages, 24 figures"},{"id":"http://arxiv.org/abs/2411.05378v1","updated":"2024-11-08T07:19:49Z","published":"2024-11-08T07:19:49Z","title":"Machine learning for prediction of dose-volume histograms of\n  organs-at-risk in prostate cancer from simple structure volume parameters","summary":"  Dose prediction is an area of ongoing research that facilitates radiotherapy\nplanning. Most commercial models utilise imaging data and intense computing\nresources. This study aimed to predict the dose-volume of rectum and bladder\nfrom volumes of target, at-risk structure organs and their overlap regions\nusing machine learning. Dose-volume information of 94 patients with prostate\ncancer planned for 6000cGy in 20 fractions was exported from the treatment\nplanning system as text files and mined to create a training dataset. Several\nstatistical modelling, machine learning methods, and a new fuzzy rule-based\nprediction (FRBP) model were explored and validated on an independent dataset\nof 39 patients. The median absolute error was 2.0%-3.7% for bladder and\n1.7-2.4% for rectum in the 4000-6420cGy range. For 5300cGy, 5600cGy and\n6000cGy, the median difference was less than 2.5% for rectum and 3.8% for\nbladder. The FRBP model produced errors of 1.2%, 1.3%, 0.9% and 1.6%, 1.2%,\n0.1% for the rectum and bladder respectively at these dose levels. These\nfindings indicate feasibility of obtaining accurate predictions of the\nclinically important dose-volume parameters for rectum and bladder using just\nthe volumes of these structures.\n","authors":["Saheli Saha","Debasmita Banerjee","Rishi Ram","Gowtham Reddy","Debashree Guha","Arnab Sarkar","Bapi Dutta","Moses ArunSingh S","Suman Chakraborty","Indranil Mallick"],"pdf_url":"https://arxiv.org/pdf/2411.05378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05375v1","updated":"2024-11-08T07:05:06Z","published":"2024-11-08T07:05:06Z","title":"Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking","summary":"  Current automated fact-checking (AFC) approaches commonly evaluate evidence\neither implicitly via the predicted verdicts or by comparing retrieved evidence\nwith a predefined closed knowledge source, such as Wikipedia. However, these\nmethods suffer from limitations, resulting from their reliance on evaluation\nmetrics developed for different purposes and constraints imposed by closed\nknowledge sources. Recent advances in natural language generation (NLG)\nevaluation offer new possibilities for evidence assessment. In this work, we\nintroduce Ev2R, an evaluation framework for AFC that comprises three types of\napproaches for evidence evaluation: reference-based, proxy-reference, and\nreference-less. We evaluate their effectiveness through agreement with human\nratings and adversarial tests, and demonstrate that prompt-based scorers,\nparticularly those leveraging LLMs and reference evidence, outperform\ntraditional evaluation approaches.\n","authors":["Mubashara Akhtar","Michael Schlichtkrull","Andreas Vlachos"],"pdf_url":"https://arxiv.org/pdf/2411.05375v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2401.17263v5","updated":"2024-11-08T06:57:05Z","published":"2024-01-30T18:56:08Z","title":"Robust Prompt Optimization for Defending Language Models Against\n  Jailbreaking Attacks","summary":"  Despite advances in AI alignment, large language models (LLMs) remain\nvulnerable to adversarial attacks or jailbreaking, in which adversaries can\nmodify prompts to induce unwanted behavior. While some defenses have been\nproposed, they have not been adapted to newly proposed attacks and more\nchallenging threat models. To address this, we propose an optimization-based\nobjective for defending LLMs against jailbreaking attacks and an algorithm,\nRobust Prompt Optimization (RPO) to create robust system-level defenses. Our\napproach directly incorporates the adversary into the defensive objective and\noptimizes a lightweight and transferable suffix, enabling RPO to adapt to\nworst-case adaptive attacks. Our theoretical and experimental results show\nimproved robustness to both jailbreaks seen during optimization and unknown\njailbreaks, reducing the attack success rate (ASR) on GPT-4 to 6% and Llama-2\nto 0% on JailbreakBench, setting the state-of-the-art. Code can be found at\nhttps://github.com/lapisrocks/rpo\n","authors":["Andy Zhou","Bo Li","Haohan Wang"],"pdf_url":"https://arxiv.org/pdf/2401.17263v5.pdf","comment":"NeurIPS 2024 Spotlight; code available at\n  https://github.com/lapisrocks/rpo"},{"id":"http://arxiv.org/abs/2411.04680v2","updated":"2024-11-08T06:47:39Z","published":"2024-11-07T13:08:06Z","title":"Differentially Private Continual Learning using Pre-Trained Models","summary":"  This work explores the intersection of continual learning (CL) and\ndifferential privacy (DP). Crucially, continual learning models must retain\nknowledge across tasks, but this conflicts with the differential privacy\nrequirement of restricting individual samples to be memorised in the model. We\npropose using pre-trained models to address the trade-offs between privacy and\nperformance in a continual learning setting. More specifically, we present\nnecessary assumptions to enable privacy-preservation and propose combining\npre-trained models with parameter-free classifiers and parameter-efficient\nadapters that are learned under differential privacy. Our experiments\ndemonstrate their effectiveness and provide insights into balancing the\ncompeting demands of continual learning and privacy.\n","authors":["Marlon Tobaben","Marcus Klasson","Rui Li","Arno Solin","Antti Honkela"],"pdf_url":"https://arxiv.org/pdf/2411.04680v2.pdf","comment":"15 pages, 3 figures, Accepted at Scalable Continual Learning for\n  Lifelong Foundation Models Workshop at 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2307.09254v2","updated":"2024-11-08T06:47:04Z","published":"2023-07-18T13:36:24Z","title":"Selective Generation for Controllable Language Models","summary":"  Trustworthiness of generative language models (GLMs) is crucial in their\ndeployment to critical decision making systems. Hence, certified risk control\nmethods such as selective prediction and conformal prediction have been applied\nto mitigating the hallucination problem in various supervised downstream tasks.\nHowever, the lack of appropriate correctness metric hinders applying such\nprincipled methods to language generation tasks. In this paper, we circumvent\nthis problem by leveraging the concept of textual entailment to evaluate the\ncorrectness of the generated sequence, and propose two selective generation\nalgorithms which control the false discovery rate with respect to the textual\nentailment relation (FDR-E) with a theoretical guarantee:\n$\\texttt{SGen}^{\\texttt{Sup}}$ and $\\texttt{SGen}^{\\texttt{Semi}}$.\n$\\texttt{SGen}^{\\texttt{Sup}}$, a direct modification of the selective\nprediction, is a supervised learning algorithm which exploits\nentailment-labeled data, annotated by humans. Since human annotation is costly,\nwe further propose a semi-supervised version, $\\texttt{SGen}^{\\texttt{Semi}}$,\nwhich fully utilizes the unlabeled data by pseudo-labeling, leveraging an\nentailment set function learned via conformal prediction. Furthermore,\n$\\texttt{SGen}^{\\texttt{Semi}}$ enables to use more general class of selection\nfunctions, neuro-selection functions, and provides users with an optimal\nselection function class given multiple candidates. Finally, we demonstrate the\nefficacy of the $\\texttt{SGen}$ family in achieving a desired FDR-E level with\ncomparable selection efficiency to those from baselines on both open and closed\nsource GLMs. Code and datasets are provided at\nhttps://github.com/ml-postech/selective-generation.\n","authors":["Minjae Lee","Kyungmin Kim","Taesoo Kim","Sangdon Park"],"pdf_url":"https://arxiv.org/pdf/2307.09254v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2303.07909v3","updated":"2024-11-08T06:19:33Z","published":"2023-03-14T13:49:54Z","title":"Text-to-image Diffusion Models in Generative AI: A Survey","summary":"  This survey reviews the progress of diffusion models in generating images\nfrom text, ~\\textit{i.e.} text-to-image diffusion models. As a self-contained\nwork, this survey starts with a brief introduction of how diffusion models work\nfor image synthesis, followed by the background for text-conditioned image\nsynthesis. Based on that, we present an organized review of pioneering methods\nand their improvements on text-to-image generation. We further summarize\napplications beyond image generation, such as text-guided generation for\nvarious modalities like videos, and text-guided image editing. Beyond the\nprogress made so far, we discuss existing challenges and promising future\ndirections.\n","authors":["Chenshuang Zhang","Chaoning Zhang","Mengchun Zhang","In So Kweon","Junmo Kim"],"pdf_url":"https://arxiv.org/pdf/2303.07909v3.pdf","comment":"First survey on the recent progress of text-to-image generation based\n  on the diffusion model"},{"id":"http://arxiv.org/abs/2411.05353v1","updated":"2024-11-08T06:19:29Z","published":"2024-11-08T06:19:29Z","title":"Controlling Grokking with Nonlinearity and Data Symmetry","summary":"  This paper demonstrates that grokking behavior in modular arithmetic with a\nmodulus P in a neural network can be controlled by modifying the profile of the\nactivation function as well as the depth and width of the model. Plotting the\neven PCA projections of the weights of the last NN layer against their odd\nprojections further yields patterns which become significantly more uniform\nwhen the nonlinearity is increased by incrementing the number of layers. These\npatterns can be employed to factor P when P is nonprime. Finally, a metric for\nthe generalization ability of the network is inferred from the entropy of the\nlayer weights while the degree of nonlinearity is related to correlations\nbetween the local entropy of the weights of the neurons in the final layer.\n","authors":["Ahmed Salah","David Yevick"],"pdf_url":"https://arxiv.org/pdf/2411.05353v1.pdf","comment":"15 pages, 14 figures"},{"id":"http://arxiv.org/abs/2411.05354v1","updated":"2024-11-08T06:19:29Z","published":"2024-11-08T06:19:29Z","title":"RED: Residual Estimation Diffusion for Low-Dose PET Sinogram\n  Reconstruction","summary":"  Recent advances in diffusion models have demonstrated exceptional performance\nin generative tasks across vari-ous fields. In positron emission tomography\n(PET), the reduction in tracer dose leads to information loss in sino-grams.\nUsing diffusion models to reconstruct missing in-formation can improve imaging\nquality. Traditional diffu-sion models effectively use Gaussian noise for image\nre-constructions. However, in low-dose PET reconstruction, Gaussian noise can\nworsen the already sparse data by introducing artifacts and inconsistencies. To\naddress this issue, we propose a diffusion model named residual esti-mation\ndiffusion (RED). From the perspective of diffusion mechanism, RED uses the\nresidual between sinograms to replace Gaussian noise in diffusion process,\nrespectively sets the low-dose and full-dose sinograms as the starting point\nand endpoint of reconstruction. This mechanism helps preserve the original\ninformation in the low-dose sinogram, thereby enhancing reconstruction\nreliability. From the perspective of data consistency, RED introduces a drift\ncorrection strategy to reduce accumulated prediction errors during the reverse\nprocess. Calibrating the inter-mediate results of reverse iterations helps\nmaintain the data consistency and enhances the stability of reconstruc-tion\nprocess. Experimental results show that RED effec-tively improves the quality\nof low-dose sinograms as well as the reconstruction results. The code is\navailable at: https://github.com/yqx7150/RED.\n","authors":["Xingyu Ai","Bin Huang","Fang Chen","Liu Shi","Binxuan Li","Shaoyu Wang","Qiegen Liu"],"pdf_url":"https://arxiv.org/pdf/2411.05354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17538v2","updated":"2024-11-08T05:59:49Z","published":"2024-05-27T18:00:00Z","title":"Bayesian RG Flow in Neural Network Field Theories","summary":"  The Neural Network Field Theory correspondence (NNFT) is a mapping from\nneural network (NN) architectures into the space of statistical field theories\n(SFTs). The Bayesian renormalization group (BRG) is an information-theoretic\ncoarse graining scheme that generalizes the principles of the exact\nrenormalization group (ERG) to arbitrarily parameterized probability\ndistributions, including those of NNs. In BRG, coarse graining is performed in\nparameter space with respect to an information-theoretic distinguishability\nscale set by the Fisher information metric. In this paper, we unify NNFT and\nBRG to form a powerful new framework for exploring the space of NNs and SFTs,\nwhich we coin BRG-NNFT. With BRG-NNFT, NN training dynamics can be interpreted\nas inducing a flow in the space of SFTs from the information-theoretic `IR'\n$\\rightarrow$ `UV'. Conversely, applying an information-shell coarse graining\nto the trained network's parameters induces a flow in the space of SFTs from\nthe information-theoretic `UV' $\\rightarrow$ `IR'. When the\ninformation-theoretic cutoff scale coincides with a standard momentum scale,\nBRG is equivalent to ERG. We demonstrate the BRG-NNFT correspondence on two\nanalytically tractable examples. First, we construct BRG flows for trained,\ninfinite-width NNs, of arbitrary depth, with generic activation functions. As a\nspecial case, we then restrict to architectures with a single infinitely-wide\nlayer, scalar outputs, and generalized cos-net activations. In this case, we\nshow that BRG coarse-graining corresponds exactly to the momentum-shell ERG\nflow of a free scalar SFT. Our analytic results are corroborated by a numerical\nexperiment in which an ensemble of asymptotically wide NNs are trained and\nsubsequently renormalized using an information-shell BRG scheme.\n","authors":["Jessica N. Howard","Marc S. Klinger","Anindita Maiti","Alexander G. Stapleton"],"pdf_url":"https://arxiv.org/pdf/2405.17538v2.pdf","comment":"39 pages, 9 figures, 2 tables; updated references and fixed typos"},{"id":"http://arxiv.org/abs/2411.05346v1","updated":"2024-11-08T05:58:09Z","published":"2024-11-08T05:58:09Z","title":"Reinforcement Learning for Adaptive Resource Scheduling in Complex\n  System Environments","summary":"  This study presents a novel computer system performance optimization and\nadaptive workload management scheduling algorithm based on Q-learning. In\nmodern computing environments, characterized by increasing data volumes, task\ncomplexity, and dynamic workloads, traditional static scheduling methods such\nas Round-Robin and Priority Scheduling fail to meet the demands of efficient\nresource allocation and real-time adaptability. By contrast, Q-learning, a\nreinforcement learning algorithm, continuously learns from system state\nchanges, enabling dynamic scheduling and resource optimization. Through\nextensive experiments, the superiority of the proposed approach is demonstrated\nin both task completion time and resource utilization, outperforming\ntraditional and dynamic resource allocation (DRA) algorithms. These findings\nare critical as they highlight the potential of intelligent scheduling\nalgorithms based on reinforcement learning to address the growing complexity\nand unpredictability of computing environments. This research provides a\nfoundation for the integration of AI-driven adaptive scheduling in future\nlarge-scale systems, offering a scalable, intelligent solution to enhance\nsystem performance, reduce operating costs, and support sustainable energy\nconsumption. The broad applicability of this approach makes it a promising\ncandidate for next-generation computing frameworks, such as edge computing,\ncloud computing, and the Internet of Things.\n","authors":["Pochun Li","Yuyang Xiao","Jinghua Yan","Xuan Li","Xiaoye Wang"],"pdf_url":"https://arxiv.org/pdf/2411.05346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04682v4","updated":"2024-11-08T05:45:45Z","published":"2024-05-07T21:52:39Z","title":"TALC: Time-Aligned Captions for Multi-Scene Text-to-Video Generation","summary":"  Most of these text-to-video (T2V) generative models often produce\nsingle-scene video clips that depict an entity performing a particular action\n(e.g., 'a red panda climbing a tree'). However, it is pertinent to generate\nmulti-scene videos since they are ubiquitous in the real-world (e.g., 'a red\npanda climbing a tree' followed by 'the red panda sleeps on the top of the\ntree'). To generate multi-scene videos from the pretrained T2V model, we\nintroduce a simple and effective Time-Aligned Captions (TALC) framework.\nSpecifically, we enhance the text-conditioning mechanism in the T2V\narchitecture to recognize the temporal alignment between the video scenes and\nscene descriptions. For instance, we condition the visual features of the\nearlier and later scenes of the generated video with the representations of the\nfirst scene description (e.g., 'a red panda climbing a tree') and second scene\ndescription (e.g., 'the red panda sleeps on the top of the tree'),\nrespectively. As a result, we show that the T2V model can generate multi-scene\nvideos that adhere to the multi-scene text descriptions and be visually\nconsistent (e.g., entity and background). Further, we finetune the pretrained\nT2V model with multi-scene video-text data using the TALC framework. We show\nthat the TALC-finetuned model outperforms the baseline by achieving a relative\ngain of 29% in the overall score, which averages visual consistency and text\nadherence using human evaluation.\n","authors":["Hritik Bansal","Yonatan Bitton","Michal Yarom","Idan Szpektor","Aditya Grover","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2405.04682v4.pdf","comment":"22 pages, 14 figures, 11 tables"},{"id":"http://arxiv.org/abs/2410.21556v3","updated":"2024-11-08T05:35:04Z","published":"2024-10-28T21:35:08Z","title":"Super-resolution in disordered media using neural networks","summary":"  We propose a methodology that exploits large and diverse data sets to\naccurately estimate the ambient medium's Green's functions in strongly\nscattering media. Given these estimates, obtained with and without the use of\nneural networks, excellent imaging results are achieved, with a resolution that\nis better than that of a homogeneous medium. This phenomenon, also known as\nsuper-resolution, occurs because the ambient scattering medium effectively\nenhances the physical imaging aperture. This work has been submitted to the\nIEEE for possible publication. Copyright may be transferred without notice,\nafter which this version may no longer be accessible.\n","authors":["Alexander Christie","Matan Leibovich","Miguel Moscoso","Alexei Novikov","George Papanicolaou","Chrysoula Tsogka"],"pdf_url":"https://arxiv.org/pdf/2410.21556v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19234v2","updated":"2024-11-08T05:34:40Z","published":"2024-07-27T11:35:19Z","title":"Ordered Momentum for Asynchronous SGD","summary":"  Distributed learning is essential for training large-scale deep models.\nAsynchronous SGD (ASGD) and its variants are commonly used distributed learning\nmethods, particularly in scenarios where the computing capabilities of workers\nin the cluster are heterogeneous. Momentum has been acknowledged for its\nbenefits in both optimization and generalization in deep model training.\nHowever, existing works have found that naively incorporating momentum into\nASGD can impede the convergence. In this paper, we propose a novel method\ncalled ordered momentum (OrMo) for ASGD. In OrMo, momentum is incorporated into\nASGD by organizing the gradients in order based on their iteration indexes. We\ntheoretically prove the convergence of OrMo with both constant and\ndelay-adaptive learning rates for non-convex problems. To the best of our\nknowledge, this is the first work to establish the convergence analysis of ASGD\nwith momentum without dependence on the maximum delay. Empirical results\ndemonstrate that OrMo can achieve better convergence performance compared with\nASGD and other asynchronous methods with momentum.\n","authors":["Chang-Wei Shi","Yi-Rui Yang","Wu-Jun Li"],"pdf_url":"https://arxiv.org/pdf/2407.19234v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05335v1","updated":"2024-11-08T05:14:46Z","published":"2024-11-08T05:14:46Z","title":"A Quality-Centric Framework for Generic Deepfake Detection","summary":"  This paper addresses the generalization issue in deepfake detection by\nharnessing forgery quality in training data. Generally, the forgery quality of\ndifferent deepfakes varies: some have easily recognizable forgery clues, while\nothers are highly realistic. Existing works often train detectors on a mix of\ndeepfakes with varying forgery qualities, potentially leading detectors to\nshort-cut the easy-to-spot artifacts from low-quality forgery samples, thereby\nhurting generalization performance. To tackle this issue, we propose a novel\nquality-centric framework for generic deepfake detection, which is composed of\na Quality Evaluator, a low-quality data enhancement module, and a learning\npacing strategy that explicitly incorporates forgery quality into the training\nprocess. The framework is inspired by curriculum learning, which is designed to\ngradually enable the detector to learn more challenging deepfake samples,\nstarting with easier samples and progressing to more realistic ones. We employ\nboth static and dynamic assessments to assess the forgery quality, combining\ntheir scores to produce a final rating for each training sample. The rating\nscore guides the selection of deepfake samples for training, with higher-rated\nsamples having a higher probability of being chosen. Furthermore, we propose a\nnovel frequency data augmentation method specifically designed for low-quality\nforgery samples, which helps to reduce obvious forgery traces and improve their\noverall realism. Extensive experiments show that our method can be applied in a\nplug-and-play manner and significantly enhance the generalization performance.\n","authors":["Wentang Song","Zhiyuan Yan","Yuzhen Lin","Taiping Yao","Changsheng Chen","Shen Chen","Yandan Zhao","Shouhong Ding","Bin Li"],"pdf_url":"https://arxiv.org/pdf/2411.05335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05331v1","updated":"2024-11-08T05:12:16Z","published":"2024-11-08T05:12:16Z","title":"Discovering Latent Structural Causal Models from Spatio-Temporal Data","summary":"  Many important phenomena in scientific fields such as climate, neuroscience,\nand epidemiology are naturally represented as spatiotemporal gridded data with\ncomplex interactions. For example, in climate science, researchers aim to\nuncover how large-scale events, such as the North Atlantic Oscillation (NAO)\nand the Antarctic Oscillation (AAO), influence other global processes.\nInferring causal relationships from these data is a challenging problem\ncompounded by the high dimensionality of such data and the correlations between\nspatially proximate points. We present SPACY (SPAtiotemporal Causal discoverY),\na novel framework based on variational inference, designed to explicitly model\nlatent time-series and their causal relationships from spatially confined modes\nin the data. Our method uses an end-to-end training process that maximizes an\nevidence-lower bound (ELBO) for the data likelihood. Theoretically, we show\nthat, under some conditions, the latent variables are identifiable up to\ntransformation by an invertible matrix. Empirically, we show that SPACY\noutperforms state-of-the-art baselines on synthetic data, remains scalable for\nlarge grids, and identifies key known phenomena from real-world climate data.\n","authors":["Kun Wang","Sumanth Varambally","Duncan Watson-Parris","Yi-An Ma","Rose Yu"],"pdf_url":"https://arxiv.org/pdf/2411.05331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05330v1","updated":"2024-11-08T05:06:47Z","published":"2024-11-08T05:06:47Z","title":"Inversion-based Latent Bayesian Optimization","summary":"  Latent Bayesian optimization (LBO) approaches have successfully adopted\nBayesian optimization over a continuous latent space by employing an\nencoder-decoder architecture to address the challenge of optimization in a high\ndimensional or discrete input space. LBO learns a surrogate model to\napproximate the black-box objective function in the latent space. However, we\nobserved that most LBO methods suffer from the `misalignment problem`, which is\ninduced by the reconstruction error of the encoder-decoder architecture. It\nhinders learning an accurate surrogate model and generating high-quality\nsolutions. In addition, several trust region-based LBO methods select the\nanchor, the center of the trust region, based solely on the objective function\nvalue without considering the trust region`s potential to enhance the\noptimization process. To address these issues, we propose Inversion-based\nLatent Bayesian Optimization (InvBO), a plug-and-play module for LBO. InvBO\nconsists of two components: an inversion method and a potential-aware trust\nregion anchor selection. The inversion method searches the latent code that\ncompletely reconstructs the given target data. The potential-aware trust region\nanchor selection considers the potential capability of the trust region for\nbetter local optimization. Experimental results demonstrate the effectiveness\nof InvBO on nine real-world benchmarks, such as molecule design and arithmetic\nexpression fitting tasks. Code is available at https://github.com/mlvlab/InvBO.\n","authors":["Jaewon Chu","Jinyoung Park","Seunghun Lee","Hyunwoo J. Kim"],"pdf_url":"https://arxiv.org/pdf/2411.05330v1.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.05324v1","updated":"2024-11-08T04:37:55Z","published":"2024-11-08T04:37:55Z","title":"SASWISE-UE: Segmentation and Synthesis with Interpretable Scalable\n  Ensembles for Uncertainty Estimation","summary":"  This paper introduces an efficient sub-model ensemble framework aimed at\nenhancing the interpretability of medical deep learning models, thus increasing\ntheir clinical applicability. By generating uncertainty maps, this framework\nenables end-users to evaluate the reliability of model outputs. We developed a\nstrategy to develop diverse models from a single well-trained checkpoint,\nfacilitating the training of a model family. This involves producing multiple\noutputs from a single input, fusing them into a final output, and estimating\nuncertainty based on output disagreements. Implemented using U-Net and UNETR\nmodels for segmentation and synthesis tasks, this approach was tested on CT\nbody segmentation and MR-CT synthesis datasets. It achieved a mean Dice\ncoefficient of 0.814 in segmentation and a Mean Absolute Error of 88.17 HU in\nsynthesis, improved from 89.43 HU by pruning. Additionally, the framework was\nevaluated under corruption and undersampling, maintaining correlation between\nuncertainty and error, which highlights its robustness. These results suggest\nthat the proposed approach not only maintains the performance of well-trained\nmodels but also enhances interpretability through effective uncertainty\nestimation, applicable to both convolutional and transformer models in a range\nof imaging tasks.\n","authors":["Weijie Chen","Alan McMillan"],"pdf_url":"https://arxiv.org/pdf/2411.05324v1.pdf","comment":"16 pages, 12 figures, 5 tables"},{"id":"http://arxiv.org/abs/2409.12296v2","updated":"2024-11-08T04:32:45Z","published":"2024-09-18T20:08:19Z","title":"JKO for Landau: a variational particle method for homogeneous Landau\n  equation","summary":"  Inspired by the gradient flow viewpoint of the Landau equation and\ncorresponding dynamic formulation of the Landau metric in [arXiv:2007.08591],\nwe develop a novel implicit particle method for the Landau equation in the\nframework of the JKO scheme. We first reformulate the Landau metric in a\ncomputationally friendly form, and then translate it into the Lagrangian\nviewpoint using the flow map. A key observation is that, while the flow map\nevolves according to a rather complicated integral equation, the unknown\ncomponent is merely a score function of the corresponding density plus an\nadditional term in the null space of the collision kernel. This insight guides\nus in designing and training the neural network for the flow map. Additionally,\nthe objective function is in a double summation form, making it highly suitable\nfor stochastic methods. Consequently, we design a tailored version of\nstochastic gradient descent that maintains particle interactions and\nsignificantly reduces the computational complexity. Compared to other\ndeterministic particle methods, the proposed method enjoys exact entropy\ndissipation and unconditional stability, therefore making it suitable for\nlarge-scale plasma simulations over extended time periods.\n","authors":["Yan Huang","Li Wang"],"pdf_url":"https://arxiv.org/pdf/2409.12296v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19976v2","updated":"2024-11-08T04:30:51Z","published":"2024-09-30T06:04:04Z","title":"Learning Partial Differential Equations with Deep Parallel Neural\n  Operator","summary":"  In recent years, Solving partial differential equations has shifted the focus\nof traditional neural network studies from finite-dimensional Euclidean spaces\nto generalized functional spaces in research. A novel methodology is to learn\nan operator as a means of approximating the mapping between outputs. Currently,\nresearchers have proposed a variety of operator architectures. Nevertheless,\nthe majority of these architectures adopt an iterative update architecture,\nwhereby a single operator is learned from the same function space. In practical\nphysical science problems, the numerical solutions of partial differential\nequations are complex, and a serial single operator is unable to accurately\napproximate the intricate mapping between input and output. So, We propose a\ndeep parallel operator model (DPNO) for efficiently and accurately solving\npartial differential equations. DPNO employs convolutional neural networks to\nextract local features and map data into distinct latent spaces. Designing a\nparallel block of double Fourier neural operators to solve the iterative error\nproblem. DPNO approximates complex mappings between inputs and outputs by\nlearning multiple operators in different potential spaces in parallel blocks.\nDPNO achieved the best performance on five of them, with an average improvement\nof 10.5\\%, and ranked second on one dataset.\n","authors":["Qinglong Ma","Peizhi Zhao","Sen Wang","Tao Song"],"pdf_url":"https://arxiv.org/pdf/2409.19976v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05318v1","updated":"2024-11-08T04:20:12Z","published":"2024-11-08T04:20:12Z","title":"Fairness in Monotone $k$-submodular Maximization: Algorithms and\n  Applications","summary":"  Submodular optimization has become increasingly prominent in machine learning\nand fairness has drawn much attention. In this paper, we propose to study the\nfair $k$-submodular maximization problem and develop a\n$\\frac{1}{3}$-approximation greedy algorithm with a running time of\n$\\mathcal{O}(knB)$. To the best of our knowledge, our work is the first to\nincorporate fairness in the context of $k$-submodular maximization, and our\ntheoretical guarantee matches the best-known $k$-submodular maximization\nresults without fairness constraints. In addition, we have developed a faster\nthreshold-based algorithm that achieves a $(\\frac{1}{3} - \\epsilon)$\napproximation with $\\mathcal{O}(\\frac{kn}{\\epsilon} \\log \\frac{B}{\\epsilon})$\nevaluations of the function $f$. Furthermore, for both algorithms, we provide\napproximation guarantees when the $k$-submodular function is not accessible but\nonly can be approximately accessed. We have extensively validated our\ntheoretical findings through empirical research and examined the practical\nimplications of fairness. Specifically, we have addressed the question: ``What\nis the price of fairness?\" through case studies on influence maximization with\n$k$ topics and sensor placement with $k$ types. The experimental results show\nthat the fairness constraints do not significantly undermine the quality of\nsolutions.\n","authors":["Yanhui Zhu","Samik Basu","A. Pavan"],"pdf_url":"https://arxiv.org/pdf/2411.05318v1.pdf","comment":"17 pages. To appear in IEEE BigData 2024"},{"id":"http://arxiv.org/abs/2411.05316v1","updated":"2024-11-08T04:15:08Z","published":"2024-11-08T04:15:08Z","title":"Exploring the Alignment Landscape: LLMs and Geometric Deep Models in\n  Protein Representation","summary":"  Latent representation alignment has become a foundational technique for\nconstructing multimodal large language models (MLLM) by mapping embeddings from\ndifferent modalities into a shared space, often aligned with the embedding\nspace of large language models (LLMs) to enable effective cross-modal\nunderstanding. While preliminary protein-focused MLLMs have emerged, they have\npredominantly relied on heuristic approaches, lacking a fundamental\nunderstanding of optimal alignment practices across representations. In this\nstudy, we explore the alignment of multimodal representations between LLMs and\nGeometric Deep Models (GDMs) in the protein domain. We comprehensively evaluate\nthree state-of-the-art LLMs (Gemma2-2B, LLaMa3.1-8B, and LLaMa3.1-70B) with\nfour protein-specialized GDMs (GearNet, GVP, ScanNet, GAT). Our work examines\nalignment factors from both model and protein perspectives, identifying\nchallenges in current alignment methodologies and proposing strategies to\nimprove the alignment process. Our key findings reveal that GDMs incorporating\nboth graph and 3D structural information align better with LLMs, larger LLMs\ndemonstrate improved alignment capabilities, and protein rarity significantly\nimpacts alignment performance. We also find that increasing GDM embedding\ndimensions, using two-layer projection heads, and fine-tuning LLMs on\nprotein-specific data substantially enhance alignment quality. These strategies\noffer potential enhancements to the performance of protein-related multimodal\nmodels. Our code and data are available at\nhttps://github.com/Tizzzzy/LLM-GDM-alignment.\n","authors":["Dong Shu","Bingbing Duan","Kai Guo","Kaixiong Zhou","Jiliang Tang","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2411.05316v1.pdf","comment":"24 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.05315v1","updated":"2024-11-08T04:13:52Z","published":"2024-11-08T04:13:52Z","title":"Differentiable Calibration of Inexact Stochastic Simulation Models via\n  Kernel Score Minimization","summary":"  Stochastic simulation models are generative models that mimic complex systems\nto help with decision-making. The reliability of these models heavily depends\non well-calibrated input model parameters. However, in many practical\nscenarios, only output-level data are available to learn the input model\nparameters, which is challenging due to the often intractable likelihood of the\nstochastic simulation model. Moreover, stochastic simulation models are\nfrequently inexact, with discrepancies between the model and the target system.\nNo existing methods can effectively learn and quantify the uncertainties of\ninput parameters using only output-level data. In this paper, we propose to\nlearn differentiable input parameters of stochastic simulation models using\noutput-level data via kernel score minimization with stochastic gradient\ndescent. We quantify the uncertainties of the learned input parameters using a\nfrequentist confidence set procedure based on a new asymptotic normality result\nthat accounts for model inexactness. The proposed method is evaluated on exact\nand inexact G/G/1 queueing models.\n","authors":["Ziwei Su","Diego Klabjan"],"pdf_url":"https://arxiv.org/pdf/2411.05315v1.pdf","comment":"31 pages, 12 tables, 4 figures"},{"id":"http://arxiv.org/abs/2405.15673v2","updated":"2024-11-08T04:12:13Z","published":"2024-05-24T16:12:39Z","title":"Consistency of Neural Causal Partial Identification","summary":"  Recent progress in Neural Causal Models (NCMs) showcased how identification\nand partial identification of causal effects can be automatically carried out\nvia training of neural generative models that respect the constraints encoded\nin a given causal graph [Xia et al. 2022, Balazadeh et al. 2022]. However,\nformal consistency of these methods has only been proven for the case of\ndiscrete variables or only for linear causal models. In this work, we prove the\nconsistency of partial identification via NCMs in a general setting with both\ncontinuous and categorical variables. Further, our results highlight the impact\nof the design of the underlying neural network architecture in terms of depth\nand connectivity as well as the importance of applying Lipschitz regularization\nin the training phase. In particular, we provide a counterexample showing that\nwithout Lipschitz regularization this method may not be asymptotically\nconsistent. Our results are enabled by new results on the approximability of\nStructural Causal Models (SCMs) via neural generative models, together with an\nanalysis of the sample complexity of the resulting architectures and how that\ntranslates into an error in the constrained optimization problem that defines\nthe partial identification bounds.\n","authors":["Jiyuan Tan","Jose Blanchet","Vasilis Syrgkanis"],"pdf_url":"https://arxiv.org/pdf/2405.15673v2.pdf","comment":"61 pages, 8 figures, accepted by Neurips 2024"},{"id":"http://arxiv.org/abs/2309.16973v2","updated":"2024-11-08T03:48:58Z","published":"2023-09-29T04:42:50Z","title":"Towards Robust Offline-to-Online Reinforcement Learning via Uncertainty\n  and Smoothness","summary":"  To obtain a near-optimal policy with fewer interactions in Reinforcement\nLearning (RL), a promising approach involves the combination of offline RL,\nwhich enhances sample efficiency by leveraging offline datasets, and online RL,\nwhich explores informative transitions by interacting with the environment.\nOffline-to-Online (O2O) RL provides a paradigm for improving an offline trained\nagent within limited online interactions. However, due to the significant\ndistribution shift between online experiences and offline data, most offline RL\nalgorithms suffer from performance drops and fail to achieve stable policy\nimprovement in O2O adaptation. To address this problem, we propose the Robust\nOffline-to-Online (RO2O) algorithm, designed to enhance offline policies\nthrough uncertainty and smoothness, and to mitigate the performance drop in\nonline adaptation. Specifically, RO2O incorporates Q-ensemble for uncertainty\npenalty and adversarial samples for policy and value smoothness, which enable\nRO2O to maintain a consistent learning procedure in online adaptation without\nrequiring special changes to the learning objective. Theoretical analyses in\nlinear MDPs demonstrate that the uncertainty and smoothness lead to a tighter\noptimality bound in O2O against distribution shift. Experimental results\nillustrate the superiority of RO2O in facilitating stable offline-to-online\nlearning and achieving significant improvement with limited online\ninteractions.\n","authors":["Xiaoyu Wen","Xudong Yu","Rui Yang","Haoyuan Chen","Chenjia Bai","Zhen Wang"],"pdf_url":"https://arxiv.org/pdf/2309.16973v2.pdf","comment":"This paper has been accepted by Journal of Artificial Intelligence\n  Research (JAIR). arXiv admin note: text overlap with arXiv:2306.06871 by\n  other authors"},{"id":"http://arxiv.org/abs/2401.11592v5","updated":"2024-11-08T03:37:03Z","published":"2024-01-21T20:46:21Z","title":"Differentially-Private Multi-Tier Federated Learning","summary":"  While federated learning (FL) eliminates the transmission of raw data over a\nnetwork, it is still vulnerable to privacy breaches from the communicated model\nparameters. In this work, we propose Multi-Tier Federated Learning with\nMulti-Tier Differential Privacy (M^2FDP), a DP-enhanced FL methodology for\njointly optimizing privacy and performance in hierarchical networks. One of the\nkey concepts of M^2FDP is to extend the concept of HDP towards Multi-Tier\nDifferential Privacy (MDP), while also adapting DP noise injection at different\nlayers of an established FL hierarchy -- edge devices, edge servers, and cloud\nservers -- according to the trust models within particular subnetworks. We\nconduct a comprehensive analysis of the convergence behavior of M^2FDP,\nrevealing conditions on parameter tuning under which the training process\nconverges sublinearly to a finite stationarity gap that depends on the network\nhierarchy, trust model, and target privacy level.\n  Subsequent numerical evaluations demonstrate that M^2FDP obtains substantial\nimprovements in these metrics over baselines for different privacy budgets, and\nvalidate the impact of different system configurations.\n","authors":["Evan Chen","Frank Po-Chen Lin","Dong-Jun Han","Christopher G. Brinton"],"pdf_url":"https://arxiv.org/pdf/2401.11592v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01801v2","updated":"2024-11-08T03:30:52Z","published":"2024-11-04T05:00:49Z","title":"Bootstrapping Top-down Information for Self-modulating Slot Attention","summary":"  Object-centric learning (OCL) aims to learn representations of individual\nobjects within visual scenes without manual supervision, facilitating efficient\nand effective visual reasoning. Traditional OCL methods primarily employ\nbottom-up approaches that aggregate homogeneous visual features to represent\nobjects. However, in complex visual environments, these methods often fall\nshort due to the heterogeneous nature of visual features within an object. To\naddress this, we propose a novel OCL framework incorporating a top-down\npathway. This pathway first bootstraps the semantics of individual objects and\nthen modulates the model to prioritize features relevant to these semantics. By\ndynamically modulating the model based on its own output, our top-down pathway\nenhances the representational quality of objects. Our framework achieves\nstate-of-the-art performance across multiple synthetic and real-world\nobject-discovery benchmarks.\n","authors":["Dongwon Kim","Seoyeon Kim","Suha Kwak"],"pdf_url":"https://arxiv.org/pdf/2411.01801v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2310.05988v3","updated":"2024-11-08T03:30:38Z","published":"2023-10-07T19:35:07Z","title":"Dual Latent State Learning: Exploiting Regional Network Similarities for\n  QoS Prediction","summary":"  Individual objects, whether users or services, within a specific region often\nexhibit similar network states due to their shared origin from the same city or\nautonomous system (AS). Despite this regional network similarity, many existing\ntechniques overlook its potential, resulting in subpar performance arising from\nchallenges such as data sparsity and label imbalance. In this paper, we\nintroduce the regional-based dual latent state learning network(R2SL), a novel\ndeep learning framework designed to overcome the pitfalls of traditional\nindividual object-based prediction techniques in Quality of Service (QoS)\nprediction. Unlike its predecessors, R2SL captures the nuances of regional\nnetwork behavior by deriving two distinct regional network latent states: the\ncity-network latent state and the AS-network latent state. These states are\nconstructed utilizing aggregated data from common regions rather than\nindividual object data. Furthermore, R2SL adopts an enhanced Huber loss\nfunction that adjusts its linear loss component, providing a remedy for\nprevalent label imbalance issues. To cap off the prediction process, a\nmulti-scale perception network is leveraged to interpret the integrated feature\nmap, a fusion of regional network latent features and other pertinent\ninformation, ultimately accomplishing the QoS prediction. Through rigorous\ntesting on real-world QoS datasets, R2SL demonstrates superior performance\ncompared to prevailing state-of-the-art methods. Our R2SL approach ushers in an\ninnovative avenue for precise QoS predictions by fully harnessing the regional\nnetwork similarities inherent in objects.\n","authors":["Ziliang Wang","Xiaohong Zhang","Kechi Zhang","Ze Shi Li","Meng Yan"],"pdf_url":"https://arxiv.org/pdf/2310.05988v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05296v1","updated":"2024-11-08T02:57:59Z","published":"2024-11-08T02:57:59Z","title":"On Training of Kolmogorov-Arnold Networks","summary":"  Kolmogorov-Arnold Networks have recently been introduced as a flexible\nalternative to multi-layer Perceptron architectures. In this paper, we examine\nthe training dynamics of different KAN architectures and compare them with\ncorresponding MLP formulations. We train with a variety of different\ninitialization schemes, optimizers, and learning rates, as well as utilize back\npropagation free approaches like the HSIC Bottleneck. We find that (when judged\nby test accuracy) KANs are an effective alternative to MLP architectures on\nhigh-dimensional datasets and have somewhat better parameter efficiency, but\nsuffer from more unstable training dynamics. Finally, we provide\nrecommendations for improving training stability of larger KAN models.\n","authors":["Shairoz Sohail"],"pdf_url":"https://arxiv.org/pdf/2411.05296v1.pdf","comment":"7 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.05241v3","updated":"2024-11-08T02:36:57Z","published":"2023-11-09T09:49:50Z","title":"When Meta-Learning Meets Online and Continual Learning: A Survey","summary":"  Over the past decade, deep neural networks have demonstrated significant\nsuccess using the training scheme that involves mini-batch stochastic gradient\ndescent on extensive datasets. Expanding upon this accomplishment, there has\nbeen a surge in research exploring the application of neural networks in other\nlearning scenarios. One notable framework that has garnered significant\nattention is meta-learning. Often described as \"learning to learn,\"\nmeta-learning is a data-driven approach to optimize the learning algorithm.\nOther branches of interest are continual learning and online learning, both of\nwhich involve incrementally updating a model with streaming data. While these\nframeworks were initially developed independently, recent works have started\ninvestigating their combinations, proposing novel problem settings and learning\nalgorithms. However, due to the elevated complexity and lack of unified\nterminology, discerning differences between the learning frameworks can be\nchallenging even for experienced researchers. To facilitate a clear\nunderstanding, this paper provides a comprehensive survey that organizes\nvarious problem settings using consistent terminology and formal descriptions.\nBy offering an overview of these learning paradigms, our work aims to foster\nfurther advancements in this promising area of research.\n","authors":["Jaehyeon Son","Soochan Lee","Gunhee Kim"],"pdf_url":"https://arxiv.org/pdf/2311.05241v3.pdf","comment":"IEEE Transactions on Pattern Analysis and Machine Intelligence"},{"id":"http://arxiv.org/abs/2411.05282v1","updated":"2024-11-08T02:25:45Z","published":"2024-11-08T02:25:45Z","title":"MicroScopiQ: Accelerating Foundational Models through Outlier-Aware\n  Microscaling Quantization","summary":"  Quantization of foundational models (FMs) is significantly more challenging\nthan traditional DNNs due to the emergence of large magnitude features called\noutliers. Existing outlier-aware algorithm/architecture co-design techniques\neither use mixed-precision, retaining outliers at high precision but compromise\nhardware efficiency, or quantize inliers and outliers at the same precision,\nimproving hardware efficiency at the cost of accuracy. To address this mutual\nexclusivity, in this paper, we propose MicroScopiQ, a novel co-design technique\nthat leverages pruning to complement outlier-aware quantization. MicroScopiQ\nretains outliers at higher precision while pruning a certain fraction of least\nimportant weights to distribute the additional outlier bits; ensuring high\naccuracy, aligned memory and hardware efficiency. We design a high-throughput,\nlow overhead accelerator architecture composed of simple multi-precision INT\nprocessing elements and a novel network-on-chip called ReCoN that efficiently\nabstracts the complexity of supporting high-precision outliers. Additionally,\nunlike existing alternatives, MicroScopiQ does not assume any locality of\noutlier weights, enabling applicability to a broad range of FMs. Extensive\nexperiments across various quantization settings show that MicroScopiQ achieves\nSoTA quantization performance while simultaneously improving inference\nperformance by 3x and reducing energy by 2x over existing alternatives.\n","authors":["Akshat Ramachandran","Souvik Kundu","Tushar Krishna"],"pdf_url":"https://arxiv.org/pdf/2411.05282v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2411.05281v1","updated":"2024-11-08T02:24:29Z","published":"2024-11-08T02:24:29Z","title":"Fox-1 Technical Report","summary":"  We present Fox-1, a series of small language models (SLMs) consisting of\nFox-1-1.6B and Fox-1-1.6B-Instruct-v0.1. These models are pre-trained on 3\ntrillion tokens of web-scraped document data and fine-tuned with 5 billion\ntokens of instruction-following and multi-turn conversation data. Aiming to\nimprove the pre-training efficiency, Fox-1-1.6B model introduces a novel\n3-stage data curriculum across all the training data with 2K-8K sequence\nlength. In architecture design, Fox-1 features a deeper layer structure, an\nexpanded vocabulary, and utilizes Grouped Query Attention (GQA), offering a\nperformant and efficient architecture compared to other SLMs. Fox-1 achieves\nbetter or on-par performance in various benchmarks compared to StableLM-2-1.6B,\nGemma-2B, Qwen1.5-1.8B, and OpenELM1.1B, with competitive inference speed and\nthroughput. The model weights have been released under the Apache 2.0 license,\nwhere we aim to promote the democratization of LLMs and make them fully\naccessible to the whole open-source community.\n","authors":["Zijian Hu","Jipeng Zhang","Rui Pan","Zhaozhuo Xu","Salman Avestimehr","Chaoyang He","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05281v1.pdf","comment":"Base model is available at\n  https://huggingface.co/tensoropera/Fox-1-1.6B and the instruction-tuned\n  version is available at\n  https://huggingface.co/tensoropera/Fox-1-1.6B-Instruct-v0.1"},{"id":"http://arxiv.org/abs/2411.05277v1","updated":"2024-11-08T02:22:30Z","published":"2024-11-08T02:22:30Z","title":"Revisiting the Robustness of Watermarking to Paraphrasing Attacks","summary":"  Amidst rising concerns about the internet being proliferated with content\ngenerated from language models (LMs), watermarking is seen as a principled way\nto certify whether text was generated from a model. Many recent watermarking\ntechniques slightly modify the output probabilities of LMs to embed a signal in\nthe generated output that can later be detected. Since early proposals for text\nwatermarking, questions about their robustness to paraphrasing have been\nprominently discussed. Lately, some techniques are deliberately designed and\nclaimed to be robust to paraphrasing. However, such watermarking schemes do not\nadequately account for the ease with which they can be reverse-engineered. We\nshow that with access to only a limited number of generations from a black-box\nwatermarked model, we can drastically increase the effectiveness of\nparaphrasing attacks to evade watermark detection, thereby rendering the\nwatermark ineffective.\n","authors":["Saksham Rastogi","Danish Pruthi"],"pdf_url":"https://arxiv.org/pdf/2411.05277v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2308.02580v3","updated":"2024-11-08T02:21:38Z","published":"2023-08-03T16:13:46Z","title":"Feature Noise Resilient for QoS Prediction with Probabilistic Deep\n  Supervision","summary":"  Accurate Quality of Service (QoS) prediction is essential for enhancing user\nsatisfaction in web recommendation systems, yet existing prediction models\noften overlook feature noise, focusing predominantly on label noise. In this\npaper, we present the Probabilistic Deep Supervision Network (PDS-Net), a\nrobust framework designed to effectively identify and mitigate feature noise,\nthereby improving QoS prediction accuracy. PDS-Net operates with a dual-branch\narchitecture: the main branch utilizes a decoder network to learn a\nGaussian-based prior distribution from known features, while the second branch\nderives a posterior distribution based on true labels. A key innovation of\nPDS-Net is its condition-based noise recognition loss function, which enables\nprecise identification of noisy features in objects (users or services). Once\nnoisy features are identified, PDS-Net refines the feature's prior\ndistribution, aligning it with the posterior distribution, and propagates this\nadjusted distribution to intermediate layers, effectively reducing noise\ninterference. Extensive experiments conducted on two real-world QoS datasets\ndemonstrate that PDS-Net consistently outperforms existing models, achieving an\naverage improvement of 8.91% in MAE on Dataset D1 and 8.32% on Dataset D2\ncompared to the ate-of-the-art. These results highlight PDS-Net's ability to\naccurately capture complex user-service relationships and handle feature noise,\nunderscoring its robustness and versatility across diverse QoS prediction\nenvironments.\n","authors":["Ziliang Wang","Xiaohong Zhang","Ze Shi Li","Sheng Huang","Meng Yan"],"pdf_url":"https://arxiv.org/pdf/2308.02580v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05276v1","updated":"2024-11-08T02:21:19Z","published":"2024-11-08T02:21:19Z","title":"GPT Semantic Cache: Reducing LLM Costs and Latency via Semantic\n  Embedding Caching","summary":"  Large Language Models (LLMs), such as GPT (Radford et al., 2019), have\nsignificantly advanced artificial intelligence by enabling sophisticated\nnatural language understanding and generation. However, the high computational\nand financial costs associated with frequent API calls to these models present\na substantial bottleneck, especially for applications like customer service\nchatbots that handle repetitive queries. In this paper, we introduce GPT\nSemantic Cache, a method that leverages semantic caching of query embeddings in\nin-memory storage (Redis). By storing embeddings of user queries, our approach\nefficiently identifies semantically similar questions, allowing for the\nretrieval of pre-generated responses without redundant API calls to the LLM.\nThis technique reduces operational costs and improves response times, enhancing\nthe efficiency of LLM-powered applications.\n","authors":["Sajal Regmi","Chetan Phakami Pun"],"pdf_url":"https://arxiv.org/pdf/2411.05276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16235v2","updated":"2024-11-08T02:17:22Z","published":"2024-06-23T22:53:47Z","title":"Preference Tuning For Toxicity Mitigation Generalizes Across Languages","summary":"  Detoxifying multilingual Large Language Models (LLMs) has become crucial due\nto their increasing global use. In this work, we explore zero-shot\ncross-lingual generalization of preference tuning in detoxifying LLMs. Unlike\nprevious studies that show limited cross-lingual generalization for other\nsafety tasks, we demonstrate that Direct Preference Optimization (DPO) training\nwith only English data can significantly reduce toxicity in multilingual\nopen-ended generations. For example, the probability of mGPT-1.3B generating\ntoxic continuations drops from 46.8% to 3.9% across 17 different languages\nafter training. Our results also extend to other multilingual LLMs, such as\nBLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal\nintervention and activation analysis, we identified the dual multilinguality\nproperty of MLP layers in LLMs, which explains the cross-lingual generalization\nof DPO. Finally, we show that bilingual sentence retrieval can predict the\ncross-lingual transferability of DPO preference tuning.\n","authors":["Xiaochen Li","Zheng-Xin Yong","Stephen H. Bach"],"pdf_url":"https://arxiv.org/pdf/2406.16235v2.pdf","comment":"Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05274v1","updated":"2024-11-08T02:16:41Z","published":"2024-11-08T02:16:41Z","title":"Distributed-Order Fractional Graph Operating Network","summary":"  We introduce the Distributed-order fRActional Graph Operating Network\n(DRAGON), a novel continuous Graph Neural Network (GNN) framework that\nincorporates distributed-order fractional calculus. Unlike traditional\ncontinuous GNNs that utilize integer-order or single fractional-order\ndifferential equations, DRAGON uses a learnable probability distribution over a\nrange of real numbers for the derivative orders. By allowing a flexible and\nlearnable superposition of multiple derivative orders, our framework captures\ncomplex graph feature updating dynamics beyond the reach of conventional\nmodels. We provide a comprehensive interpretation of our framework's capability\nto capture intricate dynamics through the lens of a non-Markovian graph random\nwalk with node feature updating driven by an anomalous diffusion process over\nthe graph. Furthermore, to highlight the versatility of the DRAGON framework,\nwe conduct empirical evaluations across a range of graph learning tasks. The\nresults consistently demonstrate superior performance when compared to\ntraditional continuous GNN models. The implementation code is available at\n\\url{https://github.com/zknus/NeurIPS-2024-DRAGON}.\n","authors":["Kai Zhao","Xuhao Li","Qiyu Kang","Feng Ji","Qinxu Ding","Yanan Zhao","Wenfei Liang","Wee Peng Tay"],"pdf_url":"https://arxiv.org/pdf/2411.05274v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05273v1","updated":"2024-11-08T02:12:34Z","published":"2024-11-08T02:12:34Z","title":"Real-World Offline Reinforcement Learning from Vision Language Model\n  Feedback","summary":"  Offline reinforcement learning can enable policy learning from pre-collected,\nsub-optimal datasets without online interactions. This makes it ideal for\nreal-world robots and safety-critical scenarios, where collecting online data\nor expert demonstrations is slow, costly, and risky. However, most existing\noffline RL works assume the dataset is already labeled with the task rewards, a\nprocess that often requires significant human effort, especially when\nground-truth states are hard to ascertain (e.g., in the real-world). In this\npaper, we build on prior work, specifically RL-VLM-F, and propose a novel\nsystem that automatically generates reward labels for offline datasets using\npreference feedback from a vision-language model and a text description of the\ntask. Our method then learns a policy using offline RL with the reward-labeled\ndataset. We demonstrate the system's applicability to a complex real-world\nrobot-assisted dressing task, where we first learn a reward function using a\nvision-language model on a sub-optimal offline dataset, and then we use the\nlearned reward to employ Implicit Q learning to develop an effective dressing\npolicy. Our method also performs well in simulation tasks involving the\nmanipulation of rigid and deformable objects, and significantly outperform\nbaselines such as behavior cloning and inverse RL. In summary, we propose a new\nsystem that enables automatic reward labeling and policy learning from\nunlabeled, sub-optimal offline datasets.\n","authors":["Sreyas Venkataraman","Yufei Wang","Ziyu Wang","Zackory Erickson","David Held"],"pdf_url":"https://arxiv.org/pdf/2411.05273v1.pdf","comment":"7 pages. Accepted at the LangRob Workshop 2024 @ CoRL, 2024"},{"id":"http://arxiv.org/abs/2411.05269v1","updated":"2024-11-08T02:04:21Z","published":"2024-11-08T02:04:21Z","title":"Cancer-Net SCa-Synth: An Open Access Synthetically Generated 2D Skin\n  Lesion Dataset for Skin Cancer Classification","summary":"  In the United States, skin cancer ranks as the most commonly diagnosed\ncancer, presenting a significant public health issue due to its high rates of\noccurrence and the risk of serious complications if not caught early. Recent\nadvancements in dataset curation and deep learning have shown promise in quick\nand accurate detection of skin cancer. However, current open-source datasets\nhave significant class imbalances which impedes the effectiveness of these deep\nlearning models. In healthcare, generative artificial intelligence (AI) models\nhave been employed to create synthetic data, addressing data imbalance in\ndatasets by augmenting underrepresented classes and enhancing the overall\nquality and performance of machine learning models. In this paper, we build on\ntop of previous work by leveraging new advancements in generative AI, notably\nStable Diffusion and DreamBooth. We introduce Cancer-Net SCa-Synth, an open\naccess synthetically generated 2D skin lesion dataset for skin cancer\nclassification. Further analysis on the data effectiveness by comparing the\nISIC 2020 test set performance for training with and without these synthetic\nimages for a simple model highlights the benefits of leveraging synthetic data\nto improve performance. Cancer-Net SCa-Synth is publicly available at\nhttps://github.com/catai9/Cancer-Net-SCa-Synth as part of a global open-source\ninitiative for accelerating machine learning for cancer care.\n","authors":["Chi-en Amy Tai","Oustan Ding","Alexander Wong"],"pdf_url":"https://arxiv.org/pdf/2411.05269v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.05715v1","updated":"2024-11-08T17:16:27Z","published":"2024-11-08T17:16:27Z","title":"On the Role of Noise in AudioVisual Integration: Evidence from\n  Artificial Neural Networks that Exhibit the McGurk Effect","summary":"  Humans are able to fuse information from both auditory and visual modalities\nto help with understanding speech. This is frequently demonstrated through an\nphenomenon known as the McGurk Effect, during which a listener is presented\nwith incongruent auditory and visual speech that fuse together into the percept\nof an illusory intermediate phoneme. Building on a recent framework that\nproposes how to address developmental 'why' questions using artificial neural\nnetworks, we evaluated a set of recent artificial neural networks trained on\naudiovisual speech by testing them with audiovisually incongruent words\ndesigned to elicit the McGurk effect. We compared networks trained on clean\nspeech to those trained on noisy speech, and discovered that training with\nnoisy speech led to an increase in both visual responses and McGurk responses\nacross all models. Furthermore, we observed that systematically increasing the\nlevel of auditory noise during ANN training also increased the amount of\naudiovisual integration up to a point, but at extreme noise levels, this\nintegration failed to develop. These results suggest that excessive noise\nexposure during critical periods of audiovisual learning may negatively\ninfluence the development of audiovisual speech integration. This work also\ndemonstrates that the McGurk effect reliably emerges untrained from the\nbehaviour of both supervised and unsupervised networks. This supports the\nnotion that artificial neural networks might be useful models for certain\naspects of perception and cognition.\n","authors":["Lukas Grasse","Matthew S. Tata"],"pdf_url":"https://arxiv.org/pdf/2411.05715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05374v1","updated":"2024-11-08T07:04:00Z","published":"2024-11-08T07:04:00Z","title":"Interdisciplinary Translations: Sensory Perception as a Universal\n  Language","summary":"  This paper investigates sensory perception's pivotal role as a universal\ncommunicative bridge across varied cultures and disciplines, and how it\nmanifests its value in the study of media art, human computer interaction and\nartificial intelligence. By analyzing its function in non-verbal communication\nthrough interactive systems, and drawing on the interpretive model in\ntranslation studies where \"sense\" acts as a mediation between two languages,\nthis paper illustrates how interdisciplinary communication in media art and\nhuman-computer interaction is afforded by the abstract language of human\nsensory perception. Specific examples from traditional art, interactive media\nart, HCI, communication, and translation studies demonstrate how sensory\nfeedback translates and conveys meaning across diverse modalities of expression\nand how it fosters connections between humans, art, and technology. Pertaining\nto this topic, this paper analyzes the impact of sensory feedback systems in\ndesigning interactive experiences, and reveals the guiding role of sensory\nperception in the design philosophy of AI systems. Overall, the study aims to\nbroaden the understanding of sensory perception's role in communication,\nhighlighting its significance in the evolution of interactive experiences and\nits capacity to unify art, science, and the human experience.\n","authors":["Xindi Kang","Xuanyang Huang","Mingdong Song","Varvara Guljajeva","JoAnn Kuchera-Morin"],"pdf_url":"https://arxiv.org/pdf/2411.05374v1.pdf","comment":"This paper has been accepted to the International Symposium of\n  Electronic Arts 2024, and the proceedings version will be available at\n  https://isea-archives.siggraph.org/publications/ with DOI to be added once\n  published"},{"id":"http://arxiv.org/abs/2411.05322v1","updated":"2024-11-08T04:29:14Z","published":"2024-11-08T04:29:14Z","title":"Rate-aware Compression for NeRF-based Volumetric Video","summary":"  The neural radiance fields (NeRF) have advanced the development of 3D\nvolumetric video technology, but the large data volumes they involve pose\nsignificant challenges for storage and transmission. To address these problems,\nthe existing solutions typically compress these NeRF representations after the\ntraining stage, leading to a separation between representation training and\ncompression. In this paper, we try to directly learn a compact NeRF\nrepresentation for volumetric video in the training stage based on the proposed\nrate-aware compression framework. Specifically, for volumetric video, we use a\nsimple yet effective modeling strategy to reduce temporal redundancy for the\nNeRF representation. Then, during the training phase, an implicit entropy model\nis utilized to estimate the bitrate of the NeRF representation. This entropy\nmodel is then encoded into the bitstream to assist in the decoding of the NeRF\nrepresentation. This approach enables precise bitrate estimation, thereby\nleading to a compact NeRF representation. Furthermore, we propose an adaptive\nquantization strategy and learn the optimal quantization step for the NeRF\nrepresentations. Finally, the NeRF representation can be optimized by using the\nrate-distortion trade-off. Our proposed compression framework can be used for\ndifferent representations and experimental results demonstrate that our\napproach significantly reduces the storage size with marginal distortion and\nachieves state-of-the-art rate-distortion performance for volumetric video on\nthe HumanRF and ReRF datasets. Compared to the previous state-of-the-art method\nTeTriRF, we achieved an approximately -80% BD-rate on the HumanRF dataset and\n-60% BD-rate on the ReRF dataset.\n","authors":["Zhiyu Zhang","Guo Lu","Huanxiong Liang","Zhengxue Cheng","Anni Tang","Li Song"],"pdf_url":"https://arxiv.org/pdf/2411.05322v1.pdf","comment":"Accepted by ACM MM 2024 (Oral)"},{"id":"http://arxiv.org/abs/2411.05295v1","updated":"2024-11-08T02:57:23Z","published":"2024-11-08T02:57:23Z","title":"Content-Adaptive Rate-Quality Curve Prediction Model in Media Processing\n  System","summary":"  In streaming media services, video transcoding is a common practice to\nalleviate bandwidth demands. Unfortunately, traditional methods employing a\nuniform rate factor (RF) across all videos often result in significant\ninefficiencies. Content-adaptive encoding (CAE) techniques address this by\ndynamically adjusting encoding parameters based on video content\ncharacteristics. However, existing CAE methods are often tightly coupled with\nspecific encoding strategies, leading to inflexibility. In this paper, we\npropose a model that predicts both RF-quality and RF-bitrate curves, which can\nbe utilized to derive a comprehensive bitrate-quality curve. This approach\nfacilitates flexible adjustments to the encoding strategy without necessitating\nmodel retraining. The model leverages codec features, content features, and\nanchor features to predict the bitrate-quality curve accurately. Additionally,\nwe introduce an anchor suspension method to enhance prediction accuracy.\nExperiments confirm that the actual quality metric (VMAF) of the compressed\nvideo stays within 1 of the target, achieving an accuracy of 99.14%. By\nincorporating our quality improvement strategy with the rate-quality curve\nprediction model, we conducted online A/B tests, obtaining both +0.107%\nimprovements in video views and video completions and +0.064% app duration\ntime. Our model has been deployed on the Xiaohongshu App.\n","authors":["Shibo Yin","Zhiyu Zhang","Peirong Ning","Qiubo Chen","Jing Chen","Quan Zhou","Li Song"],"pdf_url":"https://arxiv.org/pdf/2411.05295v1.pdf","comment":"Accepted by IEEE VCIP 2024 (Oral)"},{"id":"http://arxiv.org/abs/2411.03109v2","updated":"2024-11-08T02:51:57Z","published":"2024-11-05T13:56:44Z","title":"pTSE-T: Presentation Target Speaker Extraction using Unaligned Text Cues","summary":"  TSE(Target Speaker Extraction) aims to extract the clean speech of the target\nspeaker in an audio mixture, thus eliminating irrelevant background noise and\nspeech. While prior work has explored various auxiliary cues including\npre-recorded speech, visual information (e.g., lip motions and gestures), and\nspatial information, the acquisition and selection of such strong cues are\ninfeasible in many practical scenarios. Unlike all existing work, in this\npaper, we condition the TSE algorithm on semantic cues extracted from limited\nand unaligned text content, such as condensed points from a presentation slide.\nThis method is particularly useful in scenarios like meetings, poster sessions,\nor lecture presentations, where acquiring other cues in real-time is\nchallenging. To this end, we design two different networks. Specifically, our\nproposed TPE fuses audio features with content-based semantic cues to\nfacilitate time-frequency mask generation to filter out extraneous noise, while\nanother proposal, namely TSR, employs the contrastive learning technique to\nassociate blindly separated speech signals with semantic cues. The experimental\nresults show the efficacy in accurately identifying the target speaker by\nutilizing semantic cues derived from limited and unaligned text, resulting in\nSI-SDRi of 12.16 dB, SDRi of 12.66 dB, PESQi of 0.830 and STOIi of 0.150,\nrespectively. Dataset and source code will be publicly available. Project demo\npage: https://slideTSE.github.io/.\n","authors":["Ziyang Jiang","Xinyuan Qian","Jiahe Lei","Zexu Pan","Wei Xue","Xu-cheng Yin"],"pdf_url":"https://arxiv.org/pdf/2411.03109v2.pdf","comment":null}]},"2024-11-11T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2411.07232v1","updated":"2024-11-11T18:50:09Z","published":"2024-11-11T18:50:09Z","title":"Add-it: Training-Free Object Insertion in Images With Pretrained\n  Diffusion Models","summary":"  Adding Object into images based on text instructions is a challenging task in\nsemantic image editing, requiring a balance between preserving the original\nscene and seamlessly integrating the new object in a fitting location. Despite\nextensive efforts, existing models often struggle with this balance,\nparticularly with finding a natural location for adding an object in complex\nscenes. We introduce Add-it, a training-free approach that extends diffusion\nmodels' attention mechanisms to incorporate information from three key sources:\nthe scene image, the text prompt, and the generated image itself. Our weighted\nextended-attention mechanism maintains structural consistency and fine details\nwhile ensuring natural object placement. Without task-specific fine-tuning,\nAdd-it achieves state-of-the-art results on both real and generated image\ninsertion benchmarks, including our newly constructed \"Additing Affordance\nBenchmark\" for evaluating object placement plausibility, outperforming\nsupervised methods. Human evaluations show that Add-it is preferred in over 80%\nof cases, and it also demonstrates improvements in various automated metrics.\n","authors":["Yoad Tewel","Rinon Gal","Dvir Samuel Yuval Atzmon","Lior Wolf","Gal Chechik"],"pdf_url":"https://arxiv.org/pdf/2411.07232v1.pdf","comment":"Project page is at https://research.nvidia.com/labs/par/addit/"},{"id":"http://arxiv.org/abs/2411.07231v1","updated":"2024-11-11T18:49:58Z","published":"2024-11-11T18:49:58Z","title":"Watermark Anything with Localized Messages","summary":"  Image watermarking methods are not tailored to handle small watermarked\nareas. This restricts applications in real-world scenarios where parts of the\nimage may come from different sources or have been edited. We introduce a\ndeep-learning model for localized image watermarking, dubbed the Watermark\nAnything Model (WAM). The WAM embedder imperceptibly modifies the input image,\nwhile the extractor segments the received image into watermarked and\nnon-watermarked areas and recovers one or several hidden messages from the\nareas found to be watermarked. The models are jointly trained at low resolution\nand without perceptual constraints, then post-trained for imperceptibility and\nmultiple watermarks. Experiments show that WAM is competitive with state-of-the\nart methods in terms of imperceptibility and robustness, especially against\ninpainting and splicing, even on high-resolution images. Moreover, it offers\nnew capabilities: WAM can locate watermarked areas in spliced images and\nextract distinct 32-bit messages with less than 1 bit error from multiple small\nregions - no larger than 10% of the image surface - even for small $256\\times\n256$ images.\n","authors":["Tom Sander","Pierre Fernandez","Alain Durmus","Teddy Furon","Matthijs Douze"],"pdf_url":"https://arxiv.org/pdf/2411.07231v1.pdf","comment":"Under review. Code at\n  https://github.com/facebookresearch/watermark-anything"},{"id":"http://arxiv.org/abs/2411.02537v3","updated":"2024-11-11T18:49:52Z","published":"2024-11-04T19:16:53Z","title":"INQUIRE: A Natural World Text-to-Image Retrieval Benchmark","summary":"  We introduce INQUIRE, a text-to-image retrieval benchmark designed to\nchallenge multimodal vision-language models on expert-level queries. INQUIRE\nincludes iNaturalist 2024 (iNat24), a new dataset of five million natural world\nimages, along with 250 expert-level retrieval queries. These queries are paired\nwith all relevant images comprehensively labeled within iNat24, comprising\n33,000 total matches. Queries span categories such as species identification,\ncontext, behavior, and appearance, emphasizing tasks that require nuanced image\nunderstanding and domain expertise. Our benchmark evaluates two core retrieval\ntasks: (1) INQUIRE-Fullrank, a full dataset ranking task, and (2)\nINQUIRE-Rerank, a reranking task for refining top-100 retrievals. Detailed\nevaluation of a range of recent multimodal models demonstrates that INQUIRE\nposes a significant challenge, with the best models failing to achieve an\nmAP@50 above 50%. In addition, we show that reranking with more powerful\nmultimodal models can enhance retrieval performance, yet there remains a\nsignificant margin for improvement. By focusing on scientifically-motivated\necological challenges, INQUIRE aims to bridge the gap between AI capabilities\nand the needs of real-world scientific inquiry, encouraging the development of\nretrieval systems that can assist with accelerating ecological and biodiversity\nresearch. Our dataset and code are available at\nhttps://inquire-benchmark.github.io\n","authors":["Edward Vendrow","Omiros Pantazis","Alexander Shepard","Gabriel Brostow","Kate E. Jones","Oisin Mac Aodha","Sara Beery","Grant Van Horn"],"pdf_url":"https://arxiv.org/pdf/2411.02537v3.pdf","comment":"Published in NeurIPS 2024, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2411.07229v1","updated":"2024-11-11T18:48:31Z","published":"2024-11-11T18:48:31Z","title":"Learning from Limited and Imperfect Data","summary":"  The datasets used for Deep Neural Network training (e.g., ImageNet, MSCOCO,\netc.) are often manually balanced across categories (classes) to facilitate\nlearning of all the categories. This curation process is often expensive and\nrequires throwing away precious annotated data to balance the frequency across\nclasses. This is because the distribution of data in the world (e.g., internet,\netc.) significantly differs from the well-curated datasets and is often\nover-populated with samples from common categories. The algorithms designed for\nwell-curated datasets perform suboptimally when used to learn from imperfect\ndatasets with long-tailed imbalances and distribution shifts. For deep models\nto be widely used, getting away with the costly curation process by developing\nrobust algorithms that can learn from real-world data distribution is\nnecessary. Toward this goal, we develop practical algorithms for Deep Neural\nNetworks that can learn from limited and imperfect data present in the real\nworld. These works are divided into four segments, each covering a scenario of\nlearning from limited or imperfect data. The first part of the works focuses on\nLearning Generative Models for Long-Tail Data, where we mitigate the\nmode-collapse for tail (minority) classes and enable diverse aesthetic image\ngenerations as head (majority) classes. In the second part, we enable effective\ngeneralization on tail classes through Inductive Regularization schemes, which\nallow tail classes to generalize as the head classes without enforcing explicit\ngeneration of images. In the third part, we develop algorithms for Optimizing\nRelevant Metrics compared to the average accuracy for learning from long-tailed\ndata with limited annotation (semi-supervised), followed by the fourth part,\nwhich focuses on the effective domain adaptation of the model to various\ndomains with zero to very few labeled samples.\n","authors":["Harsh Rangwani"],"pdf_url":"https://arxiv.org/pdf/2411.07229v1.pdf","comment":"ICVGIP'24 Young Researcher Symposium Abstract"},{"id":"http://arxiv.org/abs/2411.07223v1","updated":"2024-11-11T18:43:44Z","published":"2024-11-11T18:43:44Z","title":"Grounding Video Models to Actions through Goal Conditioned Exploration","summary":"  Large video models, pretrained on massive amounts of Internet video, provide\na rich source of physical knowledge about the dynamics and motions of objects\nand tasks. However, video models are not grounded in the embodiment of an\nagent, and do not describe how to actuate the world to reach the visual states\ndepicted in a video. To tackle this problem, current methods use a separate\nvision-based inverse dynamic model trained on embodiment-specific data to map\nimage states to actions. Gathering data to train such a model is often\nexpensive and challenging, and this model is limited to visual settings similar\nto the ones in which data are available. In this paper, we investigate how to\ndirectly ground video models to continuous actions through self-exploration in\nthe embodied environment -- using generated video states as visual goals for\nexploration. We propose a framework that uses trajectory level action\ngeneration in combination with video guidance to enable an agent to solve\ncomplex tasks without any external supervision, e.g., rewards, action labels,\nor segmentation masks. We validate the proposed approach on 8 tasks in Libero,\n6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual\nNavigation. We show how our approach is on par with or even surpasses multiple\nbehavior cloning baselines trained on expert demonstrations while without\nrequiring any action annotations.\n","authors":["Yunhao Luo","Yilun Du"],"pdf_url":"https://arxiv.org/pdf/2411.07223v1.pdf","comment":"Project page at https://video-to-action.github.io/"},{"id":"http://arxiv.org/abs/2411.07205v1","updated":"2024-11-11T18:28:33Z","published":"2024-11-11T18:28:33Z","title":"DLCR: A Generative Data Expansion Framework via Diffusion for\n  Clothes-Changing Person Re-ID","summary":"  With the recent exhibited strength of generative diffusion models, an open\nresearch question is \\textit{if images generated by these models can be used to\nlearn better visual representations}. While this generative data expansion may\nsuffice for easier visual tasks, we explore its efficacy on a more difficult\ndiscriminative task: clothes-changing person re-identification (CC-ReID).\nCC-ReID aims to match people appearing in non-overlapping cameras, even when\nthey change their clothes across cameras. Not only are current CC-ReID models\nconstrained by the limited diversity of clothing in current CC-ReID datasets,\nbut generating additional data that retains important personal features for\naccurate identification is a current challenge. To address this issue we\npropose DLCR, a novel data expansion framework that leverages pre-trained\ndiffusion and large language models (LLMs) to accurately generate diverse\nimages of individuals in varied attire. We generate additional data for five\nbenchmark CC-ReID datasets (PRCC, CCVID, LaST, VC-Clothes, and LTCC) and\n\\textbf{increase their clothing diversity by \\boldmath{$10$}x, totaling over\n\\boldmath{$2.1$}M images generated}. DLCR employs diffusion-based text-guided\ninpainting, conditioned on clothing prompts constructed using LLMs, to generate\nsynthetic data that only modifies a subject's clothes while preserving their\npersonally identifiable features. With this massive increase in data, we\nintroduce two novel strategies - progressive learning and test-time prediction\nrefinement - that respectively reduce training time and further boosts CC-ReID\nperformance. On the PRCC dataset, we obtain a large top-1 accuracy improvement\nof $11.3\\%$ by training CAL, a previous state of the art (SOTA) method, with\nDLCR-generated data. We publicly release our code and generated data for each\ndataset here: \\url{https://github.com/CroitoruAlin/dlcr}.\n","authors":["Nyle Siddiqui","Florinel Alin Croitoru","Gaurav Kumar Nayak","Radu Tudor Ionescu","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2411.07205v1.pdf","comment":"Published in WACV 2025"},{"id":"http://arxiv.org/abs/2411.07199v1","updated":"2024-11-11T18:21:43Z","published":"2024-11-11T18:21:43Z","title":"OmniEdit: Building Image Editing Generalist Models Through Specialist\n  Supervision","summary":"  Instruction-guided image editing methods have demonstrated significant\npotential by training diffusion models on automatically synthesized or manually\nannotated image editing pairs. However, these methods remain far from\npractical, real-life applications. We identify three primary challenges\ncontributing to this gap. Firstly, existing models have limited editing skills\ndue to the biased synthesis process. Secondly, these methods are trained with\ndatasets with a high volume of noise and artifacts. This is due to the\napplication of simple filtering methods like CLIP-score. Thirdly, all these\ndatasets are restricted to a single low resolution and fixed aspect ratio,\nlimiting the versatility to handle real-world use cases. In this paper, we\npresent \\omniedit, which is an omnipotent editor to handle seven different\nimage editing tasks with any aspect ratio seamlessly. Our contribution is in\nfour folds: (1) \\omniedit is trained by utilizing the supervision from seven\ndifferent specialist models to ensure task coverage. (2) we utilize importance\nsampling based on the scores provided by large multimodal models (like GPT-4o)\ninstead of CLIP-score to improve the data quality. (3) we propose a new editing\narchitecture called EditNet to greatly boost the editing success rate, (4) we\nprovide images with different aspect ratios to ensure that our model can handle\nany image in the wild. We have curated a test set containing images of\ndifferent aspect ratios, accompanied by diverse instructions to cover different\ntasks. Both automatic evaluation and human evaluations demonstrate that\n\\omniedit can significantly outperform all the existing models. Our code,\ndataset and model will be available at\n\\url{https://tiger-ai-lab.github.io/OmniEdit/}\n","authors":["Cong Wei","Zheyang Xiong","Weiming Ren","Xinrun Du","Ge Zhang","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07199v1.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2406.10839v2","updated":"2024-11-11T17:59:47Z","published":"2024-06-16T08:20:12Z","title":"Reminding Multimodal Large Language Models of Object-aware Knowledge\n  with Retrieved Tags","summary":"  Despite recent advances in the general visual instruction-following ability\nof Multimodal Large Language Models (MLLMs), they still struggle with critical\nproblems when required to provide a precise and detailed response to a visual\ninstruction: (1) failure to identify novel objects or entities, (2) mention of\nnon-existent objects, and (3) neglect of object's attributed details. Intuitive\nsolutions include improving the size and quality of data or using larger\nfoundation models. They show effectiveness in mitigating these issues, but at\nan expensive cost of collecting a vast amount of new data and introducing a\nsignificantly larger model. Standing at the intersection of these approaches,\nwe examine the three object-oriented problems from the perspective of the\nimage-to-text mapping process by the multimodal connector. In this paper, we\nfirst identify the limitations of multimodal connectors stemming from\ninsufficient training data. Driven by this, we propose to enhance the mapping\nwith retrieval-augmented tag tokens, which contain rich object-aware\ninformation such as object names and attributes. With our Tag-grounded visual\ninstruction tuning with retrieval Augmentation (TUNA), we outperform baselines\nthat share the same language model and training data on 12 benchmarks.\nFurthermore, we show the zero-shot capability of TUNA when provided with\nspecific datastores.\n","authors":["Daiqing Qi","Handong Zhao","Zijun Wei","Sheng Li"],"pdf_url":"https://arxiv.org/pdf/2406.10839v2.pdf","comment":"18 pages, 11 figures"},{"id":"http://arxiv.org/abs/2411.07184v1","updated":"2024-11-11T17:59:10Z","published":"2024-11-11T17:59:10Z","title":"SAMPart3D: Segment Any Part in 3D Objects","summary":"  3D part segmentation is a crucial and challenging task in 3D perception,\nplaying a vital role in applications such as robotics, 3D generation, and 3D\nediting. Recent methods harness the powerful Vision Language Models (VLMs) for\n2D-to-3D knowledge distillation, achieving zero-shot 3D part segmentation.\nHowever, these methods are limited by their reliance on text prompts, which\nrestricts the scalability to large-scale unlabeled datasets and the flexibility\nin handling part ambiguities. In this work, we introduce SAMPart3D, a scalable\nzero-shot 3D part segmentation framework that segments any 3D object into\nsemantic parts at multiple granularities, without requiring predefined part\nlabel sets as text prompts. For scalability, we use text-agnostic vision\nfoundation models to distill a 3D feature extraction backbone, allowing scaling\nto large unlabeled 3D datasets to learn rich 3D priors. For flexibility, we\ndistill scale-conditioned part-aware 3D features for 3D part segmentation at\nmultiple granularities. Once the segmented parts are obtained from the\nscale-conditioned part-aware 3D features, we use VLMs to assign semantic labels\nto each part based on the multi-view renderings. Compared to previous methods,\nour SAMPart3D can scale to the recent large-scale 3D object dataset Objaverse\nand handle complex, non-ordinary objects. Additionally, we contribute a new 3D\npart segmentation benchmark to address the lack of diversity and complexity of\nobjects and parts in existing benchmarks. Experiments show that our SAMPart3D\nsignificantly outperforms existing zero-shot 3D part segmentation methods, and\ncan facilitate various applications such as part-level editing and interactive\nsegmentation.\n","authors":["Yunhan Yang","Yukun Huang","Yuan-Chen Guo","Liangjun Lu","Xiaoyang Wu","Edmund Y. Lam","Yan-Pei Cao","Xihui Liu"],"pdf_url":"https://arxiv.org/pdf/2411.07184v1.pdf","comment":"Project Page: https://github.com/yhyang-myron/SAMPart3D-website"},{"id":"http://arxiv.org/abs/2403.16998v2","updated":"2024-11-11T17:56:29Z","published":"2024-03-25T17:59:09Z","title":"Understanding Long Videos with Multimodal Language Models","summary":"  Large Language Models (LLMs) have allowed recent LLM-based approaches to\nachieve excellent performance on long-video understanding benchmarks. We\ninvestigate how extensive world knowledge and strong reasoning skills of\nunderlying LLMs influence this strong performance. Surprisingly, we discover\nthat LLM-based approaches can yield surprisingly good accuracy on long-video\ntasks with limited video information, sometimes even with no video specific\ninformation. Building on this, we exploring injecting video-specific\ninformation into an LLM-based framework. We utilize off-the-shelf vision tools\nto extract three object-centric information modalities from videos and then\nleverage natural language as a medium for fusing this information. Our\nresulting Multimodal Video Understanding (MVU) framework demonstrates\nstate-of-the-art performance across multiple video understanding benchmarks.\nStrong performance also on robotics domain tasks establish its strong\ngenerality. Our code will be released publicly.\n","authors":["Kanchana Ranasinghe","Xiang Li","Kumara Kahatapitiya","Michael S. Ryoo"],"pdf_url":"https://arxiv.org/pdf/2403.16998v2.pdf","comment":"Code available at https://github.com/kahnchana/mvu"},{"id":"http://arxiv.org/abs/2406.10740v3","updated":"2024-11-11T17:54:55Z","published":"2024-06-15T21:10:37Z","title":"FreeMotion: MoCap-Free Human Motion Synthesis with Multimodal Large\n  Language Models","summary":"  Human motion synthesis is a fundamental task in computer animation. Despite\nrecent progress in this field utilizing deep learning and motion capture data,\nexisting methods are always limited to specific motion categories,\nenvironments, and styles. This poor generalizability can be partially\nattributed to the difficulty and expense of collecting large-scale and\nhigh-quality motion data. At the same time, foundation models trained with\ninternet-scale image and text data have demonstrated surprising world knowledge\nand reasoning ability for various downstream tasks. Utilizing these foundation\nmodels may help with human motion synthesis, which some recent works have\nsuperficially explored. However, these methods didn't fully unveil the\nfoundation models' potential for this task and only support several simple\nactions and environments. In this paper, we for the first time, without any\nmotion data, explore open-set human motion synthesis using natural language\ninstructions as user control signals based on MLLMs across any motion task and\nenvironment. Our framework can be split into two stages: 1) sequential keyframe\ngeneration by utilizing MLLMs as a keyframe designer and animator; 2) motion\nfilling between keyframes through interpolation and motion tracking. Our method\ncan achieve general human motion synthesis for many downstream tasks. The\npromising results demonstrate the worth of mocap-free human motion synthesis\naided by MLLMs and pave the way for future research.\n","authors":["Zhikai Zhang","Yitang Li","Haofeng Huang","Mingxian Lin","Li Yi"],"pdf_url":"https://arxiv.org/pdf/2406.10740v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10733v2","updated":"2024-11-11T17:42:37Z","published":"2024-10-14T17:15:07Z","title":"Deep Compression Autoencoder for Efficient High-Resolution Diffusion\n  Models","summary":"  We present Deep Compression Autoencoder (DC-AE), a new family of autoencoder\nmodels for accelerating high-resolution diffusion models. Existing autoencoder\nmodels have demonstrated impressive results at a moderate spatial compression\nratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy for\nhigh spatial compression ratios (e.g., 64x). We address this challenge by\nintroducing two key techniques: (1) Residual Autoencoding, where we design our\nmodels to learn residuals based on the space-to-channel transformed features to\nalleviate the optimization difficulty of high spatial-compression autoencoders;\n(2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phases\ntraining strategy for mitigating the generalization penalty of high\nspatial-compression autoencoders. With these designs, we improve the\nautoencoder's spatial compression ratio up to 128 while maintaining the\nreconstruction quality. Applying our DC-AE to latent diffusion models, we\nachieve significant speedup without accuracy drop. For example, on ImageNet\n512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedup\non H100 GPU for UViT-H while achieving a better FID, compared with the widely\nused SD-VAE-f8 autoencoder. Our code is available at\nhttps://github.com/mit-han-lab/efficientvit.\n","authors":["Junyu Chen","Han Cai","Junsong Chen","Enze Xie","Shang Yang","Haotian Tang","Muyang Li","Yao Lu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2410.10733v2.pdf","comment":"Preprint. First two authors contributed equally to this work. Update:\n  add diffusion model scaling results"},{"id":"http://arxiv.org/abs/2406.12384v2","updated":"2024-11-11T17:25:20Z","published":"2024-06-18T08:15:21Z","title":"VRSBench: A Versatile Vision-Language Benchmark Dataset for Remote\n  Sensing Image Understanding","summary":"  We introduce a new benchmark designed to advance the development of\ngeneral-purpose, large-scale vision-language models for remote sensing images.\nAlthough several vision-language datasets in remote sensing have been proposed\nto pursue this goal, existing datasets are typically tailored to single tasks,\nlack detailed object information, or suffer from inadequate quality control.\nExploring these improvement opportunities, we present a Versatile\nvision-language Benchmark for Remote Sensing image understanding, termed\nVRSBench. This benchmark comprises 29,614 images, with 29,614 human-verified\ndetailed captions, 52,472 object references, and 123,221 question-answer pairs.\nIt facilitates the training and evaluation of vision-language models across a\nbroad spectrum of remote sensing image understanding tasks. We further\nevaluated state-of-the-art models on this benchmark for three vision-language\ntasks: image captioning, visual grounding, and visual question answering. Our\nwork aims to significantly contribute to the development of advanced\nvision-language models in the field of remote sensing. The data and code can be\naccessed at https://github.com/lx709/VRSBench.\n","authors":["Xiang Li","Jian Ding","Mohamed Elhoseiny"],"pdf_url":"https://arxiv.org/pdf/2406.12384v2.pdf","comment":"Accepted for publication at NeruIPS 2024 Dataset and Benchmark Track"},{"id":"http://arxiv.org/abs/2411.07146v1","updated":"2024-11-11T17:17:11Z","published":"2024-11-11T17:17:11Z","title":"Lost in Tracking Translation: A Comprehensive Analysis of Visual SLAM in\n  Human-Centered XR and IoT Ecosystems","summary":"  Advancements in tracking algorithms have empowered nascent applications\nacross various domains, from steering autonomous vehicles to guiding robots to\nenhancing augmented reality experiences for users. However, these algorithms\nare application-specific and do not work across applications with different\ntypes of motion; even a tracking algorithm designed for a given application\ndoes not work in scenarios deviating from highly standard conditions. For\nexample, a tracking algorithm designed for robot navigation inside a building\nwill not work for tracking the same robot in an outdoor environment. To\ndemonstrate this problem, we evaluate the performance of the state-of-the-art\ntracking methods across various applications and scenarios. To inform our\nanalysis, we first categorize algorithmic, environmental, and\nlocomotion-related challenges faced by tracking algorithms. We quantitatively\nevaluate the performance using multiple tracking algorithms and representative\ndatasets for a wide range of Internet of Things (IoT) and Extended Reality (XR)\napplications, including autonomous vehicles, drones, and humans. Our analysis\nshows that no tracking algorithm works across different applications and\nscenarios within applications. Ultimately, using the insights generated from\nour analysis, we discuss multiple approaches to improving the tracking\nperformance using input data characterization, leveraging intermediate\ninformation, and output evaluation.\n","authors":["Yasra Chandio","Khotso Selialia","Joseph DeGol","Luis Garcia","Fatima M. Anwar"],"pdf_url":"https://arxiv.org/pdf/2411.07146v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07138v1","updated":"2024-11-11T17:08:40Z","published":"2024-11-11T17:08:40Z","title":"Nuremberg Letterbooks: A Multi-Transcriptional Dataset of Early 15th\n  Century Manuscripts for Document Analysis","summary":"  Most datasets in the field of document analysis utilize highly standardized\nlabels, which, while simplifying specific tasks, often produce outputs that are\nnot directly applicable to humanities research. In contrast, the Nuremberg\nLetterbooks dataset, which comprises historical documents from the early 15th\ncentury, addresses this gap by providing multiple types of transcriptions and\naccompanying metadata. This approach allows for developing methods that are\nmore closely aligned with the needs of the humanities. The dataset includes 4\nbooks containing 1711 labeled pages written by 10 scribes. Three types of\ntranscriptions are provided for handwritten text recognition: Basic,\ndiplomatic, and regularized. For the latter two, versions with and without\nexpanded abbreviations are also available. A combination of letter ID and\nwriter ID supports writer identification due to changing writers within pages.\nIn the technical validation, we established baselines for various tasks,\ndemonstrating data consistency and providing benchmarks for future research to\nbuild upon.\n","authors":["Martin Mayr","Julian Krenz","Katharina Neumeier","Anna Bub","Simon Bürcky","Nina Brolich","Klaus Herbers","Mechthild Habermann","Peter Fleischmann","Andreas Maier","Vincent Christlein"],"pdf_url":"https://arxiv.org/pdf/2411.07138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07135v1","updated":"2024-11-11T17:07:43Z","published":"2024-11-11T17:07:43Z","title":"Edify 3D: Scalable High-Quality 3D Asset Generation","summary":"  We introduce Edify 3D, an advanced solution designed for high-quality 3D\nasset generation. Our method first synthesizes RGB and surface normal images of\nthe described object at multiple viewpoints using a diffusion model. The\nmulti-view observations are then used to reconstruct the shape, texture, and\nPBR materials of the object. Our method can generate high-quality 3D assets\nwith detailed geometry, clean shape topologies, high-resolution textures, and\nmaterials within 2 minutes of runtime.\n","authors":[" NVIDIA"," :","Maciej Bala","Yin Cui","Yifan Ding","Yunhao Ge","Zekun Hao","Jon Hasselgren","Jacob Huffman","Jingyi Jin","J. P. Lewis","Zhaoshuo Li","Chen-Hsuan Lin","Yen-Chen Lin","Tsung-Yi Lin","Ming-Yu Liu","Alice Luo","Qianli Ma","Jacob Munkberg","Stella Shi","Fangyin Wei","Donglai Xiang","Jiashu Xu","Xiaohui Zeng","Qinsheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07135v1.pdf","comment":"Project website: https://research.nvidia.com/labs/dir/edify-3d"},{"id":"http://arxiv.org/abs/2410.05774v4","updated":"2024-11-11T17:06:25Z","published":"2024-10-08T07:55:09Z","title":"ActionAtlas: A VideoQA Benchmark for Domain-specialized Action\n  Recognition","summary":"  Our world is full of varied actions and moves across specialized domains that\nwe, as humans, strive to identify and understand. Within any single domain,\nactions can often appear quite similar, making it challenging for deep models\nto distinguish them accurately. To evaluate the effectiveness of multimodal\nfoundation models in helping us recognize such actions, we present ActionAtlas\nv1.0, a multiple-choice video question answering benchmark featuring short\nvideos across various sports. Each video in the dataset is paired with a\nquestion and four or five choices. The question pinpoints specific individuals,\nasking which choice \"best\" describes their action within a certain temporal\ncontext. Overall, the dataset includes 934 videos showcasing 580 unique actions\nacross 56 sports, with a total of 1896 actions within choices. Unlike most\nexisting video question answering benchmarks that only cover simplistic\nactions, often identifiable from a single frame, ActionAtlas focuses on\nintricate movements and rigorously tests the model's capability to discern\nsubtle differences between moves that look similar within each domain. We\nevaluate open and proprietary foundation models on this benchmark, finding that\nthe best model, GPT-4o, achieves a maximum accuracy of 45.52%. Meanwhile,\nNon-expert crowd workers, provided with action description for each choice,\nachieve 61.64% accuracy, where random chance is approximately 21%. Our findings\nwith state-of-the-art models indicate that having a high frame sampling rate is\nimportant for accurately recognizing actions in ActionAtlas, a feature that\nsome leading proprietary video models, such as Gemini, do not include in their\ndefault configuration.\n","authors":["Mohammadreza Salehi","Jae Sung Park","Tanush Yadav","Aditya Kusupati","Ranjay Krishna","Yejin Choi","Hannaneh Hajishirzi","Ali Farhadi"],"pdf_url":"https://arxiv.org/pdf/2410.05774v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07132v1","updated":"2024-11-11T17:05:15Z","published":"2024-11-11T17:05:15Z","title":"Token Merging for Training-Free Semantic Binding in Text-to-Image\n  Synthesis","summary":"  Although text-to-image (T2I) models exhibit remarkable generation\ncapabilities, they frequently fail to accurately bind semantically related\nobjects or attributes in the input prompts; a challenge termed semantic\nbinding. Previous approaches either involve intensive fine-tuning of the entire\nT2I model or require users or large language models to specify generation\nlayouts, adding complexity. In this paper, we define semantic binding as the\ntask of associating a given object with its attribute, termed attribute\nbinding, or linking it to other related sub-objects, referred to as object\nbinding. We introduce a novel method called Token Merging (ToMe), which\nenhances semantic binding by aggregating relevant tokens into a single\ncomposite token. This ensures that the object, its attributes and sub-objects\nall share the same cross-attention map. Additionally, to address potential\nconfusion among main objects with complex textual prompts, we propose end token\nsubstitution as a complementary strategy. To further refine our approach in the\ninitial stages of T2I generation, where layouts are determined, we incorporate\ntwo auxiliary losses, an entropy loss and a semantic binding loss, to\niteratively update the composite token to improve the generation integrity. We\nconducted extensive experiments to validate the effectiveness of ToMe,\ncomparing it against various existing methods on the T2I-CompBench and our\nproposed GPT-4o object binding benchmark. Our method is particularly effective\nin complex scenarios that involve multiple objects and attributes, which\nprevious methods often fail to address. The code will be publicly available at\n\\url{https://github.com/hutaihang/ToMe}.\n","authors":["Taihang Hu","Linxuan Li","Joost van de Weijer","Hongcheng Gao","Fahad Shahbaz Khan","Jian Yang","Ming-Ming Cheng","Kai Wang","Yaxing Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07132v1.pdf","comment":"Accepted by Neurips2024"},{"id":"http://arxiv.org/abs/2411.07126v1","updated":"2024-11-11T16:58:31Z","published":"2024-11-11T16:58:31Z","title":"Edify Image: High-Quality Image Generation with Pixel Space Laplacian\n  Diffusion Models","summary":"  We introduce Edify Image, a family of diffusion models capable of generating\nphotorealistic image content with pixel-perfect accuracy. Edify Image utilizes\ncascaded pixel-space diffusion models trained using a novel Laplacian diffusion\nprocess, in which image signals at different frequency bands are attenuated at\nvarying rates. Edify Image supports a wide range of applications, including\ntext-to-image synthesis, 4K upsampling, ControlNets, 360 HDR panorama\ngeneration, and finetuning for image customization.\n","authors":[" NVIDIA"," :","Yuval Atzmon","Maciej Bala","Yogesh Balaji","Tiffany Cai","Yin Cui","Jiaojiao Fan","Yunhao Ge","Siddharth Gururani","Jacob Huffman","Ronald Isaac","Pooya Jannaty","Tero Karras","Grace Lam","J. P. Lewis","Aaron Licata","Yen-Chen Lin","Ming-Yu Liu","Qianli Ma","Arun Mallya","Ashlee Martino-Tarr","Doug Mendez","Seungjun Nah","Chris Pruett","Fitsum Reda","Jiaming Song","Ting-Chun Wang","Fangyin Wei","Xiaohui Zeng","Yu Zeng","Qinsheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07121v1","updated":"2024-11-11T16:51:17Z","published":"2024-11-11T16:51:17Z","title":"Decoding Visual Experience and Mapping Semantics through Whole-Brain\n  Analysis Using fMRI Foundation Models","summary":"  Neural decoding, the process of understanding how brain activity corresponds\nto different stimuli, has been a primary objective in cognitive sciences. Over\nthe past three decades, advancements in functional Magnetic Resonance Imaging\nand machine learning have greatly improved our ability to map visual stimuli to\nbrain activity, especially in the visual cortex. Concurrently, research has\nexpanded into decoding more complex processes like language and memory across\nthe whole brain, utilizing techniques to handle greater variability and improve\nsignal accuracy. We argue that \"seeing\" involves more than just mapping visual\nstimuli onto the visual cortex; it engages the entire brain, as various\nemotions and cognitive states can emerge from observing different scenes. In\nthis paper, we develop algorithms to enhance our understanding of visual\nprocesses by incorporating whole-brain activation maps while individuals are\nexposed to visual stimuli. We utilize large-scale fMRI encoders and Image\ngenerative models pre-trained on large public datasets, which are then\nfine-tuned through Image-fMRI contrastive learning. Our models hence can decode\nvisual experience across the entire cerebral cortex, surpassing the traditional\nconfines of the visual cortex. We first compare our method with\nstate-of-the-art approaches to decoding visual processing and show improved\npredictive semantic accuracy by 43%. A network ablation analysis suggests that\nbeyond the visual cortex, the default mode network contributes most to decoding\nstimuli, in line with the proposed role of this network in sense-making and\nsemantic processing. Additionally, we implemented zero-shot imagination\ndecoding on an extra validation dataset, achieving a p-value of 0.0206 for\nmapping the reconstructed images and ground-truth text stimuli, which\nsubstantiates the model's capability to capture semantic meanings across\nvarious scenarios.\n","authors":["Yanchen Wang","Adam Turnbull","Tiange Xiang","Yunlong Xu","Sa Zhou","Adnan Masoud","Shekoofeh Azizi","Feng Vankee Lin","Ehsan Adeli"],"pdf_url":"https://arxiv.org/pdf/2411.07121v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07118v1","updated":"2024-11-11T16:45:18Z","published":"2024-11-11T16:45:18Z","title":"ConvMixFormer- A Resource-efficient Convolution Mixer for\n  Transformer-based Dynamic Hand Gesture Recognition","summary":"  Transformer models have demonstrated remarkable success in many domains such\nas natural language processing (NLP) and computer vision. With the growing\ninterest in transformer-based architectures, they are now utilized for gesture\nrecognition. So, we also explore and devise a novel ConvMixFormer architecture\nfor dynamic hand gestures. The transformers use quadratic scaling of the\nattention features with the sequential data, due to which these models are\ncomputationally complex and heavy. We have considered this drawback of the\ntransformer and designed a resource-efficient model that replaces the\nself-attention in the transformer with the simple convolutional layer-based\ntoken mixer. The computational cost and the parameters used for the\nconvolution-based mixer are comparatively less than the quadratic\nself-attention. Convolution-mixer helps the model capture the local spatial\nfeatures that self-attention struggles to capture due to their sequential\nprocessing nature. Further, an efficient gate mechanism is employed instead of\na conventional feed-forward network in the transformer to help the model\ncontrol the flow of features within different stages of the proposed model.\nThis design uses fewer learnable parameters which is nearly half the vanilla\ntransformer that helps in fast and efficient training. The proposed method is\nevaluated on NVidia Dynamic Hand Gesture and Briareo datasets and our model has\nachieved state-of-the-art results on single and multimodal inputs. We have also\nshown the parameter efficiency of the proposed ConvMixFormer model compared to\nother methods. The source code is available at\nhttps://github.com/mallikagarg/ConvMixFormer.\n","authors":["Mallika Garg","Debashis Ghosh","Pyari Mohan Pradhan"],"pdf_url":"https://arxiv.org/pdf/2411.07118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08129v2","updated":"2024-11-11T16:44:58Z","published":"2024-10-10T17:14:16Z","title":"Efficient Perspective-Correct 3D Gaussian Splatting Using Hybrid\n  Transparency","summary":"  3D Gaussian Splats (3DGS) have proven a versatile rendering primitive, both\nfor inverse rendering as well as real-time exploration of scenes. In these\napplications, coherence across camera frames and multiple views is crucial, be\nit for robust convergence of a scene reconstruction or for artifact-free\nfly-throughs. Recent work started mitigating artifacts that break multi-view\ncoherence, including popping artifacts due to inconsistent transparency sorting\nand perspective-correct outlines of (2D) splats. At the same time, real-time\nrequirements forced such implementations to accept compromises in how\ntransparency of large assemblies of 3D Gaussians is resolved, in turn breaking\ncoherence in other ways. In our work, we aim at achieving maximum coherence, by\nrendering fully perspective-correct 3D Gaussians while using a high-quality\napproximation of accurate blending, hybrid transparency, on a per-pixel level,\nin order to retain real-time frame rates. Our fast and perspectively accurate\napproach for evaluation of 3D Gaussians does not require matrix inversions,\nthereby ensuring numerical stability and eliminating the need for special\nhandling of degenerate splats, and the hybrid transparency formulation for\nblending maintains similar quality as fully resolved per-pixel transparencies\nat a fraction of the rendering costs. We further show that each of these two\ncomponents can be independently integrated into Gaussian splatting systems. In\ncombination, they achieve up to 2$\\times$ higher frame rates, 2$\\times$ faster\noptimization, and equal or better image quality with fewer rendering artifacts\ncompared to traditional 3DGS on common benchmarks.\n","authors":["Florian Hahlbohm","Fabian Friederichs","Tim Weyrich","Linus Franke","Moritz Kappel","Susana Castillo","Marc Stamminger","Martin Eisemann","Marcus Magnor"],"pdf_url":"https://arxiv.org/pdf/2410.08129v2.pdf","comment":"Project page: https://fhahlbohm.github.io/htgs/"},{"id":"http://arxiv.org/abs/2411.04332v2","updated":"2024-11-11T16:31:24Z","published":"2024-11-07T00:14:39Z","title":"HandCraft: Anatomically Correct Restoration of Malformed Hands in\n  Diffusion Generated Images","summary":"  Generative text-to-image models, such as Stable Diffusion, have demonstrated\na remarkable ability to generate diverse, high-quality images. However, they\nare surprisingly inept when it comes to rendering human hands, which are often\nanatomically incorrect or reside in the \"uncanny valley\". In this paper, we\npropose a method HandCraft for restoring such malformed hands. This is achieved\nby automatically constructing masks and depth images for hands as conditioning\nsignals using a parametric model, allowing a diffusion-based image editor to\nfix the hand's anatomy and adjust its pose while seamlessly integrating the\nchanges into the original image, preserving pose, color, and style. Our\nplug-and-play hand restoration solution is compatible with existing pretrained\ndiffusion models, and the restoration process facilitates adoption by eschewing\nany fine-tuning or training requirements for the diffusion models. We also\ncontribute MalHand datasets that contain generated images with a wide variety\nof malformed hands in several styles for hand detector training and hand\nrestoration benchmarking, and demonstrate through qualitative and quantitative\nevaluation that HandCraft not only restores anatomical correctness but also\nmaintains the integrity of the overall image.\n","authors":["Zhenyue Qin","Yiqun Zhang","Yang Liu","Dylan Campbell"],"pdf_url":"https://arxiv.org/pdf/2411.04332v2.pdf","comment":"Accepted by WACV 2025"},{"id":"http://arxiv.org/abs/2411.07097v1","updated":"2024-11-11T16:19:55Z","published":"2024-11-11T16:19:55Z","title":"Arctique: An artificial histopathological dataset unifying realism and\n  controllability for uncertainty quantification","summary":"  Uncertainty Quantification (UQ) is crucial for reliable image segmentation.\nYet, while the field sees continual development of novel methods, a lack of\nagreed-upon benchmarks limits their systematic comparison and evaluation:\nCurrent UQ methods are typically tested either on overly simplistic toy\ndatasets or on complex real-world datasets that do not allow to discern true\nuncertainty. To unify both controllability and complexity, we introduce\nArctique, a procedurally generated dataset modeled after histopathological\ncolon images. We chose histopathological images for two reasons: 1) their\ncomplexity in terms of intricate object structures and highly variable\nappearance, which yields challenging segmentation problems, and 2) their broad\nprevalence for medical diagnosis and respective relevance of high-quality UQ.\nTo generate Arctique, we established a Blender-based framework for 3D scene\ncreation with intrinsic noise manipulation. Arctique contains 50,000 rendered\nimages with precise masks as well as noisy label simulations. We show that by\nindependently controlling the uncertainty in both images and labels, we can\neffectively study the performance of several commonly used UQ methods. Hence,\nArctique serves as a critical resource for benchmarking and advancing UQ\ntechniques and other methodologies in complex, multi-object environments,\nbridging the gap between realism and controllability. All code is publicly\navailable, allowing re-creation and controlled manipulations of our shipped\nimages as well as creation and rendering of new scenes.\n","authors":["Jannik Franzen","Claudia Winklmayr","Vanessa E. Guarino","Christoph Karg","Xiaoyan Yu","Nora Koreuber","Jan P. Albrecht","Philip Bischoff","Dagmar Kainmueller"],"pdf_url":"https://arxiv.org/pdf/2411.07097v1.pdf","comment":"13 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.07096v1","updated":"2024-11-11T16:18:28Z","published":"2024-11-11T16:18:28Z","title":"Extreme Rotation Estimation in the Wild","summary":"  We present a technique and benchmark dataset for estimating the relative 3D\norientation between a pair of Internet images captured in an extreme setting,\nwhere the images have limited or non-overlapping field of views. Prior work\ntargeting extreme rotation estimation assume constrained 3D environments and\nemulate perspective images by cropping regions from panoramic views. However,\nreal images captured in the wild are highly diverse, exhibiting variation in\nboth appearance and camera intrinsics. In this work, we propose a\nTransformer-based method for estimating relative rotations in extreme\nreal-world settings, and contribute the ExtremeLandmarkPairs dataset, assembled\nfrom scene-level Internet photo collections. Our evaluation demonstrates that\nour approach succeeds in estimating the relative rotations in a wide variety of\nextremeview Internet image pairs, outperforming various baselines, including\ndedicated rotation estimation techniques and contemporary 3D reconstruction\nmethods.\n","authors":["Hana Bezalel","Dotan Ankri","Ruojin Cai","Hadar Averbuch-Elor"],"pdf_url":"https://arxiv.org/pdf/2411.07096v1.pdf","comment":"Project webpage:\n  https://tau-vailab.github.io/ExtremeRotationsInTheWild/"},{"id":"http://arxiv.org/abs/2408.10538v3","updated":"2024-11-11T16:08:08Z","published":"2024-08-20T04:32:50Z","title":"Surgical Workflow Recognition and Blocking Effectiveness Detection in\n  Laparoscopic Liver Resections with Pringle Maneuver","summary":"  Pringle maneuver (PM) in laparoscopic liver resection aims to reduce blood\nloss and provide a clear surgical view by intermittently blocking blood inflow\nof the liver, whereas prolonged PM may cause ischemic injury. To\ncomprehensively monitor this surgical procedure and provide timely warnings of\nineffective and prolonged blocking, we suggest two complementary AI-assisted\nsurgical monitoring tasks: workflow recognition and blocking effectiveness\ndetection in liver resections. The former presents challenges in real-time\ncapturing of short-term PM, while the latter involves the intraoperative\ndiscrimination of long-term liver ischemia states. To address these challenges,\nwe meticulously collect a novel dataset, called PmLR50, consisting of 25,037\nvideo frames covering various surgical phases from 50 laparoscopic liver\nresection procedures. Additionally, we develop an online baseline for PmLR50,\ntermed PmNet. This model embraces Masked Temporal Encoding (MTE) and Compressed\nSequence Modeling (CSM) for efficient short-term and long-term temporal\ninformation modeling, and embeds Contrastive Prototype Separation (CPS) to\nenhance action discrimination between similar intraoperative operations.\nExperimental results demonstrate that PmNet outperforms existing\nstate-of-the-art surgical workflow recognition methods on the PmLR50 benchmark.\nOur research offers potential clinical applications for the laparoscopic liver\nsurgery community. Source code and data will be publicly available.\n","authors":["Diandian Guo","Weixin Si","Zhixi Li","Jialun Pei","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2408.10538v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07076v1","updated":"2024-11-11T15:51:48Z","published":"2024-11-11T15:51:48Z","title":"StoryTeller: Improving Long Video Description through Global\n  Audio-Visual Character Identification","summary":"  Existing large vision-language models (LVLMs) are largely limited to\nprocessing short, seconds-long videos and struggle with generating coherent\ndescriptions for extended video spanning minutes or more. Long video\ndescription introduces new challenges, such as plot-level consistency across\ndescriptions. To address these, we figure out audio-visual character\nidentification, matching character names to each dialogue, as a key factor. We\npropose StoryTeller, a system for generating dense descriptions of long videos,\nincorporating both low-level visual concepts and high-level plot information.\nStoryTeller uses a multimodal large language model that integrates visual,\naudio, and text modalities to perform audio-visual character identification on\nminute-long video clips. The results are then fed into a LVLM to enhance\nconsistency of video description. We validate our approach on movie description\ntasks and introduce MovieStory101, a dataset with dense descriptions for\nthree-minute movie clips. To evaluate long video descriptions, we create\nMovieQA, a large set of multiple-choice questions for the MovieStory101 test\nset. We assess descriptions by inputting them into GPT-4 to answer these\nquestions, using accuracy as an automatic evaluation metric. Experiments show\nthat StoryTeller outperforms all open and closed-source baselines on MovieQA,\nachieving 9.5% higher accuracy than the strongest baseline, Gemini-1.5-pro, and\ndemonstrating a +15.56% advantage in human side-by-side evaluations.\nAdditionally, incorporating audio-visual character identification from\nStoryTeller improves the performance of all video description models, with\nGemini-1.5-pro and GPT-4o showing relative improvement of 5.5% and 13.0%,\nrespectively, in accuracy on MovieQA.\n","authors":["Yichen He","Yuan Lin","Jianchao Wu","Hanchong Zhang","Yuchen Zhang","Ruicheng Le"],"pdf_url":"https://arxiv.org/pdf/2411.07076v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.14537v3","updated":"2024-11-11T15:49:16Z","published":"2023-03-25T19:03:57Z","title":"Deep Augmentation: Self-Supervised Learning with Transformations in\n  Activation Space","summary":"  We introduce Deep Augmentation, an approach to implicit data augmentation\nusing dropout or PCA to transform a targeted layer within a neural network to\nimprove performance and generalization. We demonstrate Deep Augmentation\nthrough extensive experiments on contrastive learning tasks in NLP, computer\nvision, and graph learning. We observe substantial performance gains with\nTransformers, ResNets, and Graph Neural Networks as the underlying models in\ncontrastive learning, but observe inverse effects on the corresponding\nsupervised problems. Our analysis suggests that Deep Augmentation alleviates\nco-adaptation between layers, a problem exhibited by self-supervised learning\nwhere ground truth labels are not available. We use this observation to\nformulate a method for selecting which layer to target; in particular, our\nexperimentation reveals that targeting deeper layers with Deep Augmentation\noutperforms augmenting the input data. The simple network- and\nmodality-agnostic nature of this approach enables its integration into various\nmachine learning pipelines.\n","authors":["Rickard Brüel-Gabrielsson","Tongzhou Wang","Manel Baradad","Justin Solomon"],"pdf_url":"https://arxiv.org/pdf/2303.14537v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07074v1","updated":"2024-11-11T15:48:11Z","published":"2024-11-11T15:48:11Z","title":"Increasing Rosacea Awareness Among Population Using Deep Learning and\n  Statistical Approaches","summary":"  Approximately 16 million Americans suffer from rosacea according to the\nNational Rosacea Society. To increase rosacea awareness, automatic rosacea\ndetection methods using deep learning and explainable statistical approaches\nare presented in this paper. The deep learning method applies the ResNet-18 for\nrosacea detection, and the statistical approaches utilize the means of the two\nclasses, namely, the rosacea class vs. the normal class, and the principal\ncomponent analysis to extract features from the facial images for automatic\nrosacea detection. The contributions of the proposed methods are three-fold.\nFirst, the proposed methods are able to automatically distinguish patients who\nare suffering from rosacea from people who are clean of this disease. Second,\nthe statistical approaches address the explainability issue that allows doctors\nand patients to understand and trust the results. And finally, the proposed\nmethods will not only help increase rosacea awareness in the general population\nbut also help remind the patients who suffer from this disease of possible\nearly treatment since rosacea is more treatable at its early stages. The code\nand data are available at https://github.com/cyang322/rosacea_detection.git.\n","authors":["Chengyu Yang","Chengjun Liu"],"pdf_url":"https://arxiv.org/pdf/2411.07074v1.pdf","comment":"Accepted to 2024 International Conference on Medical Imaging and\n  Computer-Aided Diagnosis"},{"id":"http://arxiv.org/abs/2411.07072v1","updated":"2024-11-11T15:47:25Z","published":"2024-11-11T15:47:25Z","title":"An Interpretable X-ray Style Transfer via Trainable Local Laplacian\n  Filter","summary":"  Radiologists have preferred visual impressions or 'styles' of X-ray images\nthat are manually adjusted to their needs to support their diagnostic\nperformance. In this work, we propose an automatic and interpretable X-ray\nstyle transfer by introducing a trainable version of the Local Laplacian Filter\n(LLF). From the shape of the LLF's optimized remap function, the\ncharacteristics of the style transfer can be inferred and reliability of the\nalgorithm can be ensured. Moreover, we enable the LLF to capture complex X-ray\nstyle features by replacing the remap function with a Multi-Layer Perceptron\n(MLP) and adding a trainable normalization layer. We demonstrate the\neffectiveness of the proposed method by transforming unprocessed mammographic\nX-ray images into images that match the style of target mammograms and achieve\na Structural Similarity Index (SSIM) of 0.94 compared to 0.82 of the baseline\nLLF style transfer method from Aubry et al.\n","authors":["Dominik Eckert","Ludwig Ritschl","Christopher Syben","Christian Hümmer","Julia Wicklein","Marcel Beister","Steffen Kappler","Sebastian Stober"],"pdf_url":"https://arxiv.org/pdf/2411.07072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.14807v2","updated":"2024-11-11T15:32:25Z","published":"2024-01-26T12:11:04Z","title":"PL-FSCIL: Harnessing the Power of Prompts for Few-Shot Class-Incremental\n  Learning","summary":"  Few-Shot Class-Incremental Learning (FSCIL) aims to enable deep neural\nnetworks to learn new tasks incrementally from a small number of labeled\nsamples without forgetting previously learned tasks, closely mimicking human\nlearning patterns. In this paper, we propose a novel approach called Prompt\nLearning for FSCIL (PL-FSCIL), which harnesses the power of prompts in\nconjunction with a pre-trained Vision Transformer (ViT) model to address the\nchallenges of FSCIL effectively. Our work pioneers the use of visual prompts in\nFSCIL, which is characterized by its notable simplicity. PL-FSCIL consists of\ntwo distinct prompts: the Domain Prompt and the FSCIL Prompt. Both are vectors\nthat augment the model by embedding themselves into the attention layer of the\nViT model. Specifically, the Domain Prompt assists the ViT model in adapting to\nnew data domains. The task-specific FSCIL Prompt, coupled with a prototype\nclassifier, amplifies the model's ability to effectively handle FSCIL tasks. We\nvalidate the efficacy of PL-FSCIL on widely used benchmark datasets such as\nCIFAR-100 and CUB-200. The results showcase competitive performance,\nunderscoring its promising potential for real-world applications where\nhigh-quality data is often scarce. The source code is available at:\nhttps://github.com/TianSongS/PL-FSCIL.\n","authors":["Songsong Tian","Lusi Li","Weijun Li","Hang Ran","Li Li","Xin Ning"],"pdf_url":"https://arxiv.org/pdf/2401.14807v2.pdf","comment":"Some key content in the article needs to be improved and perfected"},{"id":"http://arxiv.org/abs/2311.13682v2","updated":"2024-11-11T15:31:02Z","published":"2023-11-22T20:31:33Z","title":"Single-Shot Plug-and-Play Methods for Inverse Problems","summary":"  The utilisation of Plug-and-Play (PnP) priors in inverse problems has become\nincreasingly prominent in recent years. This preference is based on the\nmathematical equivalence between the general proximal operator and the\nregularised denoiser, facilitating the adaptation of various off-the-shelf\ndenoiser priors to a wide range of inverse problems. However, existing PnP\nmodels predominantly rely on pre-trained denoisers using large datasets. In\nthis work, we introduce Single-Shot PnP methods (SS-PnP), shifting the focus to\nsolving inverse problems with minimal data. First, we integrate Single-Shot\nproximal denoisers into iterative methods, enabling training with single\ninstances. Second, we propose implicit neural priors based on a novel function\nthat preserves relevant frequencies to capture fine details while avoiding the\nissue of vanishing gradients. We demonstrate, through extensive numerical and\nvisual experiments, that our method leads to better approximations.\n","authors":["Yanqi Cheng","Lipei Zhang","Zhenda Shen","Shujun Wang","Lequan Yu","Raymond H. Chan","Carola-Bibiane Schönlieb","Angelica I Aviles-Rivero"],"pdf_url":"https://arxiv.org/pdf/2311.13682v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04865v3","updated":"2024-11-11T15:08:49Z","published":"2024-11-07T16:58:18Z","title":"ZAHA: Introducing the Level of Facade Generalization and the Large-Scale\n  Point Cloud Facade Semantic Segmentation Benchmark Dataset","summary":"  Facade semantic segmentation is a long-standing challenge in photogrammetry\nand computer vision. Although the last decades have witnessed the influx of\nfacade segmentation methods, there is a lack of comprehensive facade classes\nand data covering the architectural variability. In ZAHA, we introduce Level of\nFacade Generalization (LoFG), novel hierarchical facade classes designed based\non international urban modeling standards, ensuring compatibility with\nreal-world challenging classes and uniform methods' comparison. Realizing the\nLoFG, we present to date the largest semantic 3D facade segmentation dataset,\nproviding 601 million annotated points at five and 15 classes of LoFG2 and\nLoFG3, respectively. Moreover, we analyze the performance of baseline semantic\nsegmentation methods on our introduced LoFG classes and data, complementing it\nwith a discussion on the unresolved challenges for facade segmentation. We\nfirmly believe that ZAHA shall facilitate further development of 3D facade\nsemantic segmentation methods, enabling robust segmentation indispensable in\ncreating urban digital twins.\n","authors":["Olaf Wysocki","Yue Tan","Thomas Froech","Yan Xia","Magdalena Wysocki","Ludwig Hoegner","Daniel Cremers","Christoph Holst"],"pdf_url":"https://arxiv.org/pdf/2411.04865v3.pdf","comment":"Accepted to WACV 2025 (IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV))"},{"id":"http://arxiv.org/abs/2407.07462v2","updated":"2024-11-11T14:59:22Z","published":"2024-07-10T08:32:26Z","title":"MAN TruckScenes: A multimodal dataset for autonomous trucking in diverse\n  conditions","summary":"  Autonomous trucking is a promising technology that can greatly impact modern\nlogistics and the environment. Ensuring its safety on public roads is one of\nthe main duties that requires an accurate perception of the environment. To\nachieve this, machine learning methods rely on large datasets, but to this day,\nno such datasets are available for autonomous trucks. In this work, we present\nMAN TruckScenes, the first multimodal dataset for autonomous trucking. MAN\nTruckScenes allows the research community to come into contact with\ntruck-specific challenges, such as trailer occlusions, novel sensor\nperspectives, and terminal environments for the first time. It comprises more\nthan 740 scenes of 20s each within a multitude of different environmental\nconditions. The sensor set includes 4 cameras, 6 lidar, 6 radar sensors, 2\nIMUs, and a high-precision GNSS. The dataset's 3D bounding boxes were manually\nannotated and carefully reviewed to achieve a high quality standard. Bounding\nboxes are available for 27 object classes, 15 attributes, and a range of more\nthan 230m. The scenes are tagged according to 34 distinct scene tags, and all\nobjects are tracked throughout the scene to promote a wide range of\napplications. Additionally, MAN TruckScenes is the first dataset to provide 4D\nradar data with 360{\\deg} coverage and is thereby the largest radar dataset\nwith annotated 3D bounding boxes. Finally, we provide extensive dataset\nanalysis and baseline results. The dataset, development kit, and more are\navailable online.\n","authors":["Felix Fent","Fabian Kuttenreich","Florian Ruch","Farija Rizwin","Stefan Juergens","Lorenz Lechermann","Christian Nissler","Andrea Perl","Ulrich Voll","Min Yan","Markus Lienkamp"],"pdf_url":"https://arxiv.org/pdf/2407.07462v2.pdf","comment":"Accepted to NeurIPS 2024 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2411.07039v1","updated":"2024-11-11T14:45:47Z","published":"2024-11-11T14:45:47Z","title":"Learning Collective Dynamics of Multi-Agent Systems using Event-based\n  Vision","summary":"  This paper proposes a novel problem: vision-based perception to learn and\npredict the collective dynamics of multi-agent systems, specifically focusing\non interaction strength and convergence time. Multi-agent systems are defined\nas collections of more than ten interacting agents that exhibit complex group\nbehaviors. Unlike prior studies that assume knowledge of agent positions, we\nfocus on deep learning models to directly predict collective dynamics from\nvisual data, captured as frames or events. Due to the lack of relevant\ndatasets, we create a simulated dataset using a state-of-the-art flocking\nsimulator, coupled with a vision-to-event conversion framework. We empirically\ndemonstrate the effectiveness of event-based representation over traditional\nframe-based methods in predicting these collective behaviors. Based on our\nanalysis, we present event-based vision for Multi-Agent dynamic Prediction\n(evMAP), a deep learning architecture designed for real-time, accurate\nunderstanding of interaction strength and collective behavior emergence in\nmulti-agent systems.\n","authors":["Minah Lee","Uday Kamal","Saibal Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2411.07039v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05747v2","updated":"2024-11-11T14:33:25Z","published":"2024-11-08T18:08:33Z","title":"WavShadow: Wavelet Based Shadow Segmentation and Removal","summary":"  Shadow removal and segmentation remain challenging tasks in computer vision,\nparticularly in complex real world scenarios. This study presents a novel\napproach that enhances the ShadowFormer model by incorporating Masked\nAutoencoder (MAE) priors and Fast Fourier Convolution (FFC) blocks, leading to\nsignificantly faster convergence and improved performance. We introduce key\ninnovations: (1) integration of MAE priors trained on Places2 dataset for\nbetter context understanding, (2) adoption of Haar wavelet features for\nenhanced edge detection and multiscale analysis, and (3) implementation of a\nmodified SAM Adapter for robust shadow segmentation. Extensive experiments on\nthe challenging DESOBA dataset demonstrate that our approach achieves state of\nthe art results, with notable improvements in both convergence speed and shadow\nremoval quality.\n","authors":["Shreyans Jain","Aadya Arora","Viraj Vekaria","Karan Gandhi"],"pdf_url":"https://arxiv.org/pdf/2411.05747v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07025v1","updated":"2024-11-11T14:30:35Z","published":"2024-11-11T14:30:35Z","title":"Scaling Mesh Generation via Compressive Tokenization","summary":"  We propose a compressive yet effective mesh representation, Blocked and\nPatchified Tokenization (BPT), facilitating the generation of meshes exceeding\n8k faces. BPT compresses mesh sequences by employing block-wise indexing and\npatch aggregation, reducing their length by approximately 75\\% compared to the\noriginal sequences. This compression milestone unlocks the potential to utilize\nmesh data with significantly more faces, thereby enhancing detail richness and\nimproving generation robustness. Empowered with the BPT, we have built a\nfoundation mesh generative model training on scaled mesh data to support\nflexible control for point clouds and images. Our model demonstrates the\ncapability to generate meshes with intricate details and accurate topology,\nachieving SoTA performance on mesh generation and reaching the level for direct\nproduct usage.\n","authors":["Haohan Weng","Zibo Zhao","Biwen Lei","Xianghui Yang","Jian Liu","Zeqiang Lai","Zhuo Chen","Yuhong Liu","Jie Jiang","Chunchao Guo","Tong Zhang","Shenghua Gao","C. L. Philip Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07025v1.pdf","comment":"Homepage: https://whaohan.github.io/bpt , Code:\n  https://github.com/whaohan/bpt"},{"id":"http://arxiv.org/abs/2411.05219v2","updated":"2024-11-11T14:17:13Z","published":"2024-11-07T22:29:05Z","title":"Anticipatory Understanding of Resilient Agriculture to Climate","summary":"  With billions of people facing moderate or severe food insecurity, the\nresilience of the global food supply will be of increasing concern due to the\neffects of climate change and geopolitical events. In this paper we describe a\nframework to better identify food security hotspots using a combination of\nremote sensing, deep learning, crop yield modeling, and causal modeling of the\nfood distribution system. While we feel that the methods are adaptable to other\nregions of the world, we focus our analysis on the wheat breadbasket of\nnorthern India, which supplies a large percentage of the world's population. We\npresent a quantitative analysis of deep learning domain adaptation methods for\nwheat farm identification based on curated remote sensing data from France. We\nmodel climate change impacts on crop yields using the existing crop yield\nmodeling tool WOFOST and we identify key drivers of crop simulation error using\na longitudinal penalized functional regression. A description of a system\ndynamics model of the food distribution system in India is also presented,\nalong with results of food insecurity identification based on seeding this\nmodel with the predicted crop yields.\n","authors":["David Willmes","Nick Krall","James Tanis","Zachary Terner","Fernando Tavares","Chris Miller","Joe Haberlin III","Matt Crichton","Alexander Schlichting"],"pdf_url":"https://arxiv.org/pdf/2411.05219v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.19197v2","updated":"2024-11-11T14:04:57Z","published":"2024-02-29T14:26:46Z","title":"Fine Structure-Aware Sampling: A New Sampling Training Scheme for\n  Pixel-Aligned Implicit Models in Single-View Human Reconstruction","summary":"  Pixel-aligned implicit models, such as PIFu, PIFuHD, and ICON, are used for\nsingle-view clothed human reconstruction. These models need to be trained using\na sampling training scheme. Existing sampling training schemes either fail to\ncapture thin surfaces (e.g. ears, fingers) or cause noisy artefacts in\nreconstructed meshes. To address these problems, we introduce Fine\nStructured-Aware Sampling (FSS), a new sampling training scheme to train\npixel-aligned implicit models for single-view human reconstruction. FSS\nresolves the aforementioned problems by proactively adapting to the thickness\nand complexity of surfaces. In addition, unlike existing sampling training\nschemes, FSS shows how normals of sample points can be capitalized in the\ntraining process to improve results. Lastly, to further improve the training\nprocess, FSS proposes a mesh thickness loss signal for pixel-aligned implicit\nmodels. It becomes computationally feasible to introduce this loss once a\nslight reworking of the pixel-aligned implicit function framework is carried\nout. Our results show that our methods significantly outperform SOTA methods\nqualitatively and quantitatively. Our code is publicly available at\nhttps://github.com/kcyt/FSS.\n","authors":["Kennard Yanting Chan","Fayao Liu","Guosheng Lin","Chuan Sheng Foo","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2402.19197v2.pdf","comment":"Accepted in Proceedings of the AAAI Conference on Artificial\n  Intelligence, 2024 (AAAI 2024)"},{"id":"http://arxiv.org/abs/2210.11456v4","updated":"2024-11-11T14:00:40Z","published":"2022-10-20T17:54:03Z","title":"MixMask: Revisiting Masking Strategy for Siamese ConvNets","summary":"  The recent progress in self-supervised learning has successfully combined\nMasked Image Modeling (MIM) with Siamese Networks, harnessing the strengths of\nboth methodologies. Nonetheless, certain challenges persist when integrating\nconventional erase-based masking within Siamese ConvNets. Two primary concerns\nare: (1) The continuous data processing nature of ConvNets, which doesn't allow\nfor the exclusion of non-informative masked regions, leading to reduced\ntraining efficiency compared to ViT architecture; (2) The misalignment between\nerase-based masking and the contrastive-based objective, distinguishing it from\nthe MIM technique. To address these challenges, this work introduces a novel\nfilling-based masking approach, termed \\textbf{MixMask}. The proposed method\nreplaces erased areas with content from a different image, effectively\ncountering the information depletion seen in traditional masking methods.\nAdditionally, we unveil an adaptive loss function that captures the semantics\nof the newly patched views, ensuring seamless integration within the\narchitectural framework. We empirically validate the effectiveness of our\napproach through comprehensive experiments across various datasets and\napplication scenarios. The findings underscore our framework's enhanced\nperformance in areas such as linear probing, semi-supervised and supervised\nfinetuning, object detection and segmentation. Notably, our method surpasses\nthe MSCN, establishing MixMask as a more advantageous masking solution for\nSiamese ConvNets. Our code and models are publicly available at\nhttps://github.com/kirill-vish/MixMask.\n","authors":["Kirill Vishniakov","Eric Xing","Zhiqiang Shen"],"pdf_url":"https://arxiv.org/pdf/2210.11456v4.pdf","comment":"Technical report. Code is available at\n  https://github.com/kirill-vish/MixMask"},{"id":"http://arxiv.org/abs/2409.16209v2","updated":"2024-11-11T13:56:30Z","published":"2024-09-24T16:09:29Z","title":"LLMCount: Enhancing Stationary mmWave Detection with Multimodal-LLM","summary":"  Millimeter wave sensing provides people with the capability of sensing the\nsurrounding crowds in a non-invasive and privacy-preserving manner, which holds\nhuge application potential. However, detecting stationary crowds remains\nchallenging due to several factors such as minimal movements (like breathing or\ncasual fidgets), which can be easily treated as noise clusters during data\ncollection and consequently filtered in the following processing procedures.\nAdditionally, the uneven distribution of signal power due to signal power\nattenuation and interferences resulting from external reflectors or absorbers\nfurther complicates accurate detection. To address these challenges and enable\nstationary crowd detection across various application scenarios requiring\nspecialized domain adaption, we introduce LLMCount, the first system to harness\nthe capabilities of large-language models (LLMs) to enhance crowd detection\nperformance. By exploiting the decision-making capability of LLM, we can\nsuccessfully compensate the signal power to acquire a uniform distribution and\nthereby achieve a detection with higher accuracy. To assess the system's\nperformance, comprehensive evaluations are conducted under diversified\nscenarios like hall, meeting room, and cinema. The evaluation results show that\nour proposed approach reaches high detection accuracy with lower overall\nlatency compared with previous methods.\n","authors":["Boyan Li","Shengyi Ding","Deen Ma","Yixuan Wu","Hongjie Liao","Kaiyuan Hu"],"pdf_url":"https://arxiv.org/pdf/2409.16209v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06991v1","updated":"2024-11-11T13:49:29Z","published":"2024-11-11T13:49:29Z","title":"SIESEF-FusionNet: Spatial Inter-correlation Enhancement and\n  Spatially-Embedded Feature Fusion Network for LiDAR Point Cloud Semantic\n  Segmentation","summary":"  The ambiguity at the boundaries of different semantic classes in point cloud\nsemantic segmentation often leads to incorrect decisions in intelligent\nperception systems, such as autonomous driving. Hence, accurate delineation of\nthe boundaries is crucial for improving safety in autonomous driving. A novel\nspatial inter-correlation enhancement and spatially-embedded feature fusion\nnetwork (SIESEF-FusionNet) is proposed in this paper, enhancing spatial\ninter-correlation by combining inverse distance weighting and angular\ncompensation to extract more beneficial spatial information without causing\nredundancy. Meanwhile, a new spatial adaptive pooling module is also designed,\nembedding enhanced spatial information into semantic features for strengthening\nthe context-awareness of semantic features. Experimental results demonstrate\nthat 83.7% mIoU and 97.8% OA are achieved by SIESEF-FusionNet on the Toronto3D\ndataset, with performance superior to other baseline methods. A value of 61.1%\nmIoU is reached on the semanticKITTI dataset, where a marked improvement in\nsegmentation performance is observed. In addition, the effectiveness and\nplug-and-play capability of the proposed modules are further verified through\nablation studies.\n","authors":["Jiale Chen","Fei Xia","Jianliang Mao","Haoping Wang","Chuanlin Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06991v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2407.17827v2","updated":"2024-11-11T13:46:50Z","published":"2024-07-25T07:35:27Z","title":"Unified Lexical Representation for Interpretable Visual-Language\n  Alignment","summary":"  Visual-Language Alignment (VLA) has gained a lot of attention since CLIP's\ngroundbreaking work. Although CLIP performs well, the typical direct latent\nfeature alignment lacks clarity in its representation and similarity scores. On\nthe other hand, lexical representation, a vector whose element represents the\nsimilarity between the sample and a word from the vocabulary, is a natural\nsparse representation and interpretable, providing exact matches for individual\nwords. However, lexical representations are difficult to learn due to no\nground-truth supervision and false-discovery issues, and thus requires complex\ndesign to train effectively. In this paper, we introduce LexVLA, a more\ninterpretable VLA framework by learning a unified lexical representation for\nboth modalities without complex design. We use DINOv2 as our visual model for\nits local-inclined features and Llama 2, a generative language model, to\nleverage its in-context lexical prediction ability. To avoid the false\ndiscovery, we propose an overuse penalty to refrain the lexical representation\nfrom falsely frequently activating meaningless words. We demonstrate that these\ntwo pre-trained uni-modal models can be well-aligned by fine-tuning on the\nmodest multi-modal dataset and avoid intricate training configurations. On\ncross-modal retrieval benchmarks, LexVLA, trained on the CC-12M multi-modal\ndataset, outperforms baselines fine-tuned on larger datasets (e.g., YFCC15M)\nand those trained from scratch on even bigger datasets (e.g., 1.1B data,\nincluding CC-12M). We conduct extensive experiments to analyze LexVLA. Codes\nare available at https://github.com/Clementine24/LexVLA.\n","authors":["Yifan Li","Yikai Wang","Yanwei Fu","Dongyu Ru","Zheng Zhang","Tong He"],"pdf_url":"https://arxiv.org/pdf/2407.17827v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.06976v1","updated":"2024-11-11T13:34:24Z","published":"2024-11-11T13:34:24Z","title":"A Hierarchical Compression Technique for 3D Gaussian Splatting\n  Compression","summary":"  3D Gaussian Splatting (GS) demonstrates excellent rendering quality and\ngeneration speed in novel view synthesis. However, substantial data size poses\nchallenges for storage and transmission, making 3D GS compression an essential\ntechnology. Current 3D GS compression research primarily focuses on developing\nmore compact scene representations, such as converting explicit 3D GS data into\nimplicit forms. In contrast, compression of the GS data itself has hardly been\nexplored. To address this gap, we propose a Hierarchical GS Compression (HGSC)\ntechnique. Initially, we prune unimportant Gaussians based on importance scores\nderived from both global and local significance, effectively reducing\nredundancy while maintaining visual quality. An Octree structure is used to\ncompress 3D positions. Based on the 3D GS Octree, we implement a hierarchical\nattribute compression strategy by employing a KD-tree to partition the 3D GS\ninto multiple blocks. We apply farthest point sampling to select anchor\nprimitives within each block and others as non-anchor primitives with varying\nLevels of Details (LoDs). Anchor primitives serve as reference points for\npredicting non-anchor primitives across different LoDs to reduce spatial\nredundancy. For anchor primitives, we use the region adaptive hierarchical\ntransform to achieve near-lossless compression of various attributes. For\nnon-anchor primitives, each is predicted based on the k-nearest anchor\nprimitives. To further minimize prediction errors, the reconstructed LoD and\nanchor primitives are combined to form new anchor primitives to predict the\nnext LoD. Our method notably achieves superior compression quality and a\nsignificant data size reduction of over 4.5 times compared to the\nstate-of-the-art compression method on small scenes datasets.\n","authors":["He Huang","Wenjie Huang","Qi Yang","Yiling Xu","Zhu li"],"pdf_url":"https://arxiv.org/pdf/2411.06976v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07955v3","updated":"2024-11-11T13:32:00Z","published":"2022-11-15T07:41:00Z","title":"IntegratedPIFu: Integrated Pixel Aligned Implicit Function for\n  Single-view Human Reconstruction","summary":"  We propose IntegratedPIFu, a new pixel aligned implicit model that builds on\nthe foundation set by PIFuHD. IntegratedPIFu shows how depth and human parsing\ninformation can be predicted and capitalised upon in a pixel-aligned implicit\nmodel. In addition, IntegratedPIFu introduces depth oriented sampling, a novel\ntraining scheme that improve any pixel aligned implicit model ability to\nreconstruct important human features without noisy artefacts. Lastly,\nIntegratedPIFu presents a new architecture that, despite using less model\nparameters than PIFuHD, is able to improves the structural correctness of\nreconstructed meshes. Our results show that IntegratedPIFu significantly\noutperforms existing state of the arts methods on single view human\nreconstruction. Our code has been made available online.\n","authors":["Kennard Yanting Chan","Guosheng Lin","Haiyu Zhao","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2211.07955v3.pdf","comment":"Accepted to ECCV 2022"},{"id":"http://arxiv.org/abs/2411.04925v2","updated":"2024-11-11T13:24:18Z","published":"2024-11-07T18:00:33Z","title":"StoryAgent: Customized Storytelling Video Generation via Multi-Agent\n  Collaboration","summary":"  The advent of AI-Generated Content (AIGC) has spurred research into automated\nvideo generation to streamline conventional processes. However, automating\nstorytelling video production, particularly for customized narratives, remains\nchallenging due to the complexity of maintaining subject consistency across\nshots. While existing approaches like Mora and AesopAgent integrate multiple\nagents for Story-to-Video (S2V) generation, they fall short in preserving\nprotagonist consistency and supporting Customized Storytelling Video Generation\n(CSVG). To address these limitations, we propose StoryAgent, a multi-agent\nframework designed for CSVG. StoryAgent decomposes CSVG into distinct subtasks\nassigned to specialized agents, mirroring the professional production process.\nNotably, our framework includes agents for story design, storyboard generation,\nvideo creation, agent coordination, and result evaluation. Leveraging the\nstrengths of different models, StoryAgent enhances control over the generation\nprocess, significantly improving character consistency. Specifically, we\nintroduce a customized Image-to-Video (I2V) method, LoRA-BE, to enhance\nintra-shot temporal consistency, while a novel storyboard generation pipeline\nis proposed to maintain subject consistency across shots. Extensive experiments\ndemonstrate the effectiveness of our approach in synthesizing highly consistent\nstorytelling videos, outperforming state-of-the-art methods. Our contributions\ninclude the introduction of StoryAgent, a versatile framework for video\ngeneration tasks, and novel techniques for preserving protagonist consistency.\n","authors":["Panwen Hu","Jin Jiang","Jianqi Chen","Mingfei Han","Shengcai Liao","Xiaojun Chang","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2411.04925v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06971v1","updated":"2024-11-11T13:18:45Z","published":"2024-11-11T13:18:45Z","title":"MapSAM: Adapting Segment Anything Model for Automated Feature Detection\n  in Historical Maps","summary":"  Automated feature detection in historical maps can significantly accelerate\nthe reconstruction of the geospatial past. However, this process is often\nconstrained by the time-consuming task of manually digitizing sufficient\nhigh-quality training data. The emergence of visual foundation models, such as\nthe Segment Anything Model (SAM), offers a promising solution due to their\nremarkable generalization capabilities and rapid adaptation to new data\ndistributions. Despite this, directly applying SAM in a zero-shot manner to\nhistorical map segmentation poses significant challenges, including poor\nrecognition of certain geospatial features and a reliance on input prompts,\nwhich limits its ability to be fully automated. To address these challenges, we\nintroduce MapSAM, a parameter-efficient fine-tuning strategy that adapts SAM\ninto a prompt-free and versatile solution for various downstream historical map\nsegmentation tasks. Specifically, we employ Weight-Decomposed Low-Rank\nAdaptation (DoRA) to integrate domain-specific knowledge into the image\nencoder. Additionally, we develop an automatic prompt generation process,\neliminating the need for manual input. We further enhance the positional prompt\nin SAM, transforming it into a higher-level positional-semantic prompt, and\nmodify the cross-attention mechanism in the mask decoder with masked attention\nfor more effective feature aggregation. The proposed MapSAM framework\ndemonstrates promising performance across two distinct historical map\nsegmentation tasks: one focused on linear features and the other on areal\nfeatures. Experimental results show that it adapts well to various features,\neven when fine-tuned with extremely limited data (e.g. 10 shots).\n","authors":["Xue Xia","Daiwei Zhang","Wenxuan Song","Wei Huang","Lorenz Hurni"],"pdf_url":"https://arxiv.org/pdf/2411.06971v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06969v1","updated":"2024-11-11T13:17:55Z","published":"2024-11-11T13:17:55Z","title":"A Hyperspectral Imaging Dataset and Methodology for Intraoperative\n  Pixel-Wise Classification of Metastatic Colon Cancer in the Liver","summary":"  Hyperspectral imaging (HSI) holds significant potential for transforming the\nfield of computational pathology. However, there is currently a shortage of\npixel-wise annotated HSI data necessary for training deep learning (DL) models.\nAdditionally, the number of HSI-based research studies remains limited, and in\nmany cases, the advantages of HSI over traditional RGB imaging have not been\nconclusively demonstrated, particularly for specimens collected\nintraoperatively. To address these challenges we present a database consisted\nof 27 HSIs of hematoxylin-eosin stained frozen sections, collected from 14\npatients with colon adenocarcinoma metastasized to the liver. It is aimed to\nvalidate pixel-wise classification for intraoperative tumor resection. The HSIs\nwere acquired in the spectral range of 450 to 800 nm, with a resolution of 1\nnm, resulting in images of 1384x1035 pixels. Pixel-wise annotations were\nperformed by three pathologists. To overcome challenges such as experimental\nvariability and the lack of annotated data, we combined label-propagation-based\nsemi-supervised learning (SSL) with spectral-spatial features extracted by: the\nmultiscale principle of relevant information (MPRI) method and tensor singular\nspectrum analysis method. Using only 1% of labeled pixels per class the\nSSL-MPRI method achieved a micro balanced accuracy (BACC) of 0.9313 and a micro\nF1-score of 0.9235 on the HSI dataset. The performance on corresponding RGB\nimages was lower, with a micro BACC of 0.8809 and a micro F1-score of 0.8688.\nThese improvements are statistically significant. The SSL-MPRI approach\noutperformed six DL architectures trained with 63% of labeled pixels. Data and\ncode are available at: https://github.com/ikopriva/ColonCancerHSI.\n","authors":["Ivica Kopriva","Dario Sitnik","Laura-Isabelle Dion-Bertrand","Marija Milković Periša","Mirko Hadžija","Marijana Popović Hadžija"],"pdf_url":"https://arxiv.org/pdf/2411.06969v1.pdf","comment":"12 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2411.06966v1","updated":"2024-11-11T13:13:39Z","published":"2024-11-11T13:13:39Z","title":"Robust Fine-tuning of Zero-shot Models via Variance Reduction","summary":"  When fine-tuning zero-shot models like CLIP, our desideratum is for the\nfine-tuned model to excel in both in-distribution (ID) and out-of-distribution\n(OOD). Recently, ensemble-based models (ESM) have been shown to offer\nsignificant robustness improvement, while preserving high ID accuracy. However,\nour study finds that ESMs do not solve the ID-OOD trade-offs: they achieve peak\nperformance for ID and OOD accuracy at different mixing coefficients. When\noptimized for OOD accuracy, the ensemble model exhibits a noticeable decline in\nID accuracy, and vice versa. In contrast, we propose a sample-wise ensembling\ntechnique that can simultaneously attain the best ID and OOD accuracy without\nthe trade-offs. Specifically, we construct a Zero-Shot Failure (ZSF) set\ncontaining training samples incorrectly predicted by the zero-shot model. For\neach test sample, we calculate its distance to the ZSF set and assign a higher\nweight to the fine-tuned model in the ensemble if the distance is small. We\nterm our method Variance Reduction Fine-tuning (VRF), as it effectively reduces\nthe variance in ensemble predictions, thereby decreasing residual error. On\nImageNet and five derived distribution shifts, our VRF further improves the OOD\naccuracy by 1.5 - 2.0 pp over the ensemble baselines while maintaining or\nincreasing ID accuracy. VRF achieves similar large robustness gains (0.9 - 3.1\npp) on other distribution shifts benchmarks. Codes are available in\nhttps://github.com/BeierZhu/VRF.\n","authors":["Beier Zhu","Jiequan Cui","Hanwang Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06966v1.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.06959v1","updated":"2024-11-11T13:05:39Z","published":"2024-11-11T13:05:39Z","title":"ENAT: Rethinking Spatial-temporal Interactions in Token-based Image\n  Synthesis","summary":"  Recently, token-based generation have demonstrated their effectiveness in\nimage synthesis. As a representative example, non-autoregressive Transformers\n(NATs) can generate decent-quality images in a few steps. NATs perform\ngeneration in a progressive manner, where the latent tokens of a resulting\nimage are incrementally revealed. At each step, the unrevealed image regions\nare padded with mask tokens and inferred by NAT. In this paper, we delve into\nthe mechanisms behind the effectiveness of NATs and uncover two important\npatterns that naturally emerge from NATs: Spatially (within a step), although\nmask and visible tokens are processed uniformly by NATs, the interactions\nbetween them are highly asymmetric. In specific, mask tokens mainly gather\ninformation for decoding, while visible tokens tend to primarily provide\ninformation, and their deep representations can be built only upon themselves.\nTemporally (across steps), the interactions between adjacent generation steps\nmostly concentrate on updating the representations of a few critical tokens,\nwhile the computation for the majority of tokens is generally repetitive.\nDriven by these findings, we propose EfficientNAT (ENAT), a NAT model that\nexplicitly encourages these critical interactions inherent in NATs. At the\nspatial level, we disentangle the computations of visible and mask tokens by\nencoding visible tokens independently, while decoding mask tokens conditioned\non the fully encoded visible tokens. At the temporal level, we prioritize the\ncomputation of the critical tokens at each step, while maximally reusing\npreviously computed token representations to supplement necessary information.\nENAT improves the performance of NATs notably with significantly reduced\ncomputational cost. Experiments on ImageNet-256, ImageNet-512 and MS-COCO\nvalidate the effectiveness of ENAT. Code is available at\nhttps://github.com/LeapLabTHU/ENAT.\n","authors":["Zanlin Ni","Yulin Wang","Renping Zhou","Yizeng Han","Jiayi Guo","Zhiyuan Liu","Yuan Yao","Gao Huang"],"pdf_url":"https://arxiv.org/pdf/2411.06959v1.pdf","comment":"Accepted by NeurIPS2024"},{"id":"http://arxiv.org/abs/2407.08680v4","updated":"2024-11-11T12:59:13Z","published":"2024-07-11T17:13:15Z","title":"Generalizable Implicit Motion Modeling for Video Frame Interpolation","summary":"  Motion modeling is critical in flow-based Video Frame Interpolation (VFI).\nExisting paradigms either consider linear combinations of bidirectional flows\nor directly predict bilateral flows for given timestamps without exploring\nfavorable motion priors, thus lacking the capability of effectively modeling\nspatiotemporal dynamics in real-world videos. To address this limitation, in\nthis study, we introduce Generalizable Implicit Motion Modeling (GIMM), a novel\nand effective approach to motion modeling for VFI. Specifically, to enable GIMM\nas an effective motion modeling paradigm, we design a motion encoding pipeline\nto model spatiotemporal motion latent from bidirectional flows extracted from\npre-trained flow estimators, effectively representing input-specific motion\npriors. Then, we implicitly predict arbitrary-timestep optical flows within two\nadjacent input frames via an adaptive coordinate-based neural network, with\nspatiotemporal coordinates and motion latent as inputs. Our GIMM can be easily\nintegrated with existing flow-based VFI works by supplying accurately modeled\nmotion. We show that GIMM performs better than the current state of the art on\nstandard VFI benchmarks.\n","authors":["Zujin Guo","Wei Li","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2407.08680v4.pdf","comment":"Project Page: https://gseancdat.github.io/projects/GIMMVFI"},{"id":"http://arxiv.org/abs/2409.18055v2","updated":"2024-11-11T12:56:11Z","published":"2024-09-26T16:59:01Z","title":"Visual Data Diagnosis and Debiasing with Concept Graphs","summary":"  The widespread success of deep learning models today is owed to the curation\nof extensive datasets significant in size and complexity. However, such models\nfrequently pick up inherent biases in the data during the training process,\nleading to unreliable predictions. Diagnosing and debiasing datasets is thus a\nnecessity to ensure reliable model performance. In this paper, we present\nConBias, a novel framework for diagnosing and mitigating Concept co-occurrence\nBiases in visual datasets. ConBias represents visual datasets as knowledge\ngraphs of concepts, enabling meticulous analysis of spurious concept\nco-occurrences to uncover concept imbalances across the whole dataset.\nMoreover, we show that by employing a novel clique-based concept balancing\nstrategy, we can mitigate these imbalances, leading to enhanced performance on\ndownstream tasks. Extensive experiments show that data augmentation based on a\nbalanced concept distribution augmented by Conbias improves generalization\nperformance across multiple datasets compared to state-of-the-art methods.\n","authors":["Rwiddhi Chakraborty","Yinong Wang","Jialu Gao","Runkai Zheng","Cheng Zhang","Fernando De la Torre"],"pdf_url":"https://arxiv.org/pdf/2409.18055v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02346v2","updated":"2024-11-11T12:54:35Z","published":"2023-06-04T12:42:45Z","title":"Concept Drift and Long-Tailed Distribution in Fine-Grained Visual\n  Categorization: Benchmark and Method","summary":"  Data is the foundation for the development of computer vision, and the\nestablishment of datasets plays an important role in advancing the techniques\nof fine-grained visual categorization~(FGVC). In the existing FGVC datasets\nused in computer vision, it is generally assumed that each collected instance\nhas fixed characteristics and the distribution of different categories is\nrelatively balanced. In contrast, the real world scenario reveals the fact that\nthe characteristics of instances tend to vary with time and exhibit a\nlong-tailed distribution. Hence, the collected datasets may mislead the\noptimization of the fine-grained classifiers, resulting in unpleasant\nperformance in real applications. Starting from the real-world conditions and\nto promote the practical progress of fine-grained visual categorization, we\npresent a Concept Drift and Long-Tailed Distribution dataset. Specifically, the\ndataset is collected by gathering 11195 images of 250 instances in different\nspecies for 47 consecutive months in their natural contexts. The collection\nprocess involves dozens of crowd workers for photographing and domain experts\nfor labeling. Meanwhile, we propose a feature recombination framework to\naddress the learning challenges associated with CDLT. Experimental results\nvalidate the efficacy of our method while also highlighting the limitations of\npopular large vision-language models (e.g., CLIP) in the context of long-tailed\ndistributions. This emphasizes the significance of CDLT as a benchmark for\ninvestigating these challenges.\n","authors":["Shuo Ye","Shiming Chen","Ruxin Wang","Tianxu Wu","Jiamiao Xu","Salman Khan","Fahad Shahbaz Khan","Ling Shao"],"pdf_url":"https://arxiv.org/pdf/2306.02346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06921v1","updated":"2024-11-11T12:25:02Z","published":"2024-11-11T12:25:02Z","title":"UMFC: Unsupervised Multi-Domain Feature Calibration for Vision-Language\n  Models","summary":"  Pre-trained vision-language models (e.g., CLIP) have shown powerful zero-shot\ntransfer capabilities. But they still struggle with domain shifts and typically\nrequire labeled data to adapt to downstream tasks, which could be costly. In\nthis work, we aim to leverage unlabeled data that naturally spans multiple\ndomains to enhance the transferability of vision-language models. Under this\nunsupervised multi-domain setting, we have identified inherent model bias\nwithin CLIP, notably in its visual and text encoders. Specifically, we observe\nthat CLIP's visual encoder tends to prioritize encoding domain over\ndiscriminative category information, meanwhile its text encoder exhibits a\npreference for domain-relevant classes. To mitigate this model bias, we propose\na training-free and label-free feature calibration method, Unsupervised\nMulti-domain Feature Calibration (UMFC). UMFC estimates image-level biases from\ndomain-specific features and text-level biases from the direction of domain\ntransition. These biases are subsequently subtracted from original image and\ntext features separately, to render them domain-invariant. We evaluate our\nmethod on multiple settings including transductive learning and test-time\nadaptation. Extensive experiments show that our method outperforms CLIP and\nperforms on par with the state-of-the-arts that need additional annotations or\noptimization. Our code is available at https://github.com/GIT-LJc/UMFC.\n","authors":["Jiachen Liang","Ruibing Hou","Minyang Hu","Hong Chang","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2411.06921v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.06916v1","updated":"2024-11-11T12:19:28Z","published":"2024-11-11T12:19:28Z","title":"Slowing Down Forgetting in Continual Learning","summary":"  A common challenge in continual learning (CL) is catastrophic forgetting,\nwhere the performance on old tasks drops after new, additional tasks are\nlearned. In this paper, we propose a novel framework called ReCL to slow down\nforgetting in CL. Our framework exploits an implicit bias of gradient-based\nneural networks due to which these converge to margin maximization points. Such\nconvergence points allow us to reconstruct old data from previous tasks, which\nwe then combine with the current training data. Our framework is flexible and\ncan be applied on top of existing, state-of-the-art CL methods to slow down\nforgetting. We further demonstrate the performance gain from our framework\nacross a large series of experiments, including different CL scenarios (class\nincremental, domain incremental, task incremental learning) different datasets\n(MNIST, CIFAR10), and different network architectures. Across all experiments,\nwe find large performance gains through ReCL. To the best of our knowledge, our\nframework is the first to address catastrophic forgetting by leveraging models\nin CL as their own memory buffers.\n","authors":["Pascal Janetzky","Tobias Schlagenhauf","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2411.06916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06911v1","updated":"2024-11-11T12:13:58Z","published":"2024-11-11T12:13:58Z","title":"Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI","summary":"  Segmentation of cardiac magnetic resonance images (MRI) is crucial for the\nanalysis and assessment of cardiac function, helping to diagnose and treat\nvarious cardiovascular diseases. Most recent techniques rely on deep learning\nand usually require an extensive amount of labeled data. To overcome this\nproblem, few-shot learning has the capability of reducing data dependency on\nlabeled data. In this work, we introduce a new method that merges few-shot\nlearning with a U-Net architecture and Gaussian Process Emulators (GPEs),\nenhancing data integration from a support set for improved performance. GPEs\nare trained to learn the relation between the support images and the\ncorresponding masks in latent space, facilitating the segmentation of unseen\nquery images given only a small labeled support set at inference. We test our\nmodel with the M&Ms-2 public dataset to assess its ability to segment the heart\nin cardiac magnetic resonance imaging from different orientations, and compare\nit with state-of-the-art unsupervised and few-shot methods. Our architecture\nshows higher DICE coefficients compared to these methods, especially in the\nmore challenging setups where the size of the support set is considerably\nsmall.\n","authors":["Bruno Viti","Franz Thaler","Kathrin Lisa Kapper","Martin Urschler","Martin Holler","Elias Karabelas"],"pdf_url":"https://arxiv.org/pdf/2411.06911v1.pdf","comment":"Submitted to Statistical Atlases and Computational Modeling of the\n  Heart (STACOM) 2024"},{"id":"http://arxiv.org/abs/2402.02090v2","updated":"2024-11-11T12:11:40Z","published":"2024-02-03T09:02:46Z","title":"All-weather Multi-Modality Image Fusion: Unified Framework and 100k\n  Benchmark","summary":"  Multi-modality image fusion (MMIF) combines complementary information from\ndifferent image modalities to provide a more comprehensive and objective\ninterpretation of scenes. However, existing MMIF methods lack the ability to\nresist different weather interferences in real-world scenes, preventing them\nfrom being useful in practical applications such as autonomous driving. To\nbridge this research gap, we proposed an all-weather MMIF model. Achieving\neffective multi-tasking in this context is particularly challenging due to the\ncomplex and diverse nature of weather conditions. A key obstacle lies in the\n'black box' nature of current deep learning architectures, which restricts\ntheir multi-tasking capabilities. To overcome this, we decompose the network\ninto two modules: a fusion module and a restoration module. For the fusion\nmodule, we introduce a learnable low-rank representation model to decompose\nimages into low-rank and sparse components. This interpretable feature\nseparation allows us to better observe and understand images. For the\nrestoration module, we propose a physically-aware clear feature prediction\nmodule based on an atmospheric scattering model that can deduce variations in\nlight transmittance from both scene illumination and reflectance. We also\nconstruct a large-scale multi-modality dataset with 100,000 image pairs across\nrain, haze, and snow conditions, covering various degradation levels and\ndiverse scenes to thoroughly evaluate image fusion methods in adverse weather.\nExperimental results in both real-world and synthetic scenes show that the\nproposed algorithm excels in detail recovery and multi-modality feature\nextraction. The code is available at https://github.com/ixilai/AWFusion.\n","authors":["Xilai Li","Wuyang Liu","Xiaosong Li","Fuqiang Zhou","Huafeng Li","Feiping Nie"],"pdf_url":"https://arxiv.org/pdf/2402.02090v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06908v1","updated":"2024-11-11T12:11:36Z","published":"2024-11-11T12:11:36Z","title":"EVQAScore: Efficient Video Question Answering Data Evaluation","summary":"  Video question-answering (QA) is a core task in video understanding.\nEvaluating the quality of video QA and video caption data quality for training\nvideo large language models (VideoLLMs) is an essential challenge. Although\nvarious methods have been proposed for assessing video caption quality, there\nremains a lack of dedicated evaluation methods for Video QA. To address this\ngap, we introduce EVQAScore, a reference-free method that leverages keyword\nextraction to assess both video caption and video QA data quality.\nAdditionally, we incorporate frame sampling and rescaling techniques to enhance\nthe efficiency and robustness of our evaluation, this enables our score to\nevaluate the quality of extremely long videos. Our approach achieves\nstate-of-the-art (SOTA) performance (32.8 for Kendall correlation and 42.3 for\nSpearman correlation, 4.7 and 5.9 higher than the previous method PAC-S++) on\nthe VATEX-EVAL benchmark for video caption evaluation. Furthermore, by using\nEVQAScore for data selection, we achieved SOTA results with only 12.5\\% of the\noriginal data volume, outperforming the previous SOTA method PAC-S and 100\\% of\ndata.\n","authors":["Hao Liang","Zirong Chen","Wentao Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06896v1","updated":"2024-11-11T11:55:14Z","published":"2024-11-11T11:55:14Z","title":"BuckTales : A multi-UAV dataset for multi-object tracking and\n  re-identification of wild antelopes","summary":"  Understanding animal behaviour is central to predicting, understanding, and\nmitigating impacts of natural and anthropogenic changes on animal populations\nand ecosystems. However, the challenges of acquiring and processing long-term,\necologically relevant data in wild settings have constrained the scope of\nbehavioural research. The increasing availability of Unmanned Aerial Vehicles\n(UAVs), coupled with advances in machine learning, has opened new opportunities\nfor wildlife monitoring using aerial tracking. However, limited availability of\ndatasets with wild animals in natural habitats has hindered progress in\nautomated computer vision solutions for long-term animal tracking. Here we\nintroduce BuckTales, the first large-scale UAV dataset designed to solve\nmulti-object tracking (MOT) and re-identification (Re-ID) problem in wild\nanimals, specifically the mating behaviour (or lekking) of blackbuck antelopes.\nCollected in collaboration with biologists, the MOT dataset includes over 1.2\nmillion annotations including 680 tracks across 12 high-resolution (5.4K)\nvideos, each averaging 66 seconds and featuring 30 to 130 individuals. The\nRe-ID dataset includes 730 individuals captured with two UAVs simultaneously.\nThe dataset is designed to drive scalable, long-term animal behaviour tracking\nusing multiple camera sensors. By providing baseline performance with two\ndetectors, and benchmarking several state-of-the-art tracking methods, our\ndataset reflects the real-world challenges of tracking wild animals in socially\nand ecologically relevant contexts. In making these data widely available, we\nhope to catalyze progress in MOT and Re-ID for wild animals, fostering insights\ninto animal behaviour, conservation efforts, and ecosystem dynamics through\nautomated, long-term monitoring.\n","authors":["Hemal Naik","Junran Yang","Dipin Das","Margaret C Crofoot","Akanksha Rathore","Vivek Hari Sridhar"],"pdf_url":"https://arxiv.org/pdf/2411.06896v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.06893v1","updated":"2024-11-11T11:49:18Z","published":"2024-11-11T11:49:18Z","title":"Multi-scale Frequency Enhancement Network for Blind Image Deblurring","summary":"  Image deblurring is an essential image preprocessing technique, aiming to\nrecover clear and detailed images form blurry ones. However, existing\nalgorithms often fail to effectively integrate multi-scale feature extraction\nwith frequency enhancement, limiting their ability to reconstruct fine\ntextures. Additionally, non-uniform blur in images also restricts the\neffectiveness of image restoration. To address these issues, we propose a\nmulti-scale frequency enhancement network (MFENet) for blind image deblurring.\nTo capture the multi-scale spatial and channel information of blurred images,\nwe introduce a multi-scale feature extraction module (MS-FE) based on depthwise\nseparable convolutions, which provides rich target features for deblurring. We\npropose a frequency enhanced blur perception module (FEBP) that employs wavelet\ntransforms to extract high-frequency details and utilizes multi-strip pooling\nto perceive non-uniform blur, combining multi-scale information with frequency\nenhancement to improve the restoration of image texture details. Experimental\nresults on the GoPro and HIDE datasets demonstrate that the proposed method\nachieves superior deblurring performance in both visual quality and objective\nevaluation metrics. Furthermore, in downstream object detection tasks, the\nproposed blind image deblurring algorithm significantly improves detection\naccuracy, further validating its effectiveness androbustness in the field of\nimage deblurring.\n","authors":["Yawen Xiang","Heng Zhou","Chengyang Li","Zhongbo Li","Yongqiang Xie"],"pdf_url":"https://arxiv.org/pdf/2411.06893v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02564v2","updated":"2024-11-11T11:46:16Z","published":"2024-11-04T19:55:32Z","title":"Continual LLaVA: Continual Instruction Tuning in Large Vision-Language\n  Models","summary":"  Instruction tuning constitutes a prevalent technique for tailoring Large\nVision Language Models (LVLMs) to meet individual task requirements. To date,\nmost of the existing approaches are confined to single-task adaptation, whereas\nthe requirements in real-world scenarios are inherently varied and continually\nevolving. Thus an ideal LVLM should sustain continual instruction tuning in the\nface of stream-task distributions (i.e., different domains, emerging\ncapabilities, and new datasets) while minimizing the forgetting of previously\nacquired knowledge. To achieve this, we propose a new benchmark for COntinuAl\ninStruction Tuning on LVLMs (COAST), which encompasses the aforementioned\ndomain-incremental, capability-incremental, and dataset-incremental\nconfigurations. In terms of methodology, we propose Continual LLaVA, a\nrehearsal-free method tailored for continual instruction tuning in LVLMs. To\ncircumvent the additional overhead associated with experience replay, we freeze\nLVLMs and construct the dual increment embeddings for each input instruction to\nfacilitate parameter-efficient tuning. Specifically, the increment embeddings\ncan be decomposed into two principal components: 1) intrinsic increment\nembeddings to encode task-specific characteristics. To achieve this, we set up\na low-rank pool containing candidate embeddings, from which we select the\nrelevant ones based on their similarity with the user instructions; 2)\ncontextual increment embeddings to investigate the inter-dependencies across\ntasks. In this regard, the low-rank embeddings chosen in the previous tasks are\naggregated via learnable weighted sum to provide complementary hints. Extensive\nexperiments indicate that the proposed Continual LLaVA outperforms previous\nmethods by significantly reducing the forgetting during the continual\ninstruction tuning process.\n","authors":["Meng Cao","Yuyang Liu","Yingfei Liu","Tiancai Wang","Jiahua Dong","Henghui Ding","Xiangyu Zhang","Ian Reid","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2411.02564v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.16798v2","updated":"2024-11-11T11:41:13Z","published":"2023-06-29T09:17:58Z","title":"Evaluation of Environmental Conditions on Object Detection using\n  Oriented Bounding Boxes for AR Applications","summary":"  The objective of augmented reality (AR) is to add digital content to natural\nimages and videos to create an interactive experience between the user and the\nenvironment. Scene analysis and object recognition play a crucial role in AR,\nas they must be performed quickly and accurately. In this study, a new approach\nis proposed that involves using oriented bounding boxes with a detection and\nrecognition deep network to improve performance and processing time. The\napproach is evaluated using two datasets: a real image dataset (DOTA dataset)\ncommonly used for computer vision tasks, and a synthetic dataset that simulates\ndifferent environmental, lighting, and acquisition conditions. The focus of the\nevaluation is on small objects, which are difficult to detect and recognise.\nThe results indicate that the proposed approach tends to produce better Average\nPrecision and greater accuracy for small objects in most of the tested\nconditions.\n","authors":["Vladislav Li","Barbara Villarini","Jean-Christophe Nebel","Thomas Lagkas","Panagiotis Sarigiannidis","Vasileios Argyriou"],"pdf_url":"https://arxiv.org/pdf/2306.16798v2.pdf","comment":"11 pages, 4 figures, conference"},{"id":"http://arxiv.org/abs/2411.06879v1","updated":"2024-11-11T11:23:43Z","published":"2024-11-11T11:23:43Z","title":"Classification of residential and non-residential buildings based on\n  satellite data using deep learning","summary":"  Accurate classification of buildings into residential and non-residential\ncategories is crucial for urban planning, infrastructure development,\npopulation estimation and resource allocation. It is a complex job to carry out\nautomatic classification of residential and nonresidential buildings manually\nusing satellite data. In this paper, we are proposing a novel deep learning\napproach that combines high-resolution satellite data (50 cm resolution Image +\n1m grid interval DEM) and vector data to achieve high-performance building\nclassification. Our architecture leverages LeakyReLU and ReLU activations to\ncapture nonlinearities in the data and employs feature-engineering techniques\nto eliminate highly correlated features, resulting in improved computational\nefficiency. Experimental results on a large-scale dataset demonstrate the\neffectiveness of our model, achieving an impressive overall F1 -score of\n0.9936. The proposed approach offers a scalable and accurate solution for\nbuilding classification, enabling informed decision-making in urban planning\nand resource allocation. This research contributes to the field of urban\nanalysis by providing a valuable tool for understanding the built environment\nand optimizing resource utilization.\n","authors":["Jai G Singla"],"pdf_url":"https://arxiv.org/pdf/2411.06879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06872v1","updated":"2024-11-11T11:12:23Z","published":"2024-11-11T11:12:23Z","title":"Multi-Modal interpretable automatic video captioning","summary":"  Video captioning aims to describe video contents using natural language\nformat that involves understanding and interpreting scenes, actions and events\nthat occurs simultaneously on the view. Current approaches have mainly\nconcentrated on visual cues, often neglecting the rich information available\nfrom other important modality of audio information, including their\ninter-dependencies. In this work, we introduce a novel video captioning method\ntrained with multi-modal contrastive loss that emphasizes both multi-modal\nintegration and interpretability. Our approach is designed to capture the\ndependency between these modalities, resulting in more accurate, thus pertinent\ncaptions. Furthermore, we highlight the importance of interpretability,\nemploying multiple attention mechanisms that provide explanation into the\nmodel's decision-making process. Our experimental results demonstrate that our\nproposed method performs favorably against the state-of the-art models on\ncommonly used benchmark datasets of MSR-VTT and VATEX.\n","authors":["Antoine Hanna-Asaad","Decky Aspandi","Titus Zaharia"],"pdf_url":"https://arxiv.org/pdf/2411.06872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06869v1","updated":"2024-11-11T11:08:26Z","published":"2024-11-11T11:08:26Z","title":"CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal\n  Large Language Models","summary":"  Category-agnostic pose estimation (CAPE) has traditionally relied on support\nimages with annotated keypoints, a process that is often cumbersome and may\nfail to fully capture the necessary correspondences across diverse object\ncategories. Recent efforts have begun exploring the use of text-based queries,\nwhere the need for support keypoints is eliminated. However, the optimal use of\ntextual descriptions for keypoints remains an underexplored area. In this work,\nwe introduce CapeLLM, a novel approach that leverages a text-based multimodal\nlarge language model (MLLM) for CAPE. Our method only employs query image and\ndetailed text descriptions as an input to estimate category-agnostic keypoints.\nWe conduct extensive experiments to systematically explore the design space of\nLLM-based CAPE, investigating factors such as choosing the optimal description\nfor keypoints, neural network architectures, and training strategies. Thanks to\nthe advanced reasoning capabilities of the pre-trained MLLM, CapeLLM\ndemonstrates superior generalization and robust performance. Our approach sets\na new state-of-the-art on the MP-100 benchmark in the challenging 1-shot\nsetting, marking a significant advancement in the field of category-agnostic\npose estimation.\n","authors":["Junho Kim","Hyungjin Chung","Byung-Hoon Kim"],"pdf_url":"https://arxiv.org/pdf/2411.06869v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.02844v4","updated":"2024-11-11T11:05:49Z","published":"2024-07-03T06:40:26Z","title":"Exploiting Precision Mapping and Component-Specific Feature Enhancement\n  for Breast Cancer Segmentation and Identification","summary":"  Breast cancer is a leading cause of mortality worldwide, and demands the\ncritical need for early and accurate diagnostic tools. Ultrasound imaging is a\nwidely used modality for breast cancer screening, yet the precise segmentation\nand classification of tumors in these images are challenging due to variations\nin tumor morphology and image quality. To address these challenges, we propose\nnovel deep learning (DL) frameworks leveraging a precision mapping mechanism\n(PMM) along with a component-specific feature enhancement module (CSFEM) to\nimprove breast cancer lesion segmentation and identification. Our PPM ensures\nthat the segmentation accurately reflects the true shape and extent of the\ntumor by meticulously delineating their boundaries. The CSFEM focuses on\nextracting and amplifying features unique to different tumor types, enabling\nthe model to effectively distinguish between benign, malignant, and normal\ntissues. Integrating PMM and CSFEM into our segmentation model yielded an\naccuracy of 98.1%, an IoU of 96.9%, and a Dice Coefficient of 97.2%. Similarly,\nour classification model achieved an accuracy of 99.2%, with F1-score,\nprecision, and recall values of 99.1%, 99.3%, and 99.1%, respectively. Our\nresults indicate significant improvement in evaluation metrics in comparison to\nstate-of-the-art (SOTA) models, demonstrating the effectiveness of precision\nmapping and component-specific feature enhancement in advancing breast cancer\nlesion analysis.\n","authors":["Pandiyaraju V","Shravan Venkatraman","Pavan Kumar S","Santhosh Malarvannan","Kannan A"],"pdf_url":"https://arxiv.org/pdf/2407.02844v4.pdf","comment":"29 pages, 15 figures, 6 tables"},{"id":"http://arxiv.org/abs/2411.06864v1","updated":"2024-11-11T10:56:40Z","published":"2024-11-11T10:56:40Z","title":"Veri-Car: Towards Open-world Vehicle Information Retrieval","summary":"  Many industrial and service sectors require tools to extract vehicle\ncharacteristics from images. This is a complex task not only by the variety of\nnoise, and large number of classes, but also by the constant introduction of\nnew vehicle models to the market. In this paper, we present Veri-Car, an\ninformation retrieval integrated approach designed to help on this task. It\nleverages supervised learning techniques to accurately identify the make, type,\nmodel, year, color, and license plate of cars. The approach also addresses the\nchallenge of handling open-world problems, where new car models and variations\nfrequently emerge, by employing a sophisticated combination of pre-trained\nmodels, and a hierarchical multi-similarity loss. Veri-Car demonstrates robust\nperformance, achieving high precision and accuracy in classifying both seen and\nunseen data. Additionally, it integrates an ensemble license plate detection,\nand an OCR model to extract license plate numbers with impressive accuracy.\n","authors":["Andrés Muñoz","Nancy Thomas","Annita Vapsi","Daciel Borrajo"],"pdf_url":"https://arxiv.org/pdf/2411.06864v1.pdf","comment":"33 pages, 12 figures"},{"id":"http://arxiv.org/abs/2411.01781v3","updated":"2024-11-11T10:48:05Z","published":"2024-11-04T04:14:39Z","title":"MSTA3D: Multi-scale Twin-attention for 3D Instance Segmentation","summary":"  Recently, transformer-based techniques incorporating superpoints have become\nprevalent in 3D instance segmentation. However, they often encounter an\nover-segmentation problem, especially noticeable with large objects.\nAdditionally, unreliable mask predictions stemming from superpoint mask\nprediction further compound this issue. To address these challenges, we propose\na novel framework called MSTA3D. It leverages multi-scale feature\nrepresentation and introduces a twin-attention mechanism to effectively capture\nthem. Furthermore, MSTA3D integrates a box query with a box regularizer,\noffering a complementary spatial constraint alongside semantic queries.\nExperimental evaluations on ScanNetV2, ScanNet200 and S3DIS datasets\ndemonstrate that our approach surpasses state-of-the-art 3D instance\nsegmentation methods.\n","authors":["Duc Dang Trung Tran","Byeongkeun Kang","Yeejin Lee"],"pdf_url":"https://arxiv.org/pdf/2411.01781v3.pdf","comment":"14 pages, 9 figures, 7 tables, conference"},{"id":"http://arxiv.org/abs/2411.06851v1","updated":"2024-11-11T10:35:23Z","published":"2024-11-11T10:35:23Z","title":"Fast and Efficient Transformer-based Method for Bird's Eye View Instance\n  Prediction","summary":"  Accurate object detection and prediction are critical to ensure the safety\nand efficiency of self-driving architectures. Predicting object trajectories\nand occupancy enables autonomous vehicles to anticipate movements and make\ndecisions with future information, increasing their adaptability and reducing\nthe risk of accidents. Current State-Of-The-Art (SOTA) approaches often isolate\nthe detection, tracking, and prediction stages, which can lead to significant\nprediction errors due to accumulated inaccuracies between stages. Recent\nadvances have improved the feature representation of multi-camera perception\nsystems through Bird's-Eye View (BEV) transformations, boosting the development\nof end-to-end systems capable of predicting environmental elements directly\nfrom vehicle sensor data. These systems, however, often suffer from high\nprocessing times and number of parameters, creating challenges for real-world\ndeployment. To address these issues, this paper introduces a novel BEV instance\nprediction architecture based on a simplified paradigm that relies only on\ninstance segmentation and flow prediction. The proposed system prioritizes\nspeed, aiming at reduced parameter counts and inference times compared to\nexisting SOTA architectures, thanks to the incorporation of an efficient\ntransformer-based architecture. Furthermore, the implementation of the proposed\narchitecture is optimized for performance improvements in PyTorch version 2.1.\nCode and trained models are available at\nhttps://github.com/miguelag99/Efficient-Instance-Prediction\n","authors":["Miguel Antunes-García","Luis M. Bergasa","Santiago Montiel-Marín","Rafael Barea","Fabio Sánchez-García","Ángel Llamazares"],"pdf_url":"https://arxiv.org/pdf/2411.06851v1.pdf","comment":"The article has been presented in the 27th IEEE International\n  Conference on Intelligent Transportation Systems (IEEE ITSC 2024) on\n  September, 2024. Number of pages: 6, Number of figures: 4"},{"id":"http://arxiv.org/abs/2411.06842v1","updated":"2024-11-11T10:17:44Z","published":"2024-11-11T10:17:44Z","title":"Maximizing domain generalization in fetal brain tissue segmentation: the\n  role of synthetic data generation, intensity clustering and real image\n  fine-tuning","summary":"  Fetal brain tissue segmentation in magnetic resonance imaging (MRI) is a\ncrucial tool that supports the understanding of neurodevelopment, yet it faces\nchallenges due to the heterogeneity of data coming from different scanners and\nsettings, and due to data scarcity. Recent approaches based on domain\nrandomization, like SynthSeg, have shown a great potential for single source\ndomain generalization, by simulating images with randomized contrast and image\nresolution from the label maps. In this work, we investigate how to maximize\nthe out-of-domain (OOD) generalization potential of SynthSeg-based methods in\nfetal brain MRI. Specifically, when studying data generation, we demonstrate\nthat the simple Gaussian mixture models used in SynthSeg enable more robust OOD\ngeneralization than physics-informed generation methods. We also investigate\nhow intensity clustering can help create more faithful synthetic images, and\nobserve that it is key to achieving a non-trivial OOD generalization capability\nwhen few label classes are available. Finally, by combining for the first time\nSynthSeg with modern fine-tuning approaches based on weight averaging, we show\nthat fine-tuning a model pre-trained on synthetic data on a few real\nimage-segmentation pairs in a new domain can lead to improvements in the target\ndomain, but also in other domains. We summarize our findings as five key\nrecommendations that we believe can guide practitioners who would like to\ndevelop SynthSeg-based approaches in other organs or modalities.\n","authors":["Vladyslav Zalevskyi","Thomas Sanchez","Margaux Roulet","Hélène Lajous","Jordina Aviles Verdera","Jana Hutter","Hamza Kebiri","Meritxell Bach Cuadra"],"pdf_url":"https://arxiv.org/pdf/2411.06842v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22771v2","updated":"2024-11-11T10:04:26Z","published":"2024-10-30T07:40:08Z","title":"FuseAnyPart: Diffusion-Driven Facial Parts Swapping via Multiple\n  Reference Images","summary":"  Facial parts swapping aims to selectively transfer regions of interest from\nthe source image onto the target image while maintaining the rest of the target\nimage unchanged. Most studies on face swapping designed specifically for\nfull-face swapping, are either unable or significantly limited when it comes to\nswapping individual facial parts, which hinders fine-grained and customized\ncharacter designs. However, designing such an approach specifically for facial\nparts swapping is challenged by a reasonable multiple reference feature fusion,\nwhich needs to be both efficient and effective. To overcome this challenge,\nFuseAnyPart is proposed to facilitate the seamless \"fuse-any-part\"\ncustomization of the face. In FuseAnyPart, facial parts from different people\nare assembled into a complete face in latent space within the Mask-based Fusion\nModule. Subsequently, the consolidated feature is dispatched to the\nAddition-based Injection Module for fusion within the UNet of the diffusion\nmodel to create novel characters. Extensive experiments qualitatively and\nquantitatively validate the superiority and robustness of FuseAnyPart. Source\ncodes are available at https://github.com/Thomas-wyh/FuseAnyPart.\n","authors":["Zheng Yu","Yaohua Wang","Siying Cui","Aixi Zhang","Wei-Long Zheng","Senzhang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.22771v2.pdf","comment":"Accepted by the NeurIPS 2024 (Spotlight). Homepage:\n  https://thomas-wyh.github.io/"},{"id":"http://arxiv.org/abs/2405.00479v2","updated":"2024-11-11T09:59:23Z","published":"2024-05-01T12:39:35Z","title":"Enhanced Textual Feature Extraction for Visual Question Answering: A\n  Simple Convolutional Approach","summary":"  Visual Question Answering (VQA) has emerged as a highly engaging field in\nrecent years, with increasing research focused on enhancing VQA accuracy\nthrough advanced models such as Transformers. Despite this growing interest,\nlimited work has examined the comparative effectiveness of textual encoders in\nVQA, particularly considering model complexity and computational efficiency. In\nthis work, we conduct a comprehensive comparison between complex textual models\nthat leverage long-range dependencies and simpler models focusing on local\ntextual features within a well-established VQA framework. Our findings reveal\nthat employing complex textual encoders is not invariably the optimal approach\nfor the VQA-v2 dataset. Motivated by this insight, we propose ConvGRU, a model\nthat incorporates convolutional layers to improve text feature representation\nwithout substantially increasing model complexity. Tested on the VQA-v2\ndataset, ConvGRU demonstrates a modest yet consistent improvement over\nbaselines for question types such as Number and Count, which highlights the\npotential of lightweight architectures for VQA tasks, especially when\ncomputational resources are limited.\n","authors":["Zhilin Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.00479v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.10805v2","updated":"2024-11-11T09:23:38Z","published":"2023-06-19T09:48:24Z","title":"Experts' cognition-driven ensemble deep learning for external validation\n  of predicting pathological complete response to neoadjuvant chemotherapy from\n  histological images in breast cancer","summary":"  In breast cancer, neoadjuvant chemotherapy (NAC) provides a standard\ntreatment option for patients who have locally advanced cancer and some large\noperable tumors. A patient will have better prognosis when he has achieved a\npathological complete response (pCR) with the treatment of NAC. There has been\na trend to directly predict pCR to NAC from histological images based on deep\nlearning (DL). However, the DL-based predictive models numerically have better\nperformances in internal validation than in external validation. In this paper,\nwe aim to alleviate this situation with an intrinsic approach. We propose an\nexperts' cognition-driven ensemble deep learning (ECDEDL) approach. Taking the\ncognition of both pathology and artificial intelligence experts into\nconsideration to improve the generalization of the predictive model to the\nexternal validation, ECDEDL can intrinsically approximate the working paradigm\nof a human being which will refer to his various working experiences to make\ndecisions. ECDEDL was validated with 695 WSIs collected from the same center as\nthe primary dataset to develop the predictive model and perform the internal\nvalidation, and was also validated with 340 WSIs collected from other three\ncenters as the external dataset to perform the external validation. In external\nvalidation, ECDEDL improves the AUCs of pCR prediction from 61.52(59.80-63.26)\nto 67.75(66.74-68.80) and the Accuracies of pCR prediction from\n56.09(49.39-62.79) to 71.01(69.44-72.58). ECDEDL was quite effective for\nexternal validation of predicting pCR to NAC from histological images in breast\ncancer, numerically approximating the internal validation.\n","authors":["Yongquan Yang","Fengling Li","Yani Wei","Yuanyuan Zhao","Jing Fu","Xiuli Xiao","Hong Bu"],"pdf_url":"https://arxiv.org/pdf/2306.10805v2.pdf","comment":"This is the final published version"},{"id":"http://arxiv.org/abs/2411.06810v1","updated":"2024-11-11T09:11:01Z","published":"2024-11-11T09:11:01Z","title":"JPEG AI Image Compression Visual Artifacts: Detection Methods and\n  Dataset","summary":"  Learning-based image compression methods have improved in recent years and\nstarted to outperform traditional codecs. However, neural-network approaches\ncan unexpectedly introduce visual artifacts in some images. We therefore\npropose methods to separately detect three types of artifacts (texture and\nboundary degradation, color change, and text corruption), to localize the\naffected regions, and to quantify the artifact strength. We consider only those\nregions that exhibit distortion due solely to the neural compression but that a\ntraditional codec recovers successfully at a comparable bitrate. We employed\nour methods to collect artifacts for the JPEG AI verification model with\nrespect to HM-18.0, the H.265 reference software. We processed about 350,000\nunique images from the Open Images dataset using different compression-quality\nparameters; the result is a dataset of 46,440 artifacts validated through\ncrowd-sourced subjective assessment. Our proposed dataset and methods are\nvaluable for testing neural-network-based image codecs, identifying bugs in\nthese codecs, and enhancing their performance. We make source code of the\nmethods and the dataset publicly available.\n","authors":["Daria Tsereh","Mark Mirgaleev","Ivan Molodetskikh","Roman Kazantsev","Dmitriy Vatolin"],"pdf_url":"https://arxiv.org/pdf/2411.06810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04097v2","updated":"2024-11-11T09:05:15Z","published":"2024-05-07T07:57:15Z","title":"Unmasking Illusions: Understanding Human Perception of Audiovisual\n  Deepfakes","summary":"  The emergence of contemporary deepfakes has attracted significant attention\nin machine learning research, as artificial intelligence (AI) generated\nsynthetic media increases the incidence of misinterpretation and is difficult\nto distinguish from genuine content. Currently, machine learning techniques\nhave been extensively studied for automatically detecting deepfakes. However,\nhuman perception has been less explored. Malicious deepfakes could ultimately\ncause public and social problems. Can we humans correctly perceive the\nauthenticity of the content of the videos we watch? The answer is obviously\nuncertain; therefore, this paper aims to evaluate the human ability to discern\ndeepfake videos through a subjective study. We present our findings by\ncomparing human observers to five state-ofthe-art audiovisual deepfake\ndetection models. To this end, we used gamification concepts to provide 110\nparticipants (55 native English speakers and 55 non-native English speakers)\nwith a webbased platform where they could access a series of 40 videos (20 real\nand 20 fake) to determine their authenticity. Each participant performed the\nexperiment twice with the same 40 videos in different random orders. The videos\nare manually selected from the FakeAVCeleb dataset. We found that all AI models\nperformed better than humans when evaluated on the same 40 videos. The study\nalso reveals that while deception is not impossible, humans tend to\noverestimate their detection capabilities. Our experimental results may help\nbenchmark human versus machine performance, advance forensics analysis, and\nenable adaptive countermeasures.\n","authors":["Ammarah Hashmi","Sahibzada Adil Shahzad","Chia-Wen Lin","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2405.04097v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06786v1","updated":"2024-11-11T08:25:21Z","published":"2024-11-11T08:25:21Z","title":"ScaleKD: Strong Vision Transformers Could Be Excellent Teachers","summary":"  In this paper, we question if well pre-trained vision transformer (ViT)\nmodels could be used as teachers that exhibit scalable properties to advance\ncross architecture knowledge distillation (KD) research, in the context of\nusing large-scale datasets for evaluation. To make this possible, our analysis\nunderlines the importance of seeking effective strategies to align (1) feature\ncomputing paradigm differences, (2) model scale differences, and (3) knowledge\ndensity differences. By combining three coupled components namely cross\nattention projector, dual-view feature mimicking and teacher parameter\nperception tailored to address the above problems, we present a simple and\neffective KD method, called ScaleKD. Our method can train student backbones\nthat span across a variety of convolutional neural network (CNN), multi-layer\nperceptron (MLP), and ViT architectures on image classification datasets,\nachieving state-of-the-art distillation performance. For instance, taking a\nwell pre-trained Swin-L as the teacher model, our method gets\n75.15%|82.03%|84.16%|78.63%|81.96%|83.93%|83.80%|85.53% top-1 accuracies for\nMobileNet-V1|ResNet-50|ConvNeXt-T|Mixer-S/16|Mixer-B/16|ViT-S/16|Swin-T|ViT-B/16\nmodels trained on ImageNet-1K dataset from scratch, showing\n3.05%|3.39%|2.02%|4.61%|5.52%|4.03%|2.62%|3.73% absolute gains to the\nindividually trained counterparts. Intriguingly, when scaling up the size of\nteacher models or their pre-training datasets, our method showcases the desired\nscalable properties, bringing increasingly larger gains to student models. The\nstudent backbones trained by our method transfer well on downstream MS-COCO and\nADE20K datasets. More importantly, our method could be used as a more efficient\nalternative to the time-intensive pre-training paradigm for any target student\nmodel if a strong pre-trained ViT is available, reducing the amount of viewed\ntraining samples up to 195x.\n","authors":["Jiawei Fan","Chao Li","Xiaolong Liu","Anbang Yao"],"pdf_url":"https://arxiv.org/pdf/2411.06786v1.pdf","comment":"This work is accepted to NeurIPS 2024. The project page:\n  https://github.com/deep-optimization/ScaleKD"},{"id":"http://arxiv.org/abs/2411.06780v1","updated":"2024-11-11T08:18:49Z","published":"2024-11-11T08:18:49Z","title":"HSTrack: Bootstrap End-to-End Multi-Camera 3D Multi-object Tracking with\n  Hybrid Supervision","summary":"  In camera-based 3D multi-object tracking (MOT), the prevailing methods follow\nthe tracking-by-query-propagation paradigm, which employs track queries to\nmanage the lifecycle of identity-consistent tracklets while object queries\nhandle the detection of new-born tracklets. However, this intertwined paradigm\nleads the inter-temporal tracking task and the single-frame detection task\nutilize the same model parameters, complicating training optimization. Drawing\ninspiration from studies on the roles of attention components in\ntransformer-based decoders, we identify that the dispersing effect of\nself-attention necessitates object queries to match with new-born tracklets.\nThis matching strategy diverges from the detection pre-training phase, where\nobject queries align with all ground-truth targets, resulting in insufficient\nsupervision signals. To address these issues, we present HSTrack, a novel\nplug-and-play method designed to co-facilitate multi-task learning for\ndetection and tracking. HSTrack constructs a parallel weight-share decoder\ndevoid of self-attention layers, circumventing competition between different\ntypes of queries. Considering the characteristics of cross-attention layer and\ndistinct query types, our parallel decoder adopt one-to-one and one-to-many\nlabel assignment strategies for track queries and object queries, respectively.\nLeveraging the shared architecture, HSTrack further improve trackers for\nspatio-temporal modeling and quality candidates generation. Extensive\nexperiments demonstrate that HSTrack consistently delivers improvements when\nintegrated with various query-based 3D MOT trackers. For example, HSTrack\nimproves the state-of-the-art PF-Track method by $+2.3\\%$ AMOTA and $+1.7\\%$\nmAP on the nuScenes dataset.\n","authors":["Shubo Lin","Yutong Kou","Bing Li","Weiming Hu","Jin Gao"],"pdf_url":"https://arxiv.org/pdf/2411.06780v1.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.06776v1","updated":"2024-11-11T08:07:34Z","published":"2024-11-11T08:07:34Z","title":"Machine vision-aware quality metrics for compressed image and video\n  assessment","summary":"  A main goal in developing video-compression algorithms is to enhance\nhuman-perceived visual quality while maintaining file size. But modern\nvideo-analysis efforts such as detection and recognition, which are integral to\nvideo surveillance and autonomous vehicles, involve so much data that they\nnecessitate machine-vision processing with minimal human intervention. In such\ncases, the video codec must be optimized for machine vision. This paper\nexplores the effects of compression on detection and recognition algorithms\n(objects, faces, and license plates) and introduces novel full-reference\nimage/video-quality metrics for each task, tailored to machine vision.\nExperimental results indicate our proposed metrics correlate better with the\nmachine-vision results for the respective tasks than do existing\nimage/video-quality metrics.\n","authors":["Mikhail Dremin","Konstantin Kozhemyakov","Ivan Molodetskikh","Malakhov Kirill","Artur Sagitov","Dmitriy Vatolin"],"pdf_url":"https://arxiv.org/pdf/2411.06776v1.pdf","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.06764v1","updated":"2024-11-11T07:36:19Z","published":"2024-11-11T07:36:19Z","title":"Multi-Stage Knowledge Integration of Vision-Language Models for\n  Continual Learning","summary":"  Vision Language Models (VLMs), pre-trained on large-scale image-text\ndatasets, enable zero-shot predictions for unseen data but may underperform on\nspecific unseen tasks. Continual learning (CL) can help VLMs effectively adapt\nto new data distributions without joint training, but faces challenges of\ncatastrophic forgetting and generalization forgetting. Although significant\nprogress has been achieved by distillation-based methods, they exhibit two\nsevere limitations. One is the popularly adopted single-teacher paradigm fails\nto impart comprehensive knowledge, The other is the existing methods\ninadequately leverage the multimodal information in the original training\ndataset, instead they rely on additional data for distillation, which increases\ncomputational and storage overhead. To mitigate both limitations, by drawing on\nKnowledge Integration Theory (KIT), we propose a Multi-Stage Knowledge\nIntegration network (MulKI) to emulate the human learning process in\ndistillation methods. MulKI achieves this through four stages, including\nEliciting Ideas, Adding New Ideas, Distinguishing Ideas, and Making\nConnections. During the four stages, we first leverage prototypes to align\nacross modalities, eliciting cross-modal knowledge, then adding new knowledge\nby constructing fine-grained intra- and inter-modality relationships with\nprototypes. After that, knowledge from two teacher models is adaptively\ndistinguished and re-weighted. Finally, we connect between models from intra-\nand inter-task, integrating preceding and new knowledge. Our method\ndemonstrates significant improvements in maintaining zero-shot capabilities\nwhile supporting continual learning across diverse downstream tasks, showcasing\nits potential in adapting VLMs to evolving data distributions.\n","authors":["Hongsheng Zhang","Zhong Ji","Jingren Liu","Yanwei Pang","Jungong Han"],"pdf_url":"https://arxiv.org/pdf/2411.06764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06757v1","updated":"2024-11-11T07:22:31Z","published":"2024-11-11T07:22:31Z","title":"LuSh-NeRF: Lighting up and Sharpening NeRFs for Low-light Scenes","summary":"  Neural Radiance Fields (NeRFs) have shown remarkable performances in\nproducing novel-view images from high-quality scene images. However, hand-held\nlow-light photography challenges NeRFs as the captured images may\nsimultaneously suffer from low visibility, noise, and camera shakes. While\nexisting NeRF methods may handle either low light or motion, directly combining\nthem or incorporating additional image-based enhancement methods does not work\nas these degradation factors are highly coupled. We observe that noise in\nlow-light images is always sharp regardless of camera shakes, which implies an\nimplicit order of these degradation factors within the image formation process.\nTo this end, we propose in this paper a novel model, named LuSh-NeRF, which can\nreconstruct a clean and sharp NeRF from a group of hand-held low-light images.\nThe key idea of LuSh-NeRF is to sequentially model noise and blur in the images\nvia multi-view feature consistency and frequency information of NeRF,\nrespectively. Specifically, LuSh-NeRF includes a novel Scene-Noise\nDecomposition (SND) module for decoupling the noise from the scene\nrepresentation and a novel Camera Trajectory Prediction (CTP) module for the\nestimation of camera motions based on low-frequency scene information. To\nfacilitate training and evaluations, we construct a new dataset containing both\nsynthetic and real images. Experiments show that LuSh-NeRF outperforms existing\napproaches. Our code and dataset can be found here:\nhttps://github.com/quzefan/LuSh-NeRF.\n","authors":["Zefan Qu","Ke Xu","Gerhard Petrus Hancke","Rynson W. H. Lau"],"pdf_url":"https://arxiv.org/pdf/2411.06757v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.06750v1","updated":"2024-11-11T07:06:29Z","published":"2024-11-11T07:06:29Z","title":"SynStitch: a Self-Supervised Learning Network for Ultrasound Image\n  Stitching Using Synthetic Training Pairs and Indirect Supervision","summary":"  Ultrasound (US) image stitching can expand the field-of-view (FOV) by\ncombining multiple US images from varied probe positions. However, registering\nUS images with only partially overlapping anatomical contents is a challenging\ntask. In this work, we introduce SynStitch, a self-supervised framework\ndesigned for 2DUS stitching. SynStitch consists of a synthetic stitching pair\ngeneration module (SSPGM) and an image stitching module (ISM). SSPGM utilizes a\npatch-conditioned ControlNet to generate realistic 2DUS stitching pairs with\nknown affine matrix from a single input image. ISM then utilizes this synthetic\npaired data to learn 2DUS stitching in a supervised manner. Our framework was\nevaluated against multiple leading methods on a kidney ultrasound dataset,\ndemonstrating superior 2DUS stitching performance through both qualitative and\nquantitative analyses. The code will be made public upon acceptance of the\npaper.\n","authors":["Xing Yao","Runxuan Yu","Dewei Hu","Hao Yang","Ange Lou","Jiacheng Wang","Daiwei Lu","Gabriel Arenas","Baris Oguz","Alison Pouch","Nadav Schwartz","Brett C Byram","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2411.06750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04485v4","updated":"2024-11-11T06:32:24Z","published":"2024-06-06T20:15:42Z","title":"GenAI Arena: An Open Evaluation Platform for Generative Models","summary":"  Generative AI has made remarkable strides to revolutionize fields such as\nimage and video generation. These advancements are driven by innovative\nalgorithms, architecture, and data. However, the rapid proliferation of\ngenerative models has highlighted a critical gap: the absence of trustworthy\nevaluation metrics. Current automatic assessments such as FID, CLIP, FVD, etc\noften fail to capture the nuanced quality and user satisfaction associated with\ngenerative outputs. This paper proposes an open platform GenAI-Arena to\nevaluate different image and video generative models, where users can actively\nparticipate in evaluating these models. By leveraging collective user feedback\nand votes, GenAI-Arena aims to provide a more democratic and accurate measure\nof model performance. It covers three tasks of text-to-image generation,\ntext-to-video generation, and image editing respectively. Currently, we cover a\ntotal of 35 open-source generative models. GenAI-Arena has been operating for\nseven months, amassing over 9000 votes from the community. We describe our\nplatform, analyze the data, and explain the statistical methods for ranking the\nmodels. To further promote the research in building model-based evaluation\nmetrics, we release a cleaned version of our preference data for the three\ntasks, namely GenAI-Bench. We prompt the existing multi-modal models like\nGemini, and GPT-4o to mimic human voting. We compute the accuracy by comparing\nthe model voting with the human voting to understand their judging abilities.\nOur results show existing multimodal models are still lagging in assessing the\ngenerated visual content, even the best model GPT-4o only achieves an average\naccuracy of 49.19 across the three generative tasks. Open-source MLLMs perform\neven worse due to the lack of instruction-following and reasoning ability in\ncomplex vision scenarios.\n","authors":["Dongfu Jiang","Max Ku","Tianle Li","Yuansheng Ni","Shizhuo Sun","Rongqi Fan","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2406.04485v4.pdf","comment":"9 pages,7 figures"},{"id":"http://arxiv.org/abs/2409.04025v2","updated":"2024-11-11T06:23:21Z","published":"2024-09-06T04:44:52Z","title":"BFA-YOLO: A balanced multiscale object detection network for building\n  façade attachments detection","summary":"  The detection of fa\\c{c}ade elements on buildings, such as doors, windows,\nbalconies, air conditioning units, billboards, and glass curtain walls, is a\ncritical step in automating the creation of Building Information Modeling\n(BIM). Yet, this field faces significant challenges, including the uneven\ndistribution of fa\\c{c}ade elements, the presence of small objects, and\nsubstantial background noise, which hamper detection accuracy. To address these\nissues, we develop the BFA-YOLO model and the BFA-3D dataset in this study. The\nBFA-YOLO model is an advanced architecture designed specifically for analyzing\nmulti-view images of fa\\c{c}ade attachments. It integrates three novel\ncomponents: the Feature Balanced Spindle Module (FBSM) that tackles the issue\nof uneven object distribution; the Target Dynamic Alignment Task Detection Head\n(TDATH) that enhances the detection of small objects; and the Position Memory\nEnhanced Self-Attention Mechanism (PMESA), aimed at reducing the impact of\nbackground noise. These elements collectively enable BFA-YOLO to effectively\naddress each challenge, thereby improving model robustness and detection\nprecision. The BFA-3D dataset, offers multi-view images with precise\nannotations across a wide range of fa\\c{c}ade attachment categories. This\ndataset is developed to address the limitations present in existing fa\\c{c}ade\ndetection datasets, which often feature a single perspective and insufficient\ncategory coverage. Through comparative analysis, BFA-YOLO demonstrated\nimprovements of 1.8\\% and 2.9\\% in mAP$_{50}$ on the BFA-3D dataset and the\npublic Fa\\c{c}ade-WHU dataset, respectively, when compared to the baseline\nYOLOv8 model. These results highlight the superior performance of BFA-YOLO in\nfa\\c{c}ade element detection and the advancement of intelligent BIM\ntechnologies.\n","authors":["Yangguang Chen","Tong Wang","Guanzhou Chen","Kun Zhu","Xiaoliang Tan","Jiaqi Wang","Wenchao Guo","Qing Wang","Xiaolong Luo","Xiaodong Zhang"],"pdf_url":"https://arxiv.org/pdf/2409.04025v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2407.13517v3","updated":"2024-11-11T06:04:50Z","published":"2024-07-18T13:48:52Z","title":"Mask2Map: Vectorized HD Map Construction Using Bird's Eye View\n  Segmentation Masks","summary":"  In this paper, we introduce Mask2Map, a novel end-to-end online HD map\nconstruction method designed for autonomous driving applications. Our approach\nfocuses on predicting the class and ordered point set of map instances within a\nscene, represented in the bird's eye view (BEV). Mask2Map consists of two\nprimary components: the Instance-Level Mask Prediction Network (IMPNet) and the\nMask-Driven Map Prediction Network (MMPNet). IMPNet generates Mask-Aware\nQueries and BEV Segmentation Masks to capture comprehensive semantic\ninformation globally. Subsequently, MMPNet enhances these query features using\nlocal contextual information through two submodules: the Positional Query\nGenerator (PQG) and the Geometric Feature Extractor (GFE). PQG extracts\ninstance-level positional queries by embedding BEV positional information into\nMask-Aware Queries, while GFE utilizes BEV Segmentation Masks to generate\npoint-level geometric features. However, we observed limited performance in\nMask2Map due to inter-network inconsistency stemming from different predictions\nto Ground Truth (GT) matching between IMPNet and MMPNet. To tackle this\nchallenge, we propose the Inter-network Denoising Training method, which guides\nthe model to denoise the output affected by both noisy GT queries and perturbed\nGT Segmentation Masks. Our evaluation conducted on nuScenes and Argoverse2\nbenchmarks demonstrates that Mask2Map achieves remarkable performance\nimprovements over previous state-of-the-art methods, with gains of 10.1% mAP\nand 4.1 mAP, respectively. Our code can be found at\nhttps://github.com/SehwanChoi0307/Mask2Map.\n","authors":["Sehwan Choi","Jungho Kim","Hongjae Shin","Jun Won Choi"],"pdf_url":"https://arxiv.org/pdf/2407.13517v3.pdf","comment":"Accepted to European Conference on Computer Vision (ECCV) 2024, 20\n  pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.06727v1","updated":"2024-11-11T05:44:48Z","published":"2024-11-11T05:44:48Z","title":"Can KAN Work? Exploring the Potential of Kolmogorov-Arnold Networks in\n  Computer Vision","summary":"  Kolmogorov-Arnold Networks(KANs), as a theoretically efficient neural network\narchitecture, have garnered attention for their potential in capturing complex\npatterns. However, their application in computer vision remains relatively\nunexplored. This study first analyzes the potential of KAN in computer vision\ntasks, evaluating the performance of KAN and its convolutional variants in\nimage classification and semantic segmentation. The focus is placed on\nexamining their characteristics across varying data scales and noise levels.\nResults indicate that while KAN exhibits stronger fitting capabilities, it is\nhighly sensitive to noise, limiting its robustness. To address this challenge,\nwe propose a smoothness regularization method and introduce a Segment\nDeactivation technique. Both approaches enhance KAN's stability and\ngeneralization, demonstrating its potential in handling complex visual data\ntasks.\n","authors":["Yueyang Cang","Yu hang liu","Li Shi"],"pdf_url":"https://arxiv.org/pdf/2411.06727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06725v1","updated":"2024-11-11T05:17:06Z","published":"2024-11-11T05:17:06Z","title":"GTA-Net: An IoT-Integrated 3D Human Pose Estimation System for Real-Time\n  Adolescent Sports Posture Correction","summary":"  With the advancement of artificial intelligence, 3D human pose\nestimation-based systems for sports training and posture correction have gained\nsignificant attention in adolescent sports. However, existing methods face\nchallenges in handling complex movements, providing real-time feedback, and\naccommodating diverse postures, particularly with occlusions, rapid movements,\nand the resource constraints of Internet of Things (IoT) devices, making it\ndifficult to balance accuracy and real-time performance. To address these\nissues, we propose GTA-Net, an intelligent system for posture correction and\nreal-time feedback in adolescent sports, integrated within an IoT-enabled\nenvironment. This model enhances pose estimation in dynamic scenes by\nincorporating Graph Convolutional Networks (GCN), Temporal Convolutional\nNetworks (TCN), and Hierarchical Attention mechanisms, achieving real-time\ncorrection through IoT devices. Experimental results show GTA-Net's superior\nperformance on Human3.6M, HumanEva-I, and MPI-INF-3DHP datasets, with Mean Per\nJoint Position Error (MPJPE) values of 32.2mm, 15.0mm, and 48.0mm,\nrespectively, significantly outperforming existing methods. The model also\ndemonstrates strong robustness in complex scenarios, maintaining high accuracy\neven with occlusions and rapid movements. This system enhances real-time\nposture correction and offers broad applications in intelligent sports and\nhealth management.\n","authors":["Shizhe Yuan","Li Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.06725v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2312.02188v2","updated":"2024-11-11T05:14:15Z","published":"2023-12-01T23:56:00Z","title":"Video Summarization: Towards Entity-Aware Captions","summary":"  Existing popular video captioning benchmarks and models deal with generic\ncaptions devoid of specific person, place or organization named entities. In\ncontrast, news videos present a challenging setting where the caption requires\nsuch named entities for meaningful summarization. As such, we propose the task\nof summarizing news video directly to entity-aware captions. We also release a\nlarge-scale dataset, VIEWS (VIdeo NEWS), to support research on this task.\nFurther, we propose a method that augments visual information from videos with\ncontext retrieved from external world knowledge to generate entity-aware\ncaptions. We demonstrate the effectiveness of our approach on three video\ncaptioning models. We also show that our approach generalizes to existing news\nimage captions dataset. With all the extensive experiments and insights, we\nbelieve we establish a solid basis for future research on this challenging\ntask.\n","authors":["Hammad A. Ayyubi","Tianqi Liu","Arsha Nagrani","Xudong Lin","Mingda Zhang","Anurag Arnab","Feng Han","Yukun Zhu","Jialu Liu","Shih-Fu Chang"],"pdf_url":"https://arxiv.org/pdf/2312.02188v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.21534v3","updated":"2024-11-11T05:12:01Z","published":"2024-07-31T11:40:29Z","title":"ControlMLLM: Training-Free Visual Prompt Learning for Multimodal Large\n  Language Models","summary":"  In this work, we propose a training-free method to inject visual referring\ninto Multimodal Large Language Models (MLLMs) through learnable visual token\noptimization. We observe the relationship between text prompt tokens and visual\ntokens in MLLMs, where attention layers model the connection between them. Our\napproach involves adjusting visual tokens from the MLP output during inference,\ncontrolling which text prompt tokens attend to which visual tokens. We optimize\na learnable visual token based on an energy function, enhancing the strength of\nreferential regions in the attention map. This enables detailed region\ndescription and reasoning without the need for substantial training costs or\nmodel retraining. Our method offers a promising direction for integrating\nreferential abilities into MLLMs. Our method support referring with box, mask,\nscribble and point. The results demonstrate that our method exhibits\ncontrollability and interpretability.\n","authors":["Mingrui Wu","Xinyue Cai","Jiayi Ji","Jiale Li","Oucheng Huang","Gen Luo","Hao Fei","Guannan Jiang","Xiaoshuai Sun","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2407.21534v3.pdf","comment":"Accepted to NeurIPS 2024;\n  Code:https://github.com/mrwu-mac/ControlMLLM"},{"id":"http://arxiv.org/abs/2411.06719v1","updated":"2024-11-11T05:09:31Z","published":"2024-11-11T05:09:31Z","title":"Shallow Signed Distance Functions for Kinematic Collision Bodies","summary":"  We present learning-based implicit shape representations designed for\nreal-time avatar collision queries arising in the simulation of clothing.\nSigned distance functions (SDFs) have been used for such queries for many years\ndue to their computational efficiency. Recently deep neural networks have been\nused for implicit shape representations (DeepSDFs) due to their ability to\nrepresent multiple shapes with modest memory requirements compared to\ntraditional representations over dense grids. However, the computational\nexpense of DeepSDFs prevents their use in real-time clothing simulation\napplications. We design a learning-based representation of SDFs for human\navatars whoes bodies change shape kinematically due to joint-based skinning.\nRather than using a single DeepSDF for the entire avatar, we use a collection\nof extremely computationally efficient (shallow) neural networks that represent\nlocalized deformations arising from changes in body shape induced by the\nvariation of a single joint. This requires a stitching process to combine each\nshallow SDF in the collection together into one SDF representing the signed\nclosest distance to the boundary of the entire body. To achieve this we augment\neach shallow SDF with an additional output that resolves whether or not the\nindividual shallow SDF value is referring to a closest point on the boundary of\nthe body, or to a point on the interior of the body (but on the boundary of the\nindividual shallow SDF). Our model is extremely fast and accurate and we\ndemonstrate its applicability with real-time simulation of garments driven by\nanimated characters.\n","authors":["Osman Akar","Yushan Han","Yizhou Chen","Weixian Lan","Benn Gallagher","Ronald Fedkiw","Joseph Teran"],"pdf_url":"https://arxiv.org/pdf/2411.06719v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2411.06714v1","updated":"2024-11-11T04:50:34Z","published":"2024-11-11T04:50:34Z","title":"DiffSR: Learning Radar Reflectivity Synthesis via Diffusion Model from\n  Satellite Observations","summary":"  Weather radar data synthesis can fill in data for areas where ground\nobservations are missing. Existing methods often employ reconstruction-based\napproaches with MSE loss to reconstruct radar data from satellite observation.\nHowever, such methods lead to over-smoothing, which hinders the generation of\nhigh-frequency details or high-value observation areas associated with\nconvective weather. To address this issue, we propose a two-stage\ndiffusion-based method called DiffSR. We first pre-train a reconstruction model\non global-scale data to obtain radar estimation and then synthesize radar\nreflectivity by combining radar estimation results with satellite data as\nconditions for the diffusion model. Extensive experiments show that our method\nachieves state-of-the-art (SOTA) results, demonstrating the ability to generate\nhigh-frequency details and high-value areas.\n","authors":["Xuming He","Zhiwang Zhou","Wenlong Zhang","Xiangyu Zhao","Hao Chen","Shiqi Chen","Lei Bai"],"pdf_url":"https://arxiv.org/pdf/2411.06714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06703v1","updated":"2024-11-11T04:12:27Z","published":"2024-11-11T04:12:27Z","title":"United Domain Cognition Network for Salient Object Detection in Optical\n  Remote Sensing Images","summary":"  Recently, deep learning-based salient object detection (SOD) in optical\nremote sensing images (ORSIs) have achieved significant breakthroughs. We\nobserve that existing ORSIs-SOD methods consistently center around optimizing\npixel features in the spatial domain, progressively distinguishing between\nbackgrounds and objects. However, pixel information represents local\nattributes, which are often correlated with their surrounding context. Even\nwith strategies expanding the local region, spatial features remain biased\ntowards local characteristics, lacking the ability of global perception. To\naddress this problem, we introduce the Fourier transform that generate global\nfrequency features and achieve an image-size receptive field. To be specific,\nwe propose a novel United Domain Cognition Network (UDCNet) to jointly explore\nthe global-local information in the frequency and spatial domains. Technically,\nwe first design a frequency-spatial domain transformer block that mutually\namalgamates the complementary local spatial and global frequency features to\nstrength the capability of initial input features. Furthermore, a dense\nsemantic excavation module is constructed to capture higher-level semantic for\nguiding the positioning of remote sensing objects. Finally, we devise a\ndual-branch joint optimization decoder that applies the saliency and edge\nbranches to generate high-quality representations for predicting salient\nobjects. Experimental results demonstrate the superiority of the proposed\nUDCNet method over 24 state-of-the-art models, through extensive quantitative\nand qualitative comparisons in three widely-used ORSIs-SOD datasets. The source\ncode is available at: \\href{https://github.com/CSYSI/UDCNet}{\\color{blue}\nhttps://github.com/CSYSI/UDCNet}.\n","authors":["Yanguang Sun","Jian Yang","Lei Luo"],"pdf_url":"https://arxiv.org/pdf/2411.06703v1.pdf","comment":"Accepted at TGRS 2024"},{"id":"http://arxiv.org/abs/2411.06702v1","updated":"2024-11-11T04:07:25Z","published":"2024-11-11T04:07:25Z","title":"Track Any Peppers: Weakly Supervised Sweet Pepper Tracking Using VLMs","summary":"  In the Detection and Multi-Object Tracking of Sweet Peppers Challenge, we\npresent Track Any Peppers (TAP) - a weakly supervised ensemble technique for\nsweet peppers tracking. TAP leverages the zero-shot detection capabilities of\nvision-language foundation models like Grounding DINO to automatically generate\npseudo-labels for sweet peppers in video sequences with minimal human\nintervention. These pseudo-labels, refined when necessary, are used to train a\nYOLOv8 segmentation network. To enhance detection accuracy under challenging\nconditions, we incorporate pre-processing techniques such as relighting\nadjustments and apply depth-based filtering during post-inference. For object\ntracking, we integrate the Matching by Segment Anything (MASA) adapter with the\nBoT-SORT algorithm. Our approach achieves a HOTA score of 80.4%, MOTA of 66.1%,\nRecall of 74.0%, and Precision of 90.7%, demonstrating effective tracking of\nsweet peppers without extensive manual effort. This work highlights the\npotential of foundation models for efficient and accurate object detection and\ntracking in agricultural settings.\n","authors":["Jia Syuen Lim","Yadan Luo","Zhi Chen","Tianqi Wei","Scott Chapman","Zi Huang"],"pdf_url":"https://arxiv.org/pdf/2411.06702v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06700v1","updated":"2024-11-11T04:05:12Z","published":"2024-11-11T04:05:12Z","title":"HomoMatcher: Dense Feature Matching Results with Semi-Dense Efficiency\n  by Homography Estimation","summary":"  Feature matching between image pairs is a fundamental problem in computer\nvision that drives many applications, such as SLAM. Recently, semi-dense\nmatching approaches have achieved substantial performance enhancements and\nestablished a widely-accepted coarse-to-fine paradigm. However, the majority of\nexisting methods focus on improving coarse feature representation rather than\nthe fine-matching module. Prior fine-matching techniques, which rely on\npoint-to-patch matching probability expectation or direct regression, often\nlack precision and do not guarantee the continuity of feature points across\nsequential images. To address this limitation, this paper concentrates on\nenhancing the fine-matching module in the semi-dense matching framework. We\nemploy a lightweight and efficient homography estimation network to generate\nthe perspective mapping between patches obtained from coarse matching. This\npatch-to-patch approach achieves the overall alignment of two patches,\nresulting in a higher sub-pixel accuracy by incorporating additional\nconstraints. By leveraging the homography estimation between patches, we can\nachieve a dense matching result with low computational cost. Extensive\nexperiments demonstrate that our method achieves higher accuracy compared to\nprevious semi-dense matchers. Meanwhile, our dense matching results exhibit\nsimilar end-point-error accuracy compared to previous dense matchers while\nmaintaining semi-dense efficiency.\n","authors":["Xiaolong Wang","Lei Yu","Yingying Zhang","Jiangwei Lao","Lixiang Ru","Liheng Zhong","Jingdong Chen","Yu Zhang","Ming Yang"],"pdf_url":"https://arxiv.org/pdf/2411.06700v1.pdf","comment":"10 pages, 5 figures, conference under review"},{"id":"http://arxiv.org/abs/2411.06696v1","updated":"2024-11-11T03:35:38Z","published":"2024-11-11T03:35:38Z","title":"Séparation en composantes structures, textures et bruit d'une image,\n  apport de l'utilisation des contourlettes","summary":"  In this paper, we propose to improve image decomposition algorithms in the\ncase of noisy images. In \\cite{gilles1,aujoluvw}, the authors propose to\nseparate structures, textures and noise from an image. Unfortunately, the use\nof separable wavelets shows some artefacts. In this paper, we propose to\nreplace the wavelet transform by the contourlet transform which better\napproximate geometry in images. For that, we define contourlet spaces and their\nassociated norms. Then, we get an iterative algorithm which we test on two\nnoisy textured images.\n","authors":["Jerome Gilles"],"pdf_url":"https://arxiv.org/pdf/2411.06696v1.pdf","comment":"in French language, GRETSI Symposium on Signal and Image Processing,\n  Dijon, France, September 2009"},{"id":"http://arxiv.org/abs/2411.06695v1","updated":"2024-11-11T03:35:31Z","published":"2024-11-11T03:35:31Z","title":"METRIC: a complete methodology for performances evaluation of automatic\n  target Detection, Recognition and Tracking algorithms in infrared imagery","summary":"  In this communication, we deal with the question of automatic target\ndetection, recognition and tracking (ATD/R/T) algorithms performance\nassessment. We propose a complete methodology of evaluation which approaches\nobjective image datasets development and adapted metrics definition for the\ndifferent tasks (detection, recognition and tracking). We present some\nperformance results which are currently processed in a French-MoD program\ncalled 2ACI (``Acquisition Automatique de Cibles par Imagerie``).\n","authors":["Jérôme Gilles","Stéphane Landeau","Tristan Dagobert","Philippe Chevalier","Eric Stiée","Damien Diaz","Jean-Luc Maillart"],"pdf_url":"https://arxiv.org/pdf/2411.06695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06692v1","updated":"2024-11-11T03:27:18Z","published":"2024-11-11T03:27:18Z","title":"Layout Control and Semantic Guidance with Attention Loss Backward for\n  T2I Diffusion Model","summary":"  Controllable image generation has always been one of the core demands in\nimage generation, aiming to create images that are both creative and logical\nwhile satisfying additional specified conditions. In the post-AIGC era,\ncontrollable generation relies on diffusion models and is accomplished by\nmaintaining certain components or introducing inference interferences. This\npaper addresses key challenges in controllable generation: 1. mismatched object\nattributes during generation and poor prompt-following effects; 2. inadequate\ncompletion of controllable layouts. We propose a train-free method based on\nattention loss backward, cleverly controlling the cross attention map. By\nutilizing external conditions such as prompts that can reasonably map onto the\nattention map, we can control image generation without any training or\nfine-tuning. This method addresses issues like attribute mismatch and poor\nprompt-following while introducing explicit layout constraints for controllable\nimage generation. Our approach has achieved excellent practical applications in\nproduction, and we hope it can serve as an inspiring technical report in this\nfield.\n","authors":["Guandong Li"],"pdf_url":"https://arxiv.org/pdf/2411.06692v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05225v2","updated":"2024-11-11T03:27:00Z","published":"2024-11-07T22:36:21Z","title":"Breaking The Ice: Video Segmentation for Close-Range Ice-Covered Waters","summary":"  Rapid ice recession in the Arctic Ocean, with predictions of ice-free summers\nby 2060, opens new maritime routes but requires reliable navigation solutions.\nCurrent approaches rely heavily on subjective expert judgment, underscoring the\nneed for automated, data-driven solutions. This study leverages machine\nlearning to assess ice conditions using ship-borne optical data, introducing a\nfinely annotated dataset of 946 images, and a semi-manual, region-based\nannotation technique. The proposed video segmentation model, UPerFlow, advances\nthe SegFlow architecture by incorporating a six-channel ResNet encoder, two\nUPerNet-based segmentation decoders for each image, PWCNet as the optical flow\nencoder, and cross-connections that integrate bi-directional flow features\nwithout loss of latent information. The proposed architecture outperforms\nbaseline image segmentation networks by an average 38\\% in occluded regions,\ndemonstrating the robustness of video segmentation in addressing challenging\nArctic conditions.\n","authors":["Corwin Grant Jeon MacMillan","K. Andrea Scott","Zhao Pan"],"pdf_url":"https://arxiv.org/pdf/2411.05225v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06686v1","updated":"2024-11-11T03:06:26Z","published":"2024-11-11T03:06:26Z","title":"SeedEdit: Align Image Re-Generation to Image Editing","summary":"  We introduce SeedEdit, a diffusion model that is able to revise a given image\nwith any text prompt. In our perspective, the key to such a task is to obtain\nan optimal balance between maintaining the original image, i.e. image\nreconstruction, and generating a new image, i.e. image re-generation. To this\nend, we start from a weak generator (text-to-image model) that creates diverse\npairs between such two directions and gradually align it into a strong image\neditor that well balances between the two tasks. SeedEdit can achieve more\ndiverse and stable editing capability over prior image editing methods,\nenabling sequential revision over images generated by diffusion models.\n","authors":["Yichun Shi","Peng Wang","Weilin Huang"],"pdf_url":"https://arxiv.org/pdf/2411.06686v1.pdf","comment":"Our website: https://team.doubao.com/seededit"},{"id":"http://arxiv.org/abs/2411.06685v1","updated":"2024-11-11T03:04:46Z","published":"2024-11-11T03:04:46Z","title":"High-Frequency Enhanced Hybrid Neural Representation for Video\n  Compression","summary":"  Neural Representations for Videos (NeRV) have simplified the video codec\nprocess and achieved swift decoding speeds by encoding video content into a\nneural network, presenting a promising solution for video compression. However,\nexisting work overlooks the crucial issue that videos reconstructed by these\nmethods lack high-frequency details. To address this problem, this paper\nintroduces a High-Frequency Enhanced Hybrid Neural Representation Network. Our\nmethod focuses on leveraging high-frequency information to improve the\nsynthesis of fine details by the network. Specifically, we design a wavelet\nhigh-frequency encoder that incorporates Wavelet Frequency Decomposer (WFD)\nblocks to generate high-frequency feature embeddings. Next, we design the\nHigh-Frequency Feature Modulation (HFM) block, which leverages the extracted\nhigh-frequency embeddings to enhance the fitting process of the decoder.\nFinally, with the refined Harmonic decoder block and a Dynamic Weighted\nFrequency Loss, we further reduce the potential loss of high-frequency\ninformation. Experiments on the Bunny and UVG datasets demonstrate that our\nmethod outperforms other methods, showing notable improvements in detail\npreservation and compression performance.\n","authors":["Li Yu","Zhihui Li","Jimin Xiao","Moncef Gabbouj"],"pdf_url":"https://arxiv.org/pdf/2411.06685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04933v3","updated":"2024-11-11T02:41:31Z","published":"2024-11-07T18:12:49Z","title":"SaSR-Net: Source-Aware Semantic Representation Network for Enhancing\n  Audio-Visual Question Answering","summary":"  Audio-Visual Question Answering (AVQA) is a challenging task that involves\nanswering questions based on both auditory and visual information in videos. A\nsignificant challenge is interpreting complex multi-modal scenes, which include\nboth visual objects and sound sources, and connecting them to the given\nquestion. In this paper, we introduce the Source-aware Semantic Representation\nNetwork (SaSR-Net), a novel model designed for AVQA. SaSR-Net utilizes\nsource-wise learnable tokens to efficiently capture and align audio-visual\nelements with the corresponding question. It streamlines the fusion of audio\nand visual information using spatial and temporal attention mechanisms to\nidentify answers in multi-modal scenes. Extensive experiments on the Music-AVQA\nand AVQA-Yang datasets show that SaSR-Net outperforms state-of-the-art AVQA\nmethods.\n","authors":["Tianyu Yang","Yiyang Nan","Lisen Dai","Zhenwen Liang","Yapeng Tian","Xiangliang Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.04933v3.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.05357v2","updated":"2024-11-11T02:24:36Z","published":"2024-11-08T06:28:02Z","title":"Enhancing Visual Classification using Comparative Descriptors","summary":"  The performance of vision-language models (VLMs), such as CLIP, in visual\nclassification tasks, has been enhanced by leveraging semantic knowledge from\nlarge language models (LLMs), including GPT. Recent studies have shown that in\nzero-shot classification tasks, descriptors incorporating additional cues,\nhigh-level concepts, or even random characters often outperform those using\nonly the category name. In many classification tasks, while the top-1 accuracy\nmay be relatively low, the top-5 accuracy is often significantly higher. This\ngap implies that most misclassifications occur among a few similar classes,\nhighlighting the model's difficulty in distinguishing between classes with\nsubtle differences. To address this challenge, we introduce a novel concept of\ncomparative descriptors. These descriptors emphasize the unique features of a\ntarget class against its most similar classes, enhancing differentiation. By\ngenerating and integrating these comparative descriptors into the\nclassification framework, we refine the semantic focus and improve\nclassification accuracy. An additional filtering process ensures that these\ndescriptors are closer to the image embeddings in the CLIP space, further\nenhancing performance. Our approach demonstrates improved accuracy and\nrobustness in visual classification tasks by addressing the specific challenge\nof subtle inter-class differences.\n","authors":["Hankyeol Lee","Gawon Seo","Wonseok Choi","Geunyoung Jung","Kyungwoo Song","Jiyoung Jung"],"pdf_url":"https://arxiv.org/pdf/2411.05357v2.pdf","comment":"Accepted by WACV 2025"},{"id":"http://arxiv.org/abs/2411.06665v1","updated":"2024-11-11T02:09:32Z","published":"2024-11-11T02:09:32Z","title":"Learning from Different Samples: A Source-free Framework for\n  Semi-supervised Domain Adaptation","summary":"  Semi-supervised domain adaptation (SSDA) has been widely studied due to its\nability to utilize a few labeled target data to improve the generalization\nability of the model. However, existing methods only consider designing certain\nstrategies for target samples to adapt, ignoring the exploration of customized\nlearning for different target samples. When the model encounters complex target\ndistribution, existing methods will perform limited due to the inability to\nclearly and comprehensively learn the knowledge of multiple types of target\nsamples. To fill this gap, this paper focuses on designing a framework to use\ndifferent strategies for comprehensively mining different target samples. We\npropose a novel source-free framework (SOUF) to achieve semi-supervised\nfine-tuning of the source pre-trained model on the target domain. Different\nfrom existing SSDA methods, SOUF decouples SSDA from the perspectives of\ndifferent target samples, specifically designing robust learning techniques for\nunlabeled, reliably labeled, and noisy pseudo-labeled target samples. For\nunlabeled target samples, probability-based weighted contrastive learning (PWC)\nhelps the model learn more discriminative feature representations. To mine the\nlatent knowledge of labeled target samples, reliability-based mixup contrastive\nlearning (RMC) learns complex knowledge from the constructed reliable sample\nset. Finally, predictive regularization learning (PR) further mitigates the\nmisleading effect of noisy pseudo-labeled samples on the model. Extensive\nexperiments on benchmark datasets demonstrate the superiority of our framework\nover state-of-the-art methods.\n","authors":["Xinyang Huang","Chuang Zhu","Bowen Zhang","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06657v1","updated":"2024-11-11T01:44:54Z","published":"2024-11-11T01:44:54Z","title":"Renaissance: Investigating the Pretraining of Vision-Language Encoders","summary":"  In the past several years there has been an explosion of available models for\nvision-language tasks. Unfortunately, the literature still leaves open a number\nof questions related to best practices in designing and training such models.\nIn this paper we seek to answer several questions related to the pretraining of\nvision-language encoders through meta-analysis. In our first set of\nexperiments, we show that we can save significant compute at no cost to\ndownstream performance, by freezing large parts of vision-language models\nduring pretraining. In our second set of experiments we examine the effect of\nbasing a VL transformer on a vision model versus a text model. Additionally, we\nintroduce a VL modeling platform called Renaissance that we use to conduct all\nof the experiments. This program offers a great deal of flexibility in\ncreating, training and evaluating transformer encoders for VL modeling. The\nsource code for Renaissance can be found at\nhttps://github.com/bsu-slim/renaissance.\n","authors":["Clayton Fields","Casey Kennington"],"pdf_url":"https://arxiv.org/pdf/2411.06657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06652v1","updated":"2024-11-11T01:37:32Z","published":"2024-11-11T01:37:32Z","title":"LFSamba: Marry SAM with Mamba for Light Field Salient Object Detection","summary":"  A light field camera can reconstruct 3D scenes using captured multi-focus\nimages that contain rich spatial geometric information, enhancing applications\nin stereoscopic photography, virtual reality, and robotic vision. In this work,\na state-of-the-art salient object detection model for multi-focus light field\nimages, called LFSamba, is introduced to emphasize four main insights: (a)\nEfficient feature extraction, where SAM is used to extract modality-aware\ndiscriminative features; (b) Inter-slice relation modeling, leveraging Mamba to\ncapture long-range dependencies across multiple focal slices, thus extracting\nimplicit depth cues; (c) Inter-modal relation modeling, utilizing Mamba to\nintegrate all-focus and multi-focus images, enabling mutual enhancement; (d)\nWeakly supervised learning capability, developing a scribble annotation dataset\nfrom an existing pixel-level mask dataset, establishing the first\nscribble-supervised baseline for light field salient object\ndetection.https://github.com/liuzywen/LFScribble\n","authors":["Zhengyi Liu","Longzhen Wang","Xianyong Fang","Zhengzheng Tu","Linbo Wang"],"pdf_url":"https://arxiv.org/pdf/2411.06652v1.pdf","comment":"Accepted by SPL"},{"id":"http://arxiv.org/abs/2411.06651v1","updated":"2024-11-11T01:36:48Z","published":"2024-11-11T01:36:48Z","title":"Machine learning enabled velocity model building with uncertainty\n  quantification","summary":"  Accurately characterizing migration velocity models is crucial for a wide\nrange of geophysical applications, from hydrocarbon exploration to monitoring\nof CO2 sequestration projects. Traditional velocity model building methods such\nas Full-Waveform Inversion (FWI) are powerful but often struggle with the\ninherent complexities of the inverse problem, including noise, limited\nbandwidth, receiver aperture and computational constraints. To address these\nchallenges, we propose a scalable methodology that integrates generative\nmodeling, in the form of Diffusion networks, with physics-informed summary\nstatistics, making it suitable for complicated imaging problems including field\ndatasets. By defining these summary statistics in terms of subsurface-offset\nimage volumes for poor initial velocity models, our approach allows for\ncomputationally efficient generation of Bayesian posterior samples for\nmigration velocity models that offer a useful assessment of uncertainty. To\nvalidate our approach, we introduce a battery of tests that measure the quality\nof the inferred velocity models, as well as the quality of the inferred\nuncertainties. With modern synthetic datasets, we reconfirm gains from using\nsubsurface-image gathers as the conditioning observable. For complex velocity\nmodel building involving salt, we propose a new iterative workflow that refines\namortized posterior approximations with salt flooding and demonstrate how the\nuncertainty in the velocity model can be propagated to the final product\nreverse time migrated images. Finally, we present a proof of concept on field\ndatasets to show that our method can scale to industry-sized problems.\n","authors":["Rafael Orozco","Huseyin Tuna Erdinc","Yunlin Zeng","Mathias Louboutin","Felix J. Herrmann"],"pdf_url":"https://arxiv.org/pdf/2411.06651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09403v3","updated":"2024-11-11T00:54:32Z","published":"2024-06-13T17:59:31Z","title":"Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal\n  Language Models","summary":"  Humans draw to facilitate reasoning: we draw auxiliary lines when solving\ngeometry problems; we mark and circle when reasoning on maps; we use sketches\nto amplify our ideas and relieve our limited-capacity working memory. However,\nsuch actions are missing in current multimodal language models (LMs). Current\nchain-of-thought and tool-use paradigms only use text as intermediate reasoning\nsteps. In this work, we introduce Sketchpad, a framework that gives multimodal\nLMs a visual sketchpad and tools to draw on the sketchpad. The LM conducts\nplanning and reasoning according to the visual artifacts it has drawn.\nDifferent from prior work, which uses text-to-image models to enable LMs to\ndraw, Sketchpad enables LMs to draw with lines, boxes, marks, etc., which is\ncloser to human sketching and better facilitates reasoning. Sketchpad can also\nuse specialist vision models during the sketching process (e.g., draw bounding\nboxes with object detection models, draw masks with segmentation models), to\nfurther enhance visual perception and reasoning. We experiment with a wide\nrange of math tasks (including geometry, functions, graphs, and chess) and\ncomplex visual reasoning tasks. Sketchpad substantially improves performance on\nall tasks over strong base models with no sketching, yielding an average gain\nof 12.7% on math tasks, and 8.6% on vision tasks. GPT-4o with Sketchpad sets a\nnew state of the art on all tasks, including V*Bench (80.3%), BLINK spatial\nreasoning (83.9%), and visual correspondence (80.8%). All codes and data are in\nhttps://visualsketchpad.github.io/.\n","authors":["Yushi Hu","Weijia Shi","Xingyu Fu","Dan Roth","Mari Ostendorf","Luke Zettlemoyer","Noah A Smith","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2406.09403v3.pdf","comment":"Accepted to NeurIPS 2024. Project and codes url:\n  https://visualsketchpad.github.io/"},{"id":"http://arxiv.org/abs/2406.16466v2","updated":"2024-11-11T23:25:00Z","published":"2024-06-24T09:16:17Z","title":"SLOctolyzer: Fully automatic analysis toolkit for segmentation and\n  feature extracting in scanning laser ophthalmoscopy images","summary":"  Purpose: The purpose of this study was to introduce SLOctolyzer: an\nopen-source analysis toolkit for en face retinal vessels in infrared\nreflectance scanning laser ophthalmoscopy (SLO) images.\n  Methods: SLOctolyzer includes two main modules: segmentation and measurement.\nThe segmentation module uses deep learning methods to delineate retinal\nanatomy, and detects the fovea and optic disc, whereas the measurement module\nquantifies the complexity, density, tortuosity, and calibre of the segmented\nretinal vessels. We evaluated the segmentation module using unseen data and\nmeasured its reproducibility.\n  Results: SLOctolyzer's segmentation module performed well against unseen\ninternal test data (Dice for all-vessels = 0.91; arteries = 0.84; veins = 0.85;\noptic disc = 0.94; and fovea = 0.88). External validation against severe\nretinal pathology showed decreased performance (Dice for arteries = 0.72; veins\n= 0.75; and optic disc = 0.90). SLOctolyzer had good reproducibility (mean\ndifference for fractal dimension = -0.001; density = -0.0003; calibre = -0.32\nmicrons; and tortuosity density = 0.001). SLOctolyzer can process a 768 x 768\npixel macula-centred SLO image in under 20 seconds and a disc-centred SLO image\nin under 30 seconds using a laptop CPU.\n  Conclusions: To our knowledge, SLOctolyzer is the first open-source tool to\nconvert raw SLO images into reproducible and clinically meaningful retinal\nvascular parameters. SLO images are captured simultaneous to optical coherence\ntomography (OCT), and we believe SLOctolyzer will be useful for extracting\nretinal vascular measurements from large OCT image sets and linking them to\nocular or systemic diseases. It requires no specialist knowledge or proprietary\nsoftware, and allows manual correction of segmentations and re-computing of\nvascular metrics. SLOctolyzer is freely available at\nhttps://github.com/jaburke166/SLOctolyzer.\n","authors":["Jamie Burke","Samuel Gibbon","Justin Engelmann","Adam Threlfall","Ylenia Giarratano","Charlene Hamid","Stuart King","Ian J. C. MacCormick","Tom MacGillivray"],"pdf_url":"https://arxiv.org/pdf/2406.16466v2.pdf","comment":"13 pages, 6 figures, 6 tables + Supplementary (9 pages, 13 figures, 4\n  tables, 2 code listings). Accepted and published at ARVO Translational Vision\n  Science and Technology"},{"id":"http://arxiv.org/abs/2411.07430v1","updated":"2024-11-11T23:12:08Z","published":"2024-11-11T23:12:08Z","title":"XPoint: A Self-Supervised Visual-State-Space based Architecture for\n  Multispectral Image Registration","summary":"  Accurate multispectral image matching presents significant challenges due to\nnon-linear intensity variations across spectral modalities, extreme viewpoint\nchanges, and the scarcity of labeled datasets. Current state-of-the-art methods\nare typically specialized for a single spectral difference, such as\nvisibleinfrared, and struggle to adapt to other modalities due to their\nreliance on expensive supervision, such as depth maps or camera poses. To\naddress the need for rapid adaptation across modalities, we introduce XPoint, a\nself-supervised, modular image-matching framework designed for adaptive\ntraining and fine-tuning on aligned multispectral datasets, allowing users to\ncustomize key components based on their specific tasks. XPoint employs\nmodularity and self-supervision to allow for the adjustment of elements such as\nthe base detector, which generates pseudoground truth keypoints invariant to\nviewpoint and spectrum variations. The framework integrates a VMamba encoder,\npretrained on segmentation tasks, for robust feature extraction, and includes\nthree joint decoder heads: two are dedicated to interest point and descriptor\nextraction; and a task-specific homography regression head imposes geometric\nconstraints for superior performance in tasks like image registration. This\nflexible architecture enables quick adaptation to a wide range of modalities,\ndemonstrated by training on Optical-Thermal data and fine-tuning on settings\nsuch as visual-near infrared, visual-infrared, visual-longwave infrared, and\nvisual-synthetic aperture radar. Experimental results show that XPoint\nconsistently outperforms or matches state-ofthe-art methods in feature matching\nand image registration tasks across five distinct multispectral datasets. Our\nsource code is available at https://github.com/canyagmur/XPoint.\n","authors":["Ismail Can Yagmur","Hasan F. Ates","Bahadir K. Gunturk"],"pdf_url":"https://arxiv.org/pdf/2411.07430v1.pdf","comment":"13 pages, 11 figures, 1 table, Journal"},{"id":"http://arxiv.org/abs/2409.18461v2","updated":"2024-11-11T22:57:16Z","published":"2024-09-27T05:49:48Z","title":"Towards Diverse Device Heterogeneous Federated Learning via Task\n  Arithmetic Knowledge Integration","summary":"  Federated Learning has emerged as a promising paradigm for collaborative\nmachine learning, while preserving user data privacy. Despite its potential,\nstandard FL lacks support for diverse heterogeneous device prototypes, which\nvary significantly in model and dataset sizes -- from small IoT devices to\nlarge workstations. This limitation is only partially addressed by existing\nknowledge distillation techniques, which often fail to transfer knowledge\neffectively across a broad spectrum of device prototypes with varied\ncapabilities. This failure primarily stems from two issues: the dilution of\ninformative logits from more capable devices by those from less capable ones,\nand the use of a single integrated logits as the distillation target across all\ndevices, which neglects their individual learning capacities and and the unique\ncontributions of each. To address these challenges, we introduce TAKFL, a novel\nKD-based framework that treats the knowledge transfer from each device\nprototype's ensemble as a separate task, independently distilling each to\npreserve its unique contributions and avoid dilution. TAKFL also incorporates a\nKD-based self-regularization technique to mitigate the issues related to the\nnoisy and unsupervised ensemble distillation process. To integrate the\nseparately distilled knowledge, we introduce an adaptive task arithmetic\nknowledge integration process, allowing each student model to customize the\nknowledge integration for optimal performance. Additionally, we present\ntheoretical results demonstrating the effectiveness of task arithmetic in\ntransferring knowledge across heterogeneous devices with varying capacities.\nComprehensive evaluations of our method across both CV and NLP tasks\ndemonstrate that TAKFL achieves SOTA results in a variety of datasets and\nsettings, significantly outperforming existing KD-based methods Code is\nreleased at https://github.com/MMorafah/TAKFL\n","authors":["Mahdi Morafah","Vyacheslav Kungurtsev","Hojin Chang","Chen Chen","Bill Lin"],"pdf_url":"https://arxiv.org/pdf/2409.18461v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2403.19596v2","updated":"2024-11-11T22:39:35Z","published":"2024-03-28T17:20:39Z","title":"LocCa: Visual Pretraining with Location-aware Captioners","summary":"  Image captioning has been shown as an effective pretraining method similar to\ncontrastive pretraining. However, the incorporation of location-aware\ninformation into visual pretraining remains an area with limited research. In\nthis paper, we propose a simple visual pretraining method with location-aware\ncaptioners (LocCa). LocCa uses a simple image captioner task interface, to\nteach a model to read out rich information, i.e. bounding box coordinates, and\ncaptions, conditioned on the image pixel input. Thanks to the multitask\ncapabilities of an encoder-decoder architecture, we show that an image\ncaptioner can easily handle multiple tasks during pretraining. Our experiments\ndemonstrate that LocCa outperforms standard captioners significantly on\nlocalization downstream tasks while maintaining comparable performance on\nholistic tasks.\n","authors":["Bo Wan","Michael Tschannen","Yongqin Xian","Filip Pavetic","Ibrahim Alabdulmohsin","Xiao Wang","André Susano Pinto","Andreas Steiner","Lucas Beyer","Xiaohua Zhai"],"pdf_url":"https://arxiv.org/pdf/2403.19596v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07416v1","updated":"2024-11-11T22:38:45Z","published":"2024-11-11T22:38:45Z","title":"T2-Only Prostate Cancer Prediction by Meta-Learning from Bi-Parametric\n  MR Imaging","summary":"  Current imaging-based prostate cancer diagnosis requires both MR T2-weighted\n(T2w) and diffusion-weighted imaging (DWI) sequences, with additional sequences\nfor potentially greater accuracy improvement. However, measuring diffusion\npatterns in DWI sequences can be time-consuming, prone to artifacts and\nsensitive to imaging parameters. While machine learning (ML) models have\ndemonstrated radiologist-level accuracy in detecting prostate cancer from these\ntwo sequences, this study investigates the potential of ML-enabled methods\nusing only the T2w sequence as input during inference time. We first discuss\nthe technical feasibility of such a T2-only approach, and then propose a novel\nML formulation, where DWI sequences - readily available for training purposes -\nare only used to train a meta-learning model, which subsequently only uses T2w\nsequences at inference. Using multiple datasets from more than 3,000 prostate\ncancer patients, we report superior or comparable performance in localising\nradiologist-identified prostate cancer using our proposed T2-only models,\ncompared with alternative models using T2-only or both sequences as input. Real\npatient cases are presented and discussed to demonstrate, for the first time,\nthe exclusively true-positive cases from models with different input sequences.\n","authors":["Weixi Yi","Yipei Wang","Natasha Thorley","Alexander Ng","Shonit Punwani","Veeru Kasivisvanathan","Dean C. Barratt","Shaheer Ullah Saeed","Yipeng Hu"],"pdf_url":"https://arxiv.org/pdf/2411.07416v1.pdf","comment":"Code: https://github.com/wxyi057/MetaT2"},{"id":"http://arxiv.org/abs/2411.07392v1","updated":"2024-11-11T21:51:45Z","published":"2024-11-11T21:51:45Z","title":"Feature-Space Semantic Invariance: Enhanced OOD Detection for Open-Set\n  Domain Generalization","summary":"  Open-set domain generalization addresses a real-world challenge: training a\nmodel to generalize across unseen domains (domain generalization) while also\ndetecting samples from unknown classes not encountered during training\n(open-set recognition). However, most existing approaches tackle these issues\nseparately, limiting their practical applicability. To overcome this\nlimitation, we propose a unified framework for open-set domain generalization\nby introducing Feature-space Semantic Invariance (FSI). FSI maintains semantic\nconsistency across different domains within the feature space, enabling more\naccurate detection of OOD instances in unseen domains. Additionally, we adopt a\ngenerative model to produce synthetic data with novel domain styles or class\nlabels, enhancing model robustness. Initial experiments show that our method\nimproves AUROC by 9.1% to 18.9% on ColoredMNIST, while also significantly\nincreasing in-distribution classification accuracy.\n","authors":["Haoliang Wang","Chen Zhao","Feng Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07392v1.pdf","comment":"IEEE BigData 2024, Ph.D. Forum"},{"id":"http://arxiv.org/abs/2411.07391v1","updated":"2024-11-11T21:46:34Z","published":"2024-11-11T21:46:34Z","title":"Federated Learning Client Pruning for Noisy Labels","summary":"  Federated Learning (FL) enables collaborative model training across\ndecentralized edge devices while preserving data privacy. However, existing FL\nmethods often assume clean annotated datasets, impractical for\nresource-constrained edge devices. In reality, noisy labels are prevalent,\nposing significant challenges to FL performance. Prior approaches attempt label\ncorrection and robust training techniques but exhibit limited efficacy,\nparticularly under high noise levels. This paper introduces ClipFL (Federated\nLearning Client Pruning), a novel framework addressing noisy labels from a\nfresh perspective. ClipFL identifies and excludes noisy clients based on their\nperformance on a clean validation dataset, tracked using a Noise Candidacy\nScore (NCS). The framework comprises three phases: pre-client pruning to\nidentify potential noisy clients and calculate their NCS, client pruning to\nexclude a percentage of clients with the highest NCS, and post-client pruning\nfor fine-tuning the global model with standard FL on clean clients. Empirical\nevaluation demonstrates ClipFL's efficacy across diverse datasets and noise\nlevels, achieving accurate noisy client identification, superior performance,\nfaster convergence, and reduced communication costs compared to\nstate-of-the-art FL methods. Our code is available at\nhttps://github.com/MMorafah/ClipFL.\n","authors":["Mahdi Morafah","Hojin Chang","Chen Chen","Bill Lin"],"pdf_url":"https://arxiv.org/pdf/2411.07391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.04928v3","updated":"2024-11-11T21:23:48Z","published":"2023-08-09T12:54:27Z","title":"GeodesicPSIM: Predicting the Quality of Static Mesh with Texture Map via\n  Geodesic Patch Similarity","summary":"  Static meshes with texture maps have attracted considerable attention in both\nindustrial manufacturing and academic research, leading to an urgent\nrequirement for effective and robust objective quality evaluation. However,\ncurrent model-based static mesh quality metrics have obvious limitations: most\nof them only consider geometry information, while color information is ignored,\nand they have strict constraints for the meshes' geometrical topology. Other\nmetrics, such as image-based and point-based metrics, are easily influenced by\nthe prepossessing algorithms, e.g., projection and sampling, hampering their\nability to perform at their best. In this paper, we propose Geodesic Patch\nSimilarity (GeodesicPSIM), a novel model-based metric to accurately predict\nhuman perception quality for static meshes. After selecting a group keypoints,\n1-hop geodesic patches are constructed based on both the reference and\ndistorted meshes cleaned by an effective mesh cleaning algorithm. A two-step\npatch cropping algorithm and a patch texture mapping module refine the size of\n1-hop geodesic patches and build the relationship between the mesh geometry and\ncolor information, resulting in the generation of 1-hop textured geodesic\npatches. Three types of features are extracted to quantify the distortion:\npatch color smoothness, patch discrete mean curvature, and patch pixel color\naverage and variance. To the best of our knowledge, GeodesicPSIM is the first\nmodel-based metric especially designed for static meshes with texture maps.\nGeodesicPSIM provides state-of-the-art performance in comparison with\nimage-based, point-based, and video-based metrics on a newly created and\nchallenging database. We also prove the robustness of GeodesicPSIM by\nintroducing different settings of hyperparameters. Ablation studies also\nexhibit the effectiveness of three proposed features and the patch cropping\nalgorithm.\n","authors":["Qi Yang","Joel Jung","Xiaozhong Xu","Shan Liu"],"pdf_url":"https://arxiv.org/pdf/2308.04928v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12306v3","updated":"2024-11-11T21:04:35Z","published":"2024-09-18T20:33:54Z","title":"Measuring Sound Symbolism in Audio-visual Models","summary":"  Audio-visual pre-trained models have gained substantial attention recently\nand demonstrated superior performance on various audio-visual tasks. This study\ninvestigates whether pre-trained audio-visual models demonstrate non-arbitrary\nassociations between sounds and visual representations$\\unicode{x2013}$known as\nsound symbolism$\\unicode{x2013}$which is also observed in humans. We developed\na specialized dataset with synthesized images and audio samples and assessed\nthese models using a non-parametric approach in a zero-shot setting. Our\nfindings reveal a significant correlation between the models' outputs and\nestablished patterns of sound symbolism, particularly in models trained on\nspeech data. These results suggest that such models can capture sound-meaning\nconnections akin to human language processing, providing insights into both\ncognitive architectures and machine learning strategies.\n","authors":["Wei-Cheng Tseng","Yi-Jen Shih","David Harwath","Raymond Mooney"],"pdf_url":"https://arxiv.org/pdf/2409.12306v3.pdf","comment":"SLT 2024"},{"id":"http://arxiv.org/abs/2411.07351v1","updated":"2024-11-11T20:19:00Z","published":"2024-11-11T20:19:00Z","title":"Generalization of Brady-Yong Algorithm for Fast Hough Transform to\n  Arbitrary Image Size","summary":"  Nowadays, the Hough (discrete Radon) transform (HT/DRT) has proved to be an\nextremely powerful and widespread tool harnessed in a number of application\nareas, ranging from general image processing to X-ray computed tomography.\nEfficient utilization of the HT to solve applied problems demands its\nacceleration and increased accuracy. Along with this, most fast algorithms for\ncomputing the HT, especially the pioneering Brady-Yong algorithm, operate on\npower-of-two size input images and are not adapted for arbitrary size images.\nThis paper presents a new algorithm for calculating the HT for images of\narbitrary size. It generalizes the Brady-Yong algorithm from which it inherits\nthe optimal computational complexity. Moreover, the algorithm allows to compute\nthe HT with considerably higher accuracy compared to the existing algorithm.\nHerewith, the paper provides a theoretical analysis of the computational\ncomplexity and accuracy of the proposed algorithm. The conclusions of the\nperformed experiments conform with the theoretical results.\n","authors":["Danil Kazimirov","Dmitry Nikolaev","Ekaterina Rybakova","Arseniy Terekhin"],"pdf_url":"https://arxiv.org/pdf/2411.07351v1.pdf","comment":"6 pages, 2 figures. Accepted to Symposium on Pattern Recognition and\n  Applications 2024 (SPRA 2024)"},{"id":"http://arxiv.org/abs/2411.07348v1","updated":"2024-11-11T20:12:13Z","published":"2024-11-11T20:12:13Z","title":"Exploring Variational Autoencoders for Medical Image Generation: A\n  Comprehensive Study","summary":"  Variational autoencoder (VAE) is one of the most common techniques in the\nfield of medical image generation, where this architecture has shown advanced\nresearchers in recent years and has developed into various architectures. VAE\nhas advantages including improving datasets by adding samples in smaller\ndatasets and in datasets with imbalanced classes, and this is how data\naugmentation works. This paper provides a comprehensive review of studies on\nVAE in medical imaging, with a special focus on their ability to create\nsynthetic images close to real data so that they can be used for data\naugmentation. This study reviews important architectures and methods used to\ndevelop VAEs for medical images and provides a comparison with other generative\nmodels such as GANs on issues such as image quality, and low diversity of\ngenerated samples. We discuss recent developments and applications in several\nmedical fields highlighting the ability of VAEs to improve segmentation and\nclassification accuracy.\n","authors":["Khadija Rais","Mohamed Amroune","Abdelmadjid Benmachiche","Mohamed Yassine Haouam"],"pdf_url":"https://arxiv.org/pdf/2411.07348v1.pdf","comment":"for associated mpeg file, see\n  https://worldresearchlibrary.org/proceeding.php?pid=6945"},{"id":"http://arxiv.org/abs/2411.07335v1","updated":"2024-11-11T19:53:05Z","published":"2024-11-11T19:53:05Z","title":"Multimodal Fusion Balancing Through Game-Theoretic Regularization","summary":"  Multimodal learning can complete the picture of information extraction by\nuncovering key dependencies between data sources. However, current systems fail\nto fully leverage multiple modalities for optimal performance. This has been\nattributed to modality competition, where modalities strive for training\nresources, leaving some underoptimized. We show that current balancing methods\nstruggle to train multimodal models that surpass even simple baselines, such as\nensembles. This raises the question: how can we ensure that all modalities in\nmultimodal training are sufficiently trained, and that learning from new\nmodalities consistently improves performance? This paper proposes the\nMultimodal Competition Regularizer (MCR), a new loss component inspired by\nmutual information (MI) decomposition designed to prevent the adverse effects\nof competition in multimodal training. Our key contributions are: 1)\nIntroducing game-theoretic principles in multimodal learning, where each\nmodality acts as a player competing to maximize its influence on the final\noutcome, enabling automatic balancing of the MI terms. 2) Refining lower and\nupper bounds for each MI term to enhance the extraction of task-relevant unique\nand shared information across modalities. 3) Suggesting latent space\npermutations for conditional MI estimation, significantly improving\ncomputational efficiency. MCR outperforms all previously suggested training\nstrategies and is the first to consistently improve multimodal learning beyond\nthe ensemble baseline, clearly demonstrating that combining modalities leads to\nsignificant performance gains on both synthetic and large real-world datasets.\n","authors":["Konstantinos Kontras","Thomas Strypsteen","Christos Chatzichristos","Paul P. Liang","Matthew Blaschko","Maarten De Vos"],"pdf_url":"https://arxiv.org/pdf/2411.07335v1.pdf","comment":"21 pages, 6 figures, 4 tables, 1 algorithm"},{"id":"http://arxiv.org/abs/2210.06094v2","updated":"2024-11-11T19:35:03Z","published":"2022-10-12T11:18:35Z","title":"Teeth3DS+: An Extended Benchmark for Intraoral 3D Scans Analysis","summary":"  Intraoral 3D scans analysis is a fundamental aspect of Computer-Aided\nDentistry (CAD) systems, playing a crucial role in various dental applications,\nincluding teeth segmentation, detection, labeling, and dental landmark\nidentification. Accurate analysis of 3D dental scans is essential for\northodontic and prosthetic treatment planning, as it enables automated\nprocessing and reduces the need for manual adjustments by dental professionals.\nHowever, developing robust automated tools for these tasks remains a\nsignificant challenge due to the limited availability of high-quality public\ndatasets and benchmarks. This article introduces Teeth3DS+, the first\ncomprehensive public benchmark designed to advance the field of intraoral 3D\nscan analysis. Developed as part of the 3DTeethSeg 2022 and 3DTeethLand 2024\nMICCAI challenges, Teeth3DS+ aims to drive research in teeth identification,\nsegmentation, labeling, 3D modeling, and dental landmarks identification. The\ndataset includes at least 1,800 intraoral scans (containing 23,999 annotated\nteeth) collected from 900 patients, covering both upper and lower jaws\nseparately. All data have been acquired and validated by experienced\northodontists and dental surgeons with over five years of expertise. Detailed\ninstructions for accessing the dataset are available at\nhttps://crns-smartvision.github.io/teeth3ds\n","authors":["Achraf Ben-Hamadou","Nour Neifar","Ahmed Rekik","Oussama Smaoui","Firas Bouzguenda","Sergi Pujades","Edmond Boyer","Edouard Ladroit"],"pdf_url":"https://arxiv.org/pdf/2210.06094v2.pdf","comment":"Draft"},{"id":"http://arxiv.org/abs/2411.07326v1","updated":"2024-11-11T19:34:47Z","published":"2024-11-11T19:34:47Z","title":"$SE(3)$ Equivariant Ray Embeddings for Implicit Multi-View Depth\n  Estimation","summary":"  Incorporating inductive bias by embedding geometric entities (such as rays)\nas input has proven successful in multi-view learning. However, the methods\nadopting this technique typically lack equivariance, which is crucial for\neffective 3D learning. Equivariance serves as a valuable inductive prior,\naiding in the generation of robust multi-view features for 3D scene\nunderstanding. In this paper, we explore the application of equivariant\nmulti-view learning to depth estimation, not only recognizing its significance\nfor computer vision and robotics but also addressing the limitations of\nprevious research. Most prior studies have either overlooked equivariance in\nthis setting or achieved only approximate equivariance through data\naugmentation, which often leads to inconsistencies across different reference\nframes. To address this issue, we propose to embed $SE(3)$ equivariance into\nthe Perceiver IO architecture. We employ Spherical Harmonics for positional\nencoding to ensure 3D rotation equivariance, and develop a specialized\nequivariant encoder and decoder within the Perceiver IO architecture. To\nvalidate our model, we applied it to the task of stereo depth estimation,\nachieving state of the art results on real-world datasets without explicit\ngeometric constraints or extensive data augmentation.\n","authors":["Yinshuang Xu","Dian Chen","Katherine Liu","Sergey Zakharov","Rares Ambrus","Kostas Daniilidis","Vitor Guizilini"],"pdf_url":"https://arxiv.org/pdf/2411.07326v1.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07322v1","updated":"2024-11-11T19:31:06Z","published":"2024-11-11T19:31:06Z","title":"Artificial Intelligence-Informed Handheld Breast Ultrasound for\n  Screening: A Systematic Review of Diagnostic Test Accuracy","summary":"  Background. Breast cancer screening programs using mammography have led to\nsignificant mortality reduction in high-income countries. However, many low-\nand middle-income countries lack resources for mammographic screening. Handheld\nbreast ultrasound (BUS) is a low-cost alternative but requires substantial\ntraining. Artificial intelligence (AI) enabled BUS may aid in both the\ndetection (perception) and classification (interpretation) of breast cancer.\nMaterials and Methods. This review (CRD42023493053) is reported in accordance\nwith the PRISMA (Preferred Reporting Items for Systematic Reviews and\nMeta-Analysis) and SWiM (Synthesis Without Meta-analysis) guidelines. PubMed\nand Google Scholar were searched from January 1, 2016 to December 12, 2023. A\nmeta-analysis was not attempted. Studies are grouped according to their AI task\ntype, application time, and AI task. Study quality is assessed using the\nQUality Assessment of Diagnostic Accuracy Studies-2 (QUADAS-2) tool. Results.\nOf 763 candidate studies, 314 total full texts were reviewed. 34 studies are\nincluded. The AI tasks of included studies are as follows: 1 frame selection, 6\ndetection, 11 segmentation, and 16 classification. In total, 5.7 million BUS\nimages from over 185,000 patients were used for AI training or validation. A\nsingle study included a prospective testing set. 79% of studies were at high or\nunclear risk of bias. Conclusion. There has been encouraging development of AI\nfor BUS. Despite studies demonstrating high performance across all identified\ntasks, the evidence supporting AI-enhanced BUS generally lacks robustness.\nHigh-quality model validation will be key to realizing the potential for\nAI-enhanced BUS in increasing access to screening in resource-limited\nenvironments.\n","authors":["Arianna Bunnell","Dustin Valdez","Fredrik Strand","Yannik Glaser","Peter Sadowski","John A. Shepherd"],"pdf_url":"https://arxiv.org/pdf/2411.07322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07311v1","updated":"2024-11-11T19:10:58Z","published":"2024-11-11T19:10:58Z","title":"GPU-Accelerated Inverse Lithography Towards High Quality Curvy Mask\n  Generation","summary":"  Inverse Lithography Technology (ILT) has emerged as a promising solution for\nphoto mask design and optimization. Relying on multi-beam mask writers, ILT\nenables the creation of free-form curvilinear mask shapes that enhance printed\nwafer image quality and process window. However, a major challenge in\nimplementing curvilinear ILT for large-scale production is mask rule checking,\nan area currently under development by foundries and EDA vendors. Although\nrecent research has incorporated mask complexity into the optimization process,\nmuch of it focuses on reducing e-beam shots, which does not align with the\ngoals of curvilinear ILT. In this paper, we introduce a GPU-accelerated ILT\nalgorithm that improves not only contour quality and process window but also\nthe precision of curvilinear mask shapes. Our experiments on open benchmarks\ndemonstrate a significant advantage of our algorithm over leading academic ILT\nengines.\n","authors":["Haoyu Yang","Haoxing Ren"],"pdf_url":"https://arxiv.org/pdf/2411.07311v1.pdf","comment":"10 pages, 5 figures, Accepted by International Symposium on Physical\n  Design (ISPD), 2025, Austin TX"},{"id":"http://arxiv.org/abs/2401.12275v2","updated":"2024-11-11T18:59:07Z","published":"2024-01-22T18:58:22Z","title":"Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation","summary":"  Social robot navigation can be helpful in various contexts of daily life but\nrequires safe human-robot interactions and efficient trajectory planning. While\nmodeling pairwise relations has been widely studied in multi-agent interacting\nsystems, the ability to capture larger-scale group-wise activities is limited.\nIn this paper, we propose a systematic relational reasoning approach with\nexplicit inference of the underlying dynamically evolving relational\nstructures, and we demonstrate its effectiveness for multi-agent trajectory\nprediction and social robot navigation. In addition to the edges between pairs\nof nodes (i.e., agents), we propose to infer hyperedges that adaptively connect\nmultiple nodes to enable group-wise reasoning in an unsupervised manner. Our\napproach infers dynamically evolving relation graphs and hypergraphs to capture\nthe evolution of relations, which the trajectory predictor employs to generate\nfuture states. Meanwhile, we propose to regularize the sharpness and sparsity\nof the learned relations and the smoothness of the relation evolution, which\nproves to enhance training stability and model performance. The proposed\napproach is validated on synthetic crowd simulations and real-world benchmark\ndatasets. Experiments demonstrate that the approach infers reasonable relations\nand achieves state-of-the-art prediction performance. In addition, we present a\ndeep reinforcement learning (DRL) framework for social robot navigation, which\nincorporates relational reasoning and trajectory prediction systematically. In\na group-based crowd simulation, our method outperforms the strongest baseline\nby a significant margin in terms of safety, efficiency, and social compliance\nin dense, interactive scenarios. We also demonstrate the practical\napplicability of our method with real-world robot experiments. The code and\nvideos can be found at https://relational-reasoning-nav.github.io/.\n","authors":["Jiachen Li","Chuanbo Hua","Jianpeng Yao","Hengbo Ma","Jinkyoo Park","Victoria Dax","Mykel J. Kochenderfer"],"pdf_url":"https://arxiv.org/pdf/2401.12275v2.pdf","comment":"Project website: https://relational-reasoning-nav.github.io/; 20\n  pages, 9 figures, 6 tables"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2411.07239v1","updated":"2024-11-11T18:58:46Z","published":"2024-11-11T18:58:46Z","title":"DeepONet as a Multi-Operator Extrapolation Model: Distributed\n  Pretraining with Physics-Informed Fine-Tuning","summary":"  We propose a novel fine-tuning method to achieve multi-operator learning\nthrough training a distributed neural operator with diverse function data and\nthen zero-shot fine-tuning the neural network using physics-informed losses for\ndownstream tasks. Operator learning effectively approximates solution operators\nfor PDEs and various PDE-related problems, yet it often struggles to generalize\nto new tasks. To address this, we investigate fine-tuning a pretrained model,\nwhile carefully selecting an initialization that enables rapid adaptation to\nnew tasks with minimal data. Our approach combines distributed learning to\nintegrate data from various operators in pre-training, while physics-informed\nmethods enable zero-shot fine-tuning, minimizing the reliance on downstream\ndata. We investigate standard fine-tuning and Low-Rank Adaptation fine-tuning,\napplying both to train complex nonlinear target operators that are difficult to\nlearn only using random initialization. Through comprehensive numerical\nexamples, we demonstrate the advantages of our approach, showcasing significant\nimprovements in accuracy. Our findings provide a robust framework for advancing\nmulti-operator learning and highlight the potential of transfer learning\ntechniques in this domain.\n","authors":["Zecheng Zhang","Christian Moya","Lu Lu","Guang Lin","Hayden Schaeffer"],"pdf_url":"https://arxiv.org/pdf/2411.07239v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07233v1","updated":"2024-11-11T18:51:08Z","published":"2024-11-11T18:51:08Z","title":"Score-based generative diffusion with \"active\" correlated noise sources","summary":"  Diffusion models exhibit robust generative properties by approximating the\nunderlying distribution of a dataset and synthesizing data by sampling from the\napproximated distribution. In this work, we explore how the generative\nperformance may be be modulated if noise sources with temporal correlations --\nakin to those used in the field of active matter -- are used for the\ndestruction of the data in the forward process. Our numerical and analytical\nexperiments suggest that the corresponding reverse process may exhibit improved\ngenerative properties.\n","authors":["Alexandra Lamtyugina","Agnish Kumar Behera","Aditya Nandy","Carlos Floyd","Suriyanarayanan Vaikuntanathan"],"pdf_url":"https://arxiv.org/pdf/2411.07233v1.pdf","comment":"18 pages, 11 figures"},{"id":"http://arxiv.org/abs/2411.07232v1","updated":"2024-11-11T18:50:09Z","published":"2024-11-11T18:50:09Z","title":"Add-it: Training-Free Object Insertion in Images With Pretrained\n  Diffusion Models","summary":"  Adding Object into images based on text instructions is a challenging task in\nsemantic image editing, requiring a balance between preserving the original\nscene and seamlessly integrating the new object in a fitting location. Despite\nextensive efforts, existing models often struggle with this balance,\nparticularly with finding a natural location for adding an object in complex\nscenes. We introduce Add-it, a training-free approach that extends diffusion\nmodels' attention mechanisms to incorporate information from three key sources:\nthe scene image, the text prompt, and the generated image itself. Our weighted\nextended-attention mechanism maintains structural consistency and fine details\nwhile ensuring natural object placement. Without task-specific fine-tuning,\nAdd-it achieves state-of-the-art results on both real and generated image\ninsertion benchmarks, including our newly constructed \"Additing Affordance\nBenchmark\" for evaluating object placement plausibility, outperforming\nsupervised methods. Human evaluations show that Add-it is preferred in over 80%\nof cases, and it also demonstrates improvements in various automated metrics.\n","authors":["Yoad Tewel","Rinon Gal","Dvir Samuel Yuval Atzmon","Lior Wolf","Gal Chechik"],"pdf_url":"https://arxiv.org/pdf/2411.07232v1.pdf","comment":"Project page is at https://research.nvidia.com/labs/par/addit/"},{"id":"http://arxiv.org/abs/2410.24210v2","updated":"2024-11-11T18:46:06Z","published":"2024-10-31T17:58:41Z","title":"TabM: Advancing Tabular Deep Learning with Parameter-Efficient\n  Ensembling","summary":"  Deep learning architectures for supervised learning on tabular data range\nfrom simple multilayer perceptrons (MLP) to sophisticated Transformers and\nretrieval-augmented methods. This study highlights a major, yet so far\noverlooked opportunity for substantially improving tabular MLPs: namely,\nparameter-efficient ensembling -- a paradigm for implementing an ensemble of\nmodels as one model producing multiple predictions. We start by developing TabM\n-- a simple model based on MLP and our variations of BatchEnsemble (an existing\ntechnique). Then, we perform a large-scale evaluation of tabular DL\narchitectures on public benchmarks in terms of both task performance and\nefficiency, which renders the landscape of tabular DL in a new light.\nGenerally, we show that MLPs, including TabM, form a line of stronger and more\npractical models compared to attention- and retrieval-based architectures. In\nparticular, we find that TabM demonstrates the best performance among tabular\nDL models. Lastly, we conduct an empirical analysis on the ensemble-like nature\nof TabM. For example, we observe that the multiple predictions of TabM are weak\nindividually, but powerful collectively. Overall, our work brings an impactful\ntechnique to tabular DL, analyses its behaviour, and advances the\nperformance-efficiency trade-off with TabM -- a simple and powerful baseline\nfor researchers and practitioners.\n","authors":["Yury Gorishniy","Akim Kotelnikov","Artem Babenko"],"pdf_url":"https://arxiv.org/pdf/2410.24210v2.pdf","comment":"Code: https://github.com/yandex-research/tabm (v2: minor changes)"},{"id":"http://arxiv.org/abs/2411.07223v1","updated":"2024-11-11T18:43:44Z","published":"2024-11-11T18:43:44Z","title":"Grounding Video Models to Actions through Goal Conditioned Exploration","summary":"  Large video models, pretrained on massive amounts of Internet video, provide\na rich source of physical knowledge about the dynamics and motions of objects\nand tasks. However, video models are not grounded in the embodiment of an\nagent, and do not describe how to actuate the world to reach the visual states\ndepicted in a video. To tackle this problem, current methods use a separate\nvision-based inverse dynamic model trained on embodiment-specific data to map\nimage states to actions. Gathering data to train such a model is often\nexpensive and challenging, and this model is limited to visual settings similar\nto the ones in which data are available. In this paper, we investigate how to\ndirectly ground video models to continuous actions through self-exploration in\nthe embodied environment -- using generated video states as visual goals for\nexploration. We propose a framework that uses trajectory level action\ngeneration in combination with video guidance to enable an agent to solve\ncomplex tasks without any external supervision, e.g., rewards, action labels,\nor segmentation masks. We validate the proposed approach on 8 tasks in Libero,\n6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual\nNavigation. We show how our approach is on par with or even surpasses multiple\nbehavior cloning baselines trained on expert demonstrations while without\nrequiring any action annotations.\n","authors":["Yunhao Luo","Yilun Du"],"pdf_url":"https://arxiv.org/pdf/2411.07223v1.pdf","comment":"Project page at https://video-to-action.github.io/"},{"id":"http://arxiv.org/abs/2409.12197v3","updated":"2024-11-11T18:42:57Z","published":"2024-09-04T13:56:49Z","title":"Nteasee: A mixed methods study of expert and general population\n  perspectives on deploying AI for health in African countries","summary":"  Artificial Intelligence (AI) for health has the potential to significantly\nchange and improve healthcare. However in most African countries, identifying\nculturally and contextually attuned approaches for deploying these solutions is\nnot well understood. To bridge this gap, we conduct a qualitative study to\ninvestigate the best practices, fairness indicators, and potential biases to\nmitigate when deploying AI for health in African countries, as well as explore\nopportunities where artificial intelligence could make a positive impact in\nhealth. We used a mixed methods approach combining in-depth interviews (IDIs)\nand surveys. We conduct 1.5-2 hour long IDIs with 50 experts in health, policy,\nand AI across 17 countries, and through an inductive approach we conduct a\nqualitative thematic analysis on expert IDI responses. We administer a blinded\n30-minute survey with case studies to 672 general population participants\nacross 5 countries in Africa and analyze responses on quantitative scales,\nstatistically comparing responses by country, age, gender, and level of\nfamiliarity with AI. We thematically summarize open-ended responses from\nsurveys. Our results find generally positive attitudes, high levels of trust,\naccompanied by moderate levels of concern among general population participants\nfor AI usage for health in Africa. This contrasts with expert responses, where\nmajor themes revolved around trust/mistrust, ethical concerns, and systemic\nbarriers to integration, among others. This work presents the first-of-its-kind\nqualitative research study of the potential of AI for health in Africa from an\nalgorithmic fairness angle, with perspectives from both experts and the general\npopulation. We hope that this work guides policymakers and drives home the need\nfor further research and the inclusion of general population perspectives in\ndecision-making around AI usage.\n","authors":["Mercy Nyamewaa Asiedu","Iskandar Haykel","Awa Dieng","Kerrie Kauer","Tousif Ahmed","Florence Ofori","Charisma Chan","Stephen Pfohl","Negar Rostamzadeh","Katherine Heller"],"pdf_url":"https://arxiv.org/pdf/2409.12197v3.pdf","comment":"added illustrative figures"},{"id":"http://arxiv.org/abs/2411.03755v2","updated":"2024-11-11T18:40:09Z","published":"2024-11-06T08:30:23Z","title":"Content-Style Learning from Unaligned Domains: Identifiability under\n  Unknown Latent Dimensions","summary":"  Understanding identifiability of latent content and style variables from\nunaligned multi-domain data is essential for tasks such as domain translation\nand data generation. Existing works on content-style identification were often\ndeveloped under somewhat stringent conditions, e.g., that all latent components\nare mutually independent and that the dimensions of the content and style\nvariables are known. We introduce a new analytical framework via cross-domain\n\\textit{latent distribution matching} (LDM), which establishes content-style\nidentifiability under substantially more relaxed conditions. Specifically, we\nshow that restrictive assumptions such as component-wise independence of the\nlatent variables can be removed. Most notably, we prove that prior knowledge of\nthe content and style dimensions is not necessary for ensuring identifiability,\nif sparsity constraints are properly imposed onto the learned latent\nrepresentations. Bypassing the knowledge of the exact latent dimension has been\na longstanding aspiration in unsupervised representation learning -- our\nanalysis is the first to underpin its theoretical and practical viability. On\nthe implementation side, we recast the LDM formulation into a regularized\nmulti-domain GAN loss with coupled latent variables. We show that the\nreformulation is equivalent to LDM under mild conditions -- yet requiring\nconsiderably less computational resource. Experiments corroborate with our\ntheoretical claims.\n","authors":["Sagar Shrestha","Xiao Fu"],"pdf_url":"https://arxiv.org/pdf/2411.03755v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02150v2","updated":"2024-11-11T18:38:32Z","published":"2023-06-03T16:36:43Z","title":"An information field theory approach to Bayesian state and parameter\n  estimation in dynamical systems","summary":"  Dynamical system state estimation and parameter calibration problems are\nubiquitous across science and engineering. Bayesian approaches to the problem\nare the gold standard as they allow for the quantification of uncertainties and\nenable the seamless fusion of different experimental modalities. When the\ndynamics are discrete and stochastic, one may employ powerful techniques such\nas Kalman, particle, or variational filters. Practitioners commonly apply these\nmethods to continuous-time, deterministic dynamical systems after discretizing\nthe dynamics and introducing fictitious transition probabilities. However,\napproaches based on time-discretization suffer from the curse of dimensionality\nsince the number of random variables grows linearly with the number of\ntime-steps. Furthermore, the introduction of fictitious transition\nprobabilities is an unsatisfactory solution because it increases the number of\nmodel parameters and may lead to inference bias. To address these drawbacks,\nthe objective of this paper is to develop a scalable Bayesian approach to state\nand parameter estimation suitable for continuous-time, deterministic dynamical\nsystems. Our methodology builds upon information field theory. Specifically, we\nconstruct a physics-informed prior probability measure on the function space of\nsystem responses so that functions that satisfy the physics are more likely.\nThis prior allows us to quantify model form errors. We connect the system's\nresponse to observations through a probabilistic model of the measurement\nprocess. The joint posterior over the system responses and all parameters is\ngiven by Bayes' rule. To approximate the intractable posterior, we develop a\nstochastic variational inference algorithm. In summary, the developed\nmethodology offers a powerful framework for Bayesian estimation in dynamical\nsystems.\n","authors":["Kairui Hao","Ilias Bilionis"],"pdf_url":"https://arxiv.org/pdf/2306.02150v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07217v1","updated":"2024-11-11T18:38:22Z","published":"2024-11-11T18:38:22Z","title":"Feature Selection Based on Wasserstein Distance","summary":"  In this paper, we present a novel feature selection method based on the\nWasserstein distance. Feature selection plays a critical role in reducing the\ndimensionality of input data, thereby improving machine learning efficiency and\ngeneralization performance. Unlike traditional feature selection approaches\nthat rely on criteria such as correlation or KL divergence, our method\nleverages the Wasserstein distance to measure the similarity between\ndistributions of selected features and original features. This approach\ninherently accounts for similarities between classes, making it robust in\nscenarios involving noisy labels. Experimental results demonstrate that our\nmethod outperforms traditional approaches, particularly in challenging settings\ninvolving noisy labeled data.\n","authors":["Fuwei Li"],"pdf_url":"https://arxiv.org/pdf/2411.07217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.13020v2","updated":"2024-11-11T18:37:22Z","published":"2024-04-19T17:30:10Z","title":"Stronger Random Baselines for In-Context Learning","summary":"  Evaluating the in-context learning classification performance of language\nmodels poses challenges due to small dataset sizes, extensive prompt-selection\nusing the validation set, and intentionally difficult tasks that lead to\nnear-random performance. The standard random baseline--the expected accuracy of\nguessing labels uniformly at random--is stable when the evaluation set is used\nonly once or when the dataset is large. We account for the common practice of\nvalidation set reuse and existing small datasets with a stronger random\nbaseline: the expected maximum accuracy across multiple random classifiers.\nWhen choosing the best prompt demonstrations across six quantized language\nmodels applied to 16 BIG-bench Lite tasks, more than 20% of the few-shot\nresults that exceed the standard baseline do not exceed this stronger random\nbaseline. When held-out test sets are available, this stronger baseline is also\na better predictor of held-out performance than the standard baseline, avoiding\nunnecessary test set evaluations. This maximum random baseline provides an\neasily calculated drop-in replacement for the standard baseline.\n","authors":["Gregory Yauney","David Mimno"],"pdf_url":"https://arxiv.org/pdf/2404.13020v2.pdf","comment":"Published at COLM 2024"},{"id":"http://arxiv.org/abs/2411.07213v1","updated":"2024-11-11T18:36:17Z","published":"2024-11-11T18:36:17Z","title":"Comparing Bottom-Up and Top-Down Steering Approaches on In-Context\n  Learning Tasks","summary":"  A key objective of interpretability research on large language models (LLMs)\nis to develop methods for robustly steering models toward desired behaviors. To\nthis end, two distinct approaches to interpretability -- ``bottom-up\" and\n``top-down\" -- have been presented, but there has been little quantitative\ncomparison between them. We present a case study comparing the effectiveness of\nrepresentative vector steering methods from each branch: function vectors (FV;\narXiv:2310.15213), as a bottom-up method, and in-context vectors (ICV;\narXiv:2311.06668) as a top-down method. While both aim to capture compact\nrepresentations of broad in-context learning tasks, we find they are effective\nonly on specific types of tasks: ICVs outperform FVs in behavioral shifting,\nwhereas FVs excel in tasks requiring more precision. We discuss the\nimplications for future evaluations of steering methods and for further\nresearch into top-down and bottom-up steering given these findings.\n","authors":["Madeline Brumley","Joe Kwon","David Krueger","Dmitrii Krasheninnikov","Usman Anwar"],"pdf_url":"https://arxiv.org/pdf/2411.07213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07207v1","updated":"2024-11-11T18:32:44Z","published":"2024-11-11T18:32:44Z","title":"General Geospatial Inference with a Population Dynamics Foundation Model","summary":"  Supporting the health and well-being of dynamic populations around the world\nrequires governmental agencies, organizations and researchers to understand and\nreason over complex relationships between human behavior and local contexts in\norder to identify high-risk groups and strategically allocate limited\nresources. Traditional approaches to these classes of problems often entail\ndeveloping manually curated, task-specific features and models to represent\nhuman behavior and the natural and built environment, which can be challenging\nto adapt to new, or even, related tasks. To address this, we introduce a\nPopulation Dynamics Foundation Model (PDFM) that aims to capture the\nrelationships between diverse data modalities and is applicable to a broad\nrange of geospatial tasks. We first construct a geo-indexed dataset for postal\ncodes and counties across the United States, capturing rich aggregated\ninformation on human behavior from maps, busyness, and aggregated search\ntrends, and environmental factors such as weather and air quality. We then\nmodel this data and the complex relationships between locations using a graph\nneural network, producing embeddings that can be adapted to a wide range of\ndownstream tasks using relatively simple models. We evaluate the effectiveness\nof our approach by benchmarking it on 27 downstream tasks spanning three\ndistinct domains: health indicators, socioeconomic factors, and environmental\nmeasurements. The approach achieves state-of-the-art performance on all 27\ngeospatial interpolation tasks, and on 25 out of the 27 extrapolation and\nsuper-resolution tasks. We combined the PDFM with a state-of-the-art\nforecasting foundation model, TimesFM, to predict unemployment and poverty,\nachieving performance that surpasses fully supervised forecasting. The full set\nof embeddings and sample code are publicly available for researchers.\n","authors":["Mohit Agarwal","Mimi Sun","Chaitanya Kamath","Arbaaz Muslim","Prithul Sarker","Joydeep Paul","Hector Yee","Marcin Sieniek","Kim Jablonski","Yael Mayer","David Fork","Sheila de Guia","Jamie McPike","Adam Boulanger","Tomer Shekel","David Schottlander","Yao Xiao","Manjit Chakravarthy Manukonda","Yun Liu","Neslihan Bulut","Sami Abu-el-haija","Arno Eigenwillig","Parth Kothari","Bryan Perozzi","Monica Bharel","Von Nguyen","Luke Barrington","Niv Efron","Yossi Matias","Greg Corrado","Krish Eswaran","Shruthi Prabhakara","Shravya Shetty","Gautam Prasad"],"pdf_url":"https://arxiv.org/pdf/2411.07207v1.pdf","comment":"28 pages, 16 figures, preprint"},{"id":"http://arxiv.org/abs/2409.06754v4","updated":"2024-11-11T18:32:16Z","published":"2024-09-10T16:05:02Z","title":"Scaling Law Hypothesis for Multimodal Model","summary":"  We propose a scaling law hypothesis for multimodal models processing text,\naudio, images, and video within a shared token and embedding space. Our\nframework predicts model performance based on modality-specific compression and\ntokenization efficiency, extending established scaling laws from text-based\ndecoder models to mixed-modality systems. We explore whether leveraging more\ntraining data in multiple modalities can reduce the size of the multimodal\nmodel, enabling efficient deployment on resource-constrained devices.\n","authors":["Qingyun Sun","Zhen Guo","PIN AI Team"],"pdf_url":"https://arxiv.org/pdf/2409.06754v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07192v1","updated":"2024-11-11T18:08:17Z","published":"2024-11-11T18:08:17Z","title":"Data-Driven Predictive Control of Nonholonomic Robots Based on a\n  Bilinear Koopman Realization: Data Does Not Replace Geometry","summary":"  Advances in machine learning and the growing trend towards effortless data\ngeneration in real-world systems has led to an increasing interest for\ndata-inferred models and data-based control in robotics. It seems appealing to\ngovern robots solely based on data, bypassing the traditional, more elaborate\npipeline of system modeling through first-principles and subsequent controller\ndesign. One promising data-driven approach is the Extended Dynamic Mode\nDecomposition (EDMD) for control-affine systems, a system class which contains\nmany vehicles and machines of immense practical importance including, e.g.,\ntypical wheeled mobile robots. EDMD can be highly data-efficient,\ncomputationally inexpensive, can deal with nonlinear dynamics as prevalent in\nrobotics and mechanics, and has a sound theoretical foundation rooted in\nKoopman theory. On this background, this present paper examines how EDMD models\ncan be integrated into predictive controllers for nonholonomic mobile robots.\nIn addition to the conventional kinematic mobile robot, we also cover the\ncomplete data-driven control pipeline - from data acquisition to control design\n- when the robot is not treated in terms of first-order kinematics but in a\nsecond-order manner, allowing to account for actuator dynamics. Using only\nreal-world measurement data, it is shown in both simulations and hardware\nexperiments that the surrogate models enable high-precision predictive\ncontrollers in the studied cases. However, the findings raise significant\nconcerns about purely data-centric approaches that overlook the underlying\ngeometry of nonholonomic systems, showing that, for nonholonomic systems, some\ngeometric insight seems necessary and cannot be easily compensated for with\nlarge amounts of data.\n","authors":["Mario Rosenfelder","Lea Bold","Hannes Eschmann","Peter Eberhard","Karl Worthmann","Henrik Ebel"],"pdf_url":"https://arxiv.org/pdf/2411.07192v1.pdf","comment":"23 pages, 12 figures"},{"id":"http://arxiv.org/abs/2402.09821v3","updated":"2024-11-11T18:07:26Z","published":"2024-02-15T09:36:36Z","title":"Diffusion Models for Audio Restoration","summary":"  With the development of audio playback devices and fast data transmission,\nthe demand for high sound quality is rising for both entertainment and\ncommunications. In this quest for better sound quality, challenges emerge from\ndistortions and interferences originating at the recording side or caused by an\nimperfect transmission pipeline. To address this problem, audio restoration\nmethods aim to recover clean sound signals from the corrupted input data. We\npresent here audio restoration algorithms based on diffusion models, with a\nfocus on speech enhancement and music restoration tasks. Traditional\napproaches, often grounded in handcrafted rules and statistical heuristics,\nhave shaped our understanding of audio signals. In the past decades, there has\nbeen a notable shift towards data-driven methods that exploit the modeling\ncapabilities of DNNs. Deep generative models, and among them diffusion models,\nhave emerged as powerful techniques for learning complex data distributions.\nHowever, relying solely on DNN-based learning approaches carries the risk of\nreducing interpretability, particularly when employing end-to-end models.\nNonetheless, data-driven approaches allow more flexibility in comparison to\nstatistical model-based frameworks, whose performance depends on distributional\nand statistical assumptions that can be difficult to guarantee. Here, we aim to\nshow that diffusion models can combine the best of both worlds and offer the\nopportunity to design audio restoration algorithms with a good degree of\ninterpretability and a remarkable performance in terms of sound quality. We\nexplain the diffusion formalism and its application to the conditional\ngeneration of clean audio signals. We believe that diffusion models open an\nexciting field of research with the potential to spawn new audio restoration\nalgorithms that are natural-sounding and remain robust in difficult acoustic\nsituations.\n","authors":["Jean-Marie Lemercier","Julius Richter","Simon Welker","Eloi Moliner","Vesa Välimäki","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2402.09821v3.pdf","comment":"Currently in revision for IEEE Signal Processing Magazine Special\n  Issue \"Model-based and Data-Driven Audio Signal Processing\""},{"id":"http://arxiv.org/abs/2411.07186v1","updated":"2024-11-11T18:01:45Z","published":"2024-11-11T18:01:45Z","title":"NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics","summary":"  Large language models (LLMs) prompted with text and audio represent the state\nof the art in various auditory tasks, including speech, music, and general\naudio, showing emergent abilities on unseen tasks. However, these capabilities\nhave yet to be fully demonstrated in bioacoustics tasks, such as detecting\nanimal vocalizations in large recordings, classifying rare and endangered\nspecies, and labeling context and behavior - tasks that are crucial for\nconservation, biodiversity monitoring, and the study of animal behavior. In\nthis work, we present NatureLM-audio, the first audio-language foundation model\nspecifically designed for bioacoustics. Our carefully curated training dataset\ncomprises text-audio pairs spanning a diverse range of bioacoustics, speech,\nand music data, designed to address the challenges posed by limited annotated\ndatasets in the field. We demonstrate successful transfer of learned\nrepresentations from music and speech to bioacoustics, and our model shows\npromising generalization to unseen taxa and tasks. Importantly, we test\nNatureLM-audio on a novel benchmark (BEANS-Zero) and it sets the new state of\nthe art (SotA) on several bioacoustics tasks, including zero-shot\nclassification of unseen species. To advance bioacoustics research, we also\nopen-source the code for generating training and benchmark data, as well as for\ntraining the model.\n","authors":["David Robinson","Marius Miron","Masato Hagiwara","Olivier Pietquin"],"pdf_url":"https://arxiv.org/pdf/2411.07186v1.pdf","comment":"Demo page: https://earthspecies.github.io/naturelm-audio-demo/ The\n  code will be open-sourced and available shortly"},{"id":"http://arxiv.org/abs/2411.07185v1","updated":"2024-11-11T17:59:21Z","published":"2024-11-11T17:59:21Z","title":"Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised\n  Domain Adaptation","summary":"  Multi-source unsupervised domain adaptation aims to leverage labeled data\nfrom multiple source domains for training a machine learning model to\ngeneralize well on a target domain without labels. Source domain selection\nplays a crucial role in determining the model's performance. It relies on the\nsimilarities amongst source and target domains. Nonetheless, existing work for\nsource domain selection often involves heavyweight computational procedures,\nespecially when dealing with numerous source domains and the need to identify\nthe best ones from them. In this paper, we introduce a framework for gradual\nfine tuning (GFT) of machine learning models on multiple source domains. We\nrepresent multiple source domains as an undirected weighted graph. We then give\na new generalization error bound for GFT along any path within the graph, which\nis used to determine the optimal path corresponding to the optimal training\norder. With this formulation, we introduce three lightweight graph-routing\nstrategies which tend to minimize the error bound. Our best strategy improves\n$2.3\\%$ of accuracy over the state-of-the-art on Natural Language Inference\n(NLI) task and achieves competitive performance on Sentiment Analysis (SA)\ntask, especially a $3.9\\%$ improvement on a more diverse subset of data we use\nfor SA.\n","authors":["Yao Ma","Samuel Louvan","Zhunxuan Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07185v1.pdf","comment":"In Proceedings of the 3rd Conference on Lifelong Learning Agents\n  (CoLLAs 2024)"},{"id":"http://arxiv.org/abs/2411.07182v1","updated":"2024-11-11T17:58:28Z","published":"2024-11-11T17:58:28Z","title":"Revisiting Ensembling in One-Shot Federated Learning","summary":"  Federated learning (FL) is an appealing approach to training machine learning\nmodels without sharing raw data. However, standard FL algorithms are iterative\nand thus induce a significant communication cost. One-shot federated learning\n(OFL) trades the iterative exchange of models between clients and the server\nwith a single round of communication, thereby saving substantially on\ncommunication costs. Not surprisingly, OFL exhibits a performance gap in terms\nof accuracy with respect to FL, especially under high data heterogeneity. We\nintroduce FENS, a novel federated ensembling scheme that approaches the\naccuracy of FL with the communication efficiency of OFL. Learning in FENS\nproceeds in two phases: first, clients train models locally and send them to\nthe server, similar to OFL; second, clients collaboratively train a lightweight\nprediction aggregator model using FL. We showcase the effectiveness of FENS\nthrough exhaustive experiments spanning several datasets and heterogeneity\nlevels. In the particular case of heterogeneously distributed CIFAR-10 dataset,\nFENS achieves up to a 26.9% higher accuracy over state-of-the-art (SOTA) OFL,\nbeing only 3.1% lower than FL. At the same time, FENS incurs at most 4.3x more\ncommunication than OFL, whereas FL is at least 10.9x more\ncommunication-intensive than FENS.\n","authors":["Youssef Allouah","Akash Dhasade","Rachid Guerraoui","Nirupam Gupta","Anne-Marie Kermarrec","Rafael Pinot","Rafael Pires","Rishi Sharma"],"pdf_url":"https://arxiv.org/pdf/2411.07182v1.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07180v1","updated":"2024-11-11T17:57:30Z","published":"2024-11-11T17:57:30Z","title":"Counterfactual Generation from Language Models","summary":"  Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to intervene on\nthese models. To understand the impact of interventions precisely, it is useful\nto examine counterfactuals -- e.g., how a given sentence would have appeared\nhad it been generated by the model following a specific intervention. We\nhighlight that counterfactual reasoning is conceptually distinct from\ninterventions, as articulated in Pearl's causal hierarchy. Based on this\nobservation, we propose a framework for generating true string counterfactuals\nby reformulating language models as Generalized Structural-equation. Models\nusing the Gumbel-max trick. This allows us to model the joint distribution over\noriginal strings and their counterfactuals resulting from the same\ninstantiation of the sampling noise. We develop an algorithm based on hindsight\nGumbel sampling that allows us to infer the latent noise variables and generate\ncounterfactuals of observed strings. Our experiments demonstrate that the\napproach produces meaningful counterfactuals while at the same time showing\nthat commonly used intervention techniques have considerable undesired side\neffects.\n","authors":["Shauli Ravfogel","Anej Svete","Vésteinn Snæbjarnarson","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07180v1.pdf","comment":"A preprint"},{"id":"http://arxiv.org/abs/2411.07179v1","updated":"2024-11-11T17:57:25Z","published":"2024-11-11T17:57:25Z","title":"Joint Age-State Belief is All You Need: Minimizing AoII via Pull-Based\n  Remote Estimation","summary":"  Age of incorrect information (AoII) is a recently proposed freshness and\nmismatch metric that penalizes an incorrect estimation along with its duration.\nTherefore, keeping track of AoII requires the knowledge of both the source and\nestimation processes. In this paper, we consider a time-slotted pull-based\nremote estimation system under a sampling rate constraint where the information\nsource is a general discrete-time Markov chain (DTMC) process. Moreover, packet\ntransmission times from the source to the monitor are non-zero which disallows\nthe monitor to have perfect information on the actual AoII process at any time.\nHence, for this pull-based system, we propose the monitor to maintain a\nsufficient statistic called {\\em belief} which stands for the joint\ndistribution of the age and source processes to be obtained from the history of\nall observations. Using belief, we first propose a maximum a posteriori (MAP)\nestimator to be used at the monitor as opposed to existing martingale\nestimators in the literature. Second, we obtain the optimality equations from\nthe belief-MDP (Markov decision process) formulation. Finally, we propose two\nbelief-dependent policies one of which is based on deep reinforcement learning,\nand the other one is a threshold-based policy based on the instantaneous\nexpected AoII.\n","authors":["Ismail Cosandal","Sennur Ulukus","Nail Akar"],"pdf_url":"https://arxiv.org/pdf/2411.07179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07176v1","updated":"2024-11-11T17:56:28Z","published":"2024-11-11T17:56:28Z","title":"More Expressive Attention with Negative Weights","summary":"  We propose a novel attention mechanism, named Cog Attention, that enables\nattention weights to be negative for enhanced expressiveness, which stems from\ntwo key factors: (1) Cog Attention can shift the token deletion and copying\nfunction from a static OV matrix to dynamic QK inner products, with the OV\nmatrix now focusing more on refinement or modification. The attention head can\nsimultaneously delete, copy, or retain tokens by assigning them negative,\npositive, or minimal attention weights, respectively. As a result, a single\nattention head becomes more flexible and expressive. (2) Cog Attention improves\nthe model's robustness against representational collapse, which can occur when\nearlier tokens are over-squashed into later positions, leading to homogeneous\nrepresentations. Negative weights reduce effective information paths from\nearlier to later tokens, helping to mitigate this issue. We develop\nTransformer-like models which use Cog Attention as attention modules, including\ndecoder-only models for language modeling and U-ViT diffusion models for image\ngeneration. Experiments show that models using Cog Attention exhibit superior\nperformance compared to those employing traditional softmax attention modules.\nOur approach suggests a promising research direction for rethinking and\nbreaking the entrenched constraints of traditional softmax attention, such as\nthe requirement for non-negative weights.\n","authors":["Ang Lv","Ruobing Xie","Shuaipeng Li","Jiayi Liao","Xingwu Sun","Zhanhui Kang","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2411.07176v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.20025v2","updated":"2024-11-11T17:53:15Z","published":"2023-05-31T16:54:25Z","title":"Mutual Information Estimation via $f$-Divergence and Data Derangements","summary":"  Estimating mutual information accurately is pivotal across diverse\napplications, from machine learning to communications and biology, enabling us\nto gain insights into the inner mechanisms of complex systems. Yet, dealing\nwith high-dimensional data presents a formidable challenge, due to its size and\nthe presence of intricate relationships. Recently proposed neural methods\nemploying variational lower bounds on the mutual information have gained\nprominence. However, these approaches suffer from either high bias or high\nvariance, as the sample size and the structure of the loss function directly\ninfluence the training process. In this paper, we propose a novel class of\ndiscriminative mutual information estimators based on the variational\nrepresentation of the $f$-divergence. We investigate the impact of the\npermutation function used to obtain the marginal training samples and present a\nnovel architectural solution based on derangements. The proposed estimator is\nflexible since it exhibits an excellent bias/variance trade-off. The comparison\nwith state-of-the-art neural estimators, through extensive experimentation\nwithin established reference scenarios, shows that our approach offers higher\naccuracy and lower complexity.\n","authors":["Nunzio A. Letizia","Nicola Novello","Andrea M. Tonello"],"pdf_url":"https://arxiv.org/pdf/2305.20025v2.pdf","comment":"Accepted at NeurIPS 2024. Code available at\n  https://github.com/tonellolab/fDIME"},{"id":"http://arxiv.org/abs/2411.07171v1","updated":"2024-11-11T17:49:47Z","published":"2024-11-11T17:49:47Z","title":"Anytime Sequential Halving in Monte-Carlo Tree Search","summary":"  Monte-Carlo Tree Search (MCTS) typically uses multi-armed bandit (MAB)\nstrategies designed to minimize cumulative regret, such as UCB1, as its\nselection strategy. However, in the root node of the search tree, it is more\nsensible to minimize simple regret. Previous work has proposed using Sequential\nHalving as selection strategy in the root node, as, in theory, it performs\nbetter with respect to simple regret. However, Sequential Halving requires a\nbudget of iterations to be predetermined, which is often impractical. This\npaper proposes an anytime version of the algorithm, which can be halted at any\narbitrary time and still return a satisfactory result, while being designed\nsuch that it approximates the behavior of Sequential Halving. Empirical results\nin synthetic MAB problems and ten different board games demonstrate that the\nalgorithm's performance is competitive with Sequential Halving and UCB1 (and\ntheir analogues in MCTS).\n","authors":["Dominic Sagers","Mark H. M. Winands","Dennis J. N. J. Soemers"],"pdf_url":"https://arxiv.org/pdf/2411.07171v1.pdf","comment":"Accepted by the Computers and Games 2024 conference"},{"id":"http://arxiv.org/abs/2411.07168v1","updated":"2024-11-11T17:48:04Z","published":"2024-11-11T17:48:04Z","title":"Enhancing Predictive Maintenance in Mining Mobile Machinery through a\n  TinyML-enabled Hierarchical Inference Network","summary":"  Mining machinery operating in variable environments faces high wear and\nunpredictable stress, challenging Predictive Maintenance (PdM). This paper\nintroduces the Edge Sensor Network for Predictive Maintenance (ESN-PdM), a\nhierarchical inference framework across edge devices, gateways, and cloud\nservices for real-time condition monitoring. The system dynamically adjusts\ninference locations--on-device, on-gateway, or on-cloud--based on trade-offs\namong accuracy, latency, and battery life, leveraging Tiny Machine Learning\n(TinyML) techniques for model optimization on resource-constrained devices.\nPerformance evaluations showed that on-sensor and on-gateway inference modes\nachieved over 90\\% classification accuracy, while cloud-based inference reached\n99\\%. On-sensor inference reduced power consumption by approximately 44\\%,\nenabling up to 104 hours of operation. Latency was lowest for on-device\ninference (3.33 ms), increasing when offloading to the gateway (146.67 ms) or\ncloud (641.71 ms). The ESN-PdM framework provides a scalable, adaptive solution\nfor reliable anomaly detection and PdM, crucial for maintaining machinery\nuptime in remote environments. By balancing accuracy, latency, and energy\nconsumption, this approach advances PdM frameworks for industrial applications.\n","authors":["Raúl de la Fuente","Luciano Radrigan","Anibal S Morales"],"pdf_url":"https://arxiv.org/pdf/2411.07168v1.pdf","comment":"This work has been submitted to the IEEE Access for possible\n  publication"},{"id":"http://arxiv.org/abs/2411.07154v1","updated":"2024-11-11T17:32:47Z","published":"2024-11-11T17:32:47Z","title":"Conditional simulation via entropic optimal transport: Toward\n  non-parametric estimation of conditional Brenier maps","summary":"  Conditional simulation is a fundamental task in statistical modeling:\nGenerate samples from the conditionals given finitely many data points from a\njoint distribution. One promising approach is to construct conditional Brenier\nmaps, where the components of the map pushforward a reference distribution to\nconditionals of the target. While many estimators exist, few, if any, come with\nstatistical or algorithmic guarantees. To this end, we propose a non-parametric\nestimator for conditional Brenier maps based on the computational scalability\nof \\emph{entropic} optimal transport. Our estimator leverages a result of\nCarlier et al. (2010), which shows that optimal transport maps under a rescaled\nquadratic cost asymptotically converge to conditional Brenier maps; our\nestimator is precisely the entropic analogues of these converging maps. We\nprovide heuristic justifications for choosing the scaling parameter in the cost\nas a function of the number of samples by fully characterizing the Gaussian\nsetting. We conclude by comparing the performance of the estimator to other\nmachine learning and non-parametric approaches on benchmark datasets and\nBayesian inference problems.\n","authors":["Ricardo Baptista","Aram-Alexandre Pooladian","Michael Brennan","Youssef Marzouk","Jonathan Niles-Weed"],"pdf_url":"https://arxiv.org/pdf/2411.07154v1.pdf","comment":"26 pages, 4 figures"},{"id":"http://arxiv.org/abs/2312.04528v2","updated":"2024-11-11T17:30:55Z","published":"2023-12-07T18:46:50Z","title":"Using Large Language Models for Hyperparameter Optimization","summary":"  This paper explores the use of foundational large language models (LLMs) in\nhyperparameter optimization (HPO). Hyperparameters are critical in determining\nthe effectiveness of machine learning models, yet their optimization often\nrelies on manual approaches in limited-budget settings. By prompting LLMs with\ndataset and model descriptions, we develop a methodology where LLMs suggest\nhyperparameter configurations, which are iteratively refined based on model\nperformance. Our empirical evaluations on standard benchmarks reveal that\nwithin constrained search budgets, LLMs can match or outperform traditional HPO\nmethods like Bayesian optimization across different models on standard\nbenchmarks. Furthermore, we propose to treat the code specifying our model as a\nhyperparameter, which the LLM outputs and affords greater flexibility than\nexisting HPO approaches.\n","authors":["Michael R. Zhang","Nishkrit Desai","Juhan Bae","Jonathan Lorraine","Jimmy Ba"],"pdf_url":"https://arxiv.org/pdf/2312.04528v2.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2209.06604v2","updated":"2024-11-11T17:23:26Z","published":"2022-09-14T12:42:59Z","title":"Knowledge Transfer in Deep Reinforcement Learning via an RL-Specific\n  GAN-Based Correspondence Function","summary":"  Deep reinforcement learning has demonstrated superhuman performance in\ncomplex decision-making tasks, but it struggles with generalization and\nknowledge reuse - key aspects of true intelligence. This article introduces a\nnovel approach that modifies Cycle Generative Adversarial Networks specifically\nfor reinforcement learning, enabling effective one-to-one knowledge transfer\nbetween two tasks. Our method enhances the loss function with two new\ncomponents: model loss, which captures dynamic relationships between source and\ntarget tasks, and Q-loss, which identifies states significantly influencing the\ntarget decision policy. Tested on the 2-D Atari game Pong, our method achieved\n100% knowledge transfer in identical tasks and either 100% knowledge transfer\nor a 30% reduction in training time for a rotated task, depending on the\nnetwork architecture. In contrast, using standard Generative Adversarial\nNetworks or Cycle Generative Adversarial Networks led to worse performance than\ntraining from scratch in the majority of cases. The results demonstrate that\nthe proposed method ensured enhanced knowledge generalization in deep\nreinforcement learning.\n","authors":["Marko Ruman","Tatiana V. Guy"],"pdf_url":"https://arxiv.org/pdf/2209.06604v2.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2411.07150v1","updated":"2024-11-11T17:23:07Z","published":"2024-11-11T17:23:07Z","title":"Variational Graph Contrastive Learning","summary":"  Graph representation learning (GRL) is a fundamental task in machine\nlearning, aiming to encode high-dimensional graph-structured data into\nlow-dimensional vectors. Self-supervised learning (SSL) methods are widely used\nin GRL because they can avoid expensive human annotation. In this work, we\npropose a novel Subgraph Gaussian Embedding Contrast (SGEC) method. Our\napproach introduces a subgraph Gaussian embedding module, which adaptively maps\nsubgraphs to a structured Gaussian space, ensuring the preservation of graph\ncharacteristics while controlling the distribution of generated subgraphs. We\nemploy optimal transport distances, including Wasserstein and\nGromov-Wasserstein distances, to effectively measure the similarity between\nsubgraphs, enhancing the robustness of the contrastive learning process.\nExtensive experiments across multiple benchmarks demonstrate that SGEC\noutperforms or presents competitive performance against state-of-the-art\napproaches. Our findings provide insights into the design of SSL methods for\nGRL, emphasizing the importance of the distribution of the generated\ncontrastive pairs.\n","authors":["Shifeng Xie","Jhony H. Giraldo"],"pdf_url":"https://arxiv.org/pdf/2411.07150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02016v2","updated":"2024-11-11T17:19:18Z","published":"2024-06-04T06:56:41Z","title":"Adaptive and Optimal Second-order Optimistic Methods for Minimax\n  Optimization","summary":"  We propose adaptive, line search-free second-order methods with optimal rate\nof convergence for solving convex-concave min-max problems. By means of an\nadaptive step size, our algorithms feature a simple update rule that requires\nsolving only one linear system per iteration, eliminating the need for line\nsearch or backtracking mechanisms. Specifically, we base our algorithms on the\noptimistic method and appropriately combine it with second-order information.\nMoreover, distinct from common adaptive schemes, we define the step size\nrecursively as a function of the gradient norm and the prediction error in the\noptimistic update. We first analyze a variant where the step size requires\nknowledge of the Lipschitz constant of the Hessian. Under the additional\nassumption of Lipschitz continuous gradients, we further design a\nparameter-free version by tracking the Hessian Lipschitz constant locally and\nensuring the iterates remain bounded. We also evaluate the practical\nperformance of our algorithm by comparing it to existing second-order\nalgorithms for minimax optimization.\n","authors":["Ruichen Jiang","Ali Kavis","Qiujiang Jin","Sujay Sanghavi","Aryan Mokhtari"],"pdf_url":"https://arxiv.org/pdf/2406.02016v2.pdf","comment":"Accepted to NeurIPS 2024; 33 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.16793v6","updated":"2024-11-11T16:59:58Z","published":"2024-06-24T16:56:41Z","title":"Adam-mini: Use Fewer Learning Rates To Gain More","summary":"  We propose Adam-mini, an optimizer that achieves on par or better performance\nthan AdamW with 50% less memory footprint. Adam-mini reduces memory by cutting\ndown the learning rate resources in Adam (i.e., $1/\\sqrt{v}$). By investigating\nthe Hessian structure of neural nets, we find Adam's $v$ might not function at\nits full potential as effectively as we expected. We find that $\\geq$ 99.9% of\nthese learning rates in $v$ could be harmlessly removed if we (1) carefully\npartition the parameters into blocks following our new principle on Hessian\nstructure; (2) assign a single but good learning rate to each parameter block.\nWe then provide one simple way to find good learning rates and propose\nAdam-mini. Empirically, we verify that Adam-mini performs on par or better than\nAdamW on various language models sized from 39M to 13B for pre-training,\nsupervised fine-tuning, and RLHF. The reduced memory footprint of Adam-mini\nalso alleviates communication overheads among GPUs, thereby increasing\nthroughput. For instance, Adam-mini achieves 49.6% higher throughput than AdamW\nwhen pre-training Llama 2-7B on $2\\times$ A800-80GB GPUs, which saves 33%\nwall-clock time for pre-training.\n","authors":["Yushun Zhang","Congliang Chen","Ziniu Li","Tian Ding","Chenwei Wu","Diederik P. Kingma","Yinyu Ye","Zhi-Quan Luo","Ruoyu Sun"],"pdf_url":"https://arxiv.org/pdf/2406.16793v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04525v4","updated":"2024-11-11T16:58:38Z","published":"2024-07-05T14:11:28Z","title":"Enhancing learning in spiking neural networks through neuronal\n  heterogeneity and neuromodulatory signaling","summary":"  Recent progress in artificial intelligence (AI) has been driven by insights\nfrom neuroscience, particularly with the development of artificial neural\nnetworks (ANNs). This has significantly enhanced the replication of complex\ncognitive tasks such as vision and natural language processing. Despite these\nadvances, ANNs struggle with continual learning, adaptable knowledge transfer,\nrobustness, and resource efficiency - capabilities that biological systems\nhandle seamlessly. Specifically, ANNs often overlook the functional and\nmorphological diversity of the brain, hindering their computational\ncapabilities. Furthermore, incorporating cell-type specific neuromodulatory\neffects into ANNs with neuronal heterogeneity could enable learning at two\nspatial scales: spiking behavior at the neuronal level, and synaptic plasticity\nat the circuit level, thereby potentially enhancing their learning abilities.\nIn this article, we summarize recent bio-inspired models, learning rules and\narchitectures and propose a biologically-informed framework for enhancing ANNs.\nOur proposed dual-framework approach highlights the potential of spiking neural\nnetworks (SNNs) for emulating diverse spiking behaviors and dendritic\ncompartments to simulate morphological and functional diversity of neuronal\ncomputations. Finally, we outline how the proposed approach integrates\nbrain-inspired compartmental models and task-driven SNNs, balances\nbioinspiration and complexity, and provides scalable solutions for pressing AI\nchallenges, such as continual learning, adaptability, robustness, and\nresource-efficiency.\n","authors":["Alejandro Rodriguez-Garcia","Jie Mei","Srikanth Ramaswamy"],"pdf_url":"https://arxiv.org/pdf/2407.04525v4.pdf","comment":"30 pages, 4 figures, 3 boxes"},{"id":"http://arxiv.org/abs/2411.07127v1","updated":"2024-11-11T16:58:36Z","published":"2024-11-11T16:58:36Z","title":"Benchmarking LLMs' Judgments with No Gold Standard","summary":"  We introduce the GEM (Generative Estimator for Mutual Information), an\nevaluation metric for assessing language generation by Large Language Models\n(LLMs), particularly in generating informative judgments, without the need for\na gold standard reference. GEM broadens the scenarios where we can benchmark\nLLM generation performance-from traditional ones, like machine translation and\nsummarization, where gold standard references are readily available, to\nsubjective tasks without clear gold standards, such as academic peer review.\n  GEM uses a generative model to estimate mutual information between candidate\nand reference responses, without requiring the reference to be a gold standard.\nIn experiments on a human-annotated dataset, GEM demonstrates competitive\ncorrelations with human scores compared to the state-of-the-art GPT-4o\nExaminer, and outperforms all other baselines. Additionally, GEM is more robust\nagainst strategic manipulations, such as rephrasing or elongation, which can\nartificially inflate scores under a GPT-4o Examiner.\n  We also present GRE-bench (Generating Review Evaluation Benchmark) which\nevaluates LLMs based on how well they can generate high-quality peer reviews\nfor academic research papers. Because GRE-bench is based upon GEM, it inherits\nits robustness properties. Additionally, GRE-bench circumvents data\ncontamination problems (or data leakage) by using the continuous influx of new\nopen-access research papers and peer reviews each year. We show GRE-bench\nresults of various popular LLMs on their peer review capabilities using the\nICLR2023 dataset.\n","authors":["Shengwei Xu","Yuxuan Lu","Grant Schoenebeck","Yuqing Kong"],"pdf_url":"https://arxiv.org/pdf/2411.07127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07126v1","updated":"2024-11-11T16:58:31Z","published":"2024-11-11T16:58:31Z","title":"Edify Image: High-Quality Image Generation with Pixel Space Laplacian\n  Diffusion Models","summary":"  We introduce Edify Image, a family of diffusion models capable of generating\nphotorealistic image content with pixel-perfect accuracy. Edify Image utilizes\ncascaded pixel-space diffusion models trained using a novel Laplacian diffusion\nprocess, in which image signals at different frequency bands are attenuated at\nvarying rates. Edify Image supports a wide range of applications, including\ntext-to-image synthesis, 4K upsampling, ControlNets, 360 HDR panorama\ngeneration, and finetuning for image customization.\n","authors":[" NVIDIA"," :","Yuval Atzmon","Maciej Bala","Yogesh Balaji","Tiffany Cai","Yin Cui","Jiaojiao Fan","Yunhao Ge","Siddharth Gururani","Jacob Huffman","Ronald Isaac","Pooya Jannaty","Tero Karras","Grace Lam","J. P. Lewis","Aaron Licata","Yen-Chen Lin","Ming-Yu Liu","Qianli Ma","Arun Mallya","Ashlee Martino-Tarr","Doug Mendez","Seungjun Nah","Chris Pruett","Fitsum Reda","Jiaming Song","Ting-Chun Wang","Fangyin Wei","Xiaohui Zeng","Yu Zeng","Qinsheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07123v1","updated":"2024-11-11T16:51:51Z","published":"2024-11-11T16:51:51Z","title":"Fast and Robust Contextual Node Representation Learning over Dynamic\n  Graphs","summary":"  Real-world graphs grow rapidly with edge and vertex insertions over time,\nmotivating the problem of efficiently maintaining robust node representation\nover evolving graphs. Recent efficient GNNs are designed to decouple recursive\nmessage passing from the learning process, and favor Personalized PageRank\n(PPR) as the underlying feature propagation mechanism. However, most PPR-based\nGNNs are designed for static graphs, and efficient PPR maintenance remains as\nan open problem. Further, there is surprisingly little theoretical\njustification for the choice of PPR, despite its impressive empirical\nperformance.\n  In this paper, we are inspired by the recent PPR formulation as an explicit\n$\\ell_1$-regularized optimization problem and propose a unified dynamic graph\nlearning framework based on sparse node-wise attention. We also present a set\nof desired properties to justify the choice of PPR in STOA GNNs, and serves as\nthe guideline for future node attention designs. Meanwhile, we take advantage\nof the PPR-equivalent optimization formulation and employ the proximal gradient\nmethod (ISTA) to improve the efficiency of PPR-based GNNs upto 6 times.\nFinally, we instantiate a simple-yet-effective model (\\textsc{GoPPE}) with\nrobust positional encodings by maximizing PPR previously used as attention. The\nmodel performs comparably to or better than the STOA baselines and greatly\noutperforms when the initial node attributes are noisy during graph evolution,\ndemonstrating the effectiveness and robustness of \\textsc{GoPPE}.\n","authors":["Xingzhi Guo","Silong Wang","Baojian Zhou","Yanghua Xiao","Steven Skiena"],"pdf_url":"https://arxiv.org/pdf/2411.07123v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12732v2","updated":"2024-11-11T16:50:48Z","published":"2024-03-19T13:47:35Z","title":"Tighter Confidence Bounds for Sequential Kernel Regression","summary":"  Confidence bounds are an essential tool for rigorously quantifying the\nuncertainty of predictions. They are a core component in many sequential\nlearning and decision-making algorithms, with tighter confidence bounds giving\nrise to algorithms with better empirical performance and better performance\nguarantees. In this work, we use martingale tail inequalities to establish new\nconfidence bounds for sequential kernel regression. Our confidence bounds can\nbe computed by solving a conic program, although this bare version quickly\nbecomes impractical, because the number of variables grows with the sample\nsize. However, we show that the dual of this conic program allows us to\nefficiently compute tight confidence bounds. We prove that our new confidence\nbounds are always tighter than existing ones in this setting. We apply our\nconfidence bounds to kernel bandit problems, and we find that when our\nconfidence bounds replace existing ones, the KernelUCB (GP-UCB) algorithm has\nbetter empirical performance, a matching worst-case performance guarantee and\ncomparable computational cost.\n","authors":["Hamish Flynn","David Reeb"],"pdf_url":"https://arxiv.org/pdf/2403.12732v2.pdf","comment":"34 pages, 7 figures"},{"id":"http://arxiv.org/abs/2401.10216v2","updated":"2024-11-11T16:50:36Z","published":"2024-01-18T18:57:10Z","title":"Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt\n  Tensor Products","summary":"  Developing equivariant neural networks for the E(3) group plays an important\nrole in modeling 3D data across real-world applications. Enforcing this\nequivariance primarily involves the tensor products of irreducible\nrepresentations (irreps). However, the computational complexity of such\noperations increases significantly as higher-order tensors are used. In this\nwork, we propose a systematic approach to substantially accelerate the\ncomputation of the tensor products of irreps. We mathematically connect the\ncommonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are\nintegrals of products of three spherical harmonics. Through Gaunt coefficients,\nthe tensor product of irreps becomes equivalent to the multiplication between\nspherical functions represented by spherical harmonics. This perspective\nfurther allows us to change the basis for the equivariant operations from\nspherical harmonics to a 2D Fourier basis. Consequently, the multiplication\nbetween spherical functions represented by a 2D Fourier basis can be\nefficiently computed via the convolution theorem and Fast Fourier Transforms.\nThis transformation reduces the complexity of full tensor products of irreps\nfrom $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of\nirreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which\nserves as a new method to construct efficient equivariant operations across\ndifferent model architectures. Our experiments on the Open Catalyst Project and\n3BPA datasets demonstrate both the increased efficiency and improved\nperformance of our approach.\n","authors":["Shengjie Luo","Tianlang Chen","Aditi S. Krishnapriyan"],"pdf_url":"https://arxiv.org/pdf/2401.10216v2.pdf","comment":"36 pages; ICLR 2024 (Spotlight Presentation); Code:\n  https://github.com/lsj2408/Gaunt-Tensor-Product"},{"id":"http://arxiv.org/abs/2410.23131v3","updated":"2024-11-11T16:48:48Z","published":"2024-10-30T15:41:35Z","title":"Federated Learning under Periodic Client Participation and Heterogeneous\n  Data: A New Communication-Efficient Algorithm and Analysis","summary":"  In federated learning, it is common to assume that clients are always\navailable to participate in training, which may not be feasible with user\ndevices in practice. Recent works analyze federated learning under more\nrealistic participation patterns, such as cyclic client availability or\narbitrary participation. However, all such works either require strong\nassumptions (e.g., all clients participate almost surely within a bounded\nwindow), do not achieve linear speedup and reduced communication rounds, or are\nnot applicable in the general non-convex setting. In this work, we focus on\nnonconvex optimization and consider participation patterns in which the chance\nof participation over a fixed window of rounds is equal among all clients,\nwhich includes cyclic client availability as a special case. Under this\nsetting, we propose a new algorithm, named Amplified SCAFFOLD, and prove that\nit achieves linear speedup, reduced communication, and resilience to data\nheterogeneity simultaneously. In particular, for cyclic participation, our\nalgorithm is proved to enjoy $\\mathcal{O}(\\epsilon^{-2})$ communication rounds\nto find an $\\epsilon$-stationary point in the non-convex stochastic setting. In\ncontrast, the prior work under the same setting requires $\\mathcal{O}(\\kappa^2\n\\epsilon^{-4})$ communication rounds, where $\\kappa$ denotes the data\nheterogeneity. Therefore, our algorithm significantly reduces communication\nrounds due to better dependency in terms of $\\epsilon$ and $\\kappa$. Our\nanalysis relies on a fine-grained treatment of the nested dependence between\nclient participation and errors in the control variates, which results in\ntighter guarantees than previous work. We also provide experimental results\nwith (1) synthetic data and (2) real-world data with a large number of clients\n$(N = 250)$, demonstrating the effectiveness of our algorithm under periodic\nclient participation.\n","authors":["Michael Crawshaw","Mingrui Liu"],"pdf_url":"https://arxiv.org/pdf/2410.23131v3.pdf","comment":"Neurips 2024"},{"id":"http://arxiv.org/abs/2411.07120v1","updated":"2024-11-11T16:48:07Z","published":"2024-11-11T16:48:07Z","title":"Efficient Adaptive Optimization via Subset-Norm and Subspace-Momentum:\n  Fast, Memory-Reduced Training with Convergence Guarantees","summary":"  We introduce two complementary techniques for efficient adaptive optimization\nthat reduce memory requirements while accelerating training of large-scale\nneural networks. The first technique, Subset-Norm adaptive step size,\ngeneralizes AdaGrad-Norm and AdaGrad(-Coordinate) by reducing the second moment\nterm's memory footprint from $O(d)$ to $O(\\sqrt{d})$ through step-size sharing,\nwhere $d$ is the model size. For non-convex smooth objectives under\ncoordinate-wise sub-gaussian gradient noise, we prove a noise-adapted\nhigh-probability convergence guarantee showing improved dimensional dependence\nover existing methods. Our second technique, Subspace-Momentum, reduces the\nmomentum state's memory footprint by operating in a low-dimensional subspace\nwhile applying standard SGD in the orthogonal complement. We establish\nhigh-probability convergence rates under similar relaxed assumptions. Empirical\nevaluation on LLaMA models from 60M to 1B parameters demonstrates the\neffectiveness of our methods, where combining subset-norm with\nsubspace-momentum achieves Adam's validation perplexity in approximately half\nthe training tokens (6.8B vs 13.1B) while using only 20% of the Adam's\noptimizer-states memory footprint and requiring minimal additional\nhyperparameter tuning.\n","authors":["Thien Hang Nguyen","Huy Le Nguyen"],"pdf_url":"https://arxiv.org/pdf/2411.07120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02926v2","updated":"2024-11-11T16:47:58Z","published":"2024-11-05T09:13:53Z","title":"Privacy-Preserving Graph-Based Machine Learning with Fully Homomorphic\n  Encryption for Collaborative Anti-Money Laundering","summary":"  Combating money laundering has become increasingly complex with the rise of\ncybercrime and digitalization of financial transactions. Graph-based machine\nlearning techniques have emerged as promising tools for Anti-Money Laundering\n(AML) detection, capturing intricate relationships within money laundering\nnetworks. However, the effectiveness of AML solutions is hindered by data silos\nwithin financial institutions, limiting collaboration and overall efficacy.\nThis research presents a novel privacy-preserving approach for collaborative\nAML machine learning, facilitating secure data sharing across institutions and\nborders while preserving privacy and regulatory compliance. Leveraging Fully\nHomomorphic Encryption (FHE), computations are directly performed on encrypted\ndata, ensuring the confidentiality of financial data. Notably, FHE over the\nTorus (TFHE) was integrated with graph-based machine learning using Zama\nConcrete ML. The research contributes two key privacy-preserving pipelines.\nFirst, the development of a privacy-preserving Graph Neural Network (GNN)\npipeline was explored. Optimization techniques like quantization and pruning\nwere used to render the GNN FHE-compatible. Second, a privacy-preserving\ngraph-based XGBoost pipeline leveraging Graph Feature Preprocessor (GFP) was\nsuccessfully developed. Experiments demonstrated strong predictive performance,\nwith the XGBoost model consistently achieving over 99% accuracy, F1-score,\nprecision, and recall on the balanced AML dataset in both unencrypted and\nFHE-encrypted inference settings. On the imbalanced dataset, the incorporation\nof graph-based features improved the F1-score by 8%. The research highlights\nthe need to balance the trade-off between privacy and computational efficiency.\n","authors":["Fabrianne Effendi","Anupam Chattopadhyay"],"pdf_url":"https://arxiv.org/pdf/2411.02926v2.pdf","comment":"14th International Conference on Security, Privacy, and Applied\n  Cryptographic Engineering (SPACE) 2024"},{"id":"http://arxiv.org/abs/2411.07118v1","updated":"2024-11-11T16:45:18Z","published":"2024-11-11T16:45:18Z","title":"ConvMixFormer- A Resource-efficient Convolution Mixer for\n  Transformer-based Dynamic Hand Gesture Recognition","summary":"  Transformer models have demonstrated remarkable success in many domains such\nas natural language processing (NLP) and computer vision. With the growing\ninterest in transformer-based architectures, they are now utilized for gesture\nrecognition. So, we also explore and devise a novel ConvMixFormer architecture\nfor dynamic hand gestures. The transformers use quadratic scaling of the\nattention features with the sequential data, due to which these models are\ncomputationally complex and heavy. We have considered this drawback of the\ntransformer and designed a resource-efficient model that replaces the\nself-attention in the transformer with the simple convolutional layer-based\ntoken mixer. The computational cost and the parameters used for the\nconvolution-based mixer are comparatively less than the quadratic\nself-attention. Convolution-mixer helps the model capture the local spatial\nfeatures that self-attention struggles to capture due to their sequential\nprocessing nature. Further, an efficient gate mechanism is employed instead of\na conventional feed-forward network in the transformer to help the model\ncontrol the flow of features within different stages of the proposed model.\nThis design uses fewer learnable parameters which is nearly half the vanilla\ntransformer that helps in fast and efficient training. The proposed method is\nevaluated on NVidia Dynamic Hand Gesture and Briareo datasets and our model has\nachieved state-of-the-art results on single and multimodal inputs. We have also\nshown the parameter efficiency of the proposed ConvMixFormer model compared to\nother methods. The source code is available at\nhttps://github.com/mallikagarg/ConvMixFormer.\n","authors":["Mallika Garg","Debashis Ghosh","Pyari Mohan Pradhan"],"pdf_url":"https://arxiv.org/pdf/2411.07118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07114v1","updated":"2024-11-11T16:41:22Z","published":"2024-11-11T16:41:22Z","title":"TinyML Security: Exploring Vulnerabilities in Resource-Constrained\n  Machine Learning Systems","summary":"  Tiny Machine Learning (TinyML) systems, which enable machine learning\ninference on highly resource-constrained devices, are transforming edge\ncomputing but encounter unique security challenges. These devices, restricted\nby RAM and CPU capabilities two to three orders of magnitude smaller than\nconventional systems, make traditional software and hardware security solutions\nimpractical. The physical accessibility of these devices exacerbates their\nsusceptibility to side-channel attacks and information leakage. Additionally,\nTinyML models pose security risks, with weights potentially encoding sensitive\ndata and query interfaces that can be exploited. This paper offers the first\nthorough survey of TinyML security threats. We present a device taxonomy that\ndifferentiates between IoT, EdgeML, and TinyML, highlighting vulnerabilities\nunique to TinyML. We list various attack vectors, assess their threat levels\nusing the Common Vulnerability Scoring System, and evaluate both existing and\npossible defenses. Our analysis identifies where traditional security measures\nare adequate and where solutions tailored to TinyML are essential. Our results\nunderscore the pressing need for specialized security solutions in TinyML to\nensure robust and secure edge computing applications. We aim to inform the\nresearch community and inspire innovative approaches to protecting this rapidly\nevolving and critical field.\n","authors":["Jacob Huckelberry","Yuke Zhang","Allison Sansone","James Mickens","Peter A. Beerel","Vijay Janapa Reddi"],"pdf_url":"https://arxiv.org/pdf/2411.07114v1.pdf","comment":"Submitted to Proceedings of the IEEE"},{"id":"http://arxiv.org/abs/2409.17852v3","updated":"2024-11-11T16:41:16Z","published":"2024-09-26T13:58:06Z","title":"AMARO: All Heavy-Atom Transferable Neural Network Potentials of Protein\n  Thermodynamics","summary":"  All-atom molecular simulations offer detailed insights into macromolecular\nphenomena, but their substantial computational cost hinders the exploration of\ncomplex biological processes. We introduce Advanced Machine-learning Atomic\nRepresentation Omni-force-field (AMARO), a new neural network potential (NNP)\nthat combines an O(3)-equivariant message-passing neural network architecture,\nTensorNet, with a coarse-graining map that excludes hydrogen atoms. AMARO\ndemonstrates the feasibility of training coarser NNP, without prior energy\nterms, to run stable protein dynamics with scalability and generalization\ncapabilities.\n","authors":["Antonio Mirarchi","Raul P. Pelaez","Guillem Simeon","Gianni De Fabritiis"],"pdf_url":"https://arxiv.org/pdf/2409.17852v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.12196v3","updated":"2024-11-11T16:40:18Z","published":"2024-01-22T18:36:29Z","title":"Learning Dynamics from Multicellular Graphs with Deep Neural Networks","summary":"  Multicellular self-assembly into functional structures is a dynamic process\nthat is critical in the development and diseases, including embryo development,\norgan formation, tumor invasion, and others. Being able to infer collective\ncell migratory dynamics from their static configuration is valuable for both\nunderstanding and predicting these complex processes. However, the\nidentification of structural features that can indicate multicellular motion\nhas been difficult, and existing metrics largely rely on physical instincts.\nHere we show that using a graph neural network (GNN), the motion of\nmulticellular collectives can be inferred from a static snapshot of cell\npositions, in both experimental and synthetic datasets.\n","authors":["Haiqian Yang","Florian Meyer","Shaoxun Huang","Liu Yang","Cristiana Lungu","Monilola A. Olayioye","Markus J. Buehler","Ming Guo"],"pdf_url":"https://arxiv.org/pdf/2401.12196v3.pdf","comment":"Accepted for publication at PRX Life"},{"id":"http://arxiv.org/abs/2406.01478v2","updated":"2024-11-11T16:37:02Z","published":"2024-06-03T16:06:23Z","title":"Stochastic Newton Proximal Extragradient Method","summary":"  Stochastic second-order methods achieve fast local convergence in strongly\nconvex optimization by using noisy Hessian estimates to precondition the\ngradient. However, these methods typically reach superlinear convergence only\nwhen the stochastic Hessian noise diminishes, increasing per-iteration costs\nover time. Recent work in [arXiv:2204.09266] addressed this with a Hessian\naveraging scheme that achieves superlinear convergence without higher\nper-iteration costs. Nonetheless, the method has slow global convergence,\nrequiring up to $\\tilde{O}(\\kappa^2)$ iterations to reach the superlinear rate\nof $\\tilde{O}((1/t)^{t/2})$, where $\\kappa$ is the problem's condition number.\nIn this paper, we propose a novel stochastic Newton proximal extragradient\nmethod that improves these bounds, achieving a faster global linear rate and\nreaching the same fast superlinear rate in $\\tilde{O}(\\kappa)$ iterations. We\naccomplish this by extending the Hybrid Proximal Extragradient (HPE) framework,\nachieving fast global and local convergence rates for strongly convex functions\nwith access to a noisy Hessian oracle.\n","authors":["Ruichen Jiang","Michał Dereziński","Aryan Mokhtari"],"pdf_url":"https://arxiv.org/pdf/2406.01478v2.pdf","comment":"Accepted to NeurIPS 2024; 35 pages, 3 figures"},{"id":"http://arxiv.org/abs/2406.12060v2","updated":"2024-11-11T16:33:25Z","published":"2024-06-17T20:00:04Z","title":"Not Eliminate but Aggregate: Post-Hoc Control over Mixture-of-Experts to\n  Address Shortcut Shifts in Natural Language Understanding","summary":"  Recent models for natural language understanding are inclined to exploit\nsimple patterns in datasets, commonly known as shortcuts. These shortcuts hinge\non spurious correlations between labels and latent features existing in the\ntraining data. At inference time, shortcut-dependent models are likely to\ngenerate erroneous predictions under distribution shifts, particularly when\nsome latent features are no longer correlated with the labels. To avoid this,\nprevious studies have trained models to eliminate the reliance on shortcuts. In\nthis study, we explore a different direction: pessimistically aggregating the\npredictions of a mixture-of-experts, assuming each expert captures relatively\ndifferent latent features. The experimental results demonstrate that our\npost-hoc control over the experts significantly enhances the model's robustness\nto the distribution shift in shortcuts. Besides, we show that our approach has\nsome practical advantages. We also analyze our model and provide results to\nsupport the assumption.\n","authors":["Ukyo Honda","Tatsushi Oka","Peinan Zhang","Masato Mita"],"pdf_url":"https://arxiv.org/pdf/2406.12060v2.pdf","comment":"21 pages, 5 figures (the layout differs from the MIT Press\n  publication version)"},{"id":"http://arxiv.org/abs/2411.07107v1","updated":"2024-11-11T16:33:25Z","published":"2024-11-11T16:33:25Z","title":"Training Neural Networks as Recognizers of Formal Languages","summary":"  Characterizing the computational power of neural network architectures in\nterms of formal language theory remains a crucial line of research, as it\ndescribes lower and upper bounds on the reasoning capabilities of modern AI.\nHowever, when empirically testing these bounds, existing work often leaves a\ndiscrepancy between experiments and the formal claims they are meant to\nsupport. The problem is that formal language theory pertains specifically to\nrecognizers: machines that receive a string as input and classify whether it\nbelongs to a language. On the other hand, it is common to instead use proxy\ntasks that are similar in only an informal sense, such as language modeling or\nsequence-to-sequence transduction. We correct this mismatch by training and\nevaluating neural networks directly as binary classifiers of strings, using a\ngeneral method that can be applied to a wide variety of languages. As part of\nthis, we extend an algorithm recently proposed by Sn{\\ae}bjarnarson et al.\n(2024) to do length-controlled sampling of strings from regular languages, with\nmuch better asymptotic time complexity than previous methods. We provide\nresults on a variety of languages across the Chomsky hierarchy for three neural\narchitectures: a simple RNN, an LSTM, and a causally-masked transformer. We\nfind that the RNN and LSTM often outperform the transformer, and that auxiliary\ntraining objectives such as language modeling can help, although no single\nobjective uniformly improves performance across languages and architectures.\nOur contributions will facilitate theoretically sound empirical testing of\nlanguage recognition claims in future work. We have released our datasets as a\nbenchmark called FLaRe (Formal Language Recognition), along with our code.\n","authors":["Alexandra Butoi","Ghazal Khalighinejad","Anej Svete","Josef Valvoda","Ryan Cotterell","Brian DuSell"],"pdf_url":"https://arxiv.org/pdf/2411.07107v1.pdf","comment":"40 pages, 2 figures. Preprint"},{"id":"http://arxiv.org/abs/2411.07104v1","updated":"2024-11-11T16:27:25Z","published":"2024-11-11T16:27:25Z","title":"Learning Multi-Agent Collaborative Manipulation for Long-Horizon\n  Quadrupedal Pushing","summary":"  Recently, quadrupedal locomotion has achieved significant success, but their\nmanipulation capabilities, particularly in handling large objects, remain\nlimited, restricting their usefulness in demanding real-world applications such\nas search and rescue, construction, industrial automation, and room\norganization. This paper tackles the task of obstacle-aware, long-horizon\npushing by multiple quadrupedal robots. We propose a hierarchical multi-agent\nreinforcement learning framework with three levels of control. The high-level\ncontroller integrates an RRT planner and a centralized adaptive policy to\ngenerate subgoals, while the mid-level controller uses a decentralized\ngoal-conditioned policy to guide the robots toward these sub-goals. A\npre-trained low-level locomotion policy executes the movement commands. We\nevaluate our method against several baselines in simulation, demonstrating\nsignificant improvements over baseline approaches, with 36.0% higher success\nrates and 24.5% reduction in completion time than the best baseline. Our\nframework successfully enables long-horizon, obstacle-aware manipulation tasks\nlike Push-Cuboid and Push-T on Go1 robots in the real world.\n","authors":["Chuye Hong","Yuming Feng","Yaru Niu","Shiqi Liu","Yuxiang Yang","Wenhao Yu","Tingnan Zhang","Jie Tan","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.07104v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07102v1","updated":"2024-11-11T16:26:33Z","published":"2024-11-11T16:26:33Z","title":"Effectively Leveraging Momentum Terms in Stochastic Line Search\n  Frameworks for Fast Optimization of Finite-Sum Problems","summary":"  In this work, we address unconstrained finite-sum optimization problems, with\nparticular focus on instances originating in large scale deep learning\nscenarios. Our main interest lies in the exploration of the relationship\nbetween recent line search approaches for stochastic optimization in the\noverparametrized regime and momentum directions. First, we point out that\ncombining these two elements with computational benefits is not\nstraightforward. To this aim, we propose a solution based on mini-batch\npersistency. We then introduce an algorithmic framework that exploits a mix of\ndata persistency, conjugate-gradient type rules for the definition of the\nmomentum parameter and stochastic line searches. The resulting algorithm is\nempirically shown to outperform other popular methods from the literature,\nobtaining state-of-the-art results in both convex and nonconvex large scale\ntraining problems.\n","authors":["Matteo Lapucci","Davide Pucci"],"pdf_url":"https://arxiv.org/pdf/2411.07102v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07099v1","updated":"2024-11-11T16:24:03Z","published":"2024-11-11T16:24:03Z","title":"Bounded Rationality Equilibrium Learning in Mean Field Games","summary":"  Mean field games (MFGs) tractably model behavior in large agent populations.\nThe literature on learning MFG equilibria typically focuses on finding Nash\nequilibria (NE), which assume perfectly rational agents and are hence\nimplausible in many realistic situations. To overcome these limitations, we\nincorporate bounded rationality into MFGs by leveraging the well-known concept\nof quantal response equilibria (QRE). Two novel types of MFG QRE enable the\nmodeling of large agent populations where individuals only noisily estimate the\ntrue objective. We also introduce a second source of bounded rationality to\nMFGs by restricting agents' planning horizon. The resulting novel receding\nhorizon (RH) MFGs are combined with QRE and existing approaches to model\ndifferent aspects of bounded rationality in MFGs. We formally define MFG QRE\nand RH MFGs and compare them to existing equilibrium concepts such as\nentropy-regularized NE. Subsequently, we design generalized fixed point\niteration and fictitious play algorithms to learn QRE and RH equilibria. After\na theoretical analysis, we give different examples to evaluate the capabilities\nof our learning algorithms and outline practical differences between the\nequilibrium concepts.\n","authors":["Yannick Eich","Christian Fabian","Kai Cui","Heinz Koeppl"],"pdf_url":"https://arxiv.org/pdf/2411.07099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21764v2","updated":"2024-11-11T16:17:07Z","published":"2024-10-29T05:58:33Z","title":"Online Mirror Descent for Tchebycheff Scalarization in Multi-Objective\n  Optimization","summary":"  The goal of multi-objective optimization (MOO) is to learn under multiple,\npotentially conflicting, objectives. One widely used technique to tackle MOO is\nthrough linear scalarization, where one fixed preference vector is used to\ncombine the objectives into a single scalar value for optimization. However,\nrecent work (Hu et al., 2024) has shown linear scalarization often fails to\ncapture the non-convex regions of the Pareto Front, failing to recover the\ncomplete set of Pareto optimal solutions. In light of the above limitations,\nthis paper focuses on Tchebycheff scalarization that optimizes for the\nworst-case objective. In particular, we propose an online mirror descent\nalgorithm for Tchebycheff scalarization, which we call OMD-TCH. We show that\nOMD-TCH enjoys a convergence rate of $O(\\sqrt{\\log m/T})$ where $m$ is the\nnumber of objectives and $T$ is the number of iteration rounds. We also propose\na novel adaptive online-to-batch conversion scheme that significantly improves\nthe practical performance of OMD-TCH while maintaining the same convergence\nguarantees. We demonstrate the effectiveness of OMD-TCH and the adaptive\nconversion scheme on both synthetic problems and federated learning tasks under\nfairness constraints, showing state-of-the-art performance.\n","authors":["Meitong Liu","Xiaoyuan Zhang","Chulin Xie","Kate Donahue","Han Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.21764v2.pdf","comment":"26 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2411.07094v1","updated":"2024-11-11T16:14:56Z","published":"2024-11-11T16:14:56Z","title":"Differentially-Private Collaborative Online Personalized Mean Estimation","summary":"  We consider the problem of collaborative personalized mean estimation under a\nprivacy constraint in an environment of several agents continuously receiving\ndata according to arbitrary unknown agent-specific distributions. In\nparticular, we provide a method based on hypothesis testing coupled with\ndifferential privacy and data variance estimation. Two privacy mechanisms and\ntwo data variance estimation schemes are proposed, and we provide a theoretical\nconvergence analysis of the proposed algorithm for any bounded unknown\ndistributions on the agents' data, showing that collaboration provides faster\nconvergence than a fully local approach where agents do not share data.\nMoreover, we provide analytical performance curves for the case with an oracle\nclass estimator, i.e., the class structure of the agents, where agents\nreceiving data from distributions with the same mean are considered to be in\nthe same class, is known. The theoretical faster-than-local convergence\nguarantee is backed up by extensive numerical results showing that for a\nconsidered scenario the proposed approach indeed converges much faster than a\nfully local approach, and performs comparably to ideal performance where all\ndata is public. This illustrates the benefit of private collaboration in an\nonline setting.\n","authors":["Yauhen Yakimenka","Chung-Wei Weng","Hsuan-Yin Lin","Eirik Rosnes","Jörg Kliewer"],"pdf_url":"https://arxiv.org/pdf/2411.07094v1.pdf","comment":"Presented in part at the 2023 IEEE International Symposium on\n  Information Theory (ISIT)"},{"id":"http://arxiv.org/abs/2411.07089v1","updated":"2024-11-11T16:09:13Z","published":"2024-11-11T16:09:13Z","title":"Towards Characterizing Cyber Networks with Large Language Models","summary":"  Threat hunting analyzes large, noisy, high-dimensional data to find sparse\nadversarial behavior. We believe adversarial activities, however they are\ndisguised, are extremely difficult to completely obscure in high dimensional\nspace. In this paper, we employ these latent features of cyber data to find\nanomalies via a prototype tool called Cyber Log Embeddings Model (CLEM). CLEM\nwas trained on Zeek network traffic logs from both a real-world production\nnetwork and an from Internet of Things (IoT) cybersecurity testbed. The model\nis deliberately overtrained on a sliding window of data to characterize each\nwindow closely. We use the Adjusted Rand Index (ARI) to comparing the k-means\nclustering of CLEM output to expert labeling of the embeddings. Our approach\ndemonstrates that there is promise in using natural language modeling to\nunderstand cyber data.\n","authors":["Alaric Hartsock","Luiz Manella Pereira","Glenn Fink"],"pdf_url":"https://arxiv.org/pdf/2411.07089v1.pdf","comment":"5 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.07087v1","updated":"2024-11-11T16:04:49Z","published":"2024-11-11T16:04:49Z","title":"OCMDP: Observation-Constrained Markov Decision Process","summary":"  In many practical applications, decision-making processes must balance the\ncosts of acquiring information with the benefits it provides. Traditional\ncontrol systems often assume full observability, an unrealistic assumption when\nobservations are expensive. We tackle the challenge of simultaneously learning\nobservation and control strategies in such cost-sensitive environments by\nintroducing the Observation-Constrained Markov Decision Process (OCMDP), where\nthe policy influences the observability of the true state. To manage the\ncomplexity arising from the combined observation and control actions, we\ndevelop an iterative, model-free deep reinforcement learning algorithm that\nseparates the sensing and control components of the policy. This decomposition\nenables efficient learning in the expanded action space by focusing on when and\nwhat to observe, as well as determining optimal control actions, without\nrequiring knowledge of the environment's dynamics. We validate our approach on\na simulated diagnostic task and a realistic healthcare environment using\nHeartPole. Given both scenarios, the experimental results demonstrate that our\nmodel achieves a substantial reduction in observation costs on average,\nsignificantly outperforming baseline methods by a notable margin in efficiency.\n","authors":["Taiyi Wang","Jianheng Liu","Jiaye Li","Zhihao Wu","Yu Wu"],"pdf_url":"https://arxiv.org/pdf/2411.07087v1.pdf","comment":"Full paper, 14 Pages"},{"id":"http://arxiv.org/abs/2411.07086v1","updated":"2024-11-11T16:02:12Z","published":"2024-11-11T16:02:12Z","title":"To Train or Not to Train: Balancing Efficiency and Training Cost in Deep\n  Reinforcement Learning for Mobile Edge Computing","summary":"  Artificial Intelligence (AI) is a key component of 6G networks, as it enables\ncommunication and computing services to adapt to end users' requirements and\ndemand patterns. The management of Mobile Edge Computing (MEC) is a meaningful\nexample of AI application: computational resources available at the network\nedge need to be carefully allocated to users, whose jobs may have different\npriorities and latency requirements. The research community has developed\nseveral AI algorithms to perform this resource allocation, but it has neglected\na key aspect: learning is itself a computationally demanding task, and\nconsidering free training results in idealized conditions and performance in\nsimulations. In this work, we consider a more realistic case in which the cost\nof learning is specifically accounted for, presenting a new algorithm to\ndynamically select when to train a Deep Reinforcement Learning (DRL) agent that\nallocates resources. Our method is highly general, as it can be directly\napplied to any scenario involving a training overhead, and it can approach the\nsame performance as an ideal learning agent even under realistic training\nconditions.\n","authors":["Maddalena Boscaro","Federico Mason","Federico Chiariotti","Andrea Zanella"],"pdf_url":"https://arxiv.org/pdf/2411.07086v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.14537v3","updated":"2024-11-11T15:49:16Z","published":"2023-03-25T19:03:57Z","title":"Deep Augmentation: Self-Supervised Learning with Transformations in\n  Activation Space","summary":"  We introduce Deep Augmentation, an approach to implicit data augmentation\nusing dropout or PCA to transform a targeted layer within a neural network to\nimprove performance and generalization. We demonstrate Deep Augmentation\nthrough extensive experiments on contrastive learning tasks in NLP, computer\nvision, and graph learning. We observe substantial performance gains with\nTransformers, ResNets, and Graph Neural Networks as the underlying models in\ncontrastive learning, but observe inverse effects on the corresponding\nsupervised problems. Our analysis suggests that Deep Augmentation alleviates\nco-adaptation between layers, a problem exhibited by self-supervised learning\nwhere ground truth labels are not available. We use this observation to\nformulate a method for selecting which layer to target; in particular, our\nexperimentation reveals that targeting deeper layers with Deep Augmentation\noutperforms augmenting the input data. The simple network- and\nmodality-agnostic nature of this approach enables its integration into various\nmachine learning pipelines.\n","authors":["Rickard Brüel-Gabrielsson","Tongzhou Wang","Manel Baradad","Justin Solomon"],"pdf_url":"https://arxiv.org/pdf/2303.14537v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07072v1","updated":"2024-11-11T15:47:25Z","published":"2024-11-11T15:47:25Z","title":"An Interpretable X-ray Style Transfer via Trainable Local Laplacian\n  Filter","summary":"  Radiologists have preferred visual impressions or 'styles' of X-ray images\nthat are manually adjusted to their needs to support their diagnostic\nperformance. In this work, we propose an automatic and interpretable X-ray\nstyle transfer by introducing a trainable version of the Local Laplacian Filter\n(LLF). From the shape of the LLF's optimized remap function, the\ncharacteristics of the style transfer can be inferred and reliability of the\nalgorithm can be ensured. Moreover, we enable the LLF to capture complex X-ray\nstyle features by replacing the remap function with a Multi-Layer Perceptron\n(MLP) and adding a trainable normalization layer. We demonstrate the\neffectiveness of the proposed method by transforming unprocessed mammographic\nX-ray images into images that match the style of target mammograms and achieve\na Structural Similarity Index (SSIM) of 0.94 compared to 0.82 of the baseline\nLLF style transfer method from Aubry et al.\n","authors":["Dominik Eckert","Ludwig Ritschl","Christopher Syben","Christian Hümmer","Julia Wicklein","Marcel Beister","Steffen Kappler","Sebastian Stober"],"pdf_url":"https://arxiv.org/pdf/2411.07072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07071v1","updated":"2024-11-11T15:47:15Z","published":"2024-11-11T15:47:15Z","title":"Universal Response and Emergence of Induction in LLMs","summary":"  While induction is considered a key mechanism for in-context learning in\nLLMs, understanding its precise circuit decomposition beyond toy models remains\nelusive. Here, we study the emergence of induction behavior within LLMs by\nprobing their response to weak single-token perturbations of the residual\nstream. We find that LLMs exhibit a robust, universal regime in which their\nresponse remains scale-invariant under changes in perturbation strength,\nthereby allowing us to quantify the build-up of token correlations throughout\nthe model. By applying our method, we observe signatures of induction behavior\nwithin the residual stream of Gemma-2-2B, Llama-3.2-3B, and GPT-2-XL. Across\nall models, we find that these induction signatures gradually emerge within\nintermediate layers and identify the relevant model sections composing this\nbehavior. Our results provide insights into the collective interplay of\ncomponents within LLMs and serve as a benchmark for large-scale circuit\nanalysis.\n","authors":["Niclas Luick"],"pdf_url":"https://arxiv.org/pdf/2411.07071v1.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2401.10825v2","updated":"2024-11-11T15:45:02Z","published":"2024-01-19T17:21:05Z","title":"Recent Advances in Named Entity Recognition: A Comprehensive Survey and\n  Comparative Study","summary":"  Named Entity Recognition seeks to extract substrings within a text that name\nreal-world objects and to determine their type (for example, whether they refer\nto persons or organizations). In this survey, we first present an overview of\nrecent popular approaches, including advancements in Transformer-based methods\nand Large Language Models (LLMs) that have not had much coverage in other\nsurveys. In addition, we discuss reinforcement learning and graph-based\napproaches, highlighting their role in enhancing NER performance. Second, we\nfocus on methods designed for datasets with scarce annotations. Third, we\nevaluate the performance of the main NER implementations on a variety of\ndatasets with differing characteristics (as regards their domain, their size,\nand their number of classes). We thus provide a deep comparison of algorithms\nthat have never been considered together. Our experiments shed some light on\nhow the characteristics of datasets affect the behavior of the methods we\ncompare.\n","authors":["Imed Keraghel","Stanislas Morbieu","Mohamed Nadif"],"pdf_url":"https://arxiv.org/pdf/2401.10825v2.pdf","comment":"44 pages"},{"id":"http://arxiv.org/abs/2405.20358v3","updated":"2024-11-11T15:37:29Z","published":"2024-05-30T07:13:08Z","title":"Medication Recommendation via Dual Molecular Modalities and Multi-Step\n  Enhancement","summary":"  Existing works based on molecular knowledge neglect the 3D geometric\nstructure of molecules and fail to learn the high-dimensional information of\nmedications, leading to structural confusion. Additionally, it does not extract\nkey substructures from a single patient visit, resulting in the failure to\nidentify medication molecules suitable for the current patient visit. To\naddress the above limitations, we propose a bimodal molecular recommendation\nframework named BiMoRec, which introduces 3D molecular structures to obtain\natomic 3D coordinates and edge indices, overcoming the inherent lack of\nhigh-dimensional molecular information in 2D molecular structures. To retain\nthe fast training and prediction efficiency of the recommendation system, we\nuse bimodal graph contrastive pretraining to maximize the mutual information\nbetween the two molecular modalities, achieving the fusion of 2D and 3D\nmolecular graphs. Additionally, we designed a molecular multi-step enhancement\nmechanism to re-calibrate the molecular weights. Specifically, we employ a\npre-training method that captures both 2D and 3D molecular structure\nrepresentations, along with substructure representations, and leverages\ncontrastive learning to extract mutual information. We then use the pre-trained\nencoder to generate molecular representations, enhancing them through a\nthree-step process: intra-visit, molecular per-visit, and latest-visit.\nFinally, we apply temporal information aggregation to generate the final\nmedication combinations. Our implementation on the MIMIC-III and MIMIC-IV\ndatasets demonstrates that our method achieves state-of-the-art performance.\n","authors":["Shi Mu","Chen Li","Xiang Li","Shunpan Liang"],"pdf_url":"https://arxiv.org/pdf/2405.20358v3.pdf","comment":"16 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.11407v2","updated":"2024-11-11T15:31:42Z","published":"2024-03-18T01:47:24Z","title":"Divide-and-Conquer Posterior Sampling for Denoising Diffusion Priors","summary":"  Recent advancements in solving Bayesian inverse problems have spotlighted\ndenoising diffusion models (DDMs) as effective priors. Although these have\ngreat potential, DDM priors yield complex posterior distributions that are\nchallenging to sample. Existing approaches to posterior sampling in this\ncontext address this problem either by retraining model-specific components,\nleading to stiff and cumbersome methods, or by introducing approximations with\nuncontrolled errors that affect the accuracy of the produced samples. We\npresent an innovative framework, divide-and-conquer posterior sampling, which\nleverages the inherent structure of DDMs to construct a sequence of\nintermediate posteriors that guide the produced samples to the target\nposterior. Our method significantly reduces the approximation error associated\nwith current techniques without the need for retraining. We demonstrate the\nversatility and effectiveness of our approach for a wide range of Bayesian\ninverse problems. The code is available at\n\\url{https://github.com/Badr-MOUFAD/dcps}\n","authors":["Yazid Janati","Badr Moufad","Alain Durmus","Eric Moulines","Jimmy Olsson"],"pdf_url":"https://arxiv.org/pdf/2403.11407v2.pdf","comment":"Updated version with significant updates"},{"id":"http://arxiv.org/abs/2411.07066v1","updated":"2024-11-11T15:30:16Z","published":"2024-11-11T15:30:16Z","title":"Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training","summary":"  Network pruning is a set of computational techniques that aim to reduce a\ngiven model's computational cost by removing a subset of its parameters while\nhaving minimal impact on performance. Throughout the last decade, the most\nwidely used pruning paradigm has focused on pruning and re-training, which\nnowadays is inconvenient due to the vast amount of pre-trained models, which\nare in any case too expensive to re-train. In this paper, we exploit functional\ninformation from dense pre-trained models, i.e., their activations, to obtain\nsparse models that maximize the activations' alignment w.r.t. their\ncorresponding dense models. Hence, we propose \\textsc{NeuroAl}, a \\emph{top-up}\nalgorithm that can be used on top of any given pruning algorithm for LLMs, that\nmodifies the block-wise and row-wise sparsity ratios to maximize the\n\\emph{neuron alignment} among activations. Moreover, differently from existing\nmethods, our approach adaptively selects the best parameters for the block-wise\nand row-wise sparsity ratios w.r.t. to the model and the desired sparsity\n(given as input), and requires \\emph{no re-training}. We test our method on 4\ndifferent LLM families and 3 different sparsity ratios, showing how it\nconsistently outperforms the latest state-of-the-art techniques. The code is\navailable at https://github.com/eliacunegatti/NeuroAL.\n","authors":["Elia Cunegatti","Leonardo Lucio Custode","Giovanni Iacca"],"pdf_url":"https://arxiv.org/pdf/2411.07066v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2406.02189v2","updated":"2024-11-11T15:29:59Z","published":"2024-06-04T10:34:40Z","title":"Fast and Scalable Multi-Kernel Encoder Classifier","summary":"  This paper introduces a new kernel-based classifier by viewing kernel\nmatrices as generalized graphs and leveraging recent progress in graph\nembedding techniques. The proposed method facilitates fast and scalable kernel\nmatrix embedding, and seamlessly integrates multiple kernels to enhance the\nlearning process. Our theoretical analysis offers a population-level\ncharacterization of this approach using random variables. Empirically, our\nmethod demonstrates superior running time compared to standard approaches such\nas support vector machines and two-layer neural network, while achieving\ncomparable classification accuracy across various simulated and real datasets.\n","authors":["Cencheng Shen"],"pdf_url":"https://arxiv.org/pdf/2406.02189v2.pdf","comment":"12 pages main + 3 pages appendix"},{"id":"http://arxiv.org/abs/2312.15225v3","updated":"2024-11-11T15:27:46Z","published":"2023-12-23T11:14:33Z","title":"Statistical Inference with Limited Memory: A Survey","summary":"  The problem of statistical inference in its various forms has been the\nsubject of decades-long extensive research. Most of the effort has been focused\non characterizing the behavior as a function of the number of available\nsamples, with far less attention given to the effect of memory limitations on\nperformance. Recently, this latter topic has drawn much interest in the\nengineering and computer science literature. In this survey paper, we attempt\nto review the state-of-the-art of statistical inference under memory\nconstraints in several canonical problems, including hypothesis testing,\nparameter estimation, and distribution property testing/estimation. We discuss\nthe main results in this developing field, and by identifying recurrent themes,\nwe extract some fundamental building blocks for algorithmic construction, as\nwell as useful techniques for lower bound derivations.\n","authors":["Tomer Berg","Or Ordentlich","Ofer Shayevitz"],"pdf_url":"https://arxiv.org/pdf/2312.15225v3.pdf","comment":"Published in JSAIT Special Issue"},{"id":"http://arxiv.org/abs/2411.07061v1","updated":"2024-11-11T15:25:48Z","published":"2024-11-11T15:25:48Z","title":"General framework for online-to-nonconvex conversion: Schedule-free SGD\n  is also effective for nonconvex optimization","summary":"  This work investigates the effectiveness of schedule-free methods, developed\nby A. Defazio et al. (NeurIPS 2024), in nonconvex optimization settings,\ninspired by their remarkable empirical success in training neural networks.\nSpecifically, we show that schedule-free SGD achieves optimal iteration\ncomplexity for nonsmooth, nonconvex optimization problems. Our proof begins\nwith the development of a general framework for online-to-nonconvex conversion,\nwhich converts a given online learning algorithm into an optimization algorithm\nfor nonconvex losses. Our general framework not only recovers existing\nconversions but also leads to two novel conversion schemes. Notably, one of\nthese new conversions corresponds directly to schedule-free SGD, allowing us to\nestablish its optimality. Additionally, our analysis provides valuable insights\ninto the parameter choices for schedule-free SGD, addressing a theoretical gap\nthat the convex theory cannot explain.\n","authors":["Kwangjun Ahn","Gagik Magakyan","Ashok Cutkosky"],"pdf_url":"https://arxiv.org/pdf/2411.07061v1.pdf","comment":"Comments would be appreciated!"},{"id":"http://arxiv.org/abs/2411.05228v2","updated":"2024-11-11T15:20:03Z","published":"2024-11-07T22:42:08Z","title":"Solving Hidden Monotone Variational Inequalities with Surrogate Losses","summary":"  Deep learning has proven to be effective in a wide variety of loss\nminimization problems. However, many applications of interest, like minimizing\nprojected Bellman error and min-max optimization, cannot be modelled as\nminimizing a scalar loss function but instead correspond to solving a\nvariational inequality (VI) problem. This difference in setting has caused many\npractical challenges as naive gradient-based approaches from supervised\nlearning tend to diverge and cycle in the VI case. In this work, we propose a\nprincipled surrogate-based approach compatible with deep learning to solve VIs.\nWe show that our surrogate-based approach has three main benefits: (1) under\nassumptions that are realistic in practice (when hidden monotone structure is\npresent, interpolation, and sufficient optimization of the surrogates), it\nguarantees convergence, (2) it provides a unifying perspective of existing\nmethods, and (3) is amenable to existing deep learning optimizers like ADAM.\nExperimentally, we demonstrate our surrogate-based approach is effective in\nmin-max optimization and minimizing projected Bellman error. Furthermore, in\nthe deep reinforcement learning case, we propose a novel variant of TD(0) which\nis more compute and sample efficient.\n","authors":["Ryan D'Orazio","Danilo Vucetic","Zichu Liu","Junhyung Lyle Kim","Ioannis Mitliagkas","Gauthier Gidel"],"pdf_url":"https://arxiv.org/pdf/2411.05228v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07055v1","updated":"2024-11-11T15:15:55Z","published":"2024-11-11T15:15:55Z","title":"Reconstruction of neuromorphic dynamics from a single scalar time series\n  using variational autoencoder and neural network map","summary":"  This paper examines the reconstruction of a family of dynamical systems with\nneuromorphic behavior using a single scalar time series. A model of a\nphysiological neuron based on the Hodgkin-Huxley formalism is considered.\nSingle time series of one of its variables is shown to be enough to train a\nneural network that can operate as a discrete time dynamical system with one\ncontrol parameter. The neural network system is created in two steps. First,\nthe delay-coordinate embedding vectors are constructed form the original time\nseries and their dimension is reduced with by means of a variational\nautoencoder to obtain the recovered state-space vectors. It is shown that an\nappropriate reduced dimension can be determined by analyzing the autoencoder\ntraining process. Second, pairs of the recovered state-space vectors at\nconsecutive time steps supplied with a constant value playing the role of a\ncontrol parameter are used to train another neural network to make it operate\nas a recurrent map. The regimes of thus created neural network system observed\nwhen its control parameter is varied are in very good accordance with those of\nthe original system, though they were not explicitly presented during training.\n","authors":["Pavel V. Kuptsov","Nataliya V. Stankevich"],"pdf_url":"https://arxiv.org/pdf/2411.07055v1.pdf","comment":"15 pages, 15 figures, 3 tables"},{"id":"http://arxiv.org/abs/2407.07462v2","updated":"2024-11-11T14:59:22Z","published":"2024-07-10T08:32:26Z","title":"MAN TruckScenes: A multimodal dataset for autonomous trucking in diverse\n  conditions","summary":"  Autonomous trucking is a promising technology that can greatly impact modern\nlogistics and the environment. Ensuring its safety on public roads is one of\nthe main duties that requires an accurate perception of the environment. To\nachieve this, machine learning methods rely on large datasets, but to this day,\nno such datasets are available for autonomous trucks. In this work, we present\nMAN TruckScenes, the first multimodal dataset for autonomous trucking. MAN\nTruckScenes allows the research community to come into contact with\ntruck-specific challenges, such as trailer occlusions, novel sensor\nperspectives, and terminal environments for the first time. It comprises more\nthan 740 scenes of 20s each within a multitude of different environmental\nconditions. The sensor set includes 4 cameras, 6 lidar, 6 radar sensors, 2\nIMUs, and a high-precision GNSS. The dataset's 3D bounding boxes were manually\nannotated and carefully reviewed to achieve a high quality standard. Bounding\nboxes are available for 27 object classes, 15 attributes, and a range of more\nthan 230m. The scenes are tagged according to 34 distinct scene tags, and all\nobjects are tracked throughout the scene to promote a wide range of\napplications. Additionally, MAN TruckScenes is the first dataset to provide 4D\nradar data with 360{\\deg} coverage and is thereby the largest radar dataset\nwith annotated 3D bounding boxes. Finally, we provide extensive dataset\nanalysis and baseline results. The dataset, development kit, and more are\navailable online.\n","authors":["Felix Fent","Fabian Kuttenreich","Florian Ruch","Farija Rizwin","Stefan Juergens","Lorenz Lechermann","Christian Nissler","Andrea Perl","Ulrich Voll","Min Yan","Markus Lienkamp"],"pdf_url":"https://arxiv.org/pdf/2407.07462v2.pdf","comment":"Accepted to NeurIPS 2024 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2401.07595v3","updated":"2024-11-11T14:53:38Z","published":"2024-01-15T11:04:47Z","title":"E3x: $\\mathrm{E}(3)$-Equivariant Deep Learning Made Easy","summary":"  This work introduces E3x, a software package for building neural networks\nthat are equivariant with respect to the Euclidean group $\\mathrm{E}(3)$,\nconsisting of translations, rotations, and reflections of three-dimensional\nspace. Compared to ordinary neural networks, $\\mathrm{E}(3)$-equivariant models\npromise benefits whenever input and/or output data are quantities associated\nwith three-dimensional objects. This is because the numeric values of such\nquantities (e.g. positions) typically depend on the chosen coordinate system.\nUnder transformations of the reference frame, the values change predictably,\nbut the underlying rules can be difficult to learn for ordinary machine\nlearning models. With built-in $\\mathrm{E}(3)$-equivariance, neural networks\nare guaranteed to satisfy the relevant transformation rules exactly, resulting\nin superior data efficiency and accuracy. The code for E3x is available from\nhttps://github.com/google-research/e3x, detailed documentation and usage\nexamples can be found on https://e3x.readthedocs.io.\n","authors":["Oliver T. Unke","Hartmut Maennel"],"pdf_url":"https://arxiv.org/pdf/2401.07595v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07043v1","updated":"2024-11-11T14:51:24Z","published":"2024-11-11T14:51:24Z","title":"Unified Bayesian representation for high-dimensional multi-modal\n  biomedical data for small-sample classification","summary":"  We present BALDUR, a novel Bayesian algorithm designed to deal with\nmulti-modal datasets and small sample sizes in high-dimensional settings while\nproviding explainable solutions. To do so, the proposed model combines within a\ncommon latent space the different data views to extract the relevant\ninformation to solve the classification task and prune out the\nirrelevant/redundant features/data views. Furthermore, to provide generalizable\nsolutions in small sample size scenarios, BALDUR efficiently integrates dual\nkernels over the views with a small sample-to-feature ratio. Finally, its\nlinear nature ensures the explainability of the model outcomes, allowing its\nuse for biomarker identification. This model was tested over two different\nneurodegeneration datasets, outperforming the state-of-the-art models and\ndetecting features aligned with markers already described in the scientific\nliterature.\n","authors":["Albert Belenguer-Llorens","Carlos Sevilla-Salcedo","Jussi Tohka","Vanessa Gómez-Verdejo"],"pdf_url":"https://arxiv.org/pdf/2411.07043v1.pdf","comment":"36 pages, 3 figures and 3 tables"},{"id":"http://arxiv.org/abs/2404.08877v2","updated":"2024-11-11T14:35:45Z","published":"2024-04-13T02:36:40Z","title":"Aligning LLMs for FL-free Program Repair","summary":"  Large language models (LLMs) have achieved decent results on automated\nprogram repair (APR). However, the next token prediction training objective of\ndecoder-only LLMs (e.g., GPT-4) is misaligned with the masked span prediction\nobjective of current infilling-style methods, which impedes LLMs from fully\nleveraging pre-trained knowledge for program repair. In addition, while some\nLLMs can locate and repair bugs in certain functions using the related\nartifacts (e.g., test cases), existing methods still depend on statement-level\nfault localization methods to provide a list of buggy hunks for repair. This\nrestriction hinders LLMs from exploring potential patches beyond the given\nlocations.\n  In this paper, we investigate a new approach to adapt LLMs to program repair.\nOur core insight is that LLM's APR capability can be greatly improved by simply\naligning the output to their training objective and allowing them to refine the\nwhole program without first identifying faulty statements. Based on this\ninsight, we designed D4C, a straightforward prompting framework for APR. D4C\ncan repair 180 bugs correctly in Defects4J, with each patch being sampled only\n10 times. This surpasses the SOTA APR methods with perfect fault localization\nby 10% and reduces the patch sampling number by 90%. Our findings reveal that\n(1) objective alignment is crucial for fully exploiting LLM's pre-trained\ncapability, and (2) replacing the traditional localize-buggy-hunks-then-repair\nworkflow with direct debugging is more effective for LLM-based APR methods.\nThus, we believe this paper introduces a new mindset for harnessing LLMs in\nAPR.\n","authors":["Junjielong Xu","Ying Fu","Shin Hwei Tan","Pinjia He"],"pdf_url":"https://arxiv.org/pdf/2404.08877v2.pdf","comment":"Accepted by ICSE'25"},{"id":"http://arxiv.org/abs/2405.09273v3","updated":"2024-11-11T14:32:58Z","published":"2024-05-15T11:42:41Z","title":"Fair Generalized Linear Mixed Models","summary":"  When using machine learning for automated prediction, it is important to\naccount for fairness in the prediction. Fairness in machine learning aims to\nensure that biases in the data and model inaccuracies do not lead to\ndiscriminatory decisions. E.g., predictions from fair machine learning models\nshould not discriminate against sensitive variables such as sexual orientation\nand ethnicity. The training data often in obtained from social surveys. In\nsocial surveys, oftentimes the data collection process is a strata sampling,\ne.g. due to cost restrictions. In strata samples, the assumption of\nindependence between the observation is not fulfilled. Hence, if the machine\nlearning models do not account for the strata correlations, the results may be\nbiased. Especially high is the bias in cases where the strata assignment is\ncorrelated to the variable of interest. We present in this paper an algorithm\nthat can handle both problems simultaneously, and we demonstrate the impact of\nstratified sampling on the quality of fair machine learning predictions in a\nreproducible simulation study.\n","authors":["Jan Pablo Burgard","João Vitor Pamplona"],"pdf_url":"https://arxiv.org/pdf/2405.09273v3.pdf","comment":"25 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:2405.06433"},{"id":"http://arxiv.org/abs/2411.07022v1","updated":"2024-11-11T14:27:30Z","published":"2024-11-11T14:27:30Z","title":"HeteroSample: Meta-path Guided Sampling for Heterogeneous Graph\n  Representation Learning","summary":"  The rapid expansion of Internet of Things (IoT) has resulted in vast,\nheterogeneous graphs that capture complex interactions among devices, sensors,\nand systems. Efficient analysis of these graphs is critical for deriving\ninsights in IoT scenarios such as smart cities, industrial IoT, and intelligent\ntransportation systems. However, the scale and diversity of IoT-generated data\npresent significant challenges, and existing methods often struggle with\npreserving the structural integrity and semantic richness of these complex\ngraphs. Many current approaches fail to maintain the balance between\ncomputational efficiency and the quality of the insights generated, leading to\npotential loss of critical information necessary for accurate decision-making\nin IoT applications. We introduce HeteroSample, a novel sampling method\ndesigned to address these challenges by preserving the structural integrity,\nnode and edge type distributions, and semantic patterns of IoT-related graphs.\nHeteroSample works by incorporating the novel top-leader selection, balanced\nneighborhood expansion, and meta-path guided sampling strategies. The key idea\nis to leverage the inherent heterogeneous structure and semantic relationships\nencoded by meta-paths to guide the sampling process. This approach ensures that\nthe resulting subgraphs are representative of the original data while\nsignificantly reducing computational overhead. Extensive experiments\ndemonstrate that HeteroSample outperforms state-of-the-art methods, achieving\nup to 15% higher F1 scores in tasks such as link prediction and node\nclassification, while reducing runtime by 20%.These advantages make\nHeteroSample a transformative tool for scalable and accurate IoT applications,\nenabling more effective and efficient analysis of complex IoT systems,\nultimately driving advancements in smart cities, industrial IoT, and beyond.\n","authors":["Ao Liu","Jing Chen","Ruiying Du","Cong Wu","Yebo Feng","Teng Li","Jianfeng Ma"],"pdf_url":"https://arxiv.org/pdf/2411.07022v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2411.07018v1","updated":"2024-11-11T14:22:16Z","published":"2024-11-11T14:22:16Z","title":"Data-Driven Gradient Optimization for Field Emission Management in a\n  Superconducting Radio-Frequency Linac","summary":"  Field emission can cause significant problems in superconducting\nradio-frequency linear accelerators (linacs). When cavity gradients are pushed\nhigher, radiation levels within the linacs may rise exponentially, causing\ndegradation of many nearby systems. This research aims to utilize machine\nlearning with uncertainty quantification to predict radiation levels at\nmultiple locations throughout the linacs and ultimately optimize cavity\ngradients to reduce field emission induced radiation while maintaining the\ntotal linac energy gain necessary for the experimental physics program. The\noptimized solutions show over 40% reductions for both neutron and gamma\nradiation from the standard operational settings.\n","authors":["Steven Goldenberg","Kawser Ahammed","Adam Carpenter","Jiang Li","Riad Suleiman","Chris Tennant"],"pdf_url":"https://arxiv.org/pdf/2411.07018v1.pdf","comment":"14 pages, 6 figures, 10 tables"},{"id":"http://arxiv.org/abs/2405.17372v3","updated":"2024-11-11T14:20:39Z","published":"2024-05-27T17:28:25Z","title":"BehaviorGPT: Smart Agent Simulation for Autonomous Driving with\n  Next-Patch Prediction","summary":"  Simulating realistic behaviors of traffic agents is pivotal for efficiently\nvalidating the safety of autonomous driving systems. Existing data-driven\nsimulators primarily use an encoder-decoder architecture to encode the\nhistorical trajectories before decoding the future. However, the heterogeneity\nbetween encoders and decoders complicates the models, and the manual separation\nof historical and future trajectories leads to low data utilization. Given\nthese limitations, we propose BehaviorGPT, a homogeneous and fully\nautoregressive Transformer designed to simulate the sequential behavior of\nmultiple agents. Crucially, our approach discards the traditional separation\nbetween \"history\" and \"future\" by modeling each time step as the \"current\" one\nfor motion generation, leading to a simpler, more parameter- and data-efficient\nagent simulator. We further introduce the Next-Patch Prediction Paradigm (NP3)\nto mitigate the negative effects of autoregressive modeling, in which models\nare trained to reason at the patch level of trajectories and capture long-range\nspatial-temporal interactions. Despite having merely 3M model parameters,\nBehaviorGPT won first place in the 2024 Waymo Open Sim Agents Challenge with a\nrealism score of 0.7473 and a minADE score of 1.4147, demonstrating its\nexceptional performance in traffic agent simulation.\n","authors":["Zikang Zhou","Haibo Hu","Xinhong Chen","Jianping Wang","Nan Guan","Kui Wu","Yung-Hui Li","Yu-Kai Huang","Chun Jason Xue"],"pdf_url":"https://arxiv.org/pdf/2405.17372v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07015v1","updated":"2024-11-11T14:18:32Z","published":"2024-11-11T14:18:32Z","title":"Leveraging LSTM for Predictive Modeling of Satellite Clock Bias","summary":"  Satellite clock bias prediction plays a crucial role in enhancing the\naccuracy of satellite navigation systems. In this paper, we propose an approach\nutilizing Long Short-Term Memory (LSTM) networks to predict satellite clock\nbias. We gather data from the PRN 8 satellite of the Galileo and preprocess it\nto obtain a single difference sequence, crucial for normalizing the data.\nNormalization allows resampling of the data, ensuring that the predictions are\nequidistant and complete. Our methodology involves training the LSTM model on\nvarying lengths of datasets, ranging from 7 days to 31 days. We employ a\ntraining set consisting of two days' worth of data in each case. Our LSTM model\nexhibits exceptional accuracy, with a Root Mean Square Error (RMSE) of 2.11\n$\\times$ 10$^{-11}$. Notably, our approach outperforms traditional methods used\nfor similar time-series forecasting projects, being 170 times more accurate\nthan RNN, 2.3 $\\times$ 10$^7$ times more accurate than MLP, and 1.9 $\\times$\n10$^4$ times more accurate than ARIMA. This study holds significant potential\nin enhancing the accuracy and efficiency of low-power receivers used in various\ndevices, particularly those requiring power conservation. By providing more\naccurate predictions of satellite clock bias, the findings of this research can\nbe integrated into the algorithms of such devices, enabling them to function\nwith heightened precision while conserving power. Improved accuracy in clock\nbias predictions ensures that low-power receivers can maintain optimal\nperformance levels, thereby enhancing the overall reliability and effectiveness\nof satellite navigation systems. Consequently, this advancement holds promise\nfor a wide range of applications, including remote areas, IoT devices, wearable\ntechnology, and other devices where power efficiency and navigation accuracy\nare paramount.\n","authors":["Ahan Bhatt","Ishaan Mehta","Pravin Patidar"],"pdf_url":"https://arxiv.org/pdf/2411.07015v1.pdf","comment":"6 Pages, 6 figures (8 sub-figures), 5 Tables Index Terms-LSTM,\n  Satellite Navigation, Deep Learning, Clock Bias"},{"id":"http://arxiv.org/abs/2411.05219v2","updated":"2024-11-11T14:17:13Z","published":"2024-11-07T22:29:05Z","title":"Anticipatory Understanding of Resilient Agriculture to Climate","summary":"  With billions of people facing moderate or severe food insecurity, the\nresilience of the global food supply will be of increasing concern due to the\neffects of climate change and geopolitical events. In this paper we describe a\nframework to better identify food security hotspots using a combination of\nremote sensing, deep learning, crop yield modeling, and causal modeling of the\nfood distribution system. While we feel that the methods are adaptable to other\nregions of the world, we focus our analysis on the wheat breadbasket of\nnorthern India, which supplies a large percentage of the world's population. We\npresent a quantitative analysis of deep learning domain adaptation methods for\nwheat farm identification based on curated remote sensing data from France. We\nmodel climate change impacts on crop yields using the existing crop yield\nmodeling tool WOFOST and we identify key drivers of crop simulation error using\na longitudinal penalized functional regression. A description of a system\ndynamics model of the food distribution system in India is also presented,\nalong with results of food insecurity identification based on seeding this\nmodel with the predicted crop yields.\n","authors":["David Willmes","Nick Krall","James Tanis","Zachary Terner","Fernando Tavares","Chris Miller","Joe Haberlin III","Matt Crichton","Alexander Schlichting"],"pdf_url":"https://arxiv.org/pdf/2411.05219v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07013v1","updated":"2024-11-11T14:15:59Z","published":"2024-11-11T14:15:59Z","title":"A neural-network based anomaly detection system and a safety protocol to\n  protect vehicular network","summary":"  This thesis addresses the use of Cooperative Intelligent Transport Systems\n(CITS) to improve road safety and efficiency by enabling vehicle-to-vehicle\ncommunication, highlighting the importance of secure and accurate data\nexchange. To ensure safety, the thesis proposes a Machine Learning-based\nMisbehavior Detection System (MDS) using Long Short-Term Memory (LSTM) networks\nto detect and mitigate incorrect or misleading messages within vehicular\nnetworks. Trained offline on the VeReMi dataset, the detection model is tested\nin real-time within a platooning scenario, demonstrating that it can prevent\nnearly all accidents caused by misbehavior by triggering a defense protocol\nthat dissolves the platoon if anomalies are detected. The results show that\nwhile the system can accurately detect general misbehavior, it struggles to\nlabel specific types due to varying traffic conditions, implying the difficulty\nof creating a universally adaptive protocol. However, the thesis suggests that\nwith more data and further refinement, this MDS could be implemented in\nreal-world CITS, enhancing driving safety by mitigating risks from misbehavior\nin cooperative driving networks.\n","authors":["Marco Franceschini"],"pdf_url":"https://arxiv.org/pdf/2411.07013v1.pdf","comment":"Master's thesis 2023-2024"},{"id":"http://arxiv.org/abs/2406.07141v2","updated":"2024-11-11T14:10:55Z","published":"2024-06-11T10:40:54Z","title":"Identifiable Object-Centric Representation Learning via Probabilistic\n  Slot Attention","summary":"  Learning modular object-centric representations is crucial for systematic\ngeneralization. Existing methods show promising object-binding capabilities\nempirically, but theoretical identifiability guarantees remain relatively\nunderdeveloped. Understanding when object-centric representations can\ntheoretically be identified is crucial for scaling slot-based methods to\nhigh-dimensional images with correctness guarantees. To that end, we propose a\nprobabilistic slot-attention algorithm that imposes an aggregate mixture prior\nover object-centric slot representations, thereby providing slot\nidentifiability guarantees without supervision, up to an equivalence relation.\nWe provide empirical verification of our theoretical identifiability result\nusing both simple 2-dimensional data and high-resolution imaging datasets.\n","authors":["Avinash Kori","Francesco Locatello","Ainkaran Santhirasekaram","Francesca Toni","Ben Glocker","Fabio De Sousa Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2406.07141v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07009v1","updated":"2024-11-11T14:09:26Z","published":"2024-11-11T14:09:26Z","title":"Hierarchical Conditional Tabular GAN for Multi-Tabular Synthetic Data\n  Generation","summary":"  The generation of synthetic data is a state-of-the-art approach to leverage\nwhen access to real data is limited or privacy regulations limit the usability\nof sensitive data. A fair amount of research has been conducted on synthetic\ndata generation for single-tabular datasets, but only a limited amount of\nresearch has been conducted on multi-tabular datasets with complex table\nrelationships. In this paper we propose the algorithm HCTGAN to synthesize\nmulti-tabular data from complex multi-tabular datasets. We compare our results\nto the probabilistic model HMA1. Our findings show that our proposed algorithm\ncan more efficiently sample large amounts of synthetic data for deep and\ncomplex multi-tabular datasets, whilst achieving adequate data quality and\nalways guaranteeing referential integrity. We conclude that the HCTGAN\nalgorithm is suitable for generating large amounts of synthetic data\nefficiently for deep multi-tabular datasets with complex relationships. We\nadditionally suggest that the HMA1 model should be used on smaller datasets\nwhen emphasis is on data quality.\n","authors":["Wilhelm Ågren","Victorio Úbeda Sosa"],"pdf_url":"https://arxiv.org/pdf/2411.07009v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03729v3","updated":"2024-11-11T14:09:00Z","published":"2024-04-04T18:00:15Z","title":"JUICER: Data-Efficient Imitation Learning for Robotic Assembly","summary":"  While learning from demonstrations is powerful for acquiring visuomotor\npolicies, high-performance imitation without large demonstration datasets\nremains challenging for tasks requiring precise, long-horizon manipulation.\nThis paper proposes a pipeline for improving imitation learning performance\nwith a small human demonstration budget. We apply our approach to assembly\ntasks that require precisely grasping, reorienting, and inserting multiple\nparts over long horizons and multiple task phases. Our pipeline combines\nexpressive policy architectures and various techniques for dataset expansion\nand simulation-based data augmentation. These help expand dataset support and\nsupervise the model with locally corrective actions near bottleneck regions\nrequiring high precision. We demonstrate our pipeline on four furniture\nassembly tasks in simulation, enabling a manipulator to assemble up to five\nparts over nearly 2500 time steps directly from RGB images, outperforming\nimitation and data augmentation baselines. Project website:\nhttps://imitation-juicer.github.io/.\n","authors":["Lars Ankile","Anthony Simeonov","Idan Shenfeld","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2404.03729v3.pdf","comment":"Published at IROS 2024. Project website:\n  https://imitation-juicer.github.io/"},{"id":"http://arxiv.org/abs/2411.07007v1","updated":"2024-11-11T14:05:50Z","published":"2024-11-11T14:05:50Z","title":"Non-Adversarial Inverse Reinforcement Learning via Successor Feature\n  Matching","summary":"  In inverse reinforcement learning (IRL), an agent seeks to replicate expert\ndemonstrations through interactions with the environment. Traditionally, IRL is\ntreated as an adversarial game, where an adversary searches over reward models,\nand a learner optimizes the reward through repeated RL procedures. This\ngame-solving approach is both computationally expensive and difficult to\nstabilize. In this work, we propose a novel approach to IRL by direct policy\noptimization: exploiting a linear factorization of the return as the inner\nproduct of successor features and a reward vector, we design an IRL algorithm\nby policy gradient descent on the gap between the learner and expert features.\nOur non-adversarial method does not require learning a reward function and can\nbe solved seamlessly with existing actor-critic RL algorithms. Remarkably, our\napproach works in state-only settings without expert action labels, a setting\nwhich behavior cloning (BC) cannot solve. Empirical results demonstrate that\nour method learns from as few as a single expert demonstration and achieves\nimproved performance on various control tasks.\n","authors":["Arnav Kumar Jain","Harley Wiltzer","Jesse Farebrother","Irina Rish","Glen Berseth","Sanjiban Choudhury"],"pdf_url":"https://arxiv.org/pdf/2411.07007v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07006v1","updated":"2024-11-11T14:05:39Z","published":"2024-11-11T14:05:39Z","title":"Estimating Causal Effects in Partially Directed Parametric Causal Factor\n  Graphs","summary":"  Lifting uses a representative of indistinguishable individuals to exploit\nsymmetries in probabilistic relational models, denoted as parametric factor\ngraphs, to speed up inference while maintaining exact answers. In this paper,\nwe show how lifting can be applied to causal inference in partially directed\ngraphs, i.e., graphs that contain both directed and undirected edges to\nrepresent causal relationships between random variables. We present partially\ndirected parametric causal factor graphs (PPCFGs) as a generalisation of\npreviously introduced parametric causal factor graphs, which require a fully\ndirected graph. We further show how causal inference can be performed on a\nlifted level in PPCFGs, thereby extending the applicability of lifted causal\ninference to a broader range of models requiring less prior knowledge about\ncausal relationships.\n","authors":["Malte Luttermann","Tanya Braun","Ralf Möller","Marcel Gehrke"],"pdf_url":"https://arxiv.org/pdf/2411.07006v1.pdf","comment":"Accepted to the Proceedings of the 16th International Conference on\n  Scalable Uncertainty Management (SUM 2024)"},{"id":"http://arxiv.org/abs/2402.19197v2","updated":"2024-11-11T14:04:57Z","published":"2024-02-29T14:26:46Z","title":"Fine Structure-Aware Sampling: A New Sampling Training Scheme for\n  Pixel-Aligned Implicit Models in Single-View Human Reconstruction","summary":"  Pixel-aligned implicit models, such as PIFu, PIFuHD, and ICON, are used for\nsingle-view clothed human reconstruction. These models need to be trained using\na sampling training scheme. Existing sampling training schemes either fail to\ncapture thin surfaces (e.g. ears, fingers) or cause noisy artefacts in\nreconstructed meshes. To address these problems, we introduce Fine\nStructured-Aware Sampling (FSS), a new sampling training scheme to train\npixel-aligned implicit models for single-view human reconstruction. FSS\nresolves the aforementioned problems by proactively adapting to the thickness\nand complexity of surfaces. In addition, unlike existing sampling training\nschemes, FSS shows how normals of sample points can be capitalized in the\ntraining process to improve results. Lastly, to further improve the training\nprocess, FSS proposes a mesh thickness loss signal for pixel-aligned implicit\nmodels. It becomes computationally feasible to introduce this loss once a\nslight reworking of the pixel-aligned implicit function framework is carried\nout. Our results show that our methods significantly outperform SOTA methods\nqualitatively and quantitatively. Our code is publicly available at\nhttps://github.com/kcyt/FSS.\n","authors":["Kennard Yanting Chan","Fayao Liu","Guosheng Lin","Chuan Sheng Foo","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2402.19197v2.pdf","comment":"Accepted in Proceedings of the AAAI Conference on Artificial\n  Intelligence, 2024 (AAAI 2024)"},{"id":"http://arxiv.org/abs/2210.11456v4","updated":"2024-11-11T14:00:40Z","published":"2022-10-20T17:54:03Z","title":"MixMask: Revisiting Masking Strategy for Siamese ConvNets","summary":"  The recent progress in self-supervised learning has successfully combined\nMasked Image Modeling (MIM) with Siamese Networks, harnessing the strengths of\nboth methodologies. Nonetheless, certain challenges persist when integrating\nconventional erase-based masking within Siamese ConvNets. Two primary concerns\nare: (1) The continuous data processing nature of ConvNets, which doesn't allow\nfor the exclusion of non-informative masked regions, leading to reduced\ntraining efficiency compared to ViT architecture; (2) The misalignment between\nerase-based masking and the contrastive-based objective, distinguishing it from\nthe MIM technique. To address these challenges, this work introduces a novel\nfilling-based masking approach, termed \\textbf{MixMask}. The proposed method\nreplaces erased areas with content from a different image, effectively\ncountering the information depletion seen in traditional masking methods.\nAdditionally, we unveil an adaptive loss function that captures the semantics\nof the newly patched views, ensuring seamless integration within the\narchitectural framework. We empirically validate the effectiveness of our\napproach through comprehensive experiments across various datasets and\napplication scenarios. The findings underscore our framework's enhanced\nperformance in areas such as linear probing, semi-supervised and supervised\nfinetuning, object detection and segmentation. Notably, our method surpasses\nthe MSCN, establishing MixMask as a more advantageous masking solution for\nSiamese ConvNets. Our code and models are publicly available at\nhttps://github.com/kirill-vish/MixMask.\n","authors":["Kirill Vishniakov","Eric Xing","Zhiqiang Shen"],"pdf_url":"https://arxiv.org/pdf/2210.11456v4.pdf","comment":"Technical report. Code is available at\n  https://github.com/kirill-vish/MixMask"},{"id":"http://arxiv.org/abs/2311.14736v3","updated":"2024-11-11T13:58:11Z","published":"2023-11-21T19:12:18Z","title":"Data Diversity Matters for Robust Instruction Tuning","summary":"  Recent works have shown that by curating high quality and diverse instruction\ntuning datasets, we can significantly improve instruction-following\ncapabilities. However, creating such datasets is difficult and most works rely\non manual curation or proprietary language models. Automatic data curation is\ndifficult as it is still not clear how we can define diversity for instruction\ntuning, how diversity and quality depend on one other, and how we can optimize\ndataset quality and diversity. To resolve these issue, we propose a new\nalgorithm, Quality-Diversity Instruction Tuning (QDIT). QDIT provides a simple\nmethod to simultaneously control dataset diversity and quality, allowing us to\nconduct an in-depth study on the effect of diversity and quality on instruction\ntuning performance. From this study we draw two key insights (1) there is a\nnatural tradeoff between data diversity and quality and (2) increasing data\ndiversity significantly improves the worst case instruction following\nperformance, therefore improving robustness. We validate the performance of\nQDIT on several large scale instruction tuning datasets, where we find it can\nsubstantially improve worst and average case performance compared to\nquality-driven data selection.\n","authors":["Alexander Bukharin","Shiyang Li","Zhengyang Wang","Jingfeng Yang","Bing Yin","Xian Li","Chao Zhang","Tuo Zhao","Haoming Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.14736v3.pdf","comment":"22 pages, 18 figures"},{"id":"http://arxiv.org/abs/2411.06995v1","updated":"2024-11-11T13:53:33Z","published":"2024-11-11T13:53:33Z","title":"Which PPML Would a User Choose? A Structured Decision Support Framework\n  for Developers to Rank PPML Techniques Based on User Acceptance Criteria","summary":"  Using Privacy-Enhancing Technologies (PETs) for machine learning often\ninfluences the characteristics of a machine learning approach, e.g., the needed\ncomputational power, timing of the answers or how the data can be utilized.\nWhen designing a new service, the developer faces the problem that some\ndecisions require a trade-off. For example, the use of a PET may cause a delay\nin the responses or adding noise to the data to improve the users' privacy\nmight have a negative impact on the accuracy of the machine learning approach.\nAs of now, there is no structured way how the users' perception of a machine\nlearning based service can contribute to the selection of Privacy Preserving\nMachine Learning (PPML) methods. This is especially a challenge since one\ncannot assume that users have a deep technical understanding of these\ntechnologies. Therefore, they can only be asked about certain attributes that\nthey can perceive when using the service and not directly which PPML they\nprefer.\n  This study introduces a decision support framework with the aim of supporting\nthe selection of PPML technologies based on user preferences. Based on prior\nwork analysing User Acceptance Criteria (UAC), we translate these criteria into\ndifferentiating characteristics for various PPML techniques. As a final result,\nwe achieve a technology ranking based on the User Acceptance Criteria while\nproviding technology insights for the developers. We demonstrate its\napplication using the use case of classifying privacy-relevant information.\n  Our contribution consists of the decision support framework which consists of\na process to connect PPML technologies with UAC, a process for evaluating the\ncharacteristics that separate PPML techniques, and a ranking method to evaluate\nthe best PPML technique for the use case.\n","authors":["Sascha Löbner","Sebastian Pape","Vanessa Bracamonte","Kittiphop Phalakarn"],"pdf_url":"https://arxiv.org/pdf/2411.06995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06990v1","updated":"2024-11-11T13:48:13Z","published":"2024-11-11T13:48:13Z","title":"Causal-discovery-based root-cause analysis and its application in\n  time-series prediction error diagnosis","summary":"  Recent rapid advancements of machine learning have greatly enhanced the\naccuracy of prediction models, but most models remain \"black boxes\", making\nprediction error diagnosis challenging, especially with outliers. This lack of\ntransparency hinders trust and reliability in industrial applications.\nHeuristic attribution methods, while helpful, often fail to capture true causal\nrelationships, leading to inaccurate error attributions. Various root-cause\nanalysis methods have been developed using Shapley values, yet they typically\nrequire predefined causal graphs, limiting their applicability for prediction\nerrors in machine learning models. To address these limitations, we introduce\nthe Causal-Discovery-based Root-Cause Analysis (CD-RCA) method that estimates\ncausal relationships between the prediction error and the explanatory\nvariables, without needing a pre-defined causal graph. By simulating synthetic\nerror data, CD-RCA can identify variable contributions to outliers in\nprediction errors by Shapley values. Extensive simulations show CD-RCA\noutperforms current heuristic attribution methods, and a sensitivity analysis\nreveals new patterns where Shapley values may misattribute errors, paving the\nway for more accurate error attribution methods.\n","authors":["Hiroshi Yokoyama","Ryusei Shingaki","Kaneharu Nishino","Shohei Shimizu","Thong Pham"],"pdf_url":"https://arxiv.org/pdf/2411.06990v1.pdf","comment":"10 pages with 5 figures"},{"id":"http://arxiv.org/abs/2407.17827v2","updated":"2024-11-11T13:46:50Z","published":"2024-07-25T07:35:27Z","title":"Unified Lexical Representation for Interpretable Visual-Language\n  Alignment","summary":"  Visual-Language Alignment (VLA) has gained a lot of attention since CLIP's\ngroundbreaking work. Although CLIP performs well, the typical direct latent\nfeature alignment lacks clarity in its representation and similarity scores. On\nthe other hand, lexical representation, a vector whose element represents the\nsimilarity between the sample and a word from the vocabulary, is a natural\nsparse representation and interpretable, providing exact matches for individual\nwords. However, lexical representations are difficult to learn due to no\nground-truth supervision and false-discovery issues, and thus requires complex\ndesign to train effectively. In this paper, we introduce LexVLA, a more\ninterpretable VLA framework by learning a unified lexical representation for\nboth modalities without complex design. We use DINOv2 as our visual model for\nits local-inclined features and Llama 2, a generative language model, to\nleverage its in-context lexical prediction ability. To avoid the false\ndiscovery, we propose an overuse penalty to refrain the lexical representation\nfrom falsely frequently activating meaningless words. We demonstrate that these\ntwo pre-trained uni-modal models can be well-aligned by fine-tuning on the\nmodest multi-modal dataset and avoid intricate training configurations. On\ncross-modal retrieval benchmarks, LexVLA, trained on the CC-12M multi-modal\ndataset, outperforms baselines fine-tuned on larger datasets (e.g., YFCC15M)\nand those trained from scratch on even bigger datasets (e.g., 1.1B data,\nincluding CC-12M). We conduct extensive experiments to analyze LexVLA. Codes\nare available at https://github.com/Clementine24/LexVLA.\n","authors":["Yifan Li","Yikai Wang","Yanwei Fu","Dongyu Ru","Zheng Zhang","Tong He"],"pdf_url":"https://arxiv.org/pdf/2407.17827v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2403.10691v2","updated":"2024-11-11T13:33:25Z","published":"2024-03-15T21:21:11Z","title":"MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual\n  Language Modeling","summary":"  A major consideration in multilingual language modeling is how to best\nrepresent languages with diverse vocabularies and scripts. Although\ncontemporary text encoding methods cover most of the world's writing systems,\nthey exhibit bias towards the high-resource languages of the Global West. As a\nresult, texts of underrepresented languages tend to be segmented into long\nsequences of linguistically meaningless units. To address the disparities, we\nintroduce a new paradigm that encodes the same information with segments of\nconsistent size across diverse languages. Our encoding convention (MYTE) is\nbased on morphemes, as their inventories are more balanced across languages\nthan characters, which are used in previous methods. We show that MYTE produces\nshorter encodings for all 99 analyzed languages, with the most notable\nimprovements for non-European languages and non-Latin scripts. This, in turn,\nimproves multilingual LM performance and diminishes the perplexity gap\nthroughout diverse languages.\n","authors":["Tomasz Limisiewicz","Terra Blevins","Hila Gonen","Orevaoghene Ahia","Luke Zettlemoyer"],"pdf_url":"https://arxiv.org/pdf/2403.10691v2.pdf","comment":"Published at ACL 2024"},{"id":"http://arxiv.org/abs/2411.06965v1","updated":"2024-11-11T13:11:18Z","published":"2024-11-11T13:11:18Z","title":"Imitation from Diverse Behaviors: Wasserstein Quality Diversity\n  Imitation Learning with Single-Step Archive Exploration","summary":"  Learning diverse and high-performance behaviors from a limited set of\ndemonstrations is a grand challenge. Traditional imitation learning methods\nusually fail in this task because most of them are designed to learn one\nspecific behavior even with multiple demonstrations. Therefore, novel\ntechniques for quality diversity imitation learning are needed to solve the\nabove challenge. This work introduces Wasserstein Quality Diversity Imitation\nLearning (WQDIL), which 1) improves the stability of imitation learning in the\nquality diversity setting with latent adversarial training based on a\nWasserstein Auto-Encoder (WAE), and 2) mitigates a behavior-overfitting issue\nusing a measure-conditioned reward function with a single-step archive\nexploration bonus. Empirically, our method significantly outperforms\nstate-of-the-art IL methods, achieving near-expert or beyond-expert QD\nperformance on the challenging continuous control tasks derived from MuJoCo\nenvironments.\n","authors":["Xingrui Yu","Zhenglin Wan","David Mark Bossens","Yueming Lyu","Qing Guo","Ivor W. Tsang"],"pdf_url":"https://arxiv.org/pdf/2411.06965v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06958v1","updated":"2024-11-11T13:05:29Z","published":"2024-11-11T13:05:29Z","title":"Data-driven discovery of mechanical models directly from MRI spectral\n  data","summary":"  Finding interpretable biomechanical models can provide insight into the\nfunctionality of organs with regard to physiology and disease. However,\nidentifying broadly applicable dynamical models for in vivo tissue remains\nchallenging. In this proof of concept study we propose a reconstruction\nframework for data-driven discovery of dynamical models from experimentally\nobtained undersampled MRI spectral data. The method makes use of the previously\ndeveloped spectro-dynamic framework which allows for reconstruction of\ndisplacement fields at high spatial and temporal resolution required for model\nidentification. The proposed framework combines this method with data-driven\ndiscovery of interpretable models using Sparse Identification of Non-linear\nDynamics (SINDy). The design of the reconstruction algorithm is such that a\nsymbiotic relation between the reconstruction of the displacement fields and\nthe model identification is created. Our method does not rely on periodicity of\nthe motion. It is successfully validated using spectral data of a dynamic\nphantom gathered on a clinical MRI scanner. The dynamic phantom is programmed\nto perform motion adhering to 5 different (non-linear) ordinary differential\nequations. The proposed framework performed better than a 2-step approach where\nthe displacement fields were first reconstructed from the undersampled data\nwithout any information on the model, followed by data-driven discovery of the\nmodel using the reconstructed displacement fields. This study serves as a first\nstep in the direction of data-driven discovery of in vivo models.\n","authors":["D. G. J. Heesterbeek","M. H. C. van Riel","T. van Leeuwen","C. A. T. van den Berg","A. Sbrizzi"],"pdf_url":"https://arxiv.org/pdf/2411.06958v1.pdf","comment":"11 pages regular paper with 8 figures, 9 pages supplementary material\n  with 6 figures, 1 supplementary video"},{"id":"http://arxiv.org/abs/2409.20361v2","updated":"2024-11-11T12:45:51Z","published":"2024-09-30T14:59:22Z","title":"Rotated Runtime Smooth: Training-Free Activation Smoother for accurate\n  INT4 inference","summary":"  Large language models have demonstrated promising capabilities upon scaling\nup parameters. However, serving large language models incurs substantial\ncomputation and memory movement costs due to their large scale. Quantization\nmethods have been employed to reduce service costs and latency. Nevertheless,\noutliers in activations hinder the development of INT4 weight-activation\nquantization. Existing approaches separate outliers and normal values into two\nmatrices or migrate outliers from activations to weights, suffering from high\nlatency or accuracy degradation. Based on observing activations from large\nlanguage models, outliers can be classified into channel-wise and spike\noutliers. In this work, we propose Rotated Runtime Smooth (RRS), a\nplug-and-play activation smoother for quantization, consisting of Runtime\nSmooth and the Rotation operation. Runtime Smooth (RS) is introduced to\neliminate channel-wise outliers by smoothing activations with channel-wise\nmaximums during runtime. The rotation operation can narrow the gap between\nspike outliers and normal values, alleviating the effect of victims caused by\nchannel-wise smoothing. The proposed method outperforms the state-of-the-art\nmethod in the LLaMA and Qwen families and improves WikiText-2 perplexity from\n57.33 to 6.66 for INT4 inference.\n","authors":["Ke Yi","Zengke Liu","Jianwei Zhang","Chengyuan Li","Tong Zhang","Junyang Lin","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2409.20361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.16468v2","updated":"2024-11-11T12:34:53Z","published":"2023-08-31T05:22:51Z","title":"Computing excited states of molecules using normalizing flows","summary":"  Calculations of highly excited and delocalized molecular vibrational states\nis a computationally challenging task, which strongly depends on the choice of\ncoordinates for describing vibrational motions. We introduce a new method that\nutilizes normalizing flows (parametrized invertible functions) to optimize\nvibrational coordinates to satisfy the variational principle. This approach\nproduces coordinates specifically tailored to the vibrational problem at hand,\nsignificantly increasing the accuracy and enhancing basis set convergence of\ncalculated energy spectrum. The efficiency of the method is demonstrated in\ncalculations of the 100 lowest excited vibrational states of H$_2$S, H$_2$CO,\nand HCN/CNH. The method effectively captures the essential vibrational behavior\nof molecules by enhancing the separability of the Hamiltonian. We further\ndemonstrate that the optimized coordinates are transferable across different\nlevels of basis set truncation, enabling a cost-efficient protocol for\ncomputing vibrational spectra of high-dimensional systems.\n","authors":["Yahya Saleh","Álvaro Fernández Corral","Emil Vogt","Armin Iske","Jochen Küpper","Andrey Yachmenev"],"pdf_url":"https://arxiv.org/pdf/2308.16468v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06919v1","updated":"2024-11-11T12:22:18Z","published":"2024-11-11T12:22:18Z","title":"Understanding Generalization in Quantum Machine Learning with Margins","summary":"  Understanding and improving generalization capabilities is crucial for both\nclassical and quantum machine learning (QML). Recent studies have revealed\nshortcomings in current generalization theories, particularly those relying on\nuniform bounds, across both classical and quantum settings. In this work, we\npresent a margin-based generalization bound for QML models, providing a more\nreliable framework for evaluating generalization. Our experimental studies on\nthe quantum phase recognition (QPR) dataset demonstrate that margin-based\nmetrics are strong predictors of generalization performance, outperforming\ntraditional metrics like parameter count. By connecting this margin-based\nmetric to quantum information theory, we demonstrate how to enhance the\ngeneralization performance of QML through a classical-quantum hybrid approach\nwhen applied to classical data.\n","authors":["Tak Hur","Daniel K. Park"],"pdf_url":"https://arxiv.org/pdf/2411.06919v1.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.06917v1","updated":"2024-11-11T12:20:57Z","published":"2024-11-11T12:20:57Z","title":"Efficient Unsupervised Domain Adaptation Regression for Spatial-Temporal\n  Air Quality Sensor Fusion","summary":"  The deployment of affordable Internet of Things (IoT) sensors for air\npollution monitoring has increased in recent years due to their scalability and\ncost-effectiveness. However, accurately calibrating these sensors in\nuncontrolled environments remains a significant challenge. While expensive\nreference sensors can provide accurate ground truth data, they are often\ndeployed on a limited scale due to high costs, leading to a scarcity of labeled\ndata. In diverse urban environments, data distributions constantly shift due to\nvarying factors such as traffic patterns, industrial activities, and weather\nconditions, which impact sensor readings. Consequently, traditional machine\nlearning models -- despite their increasing deployment for environmental sensor\ncalibration -- often struggle to provide reliable pollutant measurements across\ndifferent locations due to domain shifts. To address these challenges, we\npropose a novel unsupervised domain adaptation (UDA) method specifically\ntailored for regression tasks on graph-structured data. Our approach leverages\nGraph Neural Networks (GNNs) to model the relationships between sensors. To\neffectively capture critical spatial-temporal interactions, we incorporate\nspatial-temporal graph neural networks (STGNNs), which extend GNNs by\nincorporating temporal dynamics. To handle the resulting larger embeddings, we\npropose a domain adaptation method using a closed-form solution inspired by the\nTikhonov-regularized least-squares problem. This method leverages Cholesky\ndecomposition and power iteration to align the subspaces between source and\ntarget domains. By aligning these subspaces, our approach allows low-cost IoT\nsensors to learn calibration parameters from expensive reference sensors. This\nfacilitates reliable pollutant measurements in new locations without the need\nfor additional costly equipment.\n","authors":["Keivan Faghih Niresi","Ismail Nejjar","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2411.06917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06916v1","updated":"2024-11-11T12:19:28Z","published":"2024-11-11T12:19:28Z","title":"Slowing Down Forgetting in Continual Learning","summary":"  A common challenge in continual learning (CL) is catastrophic forgetting,\nwhere the performance on old tasks drops after new, additional tasks are\nlearned. In this paper, we propose a novel framework called ReCL to slow down\nforgetting in CL. Our framework exploits an implicit bias of gradient-based\nneural networks due to which these converge to margin maximization points. Such\nconvergence points allow us to reconstruct old data from previous tasks, which\nwe then combine with the current training data. Our framework is flexible and\ncan be applied on top of existing, state-of-the-art CL methods to slow down\nforgetting. We further demonstrate the performance gain from our framework\nacross a large series of experiments, including different CL scenarios (class\nincremental, domain incremental, task incremental learning) different datasets\n(MNIST, CIFAR10), and different network architectures. Across all experiments,\nwe find large performance gains through ReCL. To the best of our knowledge, our\nframework is the first to address catastrophic forgetting by leveraging models\nin CL as their own memory buffers.\n","authors":["Pascal Janetzky","Tobias Schlagenhauf","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2411.06916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11052v2","updated":"2024-11-11T12:16:49Z","published":"2024-07-09T06:44:09Z","title":"Revisiting, Benchmarking and Understanding Unsupervised Graph Domain\n  Adaptation","summary":"  Unsupervised Graph Domain Adaptation (UGDA) involves the transfer of\nknowledge from a label-rich source graph to an unlabeled target graph under\ndomain discrepancies. Despite the proliferation of methods designed for this\nemerging task, the lack of standard experimental settings and fair performance\ncomparisons makes it challenging to understand which and when models perform\nwell across different scenarios. To fill this gap, we present the first\ncomprehensive benchmark for unsupervised graph domain adaptation named\nGDABench, which encompasses 16 algorithms across 5 datasets with 74 adaptation\ntasks. Through extensive experiments, we observe that the performance of\ncurrent UGDA models varies significantly across different datasets and\nadaptation scenarios. Specifically, we recognize that when the source and\ntarget graphs face significant distribution shifts, it is imperative to\nformulate strategies to effectively address and mitigate graph structural\nshifts. We also find that with appropriate neighbourhood aggregation\nmechanisms, simple GNN variants can even surpass state-of-the-art UGDA\nbaselines. To facilitate reproducibility, we have developed an easy-to-use\nlibrary PyGDA for training and evaluating existing UGDA methods, providing a\nstandardized platform in this community. Our source codes and datasets can be\nfound at: https://github.com/pygda-team/pygda.\n","authors":["Meihan Liu","Zhen Zhang","Jiachen Tang","Jiajun Bu","Bingsheng He","Sheng Zhou"],"pdf_url":"https://arxiv.org/pdf/2407.11052v2.pdf","comment":"Accepted by NeurIPS-24"},{"id":"http://arxiv.org/abs/2411.06911v1","updated":"2024-11-11T12:13:58Z","published":"2024-11-11T12:13:58Z","title":"Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI","summary":"  Segmentation of cardiac magnetic resonance images (MRI) is crucial for the\nanalysis and assessment of cardiac function, helping to diagnose and treat\nvarious cardiovascular diseases. Most recent techniques rely on deep learning\nand usually require an extensive amount of labeled data. To overcome this\nproblem, few-shot learning has the capability of reducing data dependency on\nlabeled data. In this work, we introduce a new method that merges few-shot\nlearning with a U-Net architecture and Gaussian Process Emulators (GPEs),\nenhancing data integration from a support set for improved performance. GPEs\nare trained to learn the relation between the support images and the\ncorresponding masks in latent space, facilitating the segmentation of unseen\nquery images given only a small labeled support set at inference. We test our\nmodel with the M&Ms-2 public dataset to assess its ability to segment the heart\nin cardiac magnetic resonance imaging from different orientations, and compare\nit with state-of-the-art unsupervised and few-shot methods. Our architecture\nshows higher DICE coefficients compared to these methods, especially in the\nmore challenging setups where the size of the support set is considerably\nsmall.\n","authors":["Bruno Viti","Franz Thaler","Kathrin Lisa Kapper","Martin Urschler","Martin Holler","Elias Karabelas"],"pdf_url":"https://arxiv.org/pdf/2411.06911v1.pdf","comment":"Submitted to Statistical Atlases and Computational Modeling of the\n  Heart (STACOM) 2024"},{"id":"http://arxiv.org/abs/2212.10426v7","updated":"2024-11-11T12:05:10Z","published":"2022-12-20T17:04:50Z","title":"Deep Riemannian Networks for End-to-End EEG Decoding","summary":"  State-of-the-art performance in electroencephalography (EEG) decoding tasks\nis currently often achieved with either Deep-Learning (DL) or\nRiemannian-Geometry-based decoders (RBDs). Recently, there is growing interest\nin Deep Riemannian Networks (DRNs) possibly combining the advantages of both\nprevious classes of methods. However, there are still a range of topics where\nadditional insight is needed to pave the way for a more widespread application\nof DRNs in EEG. These include architecture design questions such as network\nsize and end-to-end ability. How these factors affect model performance has not\nbeen explored. Additionally, it is not clear how the data within these networks\nis transformed, and whether this would correlate with traditional EEG decoding.\nOur study aims to lay the groundwork in the area of these topics through the\nanalysis of DRNs for EEG with a wide range of hyperparameters. Networks were\ntested on five public EEG datasets and compared with state-of-the-art ConvNets.\n  Here we propose EE(G)-SPDNet, and we show that this wide, end-to-end DRN can\noutperform the ConvNets, and in doing so use physiologically plausible\nfrequency regions. We also show that the end-to-end approach learns more\ncomplex filters than traditional band-pass filters targeting the classical\nalpha, beta, and gamma frequency bands of the EEG, and that performance can\nbenefit from channel specific filtering approaches. Additionally, architectural\nanalysis revealed areas for further improvement due to the possible under\nutilisation of Riemannian specific information throughout the network. Our\nstudy thus shows how to design and train DRNs to infer task-related information\nfrom the raw EEG without the need of handcrafted filterbanks and highlights the\npotential of end-to-end DRNs such as EE(G)-SPDNet for high-performance EEG\ndecoding.\n","authors":["Daniel Wilson","Robin Tibor Schirrmeister","Lukas Alexander Wilhelm Gemein","Tonio Ball"],"pdf_url":"https://arxiv.org/pdf/2212.10426v7.pdf","comment":"32 pages, 16 Figures, + Supplementary Material"},{"id":"http://arxiv.org/abs/2403.01471v2","updated":"2024-11-11T12:01:06Z","published":"2024-03-03T10:35:46Z","title":"Preserving correlations: A statistical method for generating synthetic\n  data","summary":"  We propose a method to generate statistically representative synthetic data\nfrom a given dataset. The main goal of our method is for the created data set\nto mimic the between feature correlations present in the original data, while\nalso offering a tunable parameter to influence the privacy level. In\nparticular, our method constructs a statistical map by using the empirical\nconditional distributions between the features of the original dataset.\n  We describe in detail our algorithms used both in the construction of a\nstatistical map and how to use this map to generate synthetic observations.\n  This approach is tested in three different ways: with a hand calculated\nexample; a manufactured dataset; and a real world energy-related dataset of\nconsumption/production of households in Madeira Island. We test our method's\nperformance by comparing the datasets using the on Pearson correlation matrix.\n  The proposed methodology is general in the sense that it does not rely on the\nused test dataset. We expect it to be applicable in a much broader context than\nindicated here.\n","authors":["Nicklas Jävergård","Rainey Lyons","Adrian Muntean","Jonas Forsman"],"pdf_url":"https://arxiv.org/pdf/2403.01471v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06899v1","updated":"2024-11-11T11:57:37Z","published":"2024-11-11T11:57:37Z","title":"LongSafetyBench: Long-Context LLMs Struggle with Safety Issues","summary":"  With the development of large language models (LLMs), the sequence length of\nthese models continues to increase, drawing significant attention to\nlong-context language models. However, the evaluation of these models has been\nprimarily limited to their capabilities, with a lack of research focusing on\ntheir safety. Existing work, such as ManyShotJailbreak, has to some extent\ndemonstrated that long-context language models can exhibit safety concerns.\nHowever, the methods used are limited and lack comprehensiveness. In response,\nwe introduce \\textbf{LongSafetyBench}, the first benchmark designed to\nobjectively and comprehensively evaluate the safety of long-context models.\nLongSafetyBench consists of 10 task categories, with an average length of\n41,889 words. After testing eight long-context language models on\nLongSafetyBench, we found that existing models generally exhibit insufficient\nsafety capabilities. The proportion of safe responses from most mainstream\nlong-context LLMs is below 50\\%. Moreover, models' safety performance in\nlong-context scenarios does not always align with that in short-context\nscenarios. Further investigation revealed that long-context models tend to\noverlook harmful content within lengthy texts. We also proposed a simple yet\neffective solution, allowing open-source models to achieve performance\ncomparable to that of top-tier closed-source models. We believe that\nLongSafetyBench can serve as a valuable benchmark for evaluating the safety\ncapabilities of long-context language models. We hope that our work will\nencourage the broader community to pay attention to the safety of long-context\nmodels and contribute to the development of solutions to improve the safety of\nlong-context LLMs.\n","authors":["Mianqiu Huang","Xiaoran Liu","Shaojun Zhou","Mozhi Zhang","Chenkun Tan","Pengyu Wang","Qipeng Guo","Zhe Xu","Linyang Li","Zhikai Lei","Linlin Li","Qun Liu","Yaqian Zhou","Xipeng Qiu","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2411.06899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06890v1","updated":"2024-11-11T11:42:48Z","published":"2024-11-11T11:42:48Z","title":"SPARTAN: A Sparse Transformer Learning Local Causation","summary":"  Causal structures play a central role in world models that flexibly adapt to\nchanges in the environment. While recent works motivate the benefits of\ndiscovering local causal graphs for dynamics modelling, in this work we\ndemonstrate that accurately capturing these relationships in complex settings\nremains challenging for the current state-of-the-art. To remedy this\nshortcoming, we postulate that sparsity is a critical ingredient for the\ndiscovery of such local causal structures. To this end we present the SPARse\nTrANsformer World model (SPARTAN), a Transformer-based world model that learns\nlocal causal structures between entities in a scene. By applying sparsity\nregularisation on the attention pattern between object-factored tokens, SPARTAN\nidentifies sparse local causal models that accurately predict future object\nstates. Furthermore, we extend our model to capture sparse interventions with\nunknown targets on the dynamics of the environment. This results in a highly\ninterpretable world model that can efficiently adapt to changes. Empirically,\nwe evaluate SPARTAN against the current state-of-the-art in object-centric\nworld models on observation-based environments and demonstrate that our model\ncan learn accurate local causal graphs and achieve significantly improved\nfew-shot adaptation to changes in the dynamics of the environment as well as\nrobustness against removing irrelevant distractors.\n","authors":["Anson Lei","Ingmar Posner","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2411.06890v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16947v2","updated":"2024-11-11T11:26:26Z","published":"2024-06-19T10:28:11Z","title":"Generative Data Assimilation of Sparse Weather Station Observations at\n  Kilometer Scales","summary":"  Data assimilation of observational data into full atmospheric states is\nessential for weather forecast model initialization. Recently, methods for deep\ngenerative data assimilation have been proposed which allow for using new input\ndata without retraining the model. They could also dramatically accelerate the\ncostly data assimilation process used in operational regional weather models.\nHere, in a central US testbed, we demonstrate the viability of score-based data\nassimilation in the context of realistically complex km-scale weather. We train\nan unconditional diffusion model to generate snapshots of a state-of-the-art\nkm-scale analysis product, the High Resolution Rapid Refresh. Then, using\nscore-based data assimilation to incorporate sparse weather station data, the\nmodel produces maps of precipitation and surface winds. The generated fields\ndisplay physically plausible structures, such as gust fronts, and sensitivity\ntests confirm learnt physics through multivariate relationships. Preliminary\nskill analysis shows the approach already outperforms a naive baseline of the\nHigh-Resolution Rapid Refresh system itself. By incorporating observations from\n40 weather stations, 10% lower RMSEs on left-out stations are attained. Despite\nsome lingering imperfections such as insufficiently disperse ensemble DA\nestimates, we find the results overall an encouraging proof of concept, and the\nfirst at km-scale. It is a ripe time to explore extensions that combine\nincreasingly ambitious regional state generators with an increasing set of in\nsitu, ground-based, and satellite remote sensing data streams.\n","authors":["Peter Manshausen","Yair Cohen","Jaideep Pathak","Mike Pritchard","Piyush Garg","Morteza Mardani","Karthik Kashinath","Simon Byrne","Noah Brenowitz"],"pdf_url":"https://arxiv.org/pdf/2406.16947v2.pdf","comment":"22 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.06881v1","updated":"2024-11-11T11:26:22Z","published":"2024-11-11T11:26:22Z","title":"WassFFed: Wasserstein Fair Federated Learning","summary":"  Federated Learning (FL) employs a training approach to address scenarios\nwhere users' data cannot be shared across clients. Achieving fairness in FL is\nimperative since training data in FL is inherently geographically distributed\namong diverse user groups. Existing research on fairness predominantly assumes\naccess to the entire training data, making direct transfer to FL challenging.\nHowever, the limited existing research on fairness in FL does not effectively\naddress two key challenges, i.e., (CH1) Current methods fail to deal with the\ninconsistency between fair optimization results obtained with surrogate\nfunctions and fair classification results. (CH2) Directly aggregating local\nfair models does not always yield a globally fair model due to non Identical\nand Independent data Distributions (non-IID) among clients. To address these\nchallenges, we propose a Wasserstein Fair Federated Learning framework, namely\nWassFFed. To tackle CH1, we ensure that the outputs of local models, rather\nthan the loss calculated with surrogate functions or classification results\nwith a threshold, remain independent of various user groups. To resolve CH2, we\nemploy a Wasserstein barycenter calculation of all local models' outputs for\neach user group, bringing local model outputs closer to the global output\ndistribution to ensure consistency between the global model and local models.\nWe conduct extensive experiments on three real-world datasets, demonstrating\nthat WassFFed outperforms existing approaches in striking a balance between\naccuracy and fairness.\n","authors":["Zhongxuan Han","Li Zhang","Chaochao Chen","Xiaolin Zheng","Fei Zheng","Yuyuan Li","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2411.06881v1.pdf","comment":"Submitted to TKDE"},{"id":"http://arxiv.org/abs/2411.06878v1","updated":"2024-11-11T11:20:30Z","published":"2024-11-11T11:20:30Z","title":"GraphRPM: Risk Pattern Mining on Industrial Large Attributed Graphs","summary":"  Graph-based patterns are extensively employed and favored by practitioners\nwithin industrial companies due to their capacity to represent the behavioral\nattributes and topological relationships among users, thereby offering enhanced\ninterpretability in comparison to black-box models commonly utilized for\nclassification and recognition tasks. For instance, within the scenario of\ntransaction risk management, a graph pattern that is characteristic of a\nparticular risk category can be readily employed to discern transactions\nfraught with risk, delineate networks of criminal activity, or investigate the\nmethodologies employed by fraudsters. Nonetheless, graph data in industrial\nsettings is often characterized by its massive scale, encompassing data sets\nwith millions or even billions of nodes, making the manual extraction of graph\npatterns not only labor-intensive but also necessitating specialized knowledge\nin particular domains of risk. Moreover, existing methodologies for mining\ngraph patterns encounter significant obstacles when tasked with analyzing\nlarge-scale attributed graphs. In this work, we introduce GraphRPM, an\nindustry-purpose parallel and distributed risk pattern mining framework on\nlarge attributed graphs. The framework incorporates a novel edge-involved graph\nisomorphism network alongside optimized operations for parallel graph\ncomputation, which collectively contribute to a considerable reduction in\ncomputational complexity and resource expenditure. Moreover, the intelligent\nfiltration of efficacious risky graph patterns is facilitated by the proposed\nevaluation metrics. Comprehensive experimental evaluations conducted on\nreal-world datasets of varying sizes substantiate the capability of GraphRPM to\nadeptly address the challenges inherent in mining patterns from large-scale\nindustrial attributed graphs, thereby underscoring its substantial value for\nindustrial deployment.\n","authors":["Sheng Tian","Xintan Zeng","Yifei Hu","Baokun Wang","Yongchao Liu","Yue Jin","Changhua Meng","Chuntao Hong","Tianyi Zhang","Weiqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2411.06878v1.pdf","comment":"Accepted by ECML PKDD 2024"},{"id":"http://arxiv.org/abs/2411.06869v1","updated":"2024-11-11T11:08:26Z","published":"2024-11-11T11:08:26Z","title":"CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal\n  Large Language Models","summary":"  Category-agnostic pose estimation (CAPE) has traditionally relied on support\nimages with annotated keypoints, a process that is often cumbersome and may\nfail to fully capture the necessary correspondences across diverse object\ncategories. Recent efforts have begun exploring the use of text-based queries,\nwhere the need for support keypoints is eliminated. However, the optimal use of\ntextual descriptions for keypoints remains an underexplored area. In this work,\nwe introduce CapeLLM, a novel approach that leverages a text-based multimodal\nlarge language model (MLLM) for CAPE. Our method only employs query image and\ndetailed text descriptions as an input to estimate category-agnostic keypoints.\nWe conduct extensive experiments to systematically explore the design space of\nLLM-based CAPE, investigating factors such as choosing the optimal description\nfor keypoints, neural network architectures, and training strategies. Thanks to\nthe advanced reasoning capabilities of the pre-trained MLLM, CapeLLM\ndemonstrates superior generalization and robust performance. Our approach sets\na new state-of-the-art on the MP-100 benchmark in the challenging 1-shot\nsetting, marking a significant advancement in the field of category-agnostic\npose estimation.\n","authors":["Junho Kim","Hyungjin Chung","Byung-Hoon Kim"],"pdf_url":"https://arxiv.org/pdf/2411.06869v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06868v1","updated":"2024-11-11T11:07:38Z","published":"2024-11-11T11:07:38Z","title":"Effect sizes as a statistical feature-selector-based learning to detect\n  breast cancer","summary":"  Breast cancer detection is still an open research field, despite a tremendous\neffort devoted to work in this area. Effect size is a statistical concept that\nmeasures the strength of the relationship between two variables on a numeric\nscale. Feature selection is widely used to reduce the dimensionality of data by\nselecting only a subset of predictor variables to improve a learning model. In\nthis work, an algorithm and experimental results demonstrate the feasibility of\ndeveloping a statistical feature-selector-based learning tool capable of\nreducing the data dimensionality using parametric effect size measures from\nfeatures extracted from cell nuclei images. The SVM classifier with a linear\nkernel as a learning tool achieved an accuracy of over 90%. These excellent\nresults suggest that the effect size is within the standards of the\nfeature-selector methods\n","authors":["Nicolas Masino","Antonio Quintero-Rincon"],"pdf_url":"https://arxiv.org/pdf/2411.06868v1.pdf","comment":"16 pages, 10 figures, 5 tables,2024 IEEE Biennial Congress of\n  Argentina (ARGENCON)"},{"id":"http://arxiv.org/abs/2407.02844v4","updated":"2024-11-11T11:05:49Z","published":"2024-07-03T06:40:26Z","title":"Exploiting Precision Mapping and Component-Specific Feature Enhancement\n  for Breast Cancer Segmentation and Identification","summary":"  Breast cancer is a leading cause of mortality worldwide, and demands the\ncritical need for early and accurate diagnostic tools. Ultrasound imaging is a\nwidely used modality for breast cancer screening, yet the precise segmentation\nand classification of tumors in these images are challenging due to variations\nin tumor morphology and image quality. To address these challenges, we propose\nnovel deep learning (DL) frameworks leveraging a precision mapping mechanism\n(PMM) along with a component-specific feature enhancement module (CSFEM) to\nimprove breast cancer lesion segmentation and identification. Our PPM ensures\nthat the segmentation accurately reflects the true shape and extent of the\ntumor by meticulously delineating their boundaries. The CSFEM focuses on\nextracting and amplifying features unique to different tumor types, enabling\nthe model to effectively distinguish between benign, malignant, and normal\ntissues. Integrating PMM and CSFEM into our segmentation model yielded an\naccuracy of 98.1%, an IoU of 96.9%, and a Dice Coefficient of 97.2%. Similarly,\nour classification model achieved an accuracy of 99.2%, with F1-score,\nprecision, and recall values of 99.1%, 99.3%, and 99.1%, respectively. Our\nresults indicate significant improvement in evaluation metrics in comparison to\nstate-of-the-art (SOTA) models, demonstrating the effectiveness of precision\nmapping and component-specific feature enhancement in advancing breast cancer\nlesion analysis.\n","authors":["Pandiyaraju V","Shravan Venkatraman","Pavan Kumar S","Santhosh Malarvannan","Kannan A"],"pdf_url":"https://arxiv.org/pdf/2407.02844v4.pdf","comment":"29 pages, 15 figures, 6 tables"},{"id":"http://arxiv.org/abs/2211.10760v4","updated":"2024-11-11T11:04:06Z","published":"2022-11-19T18:18:52Z","title":"Evaluating Synthetically Generated Data from Small Sample Sizes: An\n  Experimental Study","summary":"  This work proposes a method to evaluate the similarity between low-sample\ntabular data and synthetically generated data with a larger number of samples\nthan the original. The technique is known to as data augmentation. However,\nsignificance values derived from non-parametric tests are questionable when the\nsample size is limited. Our approach uses a combination of geometry, topology,\nand robust statistics for hypothesis testing to evaluate the \"validity\" of\ngenerated data. We additionally contrast the findings with prominent global\nmetric practices described in the literature for large sample size data.\n","authors":["Javier Marin"],"pdf_url":"https://arxiv.org/pdf/2211.10760v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07262v4","updated":"2024-11-11T10:59:52Z","published":"2024-03-12T02:43:41Z","title":"A2PO: Towards Effective Offline Reinforcement Learning from an\n  Advantage-aware Perspective","summary":"  Offline reinforcement learning endeavors to leverage offline datasets to\ncraft effective agent policy without online interaction, which imposes proper\nconservative constraints with the support of behavior policies to tackle the\nout-of-distribution problem. However, existing works often suffer from the\nconstraint conflict issue when offline datasets are collected from multiple\nbehavior policies, i.e., different behavior policies may exhibit inconsistent\nactions with distinct returns across the state space. To remedy this issue,\nrecent advantage-weighted methods prioritize samples with high advantage values\nfor agent training while inevitably ignoring the diversity of behavior policy.\nIn this paper, we introduce a novel Advantage-Aware Policy Optimization (A2PO)\nmethod to explicitly construct advantage-aware policy constraints for offline\nlearning under mixed-quality datasets. Specifically, A2PO employs a conditional\nvariational auto-encoder to disentangle the action distributions of intertwined\nbehavior policies by modeling the advantage values of all training data as\nconditional variables. Then the agent can follow such disentangled action\ndistribution constraints to optimize the advantage-aware policy towards high\nadvantage values. Extensive experiments conducted on both the single-quality\nand mixed-quality datasets of the D4RL benchmark demonstrate that A2PO yields\nresults superior to the counterparts. Our code is available at\nhttps://github.com/Plankson/A2PO\n","authors":["Yunpeng Qing","Shunyu liu","Jingyuan Cong","Kaixuan Chen","Yihe Zhou","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2403.07262v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06866v1","updated":"2024-11-11T10:57:31Z","published":"2024-11-11T10:57:31Z","title":"Subgraph Retrieval Enhanced by Graph-Text Alignment for Commonsense\n  Question Answering","summary":"  Commonsense question answering is a crucial task that requires machines to\nemploy reasoning according to commonsense. Previous studies predominantly\nemploy an extracting-and-modeling paradigm to harness the information in KG,\nwhich first extracts relevant subgraphs based on pre-defined rules and then\nproceeds to design various strategies aiming to improve the representations and\nfusion of the extracted structural knowledge. Despite their effectiveness,\nthere are still two challenges. On one hand, subgraphs extracted by rule-based\nmethods may have the potential to overlook critical nodes and result in\nuncontrollable subgraph size. On the other hand, the misalignment between graph\nand text modalities undermines the effectiveness of knowledge fusion,\nultimately impacting the task performance. To deal with the problems above, we\npropose a novel framework: \\textbf{S}ubgraph R\\textbf{E}trieval Enhanced by\nGra\\textbf{P}h-\\textbf{T}ext \\textbf{A}lignment, named \\textbf{SEPTA}. Firstly,\nwe transform the knowledge graph into a database of subgraph vectors and\npropose a BFS-style subgraph sampling strategy to avoid information loss,\nleveraging the analogy between BFS and the message-passing mechanism. In\naddition, we propose a bidirectional contrastive learning approach for\ngraph-text alignment, which effectively enhances both subgraph retrieval and\nknowledge fusion. Finally, all the retrieved information is combined for\nreasoning in the prediction module. Extensive experiments on five datasets\ndemonstrate the effectiveness and robustness of our framework.\n","authors":["Boci Peng","Yongchao Liu","Xiaohe Bo","Sheng Tian","Baokun Wang","Chuntao Hong","Yan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06866v1.pdf","comment":"Accepted by ECML PKDD 2024"},{"id":"http://arxiv.org/abs/2411.06863v1","updated":"2024-11-11T10:56:31Z","published":"2024-11-11T10:56:31Z","title":"Computable Model-Independent Bounds for Adversarial Quantum Machine\n  Learning","summary":"  By leveraging the principles of quantum mechanics, QML opens doors to novel\napproaches in machine learning and offers potential speedup. However, machine\nlearning models are well-documented to be vulnerable to malicious\nmanipulations, and this susceptibility extends to the models of QML. This\nsituation necessitates a thorough understanding of QML's resilience against\nadversarial attacks, particularly in an era where quantum computing\ncapabilities are expanding. In this regard, this paper examines\nmodel-independent bounds on adversarial performance for QML. To the best of our\nknowledge, we introduce the first computation of an approximate lower bound for\nadversarial error when evaluating model resilience against sophisticated\nquantum-based adversarial attacks. Experimental results are compared to the\ncomputed bound, demonstrating the potential of QML models to achieve high\nrobustness. In the best case, the experimental error is only 10% above the\nestimated bound, offering evidence of the inherent robustness of quantum\nmodels. This work not only advances our theoretical understanding of quantum\nmodel resilience but also provides a precise reference bound for the future\ndevelopment of robust QML algorithms.\n","authors":["Bacui Li","Tansu Alpcan","Chandra Thapa","Udaya Parampalli"],"pdf_url":"https://arxiv.org/pdf/2411.06863v1.pdf","comment":"21 pages, 9 figures"},{"id":"http://arxiv.org/abs/2311.01762v2","updated":"2024-11-11T10:43:06Z","published":"2023-11-03T07:43:53Z","title":"Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant\n  Kernel","summary":"  Kernel ridge regression, KRR, is a generalization of linear ridge regression\nthat is non-linear in the data, but linear in the parameters. The solution can\nbe obtained either as a closed-form solution, which includes solving a system\nof linear equations, or iteratively through gradient descent. Using the\niterative approach opens up for changing the kernel during training, something\nthat is investigated in this paper. We theoretically address the effects this\nhas on model complexity and generalization. Based on our findings, we propose\nan update scheme for the bandwidth of translational-invariant kernels, where we\nlet the bandwidth decrease to zero during training, thus circumventing the need\nfor hyper-parameter selection. We demonstrate on real and synthetic data how\ndecreasing the bandwidth during training outperforms using a constant\nbandwidth, selected by cross-validation and marginal likelihood maximization.\nWe also show theoretically and empirically that using a decreasing bandwidth,\nwe are able to achieve both zero training error in combination with good\ngeneralization, and a double descent behavior, phenomena that do not occur for\nKRR with constant bandwidth but are known to appear for neural networks.\n","authors":["Oskar Allerbo"],"pdf_url":"https://arxiv.org/pdf/2311.01762v2.pdf","comment":"Article arXiv:2306.16838v1 has been updated and split into two\n  articles: this article and arXiv:2306.16838v2. Thus, much of the content in\n  this article is also a part of arXiv:2306.16838v1"},{"id":"http://arxiv.org/abs/2411.06858v1","updated":"2024-11-11T10:40:45Z","published":"2024-11-11T10:40:45Z","title":"Scientific machine learning in ecological systems: A study on the\n  predator-prey dynamics","summary":"  In this study, we apply two pillars of Scientific Machine Learning: Neural\nOrdinary Differential Equations (Neural ODEs) and Universal Differential\nEquations (UDEs) to the Lotka Volterra Predator Prey Model, a fundamental\necological model describing the dynamic interactions between predator and prey\npopulations. The Lotka-Volterra model is critical for understanding ecological\ndynamics, population control, and species interactions, as it is represented by\na system of differential equations. In this work, we aim to uncover the\nunderlying differential equations without prior knowledge of the system,\nrelying solely on training data and neural networks. Using robust modeling in\nthe Julia programming language, we demonstrate that both Neural ODEs and UDEs\ncan be effectively utilized for prediction and forecasting of the\nLotka-Volterra system. More importantly, we introduce the forecasting breakdown\npoint: the time at which forecasting fails for both Neural ODEs and UDEs. We\nobserve how UDEs outperform Neural ODEs by effectively recovering the\nunderlying dynamics and achieving accurate forecasting with significantly less\ntraining data. Additionally, we introduce Gaussian noise of varying magnitudes\n(from mild to high) to simulate real-world data perturbations and show that\nUDEs exhibit superior robustness, effectively recovering the underlying\ndynamics even in the presence of noisy data, while Neural ODEs struggle with\nhigh levels of noise. Through extensive hyperparameter optimization, we offer\ninsights into neural network architectures, activation functions, and\noptimizers that yield the best results. This study opens the door to applying\nScientific Machine Learning frameworks for forecasting tasks across a wide\nrange of ecological and scientific domains.\n","authors":["Ranabir Devgupta","Raj Abhijit Dandekar","Rajat Dandekar","Sreedath Panat"],"pdf_url":"https://arxiv.org/pdf/2411.06858v1.pdf","comment":"16 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2411.04696v2","updated":"2024-11-11T10:38:39Z","published":"2024-11-07T13:29:32Z","title":"The Multiple Dimensions of Spuriousness in Machine Learning","summary":"  Learning correlations from data forms the foundation of today's machine\nlearning (ML) and artificial intelligence (AI) research. While such an approach\nenables the automatic discovery of patterned relationships within big data\ncorpora, it is susceptible to failure modes when unintended correlations are\ncaptured. This vulnerability has expanded interest in interrogating\nspuriousness, often critiqued as an impediment to model performance, fairness,\nand robustness. In this article, we trace deviations from the conventional\ndefinition of statistical spuriousness-which denotes a non-causal observation\narising from either coincidence or confounding variables-to articulate how ML\nresearchers make sense of spuriousness in practice. Drawing on a broad survey\nof ML literature, we conceptualize the \"multiple dimensions of spuriousness,\"\nencompassing: relevance (\"Models should only use correlations that are relevant\nto the task.\"), generalizability (\"Models should only use correlations that\ngeneralize to unseen data\"), human-likeness (\"Models should only use\ncorrelations that a human would use to perform the same task\"), and harmfulness\n(\"Models should only use correlations that are not harmful\"). These dimensions\ndemonstrate that ML spuriousness goes beyond the causal/non-causal dichotomy\nand that the disparate interpretative paths researchers choose could\nmeaningfully influence the trajectory of ML development. By underscoring how a\nfundamental problem in ML is contingently negotiated in research contexts, we\ncontribute to ongoing debates about responsible practices in AI development.\n","authors":["Samuel J. Bell","Skyler Wang"],"pdf_url":"https://arxiv.org/pdf/2411.04696v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06851v1","updated":"2024-11-11T10:35:23Z","published":"2024-11-11T10:35:23Z","title":"Fast and Efficient Transformer-based Method for Bird's Eye View Instance\n  Prediction","summary":"  Accurate object detection and prediction are critical to ensure the safety\nand efficiency of self-driving architectures. Predicting object trajectories\nand occupancy enables autonomous vehicles to anticipate movements and make\ndecisions with future information, increasing their adaptability and reducing\nthe risk of accidents. Current State-Of-The-Art (SOTA) approaches often isolate\nthe detection, tracking, and prediction stages, which can lead to significant\nprediction errors due to accumulated inaccuracies between stages. Recent\nadvances have improved the feature representation of multi-camera perception\nsystems through Bird's-Eye View (BEV) transformations, boosting the development\nof end-to-end systems capable of predicting environmental elements directly\nfrom vehicle sensor data. These systems, however, often suffer from high\nprocessing times and number of parameters, creating challenges for real-world\ndeployment. To address these issues, this paper introduces a novel BEV instance\nprediction architecture based on a simplified paradigm that relies only on\ninstance segmentation and flow prediction. The proposed system prioritizes\nspeed, aiming at reduced parameter counts and inference times compared to\nexisting SOTA architectures, thanks to the incorporation of an efficient\ntransformer-based architecture. Furthermore, the implementation of the proposed\narchitecture is optimized for performance improvements in PyTorch version 2.1.\nCode and trained models are available at\nhttps://github.com/miguelag99/Efficient-Instance-Prediction\n","authors":["Miguel Antunes-García","Luis M. Bergasa","Santiago Montiel-Marín","Rafael Barea","Fabio Sánchez-García","Ángel Llamazares"],"pdf_url":"https://arxiv.org/pdf/2411.06851v1.pdf","comment":"The article has been presented in the 27th IEEE International\n  Conference on Intelligent Transportation Systems (IEEE ITSC 2024) on\n  September, 2024. Number of pages: 6, Number of figures: 4"},{"id":"http://arxiv.org/abs/2411.06850v1","updated":"2024-11-11T10:34:36Z","published":"2024-11-11T10:34:36Z","title":"1-800-SHARED-TASKS @ NLU of Devanagari Script Languages: Detection of\n  Language, Hate Speech, and Targets using LLMs","summary":"  This paper presents a detailed system description of our entry for the\nCHiPSAL 2025 shared task, focusing on language detection, hate speech\nidentification, and target detection in Devanagari script languages. We\nexperimented with a combination of large language models and their ensembles,\nincluding MuRIL, IndicBERT, and Gemma-2, and leveraged unique techniques like\nfocal loss to address challenges in the natural understanding of Devanagari\nlanguages, such as multilingual processing and class imbalance. Our approach\nachieved competitive results across all tasks: F1 of 0.9980, 0.7652, and 0.6804\nfor Sub-tasks A, B, and C respectively. This work provides insights into the\neffectiveness of transformer models in tasks with domain-specific and\nlinguistic challenges, as well as areas for potential improvement in future\niterations.\n","authors":["Jebish Purbey","Siddartha Pullakhandam","Kanwal Mehreen","Muhammad Arham","Drishti Sharma","Ashay Srivastava","Ram Mohan Rao Kadiyala"],"pdf_url":"https://arxiv.org/pdf/2411.06850v1.pdf","comment":"13 pages, Submitted to CHIPSAL workshop @ COLING 2025"},{"id":"http://arxiv.org/abs/2411.06848v1","updated":"2024-11-11T10:32:33Z","published":"2024-11-11T10:32:33Z","title":"Generative Feature Training of Thin 2-Layer Networks","summary":"  We consider the approximation of functions by 2-layer neural networks with a\nsmall number of hidden weights based on the squared loss and small datasets.\nDue to the highly non-convex energy landscape, gradient-based training often\nsuffers from local minima. As a remedy, we initialize the hidden weights with\nsamples from a learned proposal distribution, which we parameterize as a deep\ngenerative model. To train this model, we exploit the fact that with fixed\nhidden weights, the optimal output weights solve a linear equation. After\nlearning the generative model, we refine the sampled weights with a\ngradient-based post-processing in the latent space. Here, we also include a\nregularization scheme to counteract potential noise. Finally, we demonstrate\nthe effectiveness of our approach by numerical examples.\n","authors":["Johannes Hertrich","Sebastian Neumayer"],"pdf_url":"https://arxiv.org/pdf/2411.06848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06839v1","updated":"2024-11-11T10:07:51Z","published":"2024-11-11T10:07:51Z","title":"LLM-Neo: Parameter Efficient Knowledge Distillation for Large Language\n  Models","summary":"  In this paper, we propose a novel LLM-Neo framework that efficiently\ntransfers knowledge from a large language model (LLM) teacher to a compact\nstudent. Initially, we revisit the knowledge distillation (KD) and low-rank\nadaption (LoRA), and argue that they share the same paradigm. Inspired by this\nobservation, we explore the strategy that combines LoRA and KD to enhance the\nefficiency of knowledge transfer. We first summarize some guidelines for this\ndesign and further develop the LLM-Neo. Experimental results on compressing\nLlama 2 and Llama 3 show that LLM-Neo outperforms various baselines. Further\nanalysis demonstrates the robustness of the proposed LLM-Neo on variants of\nLoRA. The trained models have been available at\n\\href{https://huggingface.co/collections/yang31210999/llm-neo-66e3c882f5579b829ff57eba}{this\nrepository}.\n","authors":["Runming Yang","Taiqiang Wu","Jiahao Wang","Pengfei Hu","Ngai Wong","Yujiu Yang"],"pdf_url":"https://arxiv.org/pdf/2411.06839v1.pdf","comment":"ICASSP 25' under review"},{"id":"http://arxiv.org/abs/2411.06836v1","updated":"2024-11-11T10:03:59Z","published":"2024-11-11T10:03:59Z","title":"Spatially Constrained Transformer with Efficient Global Relation\n  Modelling for Spatio-Temporal Prediction","summary":"  Accurate spatio-temporal prediction is crucial for the sustainable\ndevelopment of smart cities. However, current approaches often struggle to\ncapture important spatio-temporal relationships, particularly overlooking\nglobal relations among distant city regions. Most existing techniques\npredominantly rely on Convolutional Neural Networks (CNNs) to capture global\nrelations. However, CNNs exhibit neighbourhood bias, making them insufficient\nfor capturing distant relations. To address this limitation, we propose\nST-SampleNet, a novel transformer-based architecture that combines CNNs with\nself-attention mechanisms to capture both local and global relations\neffectively. Moreover, as the number of regions increases, the quadratic\ncomplexity of self-attention becomes a challenge. To tackle this issue, we\nintroduce a lightweight region sampling strategy that prunes non-essential\nregions and enhances the efficiency of our approach. Furthermore, we introduce\na spatially constrained position embedding that incorporates spatial\nneighbourhood information into the self-attention mechanism, aiding in semantic\ninterpretation and improving the performance of ST-SampleNet. Our experimental\nevaluation on three real-world datasets demonstrates the effectiveness of\nST-SampleNet. Additionally, our efficient variant achieves a 40% reduction in\ncomputational costs with only a marginal compromise in performance,\napproximately 1%.\n","authors":["Ashutosh Sao","Simon Gottschalk"],"pdf_url":"https://arxiv.org/pdf/2411.06836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04242v3","updated":"2024-11-11T10:03:47Z","published":"2024-11-06T20:11:19Z","title":"Multimodal Structure-Aware Quantum Data Processing","summary":"  While large language models (LLMs) have advanced the field of natural\nlanguage processing (NLP), their \"black box\" nature obscures their\ndecision-making processes. To address this, researchers developed structured\napproaches using higher order tensors. These are able to model linguistic\nrelations, but stall when training on classical computers due to their\nexcessive size. Tensors are natural inhabitants of quantum systems and training\non quantum computers provides a solution by translating text to variational\nquantum circuits. In this paper, we develop MultiQ-NLP: a framework for\nstructure-aware data processing with multimodal text+image data. Here,\n\"structure\" refers to syntactic and grammatical relationships in language, as\nwell as the hierarchical organization of visual elements in images. We enrich\nthe translation with new types and type homomorphisms and develop novel\narchitectures to represent structure. When tested on a main stream image\nclassification task (SVO Probes), our best model showed a par performance with\nthe state of the art classical models; moreover the best model was fully\nstructured.\n","authors":["Hala Hawashin","Mehrnoosh Sadrzadeh"],"pdf_url":"https://arxiv.org/pdf/2411.04242v3.pdf","comment":"10 Pages, 16 Figures"},{"id":"http://arxiv.org/abs/2411.06833v1","updated":"2024-11-11T09:51:22Z","published":"2024-11-11T09:51:22Z","title":"Learning Interpretable Network Dynamics via Universal Neural Symbolic\n  Regression","summary":"  Discovering governing equations of complex network dynamics is a fundamental\nchallenge in contemporary science with rich data, which can uncover the\nmysterious patterns and mechanisms of the formation and evolution of complex\nphenomena in various fields and assist in decision-making. In this work, we\ndevelop a universal computational tool that can automatically, efficiently, and\naccurately learn the symbolic changing patterns of complex system states by\ncombining the excellent fitting ability from deep learning and the equation\ninference ability from pre-trained symbolic regression. We conduct intensive\nexperimental verifications on more than ten representative scenarios from\nphysics, biochemistry, ecology, epidemiology, etc. Results demonstrate the\noutstanding effectiveness and efficiency of our tool by comparing with the\nstate-of-the-art symbolic regression techniques for network dynamics. The\napplication to real-world systems including global epidemic transmission and\npedestrian movements has verified its practical applicability. We believe that\nour tool can serve as a universal solution to dispel the fog of hidden\nmechanisms of changes in complex phenomena, advance toward interpretability,\nand inspire more scientific discoveries.\n","authors":["Jiao Hu","Jiaxu Cui","Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2411.06833v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2411.06832v1","updated":"2024-11-11T09:48:38Z","published":"2024-11-11T09:48:38Z","title":"Optimized Quality of Service prediction in FSO Links over South Africa\n  using Ensemble Learning","summary":"  Fibre optic communication system is expected to increase exponentially in\nterms of application due to the numerous advantages over copper wires. The\noptical network evolution presents several advantages such as over\nlong-distance, low-power requirement, higher carrying capacity and high\nbandwidth among others Such network bandwidth surpasses methods of transmission\nthat include copper cables and microwaves. Despite these benefits, free-space\noptical communications are severely impacted by harsh weather situations like\nmist, precipitation, blizzard, fume, soil, and drizzle debris in the\natmosphere, all of which have an impact on the Quality of Service (QoS)\nrendered by the systems. The primary goal of this article is to optimize the\nQoS using the ensemble learning models Random Forest, ADaBoost Regression,\nStacking Regression, Gradient Boost Regression, and Multilayer Neural Network.\nTo accomplish the stated goal, meteorological data, visibility, wind speed, and\naltitude were obtained from the South Africa Weather Services archive during a\nten-year period (2010 to 2019) at four different locations: Polokwane,\nKimberley, Bloemfontein, and George. We estimated the data rate, power\nreceived, fog-induced attenuation, bit error rate and power penalty using the\ncollected and processed data. The RMSE and R-squared values of the model across\nall the study locations, Polokwane, Kimberley, Bloemfontein, and George, are\n0.0073 and 0.9951, 0.0065 and 0.9998, 0.0060 and 0.9941, and 0.0032 and 0.9906,\nrespectively. The result showed that using ensemble learning techniques in\ntransmission modeling can significantly enhance service quality and meet\ncustomer service level agreements and ensemble method was successful in\nefficiently optimizing the signal to noise ratio, which in turn enhanced the\nQoS at the point of reception.\n","authors":["S. O. Adebusola","P. A. Owolawi","J. S. Ojo","P. S. Maswikaneng"],"pdf_url":"https://arxiv.org/pdf/2411.06832v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06826v1","updated":"2024-11-11T09:39:31Z","published":"2024-11-11T09:39:31Z","title":"Adaptive Conditional Expert Selection Network for Multi-domain\n  Recommendation","summary":"  Mixture-of-Experts (MOE) has recently become the de facto standard in\nMulti-domain recommendation (MDR) due to its powerful expressive ability.\nHowever, such MOE-based method typically employs all experts for each instance,\nleading to scalability issue and low-discriminability between domains and\nexperts. Furthermore, the design of commonly used domain-specific networks\nexacerbates the scalability issues. To tackle the problems, We propose a novel\nmethod named CESAA consists of Conditional Expert Selection (CES) Module and\nAdaptive Expert Aggregation (AEA) Module to tackle these challenges.\nSpecifically, CES first combines a sparse gating strategy with domain-shared\nexperts. Then AEA utilizes mutual information loss to strengthen the\ncorrelations between experts and specific domains, and significantly improve\nthe distinction between experts. As a result, only domain-shared experts and\nselected domain-specific experts are activated for each instance, striking a\nbalance between computational efficiency and model performance. Experimental\nresults on both public ranking and industrial retrieval datasets verify the\neffectiveness of our method in MDR tasks.\n","authors":["Kuiyao Dong","Xingyu Lou","Feng Liu","Ruian Wang","Wenyi Yu","Ping Wang","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2411.06826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.09461v2","updated":"2024-11-11T09:37:09Z","published":"2024-09-14T15:13:28Z","title":"TX-Gen: Multi-Objective Optimization for Sparse Counterfactual\n  Explanations for Time-Series Classification","summary":"  In time-series classification, understanding model decisions is crucial for\ntheir application in high-stakes domains such as healthcare and finance.\nCounterfactual explanations, which provide insights by presenting alternative\ninputs that change model predictions, offer a promising solution. However,\nexisting methods for generating counterfactual explanations for time-series\ndata often struggle with balancing key objectives like proximity, sparsity, and\nvalidity. In this paper, we introduce TX-Gen, a novel algorithm for generating\ncounterfactual explanations based on the Non-dominated Sorting Genetic\nAlgorithm II (NSGA-II). TX-Gen leverages evolutionary multi-objective\noptimization to find a diverse set of counterfactuals that are both sparse and\nvalid, while maintaining minimal dissimilarity to the original time series. By\nincorporating a flexible reference-guided mechanism, our method improves the\nplausibility and interpretability of the counterfactuals without relying on\npredefined assumptions. Extensive experiments on benchmark datasets demonstrate\nthat TX-Gen outperforms existing methods in generating high-quality\ncounterfactuals, making time-series models more transparent and interpretable.\n","authors":["Qi Huang","Sofoklis Kitharidis","Thomas Bäck","Niki van Stein"],"pdf_url":"https://arxiv.org/pdf/2409.09461v2.pdf","comment":"Accepted to EXPLAINS 2024"},{"id":"http://arxiv.org/abs/2411.06823v1","updated":"2024-11-11T09:31:46Z","published":"2024-11-11T09:31:46Z","title":"Large Language Model in Medical Informatics: Direct Classification and\n  Enhanced Text Representations for Automatic ICD Coding","summary":"  Addressing the complexity of accurately classifying International\nClassification of Diseases (ICD) codes from medical discharge summaries is\nchallenging due to the intricate nature of medical documentation. This paper\nexplores the use of Large Language Models (LLM), specifically the LLAMA\narchitecture, to enhance ICD code classification through two methodologies:\ndirect application as a classifier and as a generator of enriched text\nrepresentations within a Multi-Filter Residual Convolutional Neural Network\n(MultiResCNN) framework. We evaluate these methods by comparing them against\nstate-of-the-art approaches, revealing LLAMA's potential to significantly\nimprove classification outcomes by providing deep contextual insights into\nmedical texts.\n","authors":["Zeyd Boukhers","AmeerAli Khan","Qusai Ramadan","Cong Yang"],"pdf_url":"https://arxiv.org/pdf/2411.06823v1.pdf","comment":"accepted at the 2024 IEEE International Conference on Bioinformatics\n  and Biomedicine (BIBM 2024)"},{"id":"http://arxiv.org/abs/2308.10792v7","updated":"2024-11-11T09:25:48Z","published":"2023-08-21T15:35:16Z","title":"Instruction Tuning for Large Language Models: A Survey","summary":"  This paper surveys research works in the quickly advancing field of\ninstruction tuning (IT), which can also be referred to as supervised\nfine-tuning (SFT)\\footnote{In this paper, unless specified otherwise,\ninstruction tuning (IT) will be equivalent to supervised fine-tuning (SFT).}, a\ncrucial technique to enhance the capabilities and controllability of large\nlanguage models (LLMs). Instruction tuning refers to the process of further\ntraining LLMs on a dataset consisting of \\textsc{(instruction, output)} pairs\nin a supervised fashion, which bridges the gap between the next-word prediction\nobjective of LLMs and the users' objective of having LLMs adhere to human\ninstructions. In this work, we make a systematic review of the literature,\nincluding the general methodology of IT, the construction of IT datasets, the\ntraining of IT models, and applications to different modalities, domains and\napplication, along with analysis on aspects that influence the outcome of IT\n(e.g., generation of instruction outputs, size of the instruction dataset,\netc). We also review the potential pitfalls of IT along with criticism against\nit, along with efforts pointing out current deficiencies of existing strategies\nand suggest some avenues for fruitful research.Project page:\ngithub.com/xiaoya-li/Instruction-Tuning-Survey\n","authors":["Shengyu Zhang","Linfeng Dong","Xiaoya Li","Sen Zhang","Xiaofei Sun","Shuhe Wang","Jiwei Li","Runyi Hu","Tianwei Zhang","Fei Wu","Guoyin Wang"],"pdf_url":"https://arxiv.org/pdf/2308.10792v7.pdf","comment":"V4; Last update: Nov 11, 2024"},{"id":"http://arxiv.org/abs/2405.03911v2","updated":"2024-11-11T09:23:00Z","published":"2024-05-07T00:08:15Z","title":"Federated Graph Condensation with Information Bottleneck Principles","summary":"  Graph condensation, which reduces the size of a large-scale graph by\nsynthesizing a small-scale condensed graph as its substitution, has immediately\nbenefited various graph learning tasks. However, existing graph condensation\nmethods rely on centralized data storage, which is unfeasible for real-world\ndecentralized data distribution, and overlook data holders' privacy-preserving\nrequirements. To bridge the gap, we propose and study the novel problem of\nfederated graph condensation for graph neural networks (GNNs). Specifically, we\nfirst propose a general framework for federated graph condensation, in which we\ndecouple the typical gradient matching process for graph condensation into\nclient-side gradient calculation and server-side gradient matching. In this\nway, the burdensome computation cost in client-side is largely alleviated.\nBesides, our empirical studies show that under the federated setting, the\ncondensed graph will consistently leak data membership privacy, i.e., the\ncondensed graph during the federated training can be utilized to steal the\ntraining data under the membership inference attacks (MIA). To tackle this\nissue, we innovatively incorporate information bottleneck principles into the\nfederated graph condensation, which only needs to extract partial node features\nin one local pre-training step and utilize the features during federated\ntraining. Extensive experiments on real-world datasets demonstrate that our\nframework can consistently protect membership privacy during training.\nMeanwhile, it also achieves comparable and even superior performance against\nexisting centralized graph condensation and federated graph learning methods.\n","authors":["Bo Yan","Sihao He","Cheng Yang","Shang Liu","Yang Cao","Chuan Shi"],"pdf_url":"https://arxiv.org/pdf/2405.03911v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2411.06815v1","updated":"2024-11-11T09:22:09Z","published":"2024-11-11T09:22:09Z","title":"Streetwise Agents: Empowering Offline RL Policies to Outsmart Exogenous\n  Stochastic Disturbances in RTC","summary":"  The difficulty of exploring and training online on real production systems\nlimits the scope of real-time online data/feedback-driven decision making. The\nmost feasible approach is to adopt offline reinforcement learning from limited\ntrajectory samples. However, after deployment, such policies fail due to\nexogenous factors that temporarily or permanently disturb/alter the transition\ndistribution of the assumed decision process structure induced by offline\nsamples. This results in critical policy failures and generalization errors in\nsensitive domains like Real-Time Communication (RTC). We solve this crucial\nproblem of identifying robust actions in presence of domain shifts due to\nunseen exogenous stochastic factors in the wild. As it is impossible to learn\ngeneralized offline policies within the support of offline data that are robust\nto these unseen exogenous disturbances, we propose a novel post-deployment\nshaping of policies (Streetwise), conditioned on real-time characterization of\nout-of-distribution sub-spaces. This leads to robust actions in bandwidth\nestimation (BWE) of network bottlenecks in RTC and in standard benchmarks. Our\nextensive experimental results on BWE and other standard offline RL benchmark\nenvironments demonstrate a significant improvement ($\\approx$ 18% on some\nscenarios) in final returns wrt. end-user metrics over state-of-the-art\nbaselines.\n","authors":["Aditya Soni","Mayukh Das","Anjaly Parayil","Supriyo Ghosh","Shivam Shandilya","Ching-An Cheng","Vishak Gopal","Sami Khairy","Gabriel Mittag","Yasaman Hosseinkashi","Chetan Bansal"],"pdf_url":"https://arxiv.org/pdf/2411.06815v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04875v4","updated":"2024-11-11T09:22:02Z","published":"2024-02-07T14:16:28Z","title":"On Provable Length and Compositional Generalization","summary":"  Out-of-distribution generalization capabilities of sequence-to-sequence\nmodels can be studied from the lens of two crucial forms of generalization:\nlength generalization -- the ability to generalize to longer sequences than\nones seen during training, and compositional generalization: the ability to\ngeneralize to token combinations not seen during training. In this work, we\nprovide first provable guarantees on length and compositional generalization\nfor common sequence-to-sequence models -- deep sets, transformers, state space\nmodels, and recurrent neural nets -- trained to minimize the prediction error.\nTaking a first principles perspective, we study the realizable case, i.e., the\nlabeling function is realizable on the architecture. We show that \\emph{simple\nlimited capacity} versions of these different architectures achieve both length\nand compositional generalization. In all our results across different\narchitectures, we find that the learned representations are linearly related to\nthe representations generated by the true labeling function.\n","authors":["Kartik Ahuja","Amin Mansouri"],"pdf_url":"https://arxiv.org/pdf/2402.04875v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09220v3","updated":"2024-11-11T09:16:56Z","published":"2024-05-15T09:59:37Z","title":"ALPINE: Unveiling the Planning Capability of Autoregressive Learning in\n  Language Models","summary":"  Planning is a crucial element of both human intelligence and contemporary\nlarge language models (LLMs). In this paper, we initiate a theoretical\ninvestigation into the emergence of planning capabilities in Transformer-based\nLLMs via their next-word prediction mechanisms. We model planning as a network\npath-finding task, where the objective is to generate a valid path from a\nspecified source node to a designated target node. Our mathematical\ncharacterization shows that Transformer architectures can execute path-finding\nby embedding the adjacency and reachability matrices within their weights.\nFurthermore, our theoretical analysis of gradient-based learning dynamics\nreveals that LLMs can learn both the adjacency and a limited form of the\nreachability matrices. These theoretical insights are then validated through\nexperiments, which demonstrate that Transformer architectures indeed learn the\nadjacency and an incomplete reachability matrices, consistent with our\ntheoretical predictions. When applying our methodology to the real-world\nplanning benchmark Blocksworld, our observations remain consistent.\nAdditionally, our analyses uncover a fundamental limitation of current\nTransformer architectures in path-finding: these architectures cannot identify\nreachability relationships through transitivity, which leads to failures in\ngenerating paths when concatenation is required. These findings provide new\ninsights into how the internal mechanisms of autoregressive learning facilitate\nintelligent planning and deepen our understanding of how future LLMs might\nachieve more advanced and general planning-and-reasoning capabilities across\ndiverse applications.\n","authors":["Siwei Wang","Yifei Shen","Shi Feng","Haoran Sun","Shang-Hua Teng","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2405.09220v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15729v2","updated":"2024-11-11T09:15:21Z","published":"2024-10-21T07:44:57Z","title":"Two-stage Learning-to-Defer for Multi-Task Learning","summary":"  The Learning-to-Defer approach has been explored for classification and, more\nrecently, regression tasks separately. Many contemporary learning tasks,\nhowever, involves both classification and regression components. In this paper,\nwe introduce a Learning-to-Defer approach for multi-task learning that\nencompasses both classification and regression tasks. Our two-stage approach\nutilizes a rejector that defers decisions to the most accurate agent among a\npre-trained joint classifier-regressor models and one or more external experts.\nWe show that our surrogate loss is $(\\mathcal{H}, \\mathcal{F}, \\mathcal{R})$\nand Bayes--consistent, ensuring an effective approximation of the optimal\nsolution. Additionally, we derive learning bounds that demonstrate the benefits\nof employing multiple confident experts along a rich model in a two-stage\nlearning framework. Empirical experiments conducted on electronic health record\nanalysis tasks underscore the performance enhancements achieved through our\nmethod.\n","authors":["Yannis Montreuil","Shu Heng Yeo","Axel Carlier","Lai Xing Ng","Wei Tsang Ooi"],"pdf_url":"https://arxiv.org/pdf/2410.15729v2.pdf","comment":"32 pages, 17 main paper"},{"id":"http://arxiv.org/abs/2411.06812v1","updated":"2024-11-11T09:14:27Z","published":"2024-11-11T09:14:27Z","title":"Generative midtended cognition and Artificial Intelligence. Thinging\n  with thinging things","summary":"  This paper introduces the concept of ``generative midtended cognition'',\nexploring the integration of generative AI with human cognition. The term\n\"generative\" reflects AI's ability to iteratively produce structured outputs,\nwhile \"midtended\" captures the potential hybrid (human-AI) nature of the\nprocess. It stands between traditional conceptions of intended creation,\nunderstood directed from within, and extended processes that bring\nexo-biological processes into the creative process. We examine current\ngenerative technologies (based on multimodal transformer architectures typical\nof large language models like ChatGPT), to explain how they can transform human\ncognitive agency beyond what standard theories of extended cognition can\ncapture. We suggest that the type of cognitive activity typical of the coupling\nbetween a human and generative technologies is closer (but not equivalent) to\nsocial cognition than to classical extended cognitive paradigms. Yet, it\ndeserves a specific treatment. We provide an explicit definition of generative\nmidtended cognition in which we treat interventions by AI systems as\nconstitutive of the agent's intentional creative processes. Furthermore, we\ndistinguish two dimensions of generative hybrid creativity: 1. Width: captures\nthe sensitivity of the context of the generative process (from the single\nletter to the whole historical and surrounding data), 2. Depth: captures the\ngranularity of iteration loops involved in the process. Generative midtended\ncognition stands in the middle depth between conversational forms of cognition\nin which complete utterances or creative units are exchanged, and\nmicro-cognitive (e.g. neural) subpersonal processes. Finally, the paper\ndiscusses the potential risks and benefits of widespread generative AI\nadoption, including the challenges of authenticity, generative power asymmetry,\nand creative boost or atrophy.\n","authors":["Xabier E. Barandiaran","Marta Pérez-Verdugo"],"pdf_url":"https://arxiv.org/pdf/2411.06812v1.pdf","comment":"16 pages, 2 figures. Submitted to \"Synthese\" Journal, accepted"},{"id":"http://arxiv.org/abs/2410.15761v2","updated":"2024-11-11T09:06:51Z","published":"2024-10-21T08:21:00Z","title":"Learning-to-Defer for Extractive Question Answering","summary":"  Pre-trained language models have profoundly impacted the field of extractive\nquestion-answering, leveraging large-scale textual corpora to enhance\ncontextual language understanding. Despite their success, these models struggle\nin complex scenarios that demand nuanced interpretation or inferential\nreasoning beyond immediate textual cues. Furthermore, their size poses\ndeployment challenges on resource-constrained devices. Addressing these\nlimitations, we introduce an adapted two-stage Learning-to-Defer mechanism that\nenhances decision-making by enabling selective deference to human experts or\nlarger models without retraining language models in the context of\nquestion-answering. This approach not only maintains computational efficiency\nbut also significantly improves model reliability and accuracy in ambiguous\ncontexts. We establish the theoretical soundness of our methodology by proving\nBayes and $(\\mathcal{H}, \\mathcal{R})$--consistency of our surrogate loss\nfunction, guaranteeing the optimality of the final solution. Empirical\nevaluations on the SQuADv2 dataset illustrate performance gains from\nintegrating human expertise and leveraging larger models. Our results further\ndemonstrate that deferring a minimal number of queries allows the smaller model\nto achieve performance comparable to their larger counterparts while preserving\ncomputing efficiency, thus broadening the applicability of pre-trained language\nmodels in diverse operational environments.\n","authors":["Yannis Montreuil","Axel Carlier","Lai Xing Ng","Wei Tsang Ooi"],"pdf_url":"https://arxiv.org/pdf/2410.15761v2.pdf","comment":"25 pages, 17 main paper"},{"id":"http://arxiv.org/abs/2405.04097v2","updated":"2024-11-11T09:05:15Z","published":"2024-05-07T07:57:15Z","title":"Unmasking Illusions: Understanding Human Perception of Audiovisual\n  Deepfakes","summary":"  The emergence of contemporary deepfakes has attracted significant attention\nin machine learning research, as artificial intelligence (AI) generated\nsynthetic media increases the incidence of misinterpretation and is difficult\nto distinguish from genuine content. Currently, machine learning techniques\nhave been extensively studied for automatically detecting deepfakes. However,\nhuman perception has been less explored. Malicious deepfakes could ultimately\ncause public and social problems. Can we humans correctly perceive the\nauthenticity of the content of the videos we watch? The answer is obviously\nuncertain; therefore, this paper aims to evaluate the human ability to discern\ndeepfake videos through a subjective study. We present our findings by\ncomparing human observers to five state-ofthe-art audiovisual deepfake\ndetection models. To this end, we used gamification concepts to provide 110\nparticipants (55 native English speakers and 55 non-native English speakers)\nwith a webbased platform where they could access a series of 40 videos (20 real\nand 20 fake) to determine their authenticity. Each participant performed the\nexperiment twice with the same 40 videos in different random orders. The videos\nare manually selected from the FakeAVCeleb dataset. We found that all AI models\nperformed better than humans when evaluated on the same 40 videos. The study\nalso reveals that while deception is not impossible, humans tend to\noverestimate their detection capabilities. Our experimental results may help\nbenchmark human versus machine performance, advance forensics analysis, and\nenable adaptive countermeasures.\n","authors":["Ammarah Hashmi","Sahibzada Adil Shahzad","Chia-Wen Lin","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2405.04097v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08878v4","updated":"2024-11-11T09:02:49Z","published":"2024-06-13T07:31:29Z","title":"CIMRL: Combining IMitation and Reinforcement Learning for Safe\n  Autonomous Driving","summary":"  Modern approaches to autonomous driving rely heavily on learned components\ntrained with large amounts of human driving data via imitation learning.\nHowever, these methods require large amounts of expensive data collection and\neven then face challenges with safely handling long-tail scenarios and\ncompounding errors over time. At the same time, pure Reinforcement Learning\n(RL) methods can fail to learn performant policies in sparse, constrained, and\nchallenging-to-define reward settings such as autonomous driving. Both of these\nchallenges make deploying purely cloned or pure RL policies in safety critical\napplications such as autonomous vehicles challenging. In this paper we propose\nCombining IMitation and Reinforcement Learning (CIMRL) approach - a safe\nreinforcement learning framework that enables training driving policies in\nsimulation through leveraging imitative motion priors and safety constraints.\nCIMRL does not require extensive reward specification and improves on the\nclosed loop behavior of pure cloning methods. By combining RL and imitation, we\ndemonstrate that our method achieves state-of-the-art results in closed loop\nsimulation and real world driving benchmarks.\n","authors":["Jonathan Booher","Khashayar Rohanimanesh","Junhong Xu","Vladislav Isenbaev","Ashwin Balakrishna","Ishan Gupta","Wei Liu","Aleksandr Petiushko"],"pdf_url":"https://arxiv.org/pdf/2406.08878v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06804v1","updated":"2024-11-11T09:01:36Z","published":"2024-11-11T09:01:36Z","title":"Predicting ionic conductivity in solids from the machine-learned\n  potential energy landscape","summary":"  Discovering new superionic materials is essential for advancing solid-state\nbatteries, which offer improved energy density and safety compared to the\ntraditional lithium-ion batteries with liquid electrolytes. Conventional\ncomputational methods for identifying such materials are resource-intensive and\nnot easily scalable. Recently, universal interatomic potential models have been\ndeveloped using equivariant graph neural networks. These models are trained on\nextensive datasets of first-principles force and energy calculations. One can\nachieve significant computational advantages by leveraging them as the\nfoundation for traditional methods of assessing the ionic conductivity, such as\nmolecular dynamics or nudged elastic band techniques. However, the\ngeneralization error from model inference on diverse atomic structures arising\nin such calculations can compromise the reliability of the results. In this\nwork, we propose an approach for the quick and reliable evaluation of ionic\nconductivity through the analysis of a universal interatomic potential. Our\nmethod incorporates a set of heuristic structure descriptors that effectively\nemploy the rich knowledge of the underlying model while requiring minimal\ngeneralization capabilities. Using our descriptors, we rank lithium-containing\nmaterials in the Materials Project database according to their expected ionic\nconductivity. Eight out of the ten highest-ranked materials are confirmed to be\nsuperionic at room temperature in first-principles calculations. Notably, our\nmethod achieves a speed-up factor of approximately 50 compared to molecular\ndynamics driven by a machine-learning potential, and is at least 3,000 times\nfaster compared to first-principles molecular dynamics.\n","authors":["Artem Maevskiy","Alexandra Carvalho","Emil Sataev","Volha Turchyna","Keian Noori","Aleksandr Rodin","A. H. Castro Neto","Andrey Ustyuzhanin"],"pdf_url":"https://arxiv.org/pdf/2411.06804v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06799v1","updated":"2024-11-11T08:53:02Z","published":"2024-11-11T08:53:02Z","title":"Structuring the Processing Frameworks for Data Stream Evaluation and\n  Application","summary":"  The following work addresses the problem of frameworks for data stream\nprocessing that can be used to evaluate the solutions in an environment that\nresembles real-world applications. The definition of structured frameworks\nstems from a need to reliably evaluate the data stream classification methods,\nconsidering the constraints of delayed and limited label access. The current\nexperimental evaluation often boundlessly exploits the assumption of their\ncomplete and immediate access to monitor the recognition quality and to adapt\nthe methods to the changing concepts. The problem is leveraged by reviewing\ncurrently described methods and techniques for data stream processing and\nverifying their outcomes in simulated environment. The effect of the work is a\nproposed taxonomy of data stream processing frameworks, showing the linkage\nbetween drift detection and classification methods considering a natural\nphenomenon of label delay.\n","authors":["Joanna Komorniczak","Paweł Ksieniewicz","Paweł Zyblewski"],"pdf_url":"https://arxiv.org/pdf/2411.06799v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.09938v5","updated":"2024-11-11T08:34:20Z","published":"2022-04-21T07:54:58Z","title":"Ultra-marginal Feature Importance: Learning from Data with Causal\n  Guarantees","summary":"  Scientists frequently prioritize learning from data rather than training the\nbest possible model; however, research in machine learning often prioritizes\nthe latter. Marginal contribution feature importance (MCI) was developed to\nbreak this trend by providing a useful framework for quantifying the\nrelationships in data. In this work, we aim to improve upon the theoretical\nproperties, performance, and runtime of MCI by introducing ultra-marginal\nfeature importance (UMFI), which uses dependence removal techniques from the AI\nfairness literature as its foundation. We first propose axioms for feature\nimportance methods that seek to explain the causal and associative\nrelationships in data, and we prove that UMFI satisfies these axioms under\nbasic assumptions. We then show on real and simulated data that UMFI performs\nbetter than MCI, especially in the presence of correlated interactions and\nunrelated features, while partially learning the structure of the causal graph\nand reducing the exponential runtime of MCI to super-linear.\n","authors":["Joseph Janssen","Vincent Guan","Elina Robeva"],"pdf_url":"https://arxiv.org/pdf/2204.09938v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06786v1","updated":"2024-11-11T08:25:21Z","published":"2024-11-11T08:25:21Z","title":"ScaleKD: Strong Vision Transformers Could Be Excellent Teachers","summary":"  In this paper, we question if well pre-trained vision transformer (ViT)\nmodels could be used as teachers that exhibit scalable properties to advance\ncross architecture knowledge distillation (KD) research, in the context of\nusing large-scale datasets for evaluation. To make this possible, our analysis\nunderlines the importance of seeking effective strategies to align (1) feature\ncomputing paradigm differences, (2) model scale differences, and (3) knowledge\ndensity differences. By combining three coupled components namely cross\nattention projector, dual-view feature mimicking and teacher parameter\nperception tailored to address the above problems, we present a simple and\neffective KD method, called ScaleKD. Our method can train student backbones\nthat span across a variety of convolutional neural network (CNN), multi-layer\nperceptron (MLP), and ViT architectures on image classification datasets,\nachieving state-of-the-art distillation performance. For instance, taking a\nwell pre-trained Swin-L as the teacher model, our method gets\n75.15%|82.03%|84.16%|78.63%|81.96%|83.93%|83.80%|85.53% top-1 accuracies for\nMobileNet-V1|ResNet-50|ConvNeXt-T|Mixer-S/16|Mixer-B/16|ViT-S/16|Swin-T|ViT-B/16\nmodels trained on ImageNet-1K dataset from scratch, showing\n3.05%|3.39%|2.02%|4.61%|5.52%|4.03%|2.62%|3.73% absolute gains to the\nindividually trained counterparts. Intriguingly, when scaling up the size of\nteacher models or their pre-training datasets, our method showcases the desired\nscalable properties, bringing increasingly larger gains to student models. The\nstudent backbones trained by our method transfer well on downstream MS-COCO and\nADE20K datasets. More importantly, our method could be used as a more efficient\nalternative to the time-intensive pre-training paradigm for any target student\nmodel if a strong pre-trained ViT is available, reducing the amount of viewed\ntraining samples up to 195x.\n","authors":["Jiawei Fan","Chao Li","Xiaolong Liu","Anbang Yao"],"pdf_url":"https://arxiv.org/pdf/2411.06786v1.pdf","comment":"This work is accepted to NeurIPS 2024. The project page:\n  https://github.com/deep-optimization/ScaleKD"},{"id":"http://arxiv.org/abs/2411.06785v1","updated":"2024-11-11T08:24:59Z","published":"2024-11-11T08:24:59Z","title":"White-Box Diffusion Transformer for single-cell RNA-seq generation","summary":"  As a powerful tool for characterizing cellular subpopulations and cellular\nheterogeneity, single cell RNA sequencing (scRNA-seq) technology offers\nadvantages of high throughput and multidimensional analysis. However, the\nprocess of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a hybrid model\nbased on Diffusion model and White-Box transformer that aims to generate\nsynthetic and biologically plausible scRNA-seq data. Diffusion model\nprogressively introduce noise into the data and then recover the original data\nthrough a denoising process, a forward and reverse process that is particularly\nsuitable for generating complex data distributions. White-Box transformer is a\ndeep learning architecture that emphasizes mathematical interpretability. By\nminimizing the encoding rate of the data and maximizing the sparsity of the\nrepresentation, it not only reduces the computational burden, but also provides\nclear insight into underlying structure. Our White-Box Diffusion Transformer\ncombines the generative capabilities of Diffusion model with the mathematical\ninterpretability of White-Box transformer. Through experiments using six\ndifferent single-cell RNA-Seq datasets, we visualize both generated and real\ndata using t-SNE dimensionality reduction technique, as well as quantify\nsimilarity between generated and real data using various metrics to demonstrate\ncomparable performance of White-Box Diffusion Transformer and Diffusion\nTransformer in generating scRNA-seq data alongside significant improvements in\ntraining efficiency and resource utilization. Our code is available at\nhttps://github.com/lingximamo/White-Box-Diffusion-Transformer\n","authors":["Zhuorui Cui","Shengze Dong","Ding Liu"],"pdf_url":"https://arxiv.org/pdf/2411.06785v1.pdf","comment":"11pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.06782v1","updated":"2024-11-11T08:19:54Z","published":"2024-11-11T08:19:54Z","title":"QuadWBG: Generalizable Quadrupedal Whole-Body Grasping","summary":"  Legged robots with advanced manipulation capabilities have the potential to\nsignificantly improve household duties and urban maintenance. Despite\nconsiderable progress in developing robust locomotion and precise manipulation\nmethods, seamlessly integrating these into cohesive whole-body control for\nreal-world applications remains challenging. In this paper, we present a\nmodular framework for robust and generalizable whole-body loco-manipulation\ncontroller based on a single arm-mounted camera. By using reinforcement\nlearning (RL), we enable a robust low-level policy for command execution over 5\ndimensions (5D) and a grasp-aware high-level policy guided by a novel metric,\nGeneralized Oriented Reachability Map (GORM). The proposed system achieves\nstate-of-the-art one-time grasping accuracy of 89% in the real world, including\nchallenging tasks such as grasping transparent objects. Through extensive\nsimulations and real-world experiments, we demonstrate that our system can\neffectively manage a large workspace, from floor level to above body height,\nand perform diverse whole-body loco-manipulation tasks.\n","authors":["Jilong Wang","Javokhirbek Rajabov","Chaoyi Xu","Yiming Zheng","He Wang"],"pdf_url":"https://arxiv.org/pdf/2411.06782v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06781v1","updated":"2024-11-11T08:19:22Z","published":"2024-11-11T08:19:22Z","title":"MP-PINN: A Multi-Phase Physics-Informed Neural Network for Epidemic\n  Forecasting","summary":"  Forecasting temporal processes such as virus spreading in epidemics often\nrequires more than just observed time-series data, especially at the beginning\nof a wave when data is limited. Traditional methods employ mechanistic models\nlike the SIR family, which make strong assumptions about the underlying\nspreading process, often represented as a small set of compact differential\nequations. Data-driven methods such as deep neural networks make no such\nassumptions and can capture the generative process in more detail, but fail in\nlong-term forecasting due to data limitations. We propose a new hybrid method\ncalled MP-PINN (Multi-Phase Physics-Informed Neural Network) to overcome the\nlimitations of these two major approaches. MP-PINN instils the spreading\nmechanism into a neural network, enabling the mechanism to update in phases\nover time, reflecting the dynamics of the epidemics due to policy\ninterventions. Experiments on COVID-19 waves demonstrate that MP-PINN achieves\nsuperior performance over pure data-driven or model-driven approaches for both\nshort-term and long-term forecasting.\n","authors":["Thang Nguyen","Dung Nguyen","Kha Pham","Truyen Tran"],"pdf_url":"https://arxiv.org/pdf/2411.06781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06773v1","updated":"2024-11-11T07:59:13Z","published":"2024-11-11T07:59:13Z","title":"Model Partition and Resource Allocation for Split Learning in Vehicular\n  Edge Networks","summary":"  The integration of autonomous driving technologies with vehicular networks\npresents significant challenges in privacy preservation, communication\nefficiency, and resource allocation. This paper proposes a novel U-shaped split\nfederated learning (U-SFL) framework to address these challenges on the way of\nrealizing in vehicular edge networks. U-SFL is able to enhance privacy\nprotection by keeping both raw data and labels on the vehicular user (VU) side\nwhile enabling parallel processing across multiple vehicles. To optimize\ncommunication efficiency, we introduce a semantic-aware auto-encoder (SAE) that\nsignificantly reduces the dimensionality of transmitted data while preserving\nessential semantic information. Furthermore, we develop a deep reinforcement\nlearning (DRL) based algorithm to solve the NP-hard problem of dynamic resource\nallocation and split point selection. Our comprehensive evaluation demonstrates\nthat U-SFL achieves comparable classification performance to traditional split\nlearning (SL) while substantially reducing data transmission volume and\ncommunication latency. The proposed DRL-based optimization algorithm shows good\nconvergence in balancing latency, energy consumption, and learning performance.\n","authors":["Lu Yu","Zheng Chang","Yunjian Jia","Geyong Min"],"pdf_url":"https://arxiv.org/pdf/2411.06773v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2306.12194 by other authors"},{"id":"http://arxiv.org/abs/2411.06770v1","updated":"2024-11-11T07:51:22Z","published":"2024-11-11T07:51:22Z","title":"Sketched Adaptive Federated Deep Learning: A Sharp Convergence Analysis","summary":"  Combining gradient compression methods (e.g., CountSketch, quantization) and\nadaptive optimizers (e.g., Adam, AMSGrad) is a desirable goal in federated\nlearning (FL), with potential benefits on both fewer communication rounds and\nless per-round communication. In spite of the preliminary empirical success of\nsketched adaptive methods, existing convergence analyses show the communication\ncost to have a linear dependence on the ambient dimension, i.e., number of\nparameters, which is prohibitively high for modern deep learning models.\n  In this work, we introduce specific sketched adaptive federated learning\n(SAFL) algorithms and, as our main contribution, provide theoretical\nconvergence analyses in different FL settings with guarantees on communication\ncost depending only logarithmically (instead of linearly) on the ambient\ndimension. Unlike existing analyses, we show that the entry-wise sketching\nnoise existent in the preconditioners and the first moments of SAFL can be\nimplicitly addressed by leveraging the recently-popularized anisotropic\ncurvatures in deep learning losses, e.g., fast decaying loss Hessian\neigen-values. In the i.i.d. client setting of FL, we show that SAFL achieves\nasymptotic $O(1/\\sqrt{T})$ convergence, and converges faster in the initial\nepochs. In the non-i.i.d. client setting, where non-adaptive methods lack\nconvergence guarantees, we show that SACFL (SAFL with clipping) algorithms can\nprovably converge in spite of the additional heavy-tailed noise. Our\ntheoretical claims are supported by empirical studies on vision and language\ntasks, and in both fine-tuning and training-from-scratch regimes. Surprisingly,\nas a by-product of our analysis, the proposed SAFL methods are competitive with\nthe state-of-the-art communication-efficient federated learning algorithms\nbased on error feedback.\n","authors":["Zhijie Chen","Qiaobo Li","Arindam Banerjee"],"pdf_url":"https://arxiv.org/pdf/2411.06770v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06767v1","updated":"2024-11-11T07:47:20Z","published":"2024-11-11T07:47:20Z","title":"PDC & DM-SFT: A Road for LLM SQL Bug-Fix Enhancing","summary":"  Code Large Language Models (Code LLMs), such as Code llama and\nDeepSeek-Coder, have demonstrated exceptional performance in the code\ngeneration tasks. However, most existing models focus on the abilities of\ngenerating correct code, but often struggle with bug repair. We introduce a\nsuit of methods to enhance LLM's SQL bug-fixing abilities. The methods are\nmainly consisted of two parts: A Progressive Dataset Construction (PDC) from\nscratch and Dynamic Mask Supervised Fine-tuning (DM-SFT). PDC proposes two data\nexpansion methods from the perspectives of breadth first and depth first\nrespectively. DM-SFT introduces an efficient bug-fixing supervised learning\napproach, which effectively reduce the total training steps and mitigate the\n\"disorientation\" in SQL code bug-fixing training. In our evaluation, the code\nLLM models trained with two methods have exceeds all current best performing\nmodel which size is much larger.\n","authors":["Yiwen Duan","Yonghong Yu","Xiaoming Zhao","Yichang Wu","Wenbo Liu"],"pdf_url":"https://arxiv.org/pdf/2411.06767v1.pdf","comment":"COLING-Industry 2025 accepted"},{"id":"http://arxiv.org/abs/2411.06765v1","updated":"2024-11-11T07:43:12Z","published":"2024-11-11T07:43:12Z","title":"Research on an intelligent fault diagnosis method for nuclear power\n  plants based on ETCN-SSA combined algorithm","summary":"  Utilizing fault diagnosis methods is crucial for nuclear power professionals\nto achieve efficient and accurate fault diagnosis for nuclear power plants\n(NPPs). The performance of traditional methods is limited by their dependence\non complex feature extraction and skilled expert knowledge, which can be\ntime-consuming and subjective. This paper proposes a novel intelligent fault\ndiagnosis method for NPPs that combines enhanced temporal convolutional network\n(ETCN) with sparrow search algorithm (SSA). ETCN utilizes temporal\nconvolutional network (TCN), self-attention (SA) mechanism and residual block\nfor enhancing performance. ETCN excels at extracting local features and\ncapturing time series information, while SSA adaptively optimizes its\nhyperparameters for superior performance. The proposed method's performance is\nexperimentally verified on a CPR1000 simulation dataset. Compared to other\nadvanced intelligent fault diagnosis methods, the proposed one demonstrates\nsuperior performance across all evaluation metrics. This makes it a promising\ntool for NPP intelligent fault diagnosis, ultimately enhancing operational\nreliability.\n","authors":["Jiayan Fang","Siwei Li","Yichun Wu"],"pdf_url":"https://arxiv.org/pdf/2411.06765v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06764v1","updated":"2024-11-11T07:36:19Z","published":"2024-11-11T07:36:19Z","title":"Multi-Stage Knowledge Integration of Vision-Language Models for\n  Continual Learning","summary":"  Vision Language Models (VLMs), pre-trained on large-scale image-text\ndatasets, enable zero-shot predictions for unseen data but may underperform on\nspecific unseen tasks. Continual learning (CL) can help VLMs effectively adapt\nto new data distributions without joint training, but faces challenges of\ncatastrophic forgetting and generalization forgetting. Although significant\nprogress has been achieved by distillation-based methods, they exhibit two\nsevere limitations. One is the popularly adopted single-teacher paradigm fails\nto impart comprehensive knowledge, The other is the existing methods\ninadequately leverage the multimodal information in the original training\ndataset, instead they rely on additional data for distillation, which increases\ncomputational and storage overhead. To mitigate both limitations, by drawing on\nKnowledge Integration Theory (KIT), we propose a Multi-Stage Knowledge\nIntegration network (MulKI) to emulate the human learning process in\ndistillation methods. MulKI achieves this through four stages, including\nEliciting Ideas, Adding New Ideas, Distinguishing Ideas, and Making\nConnections. During the four stages, we first leverage prototypes to align\nacross modalities, eliciting cross-modal knowledge, then adding new knowledge\nby constructing fine-grained intra- and inter-modality relationships with\nprototypes. After that, knowledge from two teacher models is adaptively\ndistinguished and re-weighted. Finally, we connect between models from intra-\nand inter-task, integrating preceding and new knowledge. Our method\ndemonstrates significant improvements in maintaining zero-shot capabilities\nwhile supporting continual learning across diverse downstream tasks, showcasing\nits potential in adapting VLMs to evolving data distributions.\n","authors":["Hongsheng Zhang","Zhong Ji","Jingren Liu","Yanwei Pang","Jungong Han"],"pdf_url":"https://arxiv.org/pdf/2411.06764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06762v1","updated":"2024-11-11T07:34:21Z","published":"2024-11-11T07:34:21Z","title":"Precision Glass Thermoforming Assisted by Neural Networks","summary":"  Glass with good processability, chemical inertness, and optical transparency\nhas been widely used in optical and aesthetic products, many of which require\ncurve pro-files with high precision. To meet the increasingly tightened\ngeometrical tolerances and fast product updating rates, the traditional\napproach of developing a thermoform-ing process through trials and errors can\ncause a large waste of time and resources and often end up with failure. Hence,\nthere is a need to develop an efficient predictive model, replacing the costly\nsimulations or experiments, to assist the design of preci-sion glass\nthermoforming. In this work, we report a dimensionless back-propagation neural\nnetwork (BPNN) that can adequately predict the form errors and thus compen-sate\nfor these errors in mold design to achieve precision glass molding. Based on\nthe precision molds, also discussed is the issue of error magnification\nconsidering that cover glass for AR/VR glasses or smartphones, with extremely\nlarge scale of produc-tion, may require a lower level of mold machining\naccuracy. It is expected that this BPNN will also be implementable in the\nglass-manufacturing industry, i.e., trained using industrial data for precision\nmold designs.\n","authors":["Yuzhou Zhang","Mohan Hua","Haihui Ruan"],"pdf_url":"https://arxiv.org/pdf/2411.06762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.07395v3","updated":"2024-11-11T07:14:07Z","published":"2022-01-19T03:08:33Z","title":"Overview frequency principle/spectral bias in deep learning","summary":"  Understanding deep learning is increasingly emergent as it penetrates more\nand more into industry and science. In recent years, a research line from\nFourier analysis sheds lights on this magical \"black box\" by showing a\nFrequency Principle (F-Principle or spectral bias) of the training behavior of\ndeep neural networks (DNNs) -- DNNs often fit functions from low to high\nfrequency during the training. The F-Principle is first demonstrated by\nonedimensional synthetic data followed by the verification in high-dimensional\nreal datasets. A series of works subsequently enhance the validity of the\nF-Principle. This low-frequency implicit bias reveals the strength of neural\nnetwork in learning low-frequency functions as well as its deficiency in\nlearning high-frequency functions. Such understanding inspires the design of\nDNN-based algorithms in practical problems, explains experimental phenomena\nemerging in various scenarios, and further advances the study of deep learning\nfrom the frequency perspective. Although incomplete, we provide an overview of\nF-Principle and propose some open problems for future research.\n","authors":["Zhi-Qin John Xu","Yaoyu Zhang","Tao Luo"],"pdf_url":"https://arxiv.org/pdf/2201.07395v3.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.07155v1","updated":"2024-11-11T17:32:55Z","published":"2024-11-11T17:32:55Z","title":"Low Complexity Learning-based Lossless Event-based Compression","summary":"  Event cameras are a cutting-edge type of visual sensors that capture data by\ndetecting brightness changes at the pixel level asynchronously. These cameras\noffer numerous benefits over conventional cameras, including high temporal\nresolution, wide dynamic range, low latency, and lower power consumption.\nHowever, the substantial data rates they produce require efficient compression\ntechniques, while also fulfilling other typical application requirements, such\nas the ability to respond to visual changes in real-time or near real-time.\nAdditionally, many event-based applications demand high accuracy, making\nlossless coding desirable, as it retains the full detail of the sensor data.\nLearning-based methods show great potential due to their ability to model the\nunique characteristics of event data thus allowing to achieve high compression\nrates. This paper proposes a low-complexity lossless coding solution based on\nthe quadtree representation that outperforms traditional compression algorithms\nin efficiency and speed, ensuring low computational complexity and minimal\ndelay for real-time applications. Experimental results show that the proposed\nmethod delivers better compression ratios, i.e., with fewer bits per event, and\nlower computational complexity compared to current lossless data compression\nmethods.\n","authors":["Ahmadreza Sezavar","Catarina Brites","Joao Ascenso"],"pdf_url":"https://arxiv.org/pdf/2411.07155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06976v1","updated":"2024-11-11T13:34:24Z","published":"2024-11-11T13:34:24Z","title":"A Hierarchical Compression Technique for 3D Gaussian Splatting\n  Compression","summary":"  3D Gaussian Splatting (GS) demonstrates excellent rendering quality and\ngeneration speed in novel view synthesis. However, substantial data size poses\nchallenges for storage and transmission, making 3D GS compression an essential\ntechnology. Current 3D GS compression research primarily focuses on developing\nmore compact scene representations, such as converting explicit 3D GS data into\nimplicit forms. In contrast, compression of the GS data itself has hardly been\nexplored. To address this gap, we propose a Hierarchical GS Compression (HGSC)\ntechnique. Initially, we prune unimportant Gaussians based on importance scores\nderived from both global and local significance, effectively reducing\nredundancy while maintaining visual quality. An Octree structure is used to\ncompress 3D positions. Based on the 3D GS Octree, we implement a hierarchical\nattribute compression strategy by employing a KD-tree to partition the 3D GS\ninto multiple blocks. We apply farthest point sampling to select anchor\nprimitives within each block and others as non-anchor primitives with varying\nLevels of Details (LoDs). Anchor primitives serve as reference points for\npredicting non-anchor primitives across different LoDs to reduce spatial\nredundancy. For anchor primitives, we use the region adaptive hierarchical\ntransform to achieve near-lossless compression of various attributes. For\nnon-anchor primitives, each is predicted based on the k-nearest anchor\nprimitives. To further minimize prediction errors, the reconstructed LoD and\nanchor primitives are combined to form new anchor primitives to predict the\nnext LoD. Our method notably achieves superior compression quality and a\nsignificant data size reduction of over 4.5 times compared to the\nstate-of-the-art compression method on small scenes datasets.\n","authors":["He Huang","Wenjie Huang","Qi Yang","Yiling Xu","Zhu li"],"pdf_url":"https://arxiv.org/pdf/2411.06976v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06810v1","updated":"2024-11-11T09:11:01Z","published":"2024-11-11T09:11:01Z","title":"JPEG AI Image Compression Visual Artifacts: Detection Methods and\n  Dataset","summary":"  Learning-based image compression methods have improved in recent years and\nstarted to outperform traditional codecs. However, neural-network approaches\ncan unexpectedly introduce visual artifacts in some images. We therefore\npropose methods to separately detect three types of artifacts (texture and\nboundary degradation, color change, and text corruption), to localize the\naffected regions, and to quantify the artifact strength. We consider only those\nregions that exhibit distortion due solely to the neural compression but that a\ntraditional codec recovers successfully at a comparable bitrate. We employed\nour methods to collect artifacts for the JPEG AI verification model with\nrespect to HM-18.0, the H.265 reference software. We processed about 350,000\nunique images from the Open Images dataset using different compression-quality\nparameters; the result is a dataset of 46,440 artifacts validated through\ncrowd-sourced subjective assessment. Our proposed dataset and methods are\nvaluable for testing neural-network-based image codecs, identifying bugs in\nthese codecs, and enhancing their performance. We make source code of the\nmethods and the dataset publicly available.\n","authors":["Daria Tsereh","Mark Mirgaleev","Ivan Molodetskikh","Roman Kazantsev","Dmitriy Vatolin"],"pdf_url":"https://arxiv.org/pdf/2411.06810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04097v2","updated":"2024-11-11T09:05:15Z","published":"2024-05-07T07:57:15Z","title":"Unmasking Illusions: Understanding Human Perception of Audiovisual\n  Deepfakes","summary":"  The emergence of contemporary deepfakes has attracted significant attention\nin machine learning research, as artificial intelligence (AI) generated\nsynthetic media increases the incidence of misinterpretation and is difficult\nto distinguish from genuine content. Currently, machine learning techniques\nhave been extensively studied for automatically detecting deepfakes. However,\nhuman perception has been less explored. Malicious deepfakes could ultimately\ncause public and social problems. Can we humans correctly perceive the\nauthenticity of the content of the videos we watch? The answer is obviously\nuncertain; therefore, this paper aims to evaluate the human ability to discern\ndeepfake videos through a subjective study. We present our findings by\ncomparing human observers to five state-ofthe-art audiovisual deepfake\ndetection models. To this end, we used gamification concepts to provide 110\nparticipants (55 native English speakers and 55 non-native English speakers)\nwith a webbased platform where they could access a series of 40 videos (20 real\nand 20 fake) to determine their authenticity. Each participant performed the\nexperiment twice with the same 40 videos in different random orders. The videos\nare manually selected from the FakeAVCeleb dataset. We found that all AI models\nperformed better than humans when evaluated on the same 40 videos. The study\nalso reveals that while deception is not impossible, humans tend to\noverestimate their detection capabilities. Our experimental results may help\nbenchmark human versus machine performance, advance forensics analysis, and\nenable adaptive countermeasures.\n","authors":["Ammarah Hashmi","Sahibzada Adil Shahzad","Chia-Wen Lin","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2405.04097v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06742v1","updated":"2024-11-11T06:40:06Z","published":"2024-11-11T06:40:06Z","title":"Loss-tolerant neural video codec aware congestion control for real time\n  video communication","summary":"  Because of reinforcement learning's (RL) ability to automatically create more\nadaptive controlling logics beyond the hand-crafted heuristics, numerous effort\nhas been made to apply RL to congestion control (CC) design for real time video\ncommunication (RTC) applications and has successfully shown promising benefits\nover the rule-based RTC CCs. Online reinforcement learning is often adopted to\ntrain the RL models so the models can directly adapt to real network\nenvironments. However, its trail-and-error manner can also cause catastrophic\ndegradation of the quality of experience (QoE) of RTC application at run time.\nThus, safeguard strategies such as falling back to hand-crafted heuristics can\nbe used to run along with RL models to guarantee the actions explored in the\ntraining sensible, despite that these safeguard strategies interrupt the\nlearning process and make it more challenging to discover optimal RL policies.\n  The recent emergence of loss-tolerant neural video codecs (NVC) naturally\nprovides a layer of protection for the online learning of RL-based congestion\ncontrol because of its resilience to packet losses, but such packet loss\nresilience have not been fully exploited in prior works yet. In this paper, we\npresent a reinforcement learning (RL) based congestion control which can be\naware of and takes advantage of packet loss tolerance characteristic of NVCs\nvia reward in online RL learning. Through extensive evaluation on various\nvideos and network traces in a simulated environment, we demonstrate that our\nNVC-aware CC running with the loss-tolerant NVC reduces the training time by\n41\\% compared to other prior RL-based CCs. It also boosts the mean video\nquality by 0.3 to 1.6dB, lower the tail frame delay by 3 to 200ms, and reduces\nthe video stalls by 20\\% to 77\\% in comparison with other baseline RTC CCs.\n","authors":["Zhengxu Xia","Hanchen Li","Junchen Jiang"],"pdf_url":"https://arxiv.org/pdf/2411.06742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02188v2","updated":"2024-11-11T05:14:15Z","published":"2023-12-01T23:56:00Z","title":"Video Summarization: Towards Entity-Aware Captions","summary":"  Existing popular video captioning benchmarks and models deal with generic\ncaptions devoid of specific person, place or organization named entities. In\ncontrast, news videos present a challenging setting where the caption requires\nsuch named entities for meaningful summarization. As such, we propose the task\nof summarizing news video directly to entity-aware captions. We also release a\nlarge-scale dataset, VIEWS (VIdeo NEWS), to support research on this task.\nFurther, we propose a method that augments visual information from videos with\ncontext retrieved from external world knowledge to generate entity-aware\ncaptions. We demonstrate the effectiveness of our approach on three video\ncaptioning models. We also show that our approach generalizes to existing news\nimage captions dataset. With all the extensive experiments and insights, we\nbelieve we establish a solid basis for future research on this challenging\ntask.\n","authors":["Hammad A. Ayyubi","Tianqi Liu","Arsha Nagrani","Xudong Lin","Mingda Zhang","Anurag Arnab","Feng Han","Yukun Zhu","Jialu Liu","Shih-Fu Chang"],"pdf_url":"https://arxiv.org/pdf/2312.02188v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07428v1","updated":"2024-11-11T23:05:02Z","published":"2024-11-11T23:05:02Z","title":"Just Label the Repeats for In-The-Wild Audio-to-Score Alignment","summary":"  We propose an efficient workflow for high-quality offline alignment of\nin-the-wild performance audio and corresponding sheet music scans (images).\nRecent work on audio-to-score alignment extends dynamic time warping (DTW) to\nbe theoretically able to handle jumps in sheet music induced by repeat\nsigns-this method requires no human annotations, but we show that it often\nyields low-quality alignments. As an alternative, we propose a workflow and\ninterface that allows users to quickly annotate jumps (by clicking on repeat\nsigns), requiring a small amount of human supervision but yielding much higher\nquality alignments on average. Additionally, we refine audio and score feature\nrepresentations to improve alignment quality by: (1) integrating measure\ndetection into the score feature representation, and (2) using raw onset\nprediction probabilities from a music transcription model instead of piano\nroll. We propose an evaluation protocol for audio-to-score alignment that\ncomputes the distance between the estimated and ground truth alignment in units\nof measures. Under this evaluation, we find that our proposed jump annotation\nworkflow and improved feature representations together improve alignment\naccuracy by 150% relative to prior work (33% to 82%).\n","authors":["Irmak Bukey","Michael Feffer","Chris Donahue"],"pdf_url":"https://arxiv.org/pdf/2411.07428v1.pdf","comment":"25th International Society for Music Information Retrieval\n  Conference, San Francisco, 2024"},{"id":"http://arxiv.org/abs/2411.07335v1","updated":"2024-11-11T19:53:05Z","published":"2024-11-11T19:53:05Z","title":"Multimodal Fusion Balancing Through Game-Theoretic Regularization","summary":"  Multimodal learning can complete the picture of information extraction by\nuncovering key dependencies between data sources. However, current systems fail\nto fully leverage multiple modalities for optimal performance. This has been\nattributed to modality competition, where modalities strive for training\nresources, leaving some underoptimized. We show that current balancing methods\nstruggle to train multimodal models that surpass even simple baselines, such as\nensembles. This raises the question: how can we ensure that all modalities in\nmultimodal training are sufficiently trained, and that learning from new\nmodalities consistently improves performance? This paper proposes the\nMultimodal Competition Regularizer (MCR), a new loss component inspired by\nmutual information (MI) decomposition designed to prevent the adverse effects\nof competition in multimodal training. Our key contributions are: 1)\nIntroducing game-theoretic principles in multimodal learning, where each\nmodality acts as a player competing to maximize its influence on the final\noutcome, enabling automatic balancing of the MI terms. 2) Refining lower and\nupper bounds for each MI term to enhance the extraction of task-relevant unique\nand shared information across modalities. 3) Suggesting latent space\npermutations for conditional MI estimation, significantly improving\ncomputational efficiency. MCR outperforms all previously suggested training\nstrategies and is the first to consistently improve multimodal learning beyond\nthe ensemble baseline, clearly demonstrating that combining modalities leads to\nsignificant performance gains on both synthetic and large real-world datasets.\n","authors":["Konstantinos Kontras","Thomas Strypsteen","Christos Chatzichristos","Paul P. Liang","Matthew Blaschko","Maarten De Vos"],"pdf_url":"https://arxiv.org/pdf/2411.07335v1.pdf","comment":"21 pages, 6 figures, 4 tables, 1 algorithm"}]},"2024-11-10T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2411.06632v1","updated":"2024-11-10T23:52:24Z","published":"2024-11-10T23:52:24Z","title":"Few-shot Semantic Learning for Robust Multi-Biome 3D Semantic Mapping in\n  Off-Road Environments","summary":"  Off-road environments pose significant perception challenges for high-speed\nautonomous navigation due to unstructured terrain, degraded sensing conditions,\nand domain-shifts among biomes. Learning semantic information across these\nconditions and biomes can be challenging when a large amount of ground truth\ndata is required. In this work, we propose an approach that leverages a\npre-trained Vision Transformer (ViT) with fine-tuning on a small (<500 images),\nsparse and coarsely labeled (<30% pixels) multi-biome dataset to predict 2D\nsemantic segmentation classes. These classes are fused over time via a novel\nrange-based metric and aggregated into a 3D semantic voxel map. We demonstrate\nzero-shot out-of-biome 2D semantic segmentation on the Yamaha (52.9 mIoU) and\nRellis (55.5 mIoU) datasets along with few-shot coarse sparse labeling with\nexisting data for improved segmentation performance on Yamaha (66.6 mIoU) and\nRellis (67.2 mIoU). We further illustrate the feasibility of using a voxel map\nwith a range-based semantic fusion approach to handle common off-road hazards\nlike pop-up hazards, overhangs, and water features.\n","authors":["Deegan Atha","Xianmei Lei","Shehryar Khattak","Anna Sabel","Elle Miller","Aurelio Noca","Grace Lim","Jeffrey Edlund","Curtis Padgett","Patrick Spieler"],"pdf_url":"https://arxiv.org/pdf/2411.06632v1.pdf","comment":"Accepted to Australasian Conference on Robotics and Automation (ACRA\n  2024)"},{"id":"http://arxiv.org/abs/2408.14371v2","updated":"2024-11-10T21:45:49Z","published":"2024-08-26T15:53:50Z","title":"SelEx: Self-Expertise in Fine-Grained Generalized Category Discovery","summary":"  In this paper, we address Generalized Category Discovery, aiming to\nsimultaneously uncover novel categories and accurately classify known ones.\nTraditional methods, which lean heavily on self-supervision and contrastive\nlearning, often fall short when distinguishing between fine-grained categories.\nTo address this, we introduce a novel concept called `self-expertise', which\nenhances the model's ability to recognize subtle differences and uncover\nunknown categories. Our approach combines unsupervised and supervised\nself-expertise strategies to refine the model's discernment and generalization.\nInitially, hierarchical pseudo-labeling is used to provide `soft supervision',\nimproving the effectiveness of self-expertise. Our supervised technique differs\nfrom traditional methods by utilizing more abstract positive and negative\nsamples, aiding in the formation of clusters that can generalize to novel\ncategories. Meanwhile, our unsupervised strategy encourages the model to\nsharpen its category distinctions by considering within-category examples as\n`hard' negatives. Supported by theoretical insights, our empirical results\nshowcase that our method outperforms existing state-of-the-art techniques in\nGeneralized Category Discovery across several fine-grained datasets. Our code\nis available at: https://github.com/SarahRastegar/SelEx.\n","authors":["Sarah Rastegar","Mohammadreza Salehi","Yuki M. Asano","Hazel Doughty","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2408.14371v2.pdf","comment":"Accepted by ECCV 2024"},{"id":"http://arxiv.org/abs/2411.06602v1","updated":"2024-11-10T21:30:16Z","published":"2024-11-10T21:30:16Z","title":"Adaptive and Temporally Consistent Gaussian Surfels for Multi-view\n  Dynamic Reconstruction","summary":"  3D Gaussian Splatting has recently achieved notable success in novel view\nsynthesis for dynamic scenes and geometry reconstruction in static scenes.\nBuilding on these advancements, early methods have been developed for dynamic\nsurface reconstruction by globally optimizing entire sequences. However,\nreconstructing dynamic scenes with significant topology changes, emerging or\ndisappearing objects, and rapid movements remains a substantial challenge,\nparticularly for long sequences. To address these issues, we propose AT-GS, a\nnovel method for reconstructing high-quality dynamic surfaces from multi-view\nvideos through per-frame incremental optimization. To avoid local minima across\nframes, we introduce a unified and adaptive gradient-aware densification\nstrategy that integrates the strengths of conventional cloning and splitting\ntechniques. Additionally, we reduce temporal jittering in dynamic surfaces by\nensuring consistency in curvature maps across consecutive frames. Our method\nachieves superior accuracy and temporal coherence in dynamic surface\nreconstruction, delivering high-fidelity space-time novel view synthesis, even\nin complex and challenging scenes. Extensive experiments on diverse multi-view\nvideo datasets demonstrate the effectiveness of our approach, showing clear\nadvantages over baseline methods. Project page:\n\\url{https://fraunhoferhhi.github.io/AT-GS}\n","authors":["Decai Chen","Brianne Oberson","Ingo Feldmann","Oliver Schreer","Anna Hilsmann","Peter Eisert"],"pdf_url":"https://arxiv.org/pdf/2411.06602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.08906v2","updated":"2024-11-10T21:07:59Z","published":"2024-07-12T00:52:04Z","title":"AirSketch: Generative Motion to Sketch","summary":"  Illustration is a fundamental mode of human expression and communication.\nCertain types of motion that accompany speech can provide this illustrative\nmode of communication. While Augmented and Virtual Reality technologies (AR/VR)\nhave introduced tools for producing drawings with hand motions (air drawing),\nthey typically require costly hardware and additional digital markers, thereby\nlimiting their accessibility and portability. Furthermore, air drawing demands\nconsiderable skill to achieve aesthetic results. To address these challenges,\nwe introduce the concept of AirSketch, aimed at generating faithful and\nvisually coherent sketches directly from hand motions, eliminating the need for\ncomplicated headsets or markers. We devise a simple augmentation-based\nself-supervised training procedure, enabling a controllable image diffusion\nmodel to learn to translate from highly noisy hand tracking images to clean,\naesthetically pleasing sketches, while preserving the essential visual cues\nfrom the original tracking data. We present two air drawing datasets to study\nthis problem. Our findings demonstrate that beyond producing photo-realistic\nimages from precise spatial inputs, controllable image diffusion can\neffectively produce a refined, clear sketch from a noisy input. Our work serves\nas an initial step towards marker-less air drawing and reveals distinct\napplications of controllable diffusion models to AirSketch and AR/VR in\ngeneral.\n","authors":["Hui Xian Grace Lim","Xuanming Cui","Ser-Nam Lim","Yogesh S Rawat"],"pdf_url":"https://arxiv.org/pdf/2407.08906v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06596v1","updated":"2024-11-10T20:59:23Z","published":"2024-11-10T20:59:23Z","title":"Graph Neural Networks for modelling breast biomechanical compression","summary":"  Breast compression simulation is essential for accurate image registration\nfrom 3D modalities to X-ray procedures like mammography. It accounts for tissue\nshape and position changes due to compression, ensuring precise alignment and\nimproved analysis. Although Finite Element Analysis (FEA) is reliable for\napproximating soft tissue deformation, it struggles with balancing accuracy and\ncomputational efficiency. Recent studies have used data-driven models trained\non FEA results to speed up tissue deformation predictions. We propose to\nexplore Physics-based Graph Neural Networks (PhysGNN) for breast compression\nsimulation. PhysGNN has been used for data-driven modelling in other domains,\nand this work presents the first investigation of their potential in predicting\nbreast deformation during mammographic compression. Unlike conventional\ndata-driven models, PhysGNN, which incorporates mesh structural information and\nenables inductive learning on unstructured grids, is well-suited for capturing\ncomplex breast tissue geometries. Trained on deformations from incremental FEA\nsimulations, PhysGNN's performance is evaluated by comparing predicted nodal\ndisplacements with those from finite element (FE) simulations. This deep\nlearning (DL) framework shows promise for accurate, rapid breast deformation\napproximations, offering enhanced computational efficiency for real-world\nscenarios.\n","authors":["Hadeel Awwad","Eloy García","Robert Martí"],"pdf_url":"https://arxiv.org/pdf/2411.06596v1.pdf","comment":"Deep Breath @ MICCAI 2024 | The code is available at this URL:\n  https://github.com/hadiiiil/GNNs-BreastCompression"},{"id":"http://arxiv.org/abs/2405.17446v2","updated":"2024-11-10T20:52:56Z","published":"2024-05-20T20:13:03Z","title":"Comparing ImageNet Pre-training with Digital Pathology Foundation Models\n  for Whole Slide Image-Based Survival Analysis","summary":"  The abundance of information present in Whole Slide Images (WSIs) renders\nthem an essential tool for survival analysis. Several Multiple Instance\nLearning frameworks proposed for this task utilize a ResNet50 backbone\npre-trained on natural images. By leveraging recenetly released\nhistopathological foundation models such as UNI and Hibou, the predictive\nprowess of existing MIL networks can be enhanced. Furthermore, deploying an\nensemble of digital pathology foundation models yields higher baseline\naccuracy, although the benefits appear to diminish with more complex MIL\narchitectures. Our code will be made publicly available upon acceptance.\n","authors":["Kleanthis Marios Papadopoulos"],"pdf_url":"https://arxiv.org/pdf/2405.17446v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06583v1","updated":"2024-11-10T20:16:32Z","published":"2024-11-10T20:16:32Z","title":"Enhancing frozen histological section images using\n  permanent-section-guided deep learning with nuclei attention","summary":"  In histological pathology, frozen sections are often used for rapid diagnosis\nduring surgeries, as they can be produced within minutes. However, they suffer\nfrom artifacts and often lack crucial diagnostic details, particularly within\nthe cell nuclei region. Permanent sections, on the other hand, contain more\ndiagnostic detail but require a time-intensive preparation process. Here, we\npresent a generative deep learning approach to enhance frozen section images by\nleveraging guidance from permanent sections. Our method places a strong\nemphasis on the nuclei region, which contains critical information in both\nfrozen and permanent sections. Importantly, our approach avoids generating\nartificial data in blank regions, ensuring that the network only enhances\nexisting features without introducing potentially unreliable information. We\nachieve this through a segmented attention network, incorporating\nnuclei-segmented images during training and adding an additional loss function\nto refine the nuclei details in the generated permanent images. We validated\nour method across various tissues, including kidney, breast, and colon. This\napproach significantly improves histological efficiency and diagnostic\naccuracy, enhancing frozen section images within seconds, and seamlessly\nintegrating into existing laboratory workflows.\n","authors":["Elad Yoshai","Gil Goldinger","Miki Haifler","Natan T. Shaked"],"pdf_url":"https://arxiv.org/pdf/2411.06583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03924v2","updated":"2024-11-10T20:09:50Z","published":"2024-11-06T13:54:26Z","title":"Self-supervised Representation Learning for Cell Event Recognition\n  through Time Arrow Prediction","summary":"  The spatio-temporal nature of live-cell microscopy data poses challenges in\nthe analysis of cell states which is fundamental in bioimaging. Deep-learning\nbased segmentation or tracking methods rely on large amount of high quality\nannotations to work effectively. In this work, we explore an alternative\nsolution: using feature maps obtained from self-supervised representation\nlearning (SSRL) on time arrow prediction (TAP) for the downstream supervised\ntask of cell event recognition. We demonstrate through extensive experiments\nand analysis that this approach can achieve better performance with limited\nannotation compared to models trained from end to end using fully supervised\napproach. Our analysis also provides insight into applications of the SSRL\nusing TAP in live-cell microscopy.\n","authors":["Cangxiong Chen","Vinay P. Namboodiri","Julia E. Sero"],"pdf_url":"https://arxiv.org/pdf/2411.03924v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.13236v3","updated":"2024-11-10T20:02:06Z","published":"2023-12-20T18:00:16Z","title":"Diffusion Models With Learned Adaptive Noise","summary":"  Diffusion models have gained traction as powerful algorithms for synthesizing\nhigh-quality images. Central to these algorithms is the diffusion process, a\nset of equations which maps data to noise in a way that can significantly\naffect performance. In this paper, we explore whether the diffusion process can\nbe learned from data. Our work is grounded in Bayesian inference and seeks to\nimprove log-likelihood estimation by casting the learned diffusion process as\nan approximate variational posterior that yields a tighter lower bound (ELBO)\non the likelihood. A widely held assumption is that the ELBO is invariant to\nthe noise process: our work dispels this assumption and proposes multivariate\nlearned adaptive noise (MULAN), a learned diffusion process that applies noise\nat different rates across an image. Specifically, our method relies on a\nmultivariate noise schedule that is a function of the data to ensure that the\nELBO is no longer invariant to the choice of the noise schedule as in previous\nworks. Empirically, MULAN sets a new state-of-the-art in density estimation on\nCIFAR-10 and ImageNet and reduces the number of training steps by 50%. We\nprovide the code, along with a blog post and video tutorial on the project\npage: https://s-sahoo.com/MuLAN\n","authors":["Subham Sekhar Sahoo","Aaron Gokaslan","Chris De Sa","Volodymyr Kuleshov"],"pdf_url":"https://arxiv.org/pdf/2312.13236v3.pdf","comment":"NeurIPS 2024 (spotlight). Code is available at\n  https://github.com/s-sahoo/MuLAN"},{"id":"http://arxiv.org/abs/2410.19944v2","updated":"2024-11-10T19:21:42Z","published":"2024-10-25T19:42:57Z","title":"A Multimodal Approach For Endoscopic VCE Image Classification Using\n  BiomedCLIP-PubMedBERT","summary":"  This Paper presents an advanced approach for fine-tuning BiomedCLIP\nPubMedBERT, a multimodal model, to classify abnormalities in Video Capsule\nEndoscopy (VCE) frames, aiming to enhance diagnostic efficiency in\ngastrointestinal healthcare. By integrating the PubMedBERT language model with\na Vision Transformer (ViT) to process endoscopic images, our method categorizes\nimages into ten specific classes: angioectasia, bleeding, erosion, erythema,\nforeign body, lymphangiectasia, polyp, ulcer, worms, and normal. Our workflow\nincorporates image preprocessing and fine-tunes the BiomedCLIP model to\ngenerate high-quality embeddings for both visual and textual inputs, aligning\nthem through similarity scoring for classification. Performance metrics,\nincluding classification, accuracy, recall, and F1 score, indicate the models\nstrong ability to accurately identify abnormalities in endoscopic frames,\nshowing promise for practical use in clinical diagnostics.\n","authors":["Nagarajan Ganapathy","Podakanti Satyajith Chary","Teja Venkata Ramana Kumar Pithani","Pavan Kavati","Arun Kumar S"],"pdf_url":"https://arxiv.org/pdf/2410.19944v2.pdf","comment":"11 Pages, 2 Figures, Capsule Vision 2024 Challenge"},{"id":"http://arxiv.org/abs/2411.06558v1","updated":"2024-11-10T18:45:41Z","published":"2024-11-10T18:45:41Z","title":"Region-Aware Text-to-Image Generation via Hard Binding and Soft\n  Refinement","summary":"  In this paper, we present RAG, a Regional-Aware text-to-image Generation\nmethod conditioned on regional descriptions for precise layout composition.\nRegional prompting, or compositional generation, which enables fine-grained\nspatial control, has gained increasing attention for its practicality in\nreal-world applications. However, previous methods either introduce additional\ntrainable modules, thus only applicable to specific models, or manipulate on\nscore maps within cross-attention layers using attention masks, resulting in\nlimited control strength when the number of regions increases. To handle these\nlimitations, we decouple the multi-region generation into two sub-tasks, the\nconstruction of individual region (Regional Hard Binding) that ensures the\nregional prompt is properly executed, and the overall detail refinement\n(Regional Soft Refinement) over regions that dismiss the visual boundaries and\nenhance adjacent interactions. Furthermore, RAG novelly makes repainting\nfeasible, where users can modify specific unsatisfied regions in the last\ngeneration while keeping all other regions unchanged, without relying on\nadditional inpainting models. Our approach is tuning-free and applicable to\nother frameworks as an enhancement to the prompt following property.\nQuantitative and qualitative experiments demonstrate that RAG achieves superior\nperformance over attribute binding and object relationship than previous\ntuning-free methods.\n","authors":["Zhennan Chen","Yajie Li","Haofan Wang","Zhibo Chen","Zhengkai Jiang","Jun Li","Qian Wang","Jian Yang","Ying Tai"],"pdf_url":"https://arxiv.org/pdf/2411.06558v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06553v1","updated":"2024-11-10T18:28:52Z","published":"2024-11-10T18:28:52Z","title":"Extended multi-stream temporal-attention module for skeleton-based human\n  action recognition (HAR)","summary":"  Graph convolutional networks (GCNs) are an effective skeleton-based human\naction recognition (HAR) technique. GCNs enable the specification of CNNs to a\nnon-Euclidean frame that is more flexible. The previous GCN-based models still\nhave a lot of issues: (I) The graph structure is the same for all model layers\nand input data.\n","authors":["Faisal Mehmood","Xin Guo","Enqing Chen","Muhammad Azeem Akbar","Arif Ali Khan","Sami Ullah"],"pdf_url":"https://arxiv.org/pdf/2411.06553v1.pdf","comment":"This paper accepted in Computers in Human Behavior Journal"},{"id":"http://arxiv.org/abs/2411.06530v1","updated":"2024-11-10T17:13:01Z","published":"2024-11-10T17:13:01Z","title":"Image Segmentation from Shadow-Hints using Minimum Spanning Trees","summary":"  Image segmentation in RGB space is a notoriously difficult task where\nstate-of-the-art methods are trained on thousands or even millions of annotated\nimages. While the performance is impressive, it is still not perfect. We\npropose a novel image segmentation method, achieving similar segmentation\nquality but without training. Instead, we require an image sequence with a\nstatic camera and a single light source at varying positions, as used in for\nphotometric stereo, for example.\n","authors":["Moritz Heep","Eduard Zell"],"pdf_url":"https://arxiv.org/pdf/2411.06530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06525v1","updated":"2024-11-10T16:59:39Z","published":"2024-11-10T16:59:39Z","title":"I2VControl-Camera: Precise Video Camera Control with Adjustable Motion\n  Strength","summary":"  Video generation technologies are developing rapidly and have broad potential\napplications. Among these technologies, camera control is crucial for\ngenerating professional-quality videos that accurately meet user expectations.\nHowever, existing camera control methods still suffer from several limitations,\nincluding control precision and the neglect of the control for subject motion\ndynamics. In this work, we propose I2VControl-Camera, a novel camera control\nmethod that significantly enhances controllability while providing\nadjustability over the strength of subject motion. To improve control\nprecision, we employ point trajectory in the camera coordinate system instead\nof only extrinsic matrix information as our control signal. To accurately\ncontrol and adjust the strength of subject motion, we explicitly model the\nhigher-order components of the video trajectory expansion, not merely the\nlinear terms, and design an operator that effectively represents the motion\nstrength. We use an adapter architecture that is independent of the base model\nstructure. Experiments on static and dynamic scenes show that our framework\noutperformances previous methods both quantitatively and qualitatively.\n","authors":["Wanquan Feng","Jiawei Liu","Pengqi Tu","Tianhao Qi","Mingzhen Sun","Tianxiang Ma","Songtao Zhao","Siyu Zhou","Qian He"],"pdf_url":"https://arxiv.org/pdf/2411.06525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23091v2","updated":"2024-11-10T16:38:14Z","published":"2024-10-30T15:06:44Z","title":"CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for\n  Adversarial Defense","summary":"  Despite ongoing efforts to defend neural classifiers from adversarial\nattacks, they remain vulnerable, especially to unseen attacks. In contrast,\nhumans are difficult to be cheated by subtle manipulations, since we make\njudgments only based on essential factors. Inspired by this observation, we\nattempt to model label generation with essential label-causative factors and\nincorporate label-non-causative factors to assist data generation. For an\nadversarial example, we aim to discriminate the perturbations as non-causative\nfactors and make predictions only based on the label-causative factors.\nConcretely, we propose a casual diffusion model (CausalDiff) that adapts\ndiffusion models for conditional data generation and disentangles the two types\nof casual factors by learning towards a novel casual information bottleneck\nobjective. Empirically, CausalDiff has significantly outperformed\nstate-of-the-art defense methods on various unseen attacks, achieving an\naverage robustness of 86.39% (+4.01%) on CIFAR-10, 56.25% (+3.13%) on\nCIFAR-100, and 82.62% (+4.93%) on GTSRB (German Traffic Sign Recognition\nBenchmark).\n","authors":["Mingkun Zhang","Keping Bi","Wei Chen","Quanrun Chen","Jiafeng Guo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2410.23091v2.pdf","comment":"accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.06513v1","updated":"2024-11-10T16:29:23Z","published":"2024-11-10T16:29:23Z","title":"PRISM: Privacy-preserving Inter-Site MRI Harmonization via Disentangled\n  Representation Learning","summary":"  Multi-site MRI studies often suffer from site-specific variations arising\nfrom differences in methodology, hardware, and acquisition protocols, thereby\ncompromising accuracy and reliability in clinical AI/ML tasks. We present PRISM\n(Privacy-preserving Inter-Site MRI Harmonization), a novel Deep Learning\nframework for harmonizing structural brain MRI across multiple sites while\npreserving data privacy. PRISM employs a dual-branch autoencoder with\ncontrastive learning and variational inference to disentangle anatomical\nfeatures from style and site-specific variations, enabling unpaired image\ntranslation without traveling subjects or multiple MRI modalities. Our modular\ndesign allows harmonization to any target site and seamless integration of new\nsites without the need for retraining or fine-tuning. Using multi-site\nstructural MRI data, we demonstrate PRISM's effectiveness in downstream tasks\nsuch as brain tissue segmentation and validate its harmonization performance\nthrough multiple experiments. Our framework addresses key challenges in medical\nAI/ML, including data privacy, distribution shifts, model generalizability and\ninterpretability. Code is available at https://github.com/saranggalada/PRISM\n","authors":["Sarang Galada","Tanurima Halder","Kunal Deo","Ram P Krish","Kshitij Jadhav"],"pdf_url":"https://arxiv.org/pdf/2411.06513v1.pdf","comment":"This work has been submitted to ISBI 2025"},{"id":"http://arxiv.org/abs/2411.06510v1","updated":"2024-11-10T16:16:06Z","published":"2024-11-10T16:16:06Z","title":"Offline Handwritten Signature Verification Using a Stream-Based Approach","summary":"  Handwritten Signature Verification (HSV) systems distinguish between genuine\nand forged signatures. Traditional HSV development involves a static batch\nconfiguration, constraining the system's ability to model signatures to the\nlimited data available. Signatures exhibit high intra-class variability and are\nsensitive to various factors, including time and external influences, imparting\nthem a dynamic nature. This paper investigates the signature learning process\nwithin a data stream context. We propose a novel HSV approach with an adaptive\nsystem that receives an infinite sequence of signatures and is updated over\ntime. Experiments were carried out on GPDS Synthetic, CEDAR, and MCYT datasets.\nResults demonstrate the superior performance of the proposed method compared to\nstandard approaches that use a Support Vector Machine as a classifier.\nImplementation of the method is available at\nhttps://github.com/kdMoura/stream_hsv.\n","authors":["Kecia G. de Moura","Rafael M. O. Cruz","Robert Sabourin"],"pdf_url":"https://arxiv.org/pdf/2411.06510v1.pdf","comment":"Accepted for oral presentation at the International Conference on\n  Pattern Recognition (ICPR) 2024"},{"id":"http://arxiv.org/abs/2411.06508v1","updated":"2024-11-10T16:09:47Z","published":"2024-11-10T16:09:47Z","title":"Understanding the Role of Equivariance in Self-supervised Learning","summary":"  Contrastive learning has been a leading paradigm for self-supervised\nlearning, but it is widely observed that it comes at the price of sacrificing\nuseful features (\\eg colors) by being invariant to data augmentations. Given\nthis limitation, there has been a surge of interest in equivariant\nself-supervised learning (E-SSL) that learns features to be augmentation-aware.\nHowever, even for the simplest rotation prediction method, there is a lack of\nrigorous understanding of why, when, and how E-SSL learns useful features for\ndownstream tasks. To bridge this gap between practice and theory, we establish\nan information-theoretic perspective to understand the generalization ability\nof E-SSL. In particular, we identify a critical explaining-away effect in E-SSL\nthat creates a synergy between the equivariant and classification tasks. This\nsynergy effect encourages models to extract class-relevant features to improve\nits equivariant prediction, which, in turn, benefits downstream tasks requiring\nsemantic features. Based on this perspective, we theoretically analyze the\ninfluence of data transformations and reveal several principles for practical\ndesigns of E-SSL. Our theory not only aligns well with existing E-SSL methods\nbut also sheds light on new directions by exploring the benefits of model\nequivariance. We believe that a theoretically grounded understanding on the\nrole of equivariance would inspire more principled and advanced designs in this\nfield. Code is available at https://github.com/kaotty/Understanding-ESSL.\n","authors":["Yifei Wang","Kaiwen Hu","Sharut Gupta","Ziyu Ye","Yisen Wang","Stefanie Jegelka"],"pdf_url":"https://arxiv.org/pdf/2411.06508v1.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.06503v1","updated":"2024-11-10T15:57:53Z","published":"2024-11-10T15:57:53Z","title":"Diffusion Sampling Correction via Approximately 10 Parameters","summary":"  Diffusion Probabilistic Models (DPMs) have demonstrated exceptional\nperformance in generative tasks, but this comes at the expense of sampling\nefficiency. To enhance sampling speed without sacrificing quality, various\ndistillation-based accelerated sampling algorithms have been recently proposed.\nHowever, they typically require significant additional training costs and model\nparameter storage, which limit their practical application. In this work, we\npropose PCA-based Adaptive Search (PAS), which optimizes existing solvers for\nDPMs with minimal learnable parameters and training costs. Specifically, we\nfirst employ PCA to obtain a few orthogonal unit basis vectors to span the\nhigh-dimensional sampling space, which enables us to learn just a set of\ncoordinates to correct the sampling direction; furthermore, based on the\nobservation that the cumulative truncation error exhibits an ``S''-shape, we\ndesign an adaptive search strategy that further enhances the sampling\nefficiency and reduces the number of stored parameters to approximately 10.\nExtensive experiments demonstrate that PAS can significantly enhance existing\nfast solvers in a plug-and-play manner with negligible costs. For instance, on\nCIFAR10, PAS requires only 12 parameters and less than 1 minute of training on\na single NVIDIA A100 GPU to optimize the DDIM from 15.69 FID (NFE=10) to 4.37.\n","authors":["Guangyi Wang","Wei Peng","Lijiang Li","Wenyu Chen","Yuren Cai","Songzhi Su"],"pdf_url":"https://arxiv.org/pdf/2411.06503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06499v1","updated":"2024-11-10T15:48:29Z","published":"2024-11-10T15:48:29Z","title":"Mitigating covariate shift in non-colocated data with learned parameter\n  priors","summary":"  When training data are distributed across{ time or space,} covariate shift\nacross fragments of training data biases cross-validation, compromising model\nselection and assessment. We present \\textit{Fragmentation-Induced\ncovariate-shift Remediation} ($FIcsR$), which minimizes an $f$-divergence\nbetween a fragment's covariate distribution and that of the standard\ncross-validation baseline. We s{how} an equivalence with popular\nimportance-weighting methods. {The method}'s numerical solution poses a\ncomputational challenge owing to the overparametrized nature of a neural\nnetwork, and we derive a Fisher Information approximation. When accumulated\nover fragments, this provides a global estimate of the amount of shift\nremediation thus far needed, and we incorporate that as a prior via the\nminimization objective. In the paper, we run extensive classification\nexperiments on multiple data classes, over $40$ datasets, and with data batched\nover multiple sequence lengths. We extend the study to the $k$-fold\ncross-validation setting through a similar set of experiments. An ablation\nstudy exposes the method to varying amounts of shift and demonstrates slower\ndegradation with $FIcsR$ in place. The results are promising under all these\nconditions; with improved accuracy against batch and fold state-of-the-art by\nmore than $5\\%$ and $10\\%$, respectively.\n","authors":["Behraj Khan","Behroz Mirza","Nouman Durrani","Tahir Syed"],"pdf_url":"https://arxiv.org/pdf/2411.06499v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.18861v3","updated":"2024-11-10T15:06:53Z","published":"2024-04-29T16:51:30Z","title":"Visual Mamba: A Survey and New Outlooks","summary":"  Mamba, a recent selective structured state space model, excels in long\nsequence modeling, which is vital in the large model era. Long sequence\nmodeling poses significant challenges, including capturing long-range\ndependencies within the data and handling the computational demands caused by\ntheir extensive length. Mamba addresses these challenges by overcoming the\nlocal perception limitations of convolutional neural networks and the quadratic\ncomputational complexity of Transformers. Given its advantages over these\nmainstream foundation architectures, Mamba exhibits great potential to be a\nvisual foundation architecture. Since January 2024, Mamba has been actively\napplied to diverse computer vision tasks, yielding numerous contributions. To\nhelp keep pace with the rapid advancements, this paper reviews visual Mamba\napproaches, analyzing over 200 papers. This paper begins by delineating the\nformulation of the original Mamba model. Subsequently, it delves into\nrepresentative backbone networks, and applications categorized using different\nmodalities, including image, video, point cloud, and multi-modal data.\nParticularly, we identify scanning techniques as critical for adapting Mamba to\nvision tasks, and decouple these scanning techniques to clarify their\nfunctionality and enhance their flexibility across various applications.\nFinally, we discuss the challenges and future directions, providing insights\ninto new outlooks in this fast evolving area. A comprehensive list of visual\nMamba models reviewed in this work is available at\nhttps://github.com/Ruixxxx/Awesome-Vision-Mamba-Models.\n","authors":["Rui Xu","Shu Yang","Yihui Wang","Yu Cai","Bo Du","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2404.18861v3.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2411.06486v1","updated":"2024-11-10T14:59:29Z","published":"2024-11-10T14:59:29Z","title":"DDIM-Driven Coverless Steganography Scheme with Real Key","summary":"  Typical steganography embeds secret information into images by exploiting\ntheir redundancy. Since the visual imperceptibility of secret information is a\nkey factor in scheme evaluation, conventional methods aim to balance this\nrequirement with embedding capacity. Consequently, integrating emerging image\ngeneration models and secret transmission has been extensively explored to\nachieve a higher embedding capacity. Previous works mostly focus on generating\nstego-images with Generative Adversarial Networks (GANs) and usually rely on\npseudo-keys, namely conditions or parameters involved in the generation\nprocess, which are related to secret images. However, studies on\ndiffusion-based coverless steganography remain insufficient. In this work, we\nleverage the Denoising Diffusion Implicit Model (DDIM) to generate high-quality\nstego-images without introducing pseudo-keys, instead employing real keys to\nenhance security. Furthermore, our method offers low-image-correlation real-key\nprotection by incorporating chaotic encryption. Another core innovation is that\nour method requires only one-time negotiation for multiple communications,\nunlike prior methods that necessitate negotiation for each interaction.\n","authors":["Mingyu Yu","Haonan Miao","Zhengping Jin","Sujuan Qing"],"pdf_url":"https://arxiv.org/pdf/2411.06486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06481v1","updated":"2024-11-10T14:41:38Z","published":"2024-11-10T14:41:38Z","title":"KMM: Key Frame Mask Mamba for Extended Motion Generation","summary":"  Human motion generation is a cut-edge area of research in generative computer\nvision, with promising applications in video creation, game development, and\nrobotic manipulation. The recent Mamba architecture shows promising results in\nefficiently modeling long and complex sequences, yet two significant challenges\nremain: Firstly, directly applying Mamba to extended motion generation is\nineffective, as the limited capacity of the implicit memory leads to memory\ndecay. Secondly, Mamba struggles with multimodal fusion compared to\nTransformers, and lack alignment with textual queries, often confusing\ndirections (left or right) or omitting parts of longer text queries. To address\nthese challenges, our paper presents three key contributions: Firstly, we\nintroduce KMM, a novel architecture featuring Key frame Masking Modeling,\ndesigned to enhance Mamba's focus on key actions in motion segments. This\napproach addresses the memory decay problem and represents a pioneering method\nin customizing strategic frame-level masking in SSMs. Additionally, we designed\na contrastive learning paradigm for addressing the multimodal fusion problem in\nMamba and improving the motion-text alignment. Finally, we conducted extensive\nexperiments on the go-to dataset, BABEL, achieving state-of-the-art performance\nwith a reduction of more than 57% in FID and 70% parameters compared to\nprevious state-of-the-art methods. See project website:\nhttps://steve-zeyu-zhang.github.io/KMM\n","authors":["Zeyu Zhang","Hang Gao","Akide Liu","Qi Chen","Feng Chen","Yiran Wang","Danning Li","Hao Tang"],"pdf_url":"https://arxiv.org/pdf/2411.06481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06478v1","updated":"2024-11-10T14:31:56Z","published":"2024-11-10T14:31:56Z","title":"Superpixel Segmentation: A Long-Lasting Ill-Posed Problem","summary":"  For many years, image over-segmentation into superpixels has been essential\nto computer vision pipelines, by creating homogeneous and identifiable regions\nof similar sizes. Such constrained segmentation problem would require a clear\ndefinition and specific evaluation criteria. However, the validation framework\nfor superpixel methods, typically viewed as standard object segmentation, has\nrarely been thoroughly studied. In this work, we first take a step back to show\nthat superpixel segmentation is fundamentally an ill-posed problem, due to the\nimplicit regularity constraint on the shape and size of superpixels. We also\ndemonstrate through a novel comprehensive study that the literature suffers\nfrom only evaluating certain aspects, sometimes incorrectly and with\ninappropriate metrics. Concurrently, recent deep learning-based superpixel\nmethods mainly focus on the object segmentation task at the expense of\nregularity. In this ill-posed context, we show that we can achieve competitive\nresults using a recent architecture like the Segment Anything Model (SAM),\nwithout dedicated training for the superpixel segmentation task. This leads to\nrethinking superpixel segmentation and the necessary properties depending on\nthe targeted downstream task.\n","authors":["Rémi Giraud","Michaël Clément"],"pdf_url":"https://arxiv.org/pdf/2411.06478v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12299v2","updated":"2024-11-10T13:46:36Z","published":"2024-05-20T18:04:59Z","title":"Perturbing the Gradient for Alleviating Meta Overfitting","summary":"  The reason for Meta Overfitting can be attributed to two factors: Mutual\nNon-exclusivity and the Lack of diversity, consequent to which a single global\nfunction can fit the support set data of all the meta-training tasks and fail\nto generalize to new unseen tasks. This issue is evidenced by low error rates\non the meta-training tasks, but high error rates on new tasks. However, there\ncan be a number of novel solutions to this problem keeping in mind any of the\ntwo objectives to be attained, i.e. to increase diversity in the tasks and to\nreduce the confidence of the model for some of the tasks. In light of the\nabove, this paper proposes a number of solutions to tackle meta-overfitting on\nfew-shot learning settings, such as few-shot sinusoid regression and few shot\nclassification. Our proposed approaches demonstrate improved generalization\nperformance compared to state-of-the-art baselines for learning in a\nnon-mutually exclusive task setting. Overall, this paper aims to provide\ninsights into tackling overfitting in meta-learning and to advance the field\ntowards more robust and generalizable models.\n","authors":["Manas Gogoi","Sambhavi Tiwari","Shekhar Verma"],"pdf_url":"https://arxiv.org/pdf/2405.12299v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17136v2","updated":"2024-11-10T13:45:57Z","published":"2024-10-22T16:08:09Z","title":"AlphaChimp: Tracking and Behavior Recognition of Chimpanzees","summary":"  Understanding non-human primate behavior is crucial for improving animal\nwelfare, modeling social behavior, and gaining insights into both distinctly\nhuman and shared behaviors. Despite recent advances in computer vision,\nautomated analysis of primate behavior remains challenging due to the\ncomplexity of their social interactions and the lack of specialized algorithms.\nExisting methods often struggle with the nuanced behaviors and frequent\nocclusions characteristic of primate social dynamics. This study aims to\ndevelop an effective method for automated detection, tracking, and recognition\nof chimpanzee behaviors in video footage. Here we show that our proposed\nmethod, AlphaChimp, an end-to-end approach that simultaneously detects\nchimpanzee positions and estimates behavior categories from videos,\nsignificantly outperforms existing methods in behavior recognition. AlphaChimp\nachieves approximately 10% higher tracking accuracy and a 20% improvement in\nbehavior recognition compared to state-of-the-art methods, particularly\nexcelling in the recognition of social behaviors. This superior performance\nstems from AlphaChimp's innovative architecture, which integrates temporal\nfeature fusion with a Transformer-based self-attention mechanism, enabling more\neffective capture and interpretation of complex social interactions among\nchimpanzees. Our approach bridges the gap between computer vision and\nprimatology, enhancing technical capabilities and deepening our understanding\nof primate communication and sociality. We release our code and models and hope\nthis will facilitate future research in animal social dynamics. This work\ncontributes to ethology, cognitive science, and artificial intelligence,\noffering new perspectives on social intelligence.\n","authors":["Xiaoxuan Ma","Yutang Lin","Yuan Xu","Stephan P. Kaufhold","Jack Terwilliger","Andres Meza","Yixin Zhu","Federico Rossano","Yizhou Wang"],"pdf_url":"https://arxiv.org/pdf/2410.17136v2.pdf","comment":"An extension of ChimpACT [arXiv:2310.16447], proposes AlphaChimp for\n  tracking and behavior recognition of chimpanzees. arXiv admin note:\n  substantial text overlap with arXiv:2310.16447"},{"id":"http://arxiv.org/abs/2411.06463v1","updated":"2024-11-10T13:35:10Z","published":"2024-11-10T13:35:10Z","title":"RL-Pruner: Structured Pruning Using Reinforcement Learning for CNN\n  Compression and Acceleration","summary":"  Convolutional Neural Networks (CNNs) have demonstrated exceptional\nperformance in recent years. Compressing these models not only reduces storage\nrequirements, making deployment to edge devices feasible, but also accelerates\ninference, thereby reducing latency and computational costs. Structured\npruning, which removes filters at the layer level, directly modifies the model\narchitecture. This approach achieves a more compact architecture while\nmaintaining target accuracy, ensuring that the compressed model retains good\ncompatibility and hardware efficiency. Our method is based on a key\nobservation: filters in different layers of a neural network have varying\nimportance to the model's performance. When the number of filters to prune is\nfixed, the optimal pruning distribution across different layers is uneven to\nminimize performance loss. Layers that are more sensitive to pruning should\naccount for a smaller proportion of the pruning distribution. To leverage this\ninsight, we propose RL-Pruner, which uses reinforcement learning to learn the\noptimal pruning distribution. RL-Pruner can automatically extract dependencies\nbetween filters in the input model and perform pruning, without requiring\nmodel-specific pruning implementations. We conducted experiments on models such\nas GoogleNet, ResNet, and MobileNet, comparing our approach to other structured\npruning methods to validate its effectiveness. Our code is available at\nhttps://github.com/Beryex/RLPruner-CNN.\n","authors":["Boyao Wang","Volodymyr Kindratenko"],"pdf_url":"https://arxiv.org/pdf/2411.06463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01455v2","updated":"2024-11-10T13:10:53Z","published":"2024-06-03T15:43:29Z","title":"Automatic Fused Multimodal Deep Learning for Plant Identification","summary":"  Plant classification is vital for ecological conservation and agricultural\nproductivity, enhancing our understanding of plant growth dynamics and aiding\nspecies preservation. The advent of deep learning (DL) techniques has\nrevolutionized this field by enabling autonomous feature extraction,\nsignificantly reducing the dependence on manual expertise. However,\nconventional DL models often rely solely on single data sources, failing to\ncapture the full biological diversity of plant species comprehensively. Recent\nresearch has turned to multimodal learning to overcome this limitation by\nintegrating multiple data types, which enriches the representation of plant\ncharacteristics. This shift introduces the challenge of determining the optimal\npoint for modality fusion. In this paper, we introduce a pioneering multimodal\nDL-based approach for plant classification with automatic modality fusion.\nUtilizing the multimodal fusion architecture search, our method integrates\nimages from multiple plant organs--flowers, leaves, fruits, and stems--into a\ncohesive model. Our method achieves 82.61% accuracy on 979 classes of the\nPlantCLEF2015 dataset, surpassing state-of-the-art methods and outperforming\nlate fusion by 10.33%. Through the incorporation of multimodal dropout, our\napproach demonstrates strong robustness to missing modalities. We validate our\nmodel against established benchmarks using standard performance metrics and\nMcNemar's test, further underscoring its superiority.\n","authors":["Alfreds Lapkovskis","Natalia Nefedova","Ali Beikmohammadi"],"pdf_url":"https://arxiv.org/pdf/2406.01455v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06456v1","updated":"2024-11-10T13:05:36Z","published":"2024-11-10T13:05:36Z","title":"Dropout the High-rate Downsampling: A Novel Design Paradigm for UHD\n  Image Restoration","summary":"  With the popularization of high-end mobile devices, Ultra-high-definition\n(UHD) images have become ubiquitous in our lives. The restoration of UHD images\nis a highly challenging problem due to the exaggerated pixel count, which often\nleads to memory overflow during processing. Existing methods either downsample\nUHD images at a high rate before processing or split them into multiple patches\nfor separate processing. However, high-rate downsampling leads to significant\ninformation loss, while patch-based approaches inevitably introduce boundary\nartifacts. In this paper, we propose a novel design paradigm to solve the UHD\nimage restoration problem, called D2Net. D2Net enables direct full-resolution\ninference on UHD images without the need for high-rate downsampling or dividing\nthe images into several patches. Specifically, we ingeniously utilize the\ncharacteristics of the frequency domain to establish long-range dependencies of\nfeatures. Taking into account the richer local patterns in UHD images, we also\ndesign a multi-scale convolutional group to capture local features.\nAdditionally, during the decoding stage, we dynamically incorporate features\nfrom the encoding stage to reduce the flow of irrelevant information. Extensive\nexperiments on three UHD image restoration tasks, including low-light image\nenhancement, image dehazing, and image deblurring, show that our model achieves\nbetter quantitative and qualitative results than state-of-the-art methods.\n","authors":["Chen Wu","Ling Wang","Long Peng","Dianjie Lu","Zhuoran Zheng"],"pdf_url":"https://arxiv.org/pdf/2411.06456v1.pdf","comment":"WACV2025"},{"id":"http://arxiv.org/abs/2411.06449v1","updated":"2024-11-10T12:43:38Z","published":"2024-11-10T12:43:38Z","title":"Improved Video VAE for Latent Video Diffusion Model","summary":"  Variational Autoencoder (VAE) aims to compress pixel data into\nlow-dimensional latent space, playing an important role in OpenAI's Sora and\nother latent video diffusion generation models. While most of existing video\nVAEs inflate a pretrained image VAE into the 3D causal structure for\ntemporal-spatial compression, this paper presents two astonishing findings: (1)\nThe initialization from a well-trained image VAE with the same latent\ndimensions suppresses the improvement of subsequent temporal compression\ncapabilities. (2) The adoption of causal reasoning leads to unequal information\ninteractions and unbalanced performance between frames. To alleviate these\nproblems, we propose a keyframe-based temporal compression (KTC) architecture\nand a group causal convolution (GCConv) module to further improve video VAE\n(IV-VAE). Specifically, the KTC architecture divides the latent space into two\nbranches, in which one half completely inherits the compression prior of\nkeyframes from a lower-dimension image VAE while the other half involves\ntemporal compression through 3D group causal convolution, reducing\ntemporal-spatial conflicts and accelerating the convergence speed of video VAE.\nThe GCConv in above 3D half uses standard convolution within each frame group\nto ensure inter-frame equivalence, and employs causal logical padding between\ngroups to maintain flexibility in processing variable frame video. Extensive\nexperiments on five benchmarks demonstrate the SOTA video reconstruction and\ngeneration capabilities of the proposed IV-VAE\n(https://wpy1999.github.io/IV-VAE/).\n","authors":["Pingyu Wu","Kai Zhu","Yu Liu","Liming Zhao","Wei Zhai","Yang Cao","Zheng-Jun Zha"],"pdf_url":"https://arxiv.org/pdf/2411.06449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06444v1","updated":"2024-11-10T12:25:00Z","published":"2024-11-10T12:25:00Z","title":"SamRobNODDI: Q-Space Sampling-Augmented Continuous Representation\n  Learning for Robust and Generalized NODDI","summary":"  Neurite Orientation Dispersion and Density Imaging (NODDI) microstructure\nestimation from diffusion magnetic resonance imaging (dMRI) is of great\nsignificance for the discovery and treatment of various neurological diseases.\nCurrent deep learning-based methods accelerate the speed of NODDI parameter\nestimation and improve the accuracy. However, most methods require the number\nand coordinates of gradient directions during testing and training to remain\nstrictly consistent, significantly limiting the generalization and robustness\nof these models in NODDI parameter estimation. In this paper, we propose a\nq-space sampling augmentation-based continuous representation learning\nframework (SamRobNODDI) to achieve robust and generalized NODDI. Specifically,\na continuous representation learning method based on q-space sampling\naugmentation is introduced to fully explore the information between different\ngradient directions in q-space. Furthermore, we design a sampling consistency\nloss to constrain the outputs of different sampling schemes, ensuring that the\noutputs remain as consistent as possible, thereby further enhancing performance\nand robustness to varying q-space sampling schemes. SamRobNODDI is also a\nflexible framework that can be applied to different backbone networks. To\nvalidate the effectiveness of the proposed method, we compared it with 7\nstate-of-the-art methods across 18 different q-space sampling schemes,\ndemonstrating that the proposed SamRobNODDI has better performance, robustness,\ngeneralization, and flexibility.\n","authors":["Taohui Xiao","Jian Cheng","Wenxin Fan","Enqing Dong","Hairong Zheng","Shanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2411.06444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06442v1","updated":"2024-11-10T12:21:14Z","published":"2024-11-10T12:21:14Z","title":"Local Implicit Wavelet Transformer for Arbitrary-Scale Super-Resolution","summary":"  Implicit neural representations have recently demonstrated promising\npotential in arbitrary-scale Super-Resolution (SR) of images. Most existing\nmethods predict the pixel in the SR image based on the queried coordinate and\nensemble nearby features, overlooking the importance of incorporating\nhigh-frequency prior information in images, which results in limited\nperformance in reconstructing high-frequency texture details in images. To\naddress this issue, we propose the Local Implicit Wavelet Transformer (LIWT) to\nenhance the restoration of high-frequency texture details. Specifically, we\ndecompose the features extracted by an encoder into four sub-bands containing\ndifferent frequency information using Discrete Wavelet Transform (DWT). We then\nintroduce the Wavelet Enhanced Residual Module (WERM) to transform these four\nsub-bands into high-frequency priors, followed by utilizing the Wavelet Mutual\nProjected Fusion (WMPF) and the Wavelet-aware Implicit Attention (WIA) to fully\nexploit the high-frequency prior information for recovering high-frequency\ndetails in images. We conducted extensive experiments on benchmark datasets to\nvalidate the effectiveness of LIWT. Both qualitative and quantitative results\ndemonstrate that LIWT achieves promising performance in arbitrary-scale SR\ntasks, outperforming other state-of-the-art methods. The code is available at\nhttps://github.com/dmhdmhdmh/LIWT.\n","authors":["Minghong Duan","Linhao Qu","Shaolei Liu","Manning Wang"],"pdf_url":"https://arxiv.org/pdf/2411.06442v1.pdf","comment":"Accepted by BMVC 2024"},{"id":"http://arxiv.org/abs/2411.06441v1","updated":"2024-11-10T12:17:32Z","published":"2024-11-10T12:17:32Z","title":"Detecting AutoEncoder is Enough to Catch LDM Generated Images","summary":"  In recent years, diffusion models have become one of the main methods for\ngenerating images. However, detecting images generated by these models remains\na challenging task. This paper proposes a novel method for detecting images\ngenerated by Latent Diffusion Models (LDM) by identifying artifacts introduced\nby their autoencoders. By training a detector to distinguish between real\nimages and those reconstructed by the LDM autoencoder, the method enables\ndetection of generated images without directly training on them. The novelty of\nthis research lies in the fact that, unlike similar approaches, this method\ndoes not require training on synthesized data, significantly reducing\ncomputational costs and enhancing generalization ability. Experimental results\nshow high detection accuracy with minimal false positives, making this approach\na promising tool for combating fake images.\n","authors":["Dmitry Vesnin","Dmitry Levshun","Andrey Chechulin"],"pdf_url":"https://arxiv.org/pdf/2411.06441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18456v2","updated":"2024-11-10T12:13:17Z","published":"2024-10-24T06:10:09Z","title":"Multi-Stage Airway Segmentation in Lung CT Based on Multi-scale Nested\n  Residual UNet","summary":"  Accurate and complete segmentation of airways in chest CT images is essential\nfor the quantitative assessment of lung diseases and the facilitation of\npulmonary interventional procedures. Although deep learning has led to\nsignificant advancements in medical image segmentation, maintaining airway\ncontinuity remains particularly challenging. This difficulty arises primarily\nfrom the small and dispersed nature of airway structures, as well as class\nimbalance in CT scans. To address these challenges, we designed a Multi-scale\nNested Residual U-Net (MNR-UNet), incorporating multi-scale inputs and Residual\nMulti-scale Modules (RMM) into a nested residual framework to enhance\ninformation flow, effectively capturing the intricate details of small airways\nand mitigating gradient vanishing. Building on this, we developed a three-stage\nsegmentation pipeline to optimize the training of the MNR-UNet. The first two\nstages prioritize high accuracy and sensitivity, while the third stage focuses\non repairing airway breakages to balance topological completeness and\ncorrectness. To further address class imbalance, we introduced a weighted\nBreakage-Aware Loss (wBAL) to heighten focus on challenging samples, penalizing\nbreakages and thereby extending the length of the airway tree. Additionally, we\nproposed a hierarchical evaluation framework to offer more clinically\nmeaningful analysis. Validation on both in-house and public datasets\ndemonstrates that our approach achieves superior performance in detecting more\naccurate airway voxels and identifying additional branches, significantly\nimproving airway topological completeness. The code will be released publicly\nfollowing the publication of the paper.\n","authors":["Bingyu Yang","Huai Liao","Xinyan Huang","Qingyao Tian","Jinlin Wu","Jingdi Hu","Hongbin Liu"],"pdf_url":"https://arxiv.org/pdf/2410.18456v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04170v2","updated":"2024-11-10T11:27:34Z","published":"2024-07-04T22:09:01Z","title":"Attention Normalization Impacts Cardinality Generalization in Slot\n  Attention","summary":"  Object-centric scene decompositions are important representations for\ndownstream tasks in fields such as computer vision and robotics. The recently\nproposed Slot Attention module, already leveraged by several derivative works\nfor image segmentation and object tracking in videos, is a deep learning\ncomponent which performs unsupervised object-centric scene decomposition on\ninput images. It is based on an attention architecture, in which latent slot\nvectors, which hold compressed information on objects, attend to localized\nperceptual features from the input image. In this paper, we demonstrate that\ndesign decisions on normalizing the aggregated values in the attention\narchitecture have considerable impact on the capabilities of Slot Attention to\ngeneralize to a higher number of slots and objects as seen during training. We\npropose and investigate alternatives to the original normalization scheme which\nincrease the generalization capabilities of Slot Attention to varying slot and\nobject counts, resulting in performance gains on the task of unsupervised image\nsegmentation. The newly proposed normalizations represent minimal and easy to\nimplement modifications of the usual Slot Attention module, changing the value\naggregation mechanism from a weighted mean operation to a scaled weighted sum\noperation.\n","authors":["Markus Krimmel","Jan Achterhold","Joerg Stueckler"],"pdf_url":"https://arxiv.org/pdf/2407.04170v2.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2410.22709v3","updated":"2024-11-10T11:09:57Z","published":"2024-10-30T05:38:03Z","title":"FilterViT and DropoutViT","summary":"  In this study, we introduce an enhanced version of ViT that conducts\nattention-based QKV operations during the initial stages of downsampling.\nPerforming attention directly on high-resolution feature maps is\ncomputationally demanding due to the large size and numerous tokens. To\nmitigate this, we propose a filter attention mechanism that uses a Filter Block\nto create a salient mask (Filter Mask) for selecting the most informative\npixels for attention.\n  The Filter Block scores the pixels of the feature map, and we sort these\nscores to retain only the top K pixels (with K varying across layers). This\napproach effectively decreases the number of tokens involved in the attention\ncomputation, reducing computational complexity and boosting processing speed.\nFurthermore, the salient mask provides interpretability, as the model focuses\non regions of the image most critical to the outcome.\n  Our experimental results show that this model improves parameter efficiency\nand computational speed while enhancing accuracy. Compared to existing models,\nour approach significantly reduces resource consumption while maintaining high\nperformance.\n","authors":["Bohang Sun"],"pdf_url":"https://arxiv.org/pdf/2410.22709v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.16221v5","updated":"2024-11-10T10:37:48Z","published":"2023-10-24T22:24:44Z","title":"Hierarchical Randomized Smoothing","summary":"  Real-world data is complex and often consists of objects that can be\ndecomposed into multiple entities (e.g. images into pixels, graphs into\ninterconnected nodes). Randomized smoothing is a powerful framework for making\nmodels provably robust against small changes to their inputs - by guaranteeing\nrobustness of the majority vote when randomly adding noise before\nclassification. Yet, certifying robustness on such complex data via randomized\nsmoothing is challenging when adversaries do not arbitrarily perturb entire\nobjects (e.g. images) but only a subset of their entities (e.g. pixels). As a\nsolution, we introduce hierarchical randomized smoothing: We partially smooth\nobjects by adding random noise only on a randomly selected subset of their\nentities. By adding noise in a more targeted manner than existing methods we\nobtain stronger robustness guarantees while maintaining high accuracy. We\ninitialize hierarchical smoothing using different noising distributions,\nyielding novel robustness certificates for discrete and continuous domains. We\nexperimentally demonstrate the importance of hierarchical smoothing in image\nand node classification, where it yields superior robustness-accuracy\ntrade-offs. Overall, hierarchical smoothing is an important contribution\ntowards models that are both - certifiably robust to perturbations and\naccurate.\n","authors":["Yan Scholten","Jan Schuchardt","Aleksandar Bojchevski","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2310.16221v5.pdf","comment":"Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2406.04873v2","updated":"2024-11-10T10:08:37Z","published":"2024-06-07T12:12:25Z","title":"Ada-VE: Training-Free Consistent Video Editing Using Adaptive Motion\n  Prior","summary":"  Video-to-video synthesis poses significant challenges in maintaining\ncharacter consistency, smooth temporal transitions, and preserving visual\nquality during fast motion. While recent fully cross-frame self-attention\nmechanisms have improved character consistency across multiple frames, they\ncome with high computational costs and often include redundant operations,\nespecially for videos with higher frame rates. To address these inefficiencies,\nwe propose an adaptive motion-guided cross-frame attention mechanism that\nselectively reduces redundant computations. This enables a greater number of\ncross-frame attentions over more frames within the same computational budget,\nthereby enhancing both video quality and temporal coherence. Our method\nleverages optical flow to focus on moving regions while sparsely attending to\nstationary areas, allowing for the joint editing of more frames without\nincreasing computational demands. Traditional frame interpolation techniques\nstruggle with motion blur and flickering in intermediate frames, which\ncompromises visual fidelity. To mitigate this, we introduce KV-caching for\njointly edited frames, reusing keys and values across intermediate frames to\npreserve visual quality and maintain temporal consistency throughout the video.\nWith our adaptive cross-frame self-attention approach, we achieve a threefold\nincrease in the number of keyframes processed compared to existing methods, all\nwithin the same computational budget as fully cross-frame attention baselines.\nThis results in significant improvements in prediction accuracy and temporal\nconsistency, outperforming state-of-the-art approaches. Code will be made\npublicly available at https://github.com/tanvir-utexas/AdaVE/tree/main\n","authors":["Tanvir Mahmud","Mustafa Munir","Radu Marculescu","Diana Marculescu"],"pdf_url":"https://arxiv.org/pdf/2406.04873v2.pdf","comment":"Accepted in WACV 2025. Project page:\n  https://tanvir-utexas.github.io/AdaVE_Demo/"},{"id":"http://arxiv.org/abs/2411.06397v1","updated":"2024-11-10T09:09:41Z","published":"2024-11-10T09:09:41Z","title":"A Hybrid Approach for COVID-19 Detection: Combining Wasserstein GAN with\n  Transfer Learning","summary":"  COVID-19 is extremely contagious and its rapid growth has drawn attention\ntowards its early diagnosis. Early diagnosis of COVID-19 enables healthcare\nprofessionals and government authorities to break the chain of transition and\nflatten the epidemic curve. With the number of cases accelerating across the\ndeveloped world, COVID-19 induced Viral Pneumonia cases is a big challenge.\nOverlapping of COVID-19 cases with Viral Pneumonia and other lung infections\nwith limited dataset and long training hours is a serious problem to cater.\nLimited amount of data often results in over-fitting models and due to this\nreason, model does not predict generalized results. To fill this gap, we\nproposed GAN-based approach to synthesize images which later fed into the deep\nlearning models to classify images of COVID-19, Normal, and Viral Pneumonia.\nSpecifically, customized Wasserstein GAN is proposed to generate 19% more Chest\nX-ray images as compare to the real images. This expanded dataset is then used\nto train four proposed deep learning models: VGG-16, ResNet-50, GoogLeNet and\nMNAST. The result showed that expanded dataset utilized deep learning models to\ndeliver high classification accuracies. In particular, VGG-16 achieved highest\naccuracy of 99.17% among all four proposed schemes. Rest of the models like\nResNet-50, GoogLeNet and MNAST delivered 93.9%, 94.49% and 97.75% testing\naccuracies respectively. Later, the efficiency of these models is compared with\nthe state of art models on the basis of accuracy. Further, our proposed models\ncan be applied to address the issue of scant datasets for any problem of image\nanalysis.\n","authors":["Sumera Rounaq","Shahid Munir Shah","Mahmoud Aljawarneh","Sarah Khan","Ghulam Muhammad"],"pdf_url":"https://arxiv.org/pdf/2411.06397v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06599v8","updated":"2024-11-10T08:36:05Z","published":"2023-06-11T06:27:06Z","title":"Variational Imbalanced Regression: Fair Uncertainty Quantification via\n  Probabilistic Smoothing","summary":"  Existing regression models tend to fall short in both accuracy and\nuncertainty estimation when the label distribution is imbalanced. In this\npaper, we propose a probabilistic deep learning model, dubbed variational\nimbalanced regression (VIR), which not only performs well in imbalanced\nregression but naturally produces reasonable uncertainty estimation as a\nbyproduct. Different from typical variational autoencoders assuming I.I.D.\nrepresentations (a data point's representation is not directly affected by\nother data points), our VIR borrows data with similar regression labels to\ncompute the latent representation's variational distribution; furthermore,\ndifferent from deterministic regression models producing point estimates, VIR\npredicts the entire normal-inverse-gamma distributions and modulates the\nassociated conjugate distributions to impose probabilistic reweighting on the\nimbalanced data, thereby providing better uncertainty estimation. Experiments\nin several real-world datasets show that our VIR can outperform\nstate-of-the-art imbalanced regression models in terms of both accuracy and\nuncertainty estimation. Code will soon be available at\nhttps://github.com/Wang-ML-Lab/variational-imbalanced-regression.\n","authors":["Ziyan Wang","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2306.06599v8.pdf","comment":"Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2411.06390v1","updated":"2024-11-10T08:23:27Z","published":"2024-11-10T08:23:27Z","title":"SplatFormer: Point Transformer for Robust 3D Gaussian Splatting","summary":"  3D Gaussian Splatting (3DGS) has recently transformed photorealistic\nreconstruction, achieving high visual fidelity and real-time performance.\nHowever, rendering quality significantly deteriorates when test views deviate\nfrom the camera angles used during training, posing a major challenge for\napplications in immersive free-viewpoint rendering and navigation. In this\nwork, we conduct a comprehensive evaluation of 3DGS and related novel view\nsynthesis methods under out-of-distribution (OOD) test camera scenarios. By\ncreating diverse test cases with synthetic and real-world datasets, we\ndemonstrate that most existing methods, including those incorporating various\nregularization techniques and data-driven priors, struggle to generalize\neffectively to OOD views. To address this limitation, we introduce SplatFormer,\nthe first point transformer model specifically designed to operate on Gaussian\nsplats. SplatFormer takes as input an initial 3DGS set optimized under limited\ntraining views and refines it in a single forward pass, effectively removing\npotential artifacts in OOD test views. To our knowledge, this is the first\nsuccessful application of point transformers directly on 3DGS sets, surpassing\nthe limitations of previous multi-scene training methods, which could handle\nonly a restricted number of input views during inference. Our model\nsignificantly improves rendering quality under extreme novel views, achieving\nstate-of-the-art performance in these challenging scenarios and outperforming\nvarious 3DGS regularization techniques, multi-scene models tailored for sparse\nview synthesis, and diffusion-based frameworks.\n","authors":["Yutong Chen","Marko Mihajlovic","Xiyi Chen","Yiming Wang","Sergey Prokudin","Siyu Tang"],"pdf_url":"https://arxiv.org/pdf/2411.06390v1.pdf","comment":"Code and dataset are publicly available. Project page:\n  https://sergeyprokudin.github.io/splatformer/"},{"id":"http://arxiv.org/abs/2411.06381v1","updated":"2024-11-10T07:41:00Z","published":"2024-11-10T07:41:00Z","title":"SAN: Structure-Aware Network for Complex and Long-tailed Chinese Text\n  Recognition","summary":"  In text recognition, complex glyphs and tail classes have always been factors\naffecting model performance. Specifically for Chinese text recognition, the\nlack of shape-awareness can lead to confusion among close complex characters.\nSince such characters are often tail classes that appear less frequently in the\ntraining-set, making it harder for the model to capture its shape information.\nHence in this work, we propose a structure-aware network utilizing the\nhierarchical composition information to improve the recognition performance of\ncomplex characters. Implementation-wise, we first propose an auxiliary radical\nbranch and integrate it into the base recognition network as a regularization\nterm, which distills hierarchical composition information into the feature\nextractor. A Tree-Similarity-based weighting mechanism is then proposed to\nfurther utilize the depth information in the hierarchical representation.\nExperiments demonstrate that the proposed approach can significantly improve\nthe performances of complex characters and tail characters, yielding a better\noverall performance. Code is available at https://github.com/Levi-ZJY/SAN.\n","authors":["Junyi Zhang","Chang Liu","Chun Yang"],"pdf_url":"https://arxiv.org/pdf/2411.06381v1.pdf","comment":"Published in ICDAR 2023"},{"id":"http://arxiv.org/abs/2411.06378v1","updated":"2024-11-10T07:34:31Z","published":"2024-11-10T07:34:31Z","title":"PKF: Probabilistic Data Association Kalman Filter for Multi-Object\n  Tracking","summary":"  In this paper, we derive a new Kalman filter with probabilistic data\nassociation between measurements and states. We formulate a variational\ninference problem to approximate the posterior density of the state conditioned\non the measurement data. We view the unknown data association as a latent\nvariable and apply Expectation Maximization (EM) to obtain a filter with update\nstep in the same form as the Kalman filter but with expanded measurement vector\nof all potential associations. We show that the association probabilities can\nbe computed as permanents of matrices with measurement likelihood entries. We\nalso propose an ambiguity check that associates only a subset of ambiguous\nmeasurements and states probabilistically, thus reducing the association time\nand preventing low-probability measurements from harming the estimation\naccuracy. Experiments in simulation show that our filter achieves lower\ntracking errors than the well-established joint probabilistic data association\nfilter (JPDAF), while running at comparable rate. We also demonstrate the\neffectiveness of our filter in multi-object tracking (MOT) on multiple\nreal-world datasets, including MOT17, MOT20, and DanceTrack. We achieve better\nhigher order tracking accuracy (HOTA) than previous Kalman-filter methods and\nremain real-time. Associating only bounding boxes without deep features or\nvelocities, our method ranks top-10 on both MOT17 and MOT20 in terms of HOTA.\nGiven offline detections, our algorithm tracks at 250+ fps on a single laptop\nCPU. Code is available at https://github.com/hwcao17/pkf.\n","authors":["Hanwen Cao","George J. Pappas","Nikolay Atanasov"],"pdf_url":"https://arxiv.org/pdf/2411.06378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16279v2","updated":"2024-11-10T07:34:22Z","published":"2024-06-24T03:01:08Z","title":"SegNet4D: Efficient Instance-Aware 4D LiDAR Semantic Segmentation for\n  Driving Scenarios","summary":"  4D LiDAR semantic segmentation, also referred to as multi-scan semantic\nsegmentation, plays a crucial role in enhancing the environmental understanding\ncapabilities of autonomous robots. It classifies the semantic category of each\nLiDAR point and detects whether it is dynamic, a critical ability for tasks\nlike obstacle avoidance and autonomous navigation. Existing approaches often\nrely on computationally heavy 4D convolutions or recursive networks, which\nresult in poor real-time performance, making them unsuitable for online\nrobotics and autonomous driving applications. In this paper, we introduce\nSegNet4D, a novel real-time 4D semantic segmentation network offering both\nefficiency and strong semantic understanding. SegNet4D addresses 4D\nsegmentation as two tasks: single-scan semantic segmentation and moving object\nsegmentation, each tackled by a separate network head. Both results are\ncombined in a motion-semantic fusion module to achieve comprehensive 4D\nsegmentation. Additionally, instance information is extracted from the current\nscan and exploited for instance-wise segmentation consistency. Our approach\nsurpasses state-of-the-art in both multi-scan semantic segmentation and moving\nobject segmentation while offering greater efficiency, enabling real-time\noperation. Besides, its effectiveness and efficiency have also been validated\non a real-world robotic platform. Our code will be released at\nhttps://github.com/nubot-nudt/SegNet4D.\n","authors":["Neng Wang","Ruibin Guo","Chenghao Shi","Ziyue Wang","Hui Zhang","Huimin Lu","Zhiqiang Zheng","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2406.16279v2.pdf","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2405.14737v2","updated":"2024-11-10T07:31:55Z","published":"2024-05-23T16:03:55Z","title":"CLIPScope: Enhancing Zero-Shot OOD Detection with Bayesian Scoring","summary":"  Detection of out-of-distribution (OOD) samples is crucial for safe real-world\ndeployment of machine learning models. Recent advances in vision language\nfoundation models have made them capable of detecting OOD samples without\nrequiring in-distribution (ID) images. However, these zero-shot methods often\nunderperform as they do not adequately consider ID class likelihoods in their\ndetection confidence scoring. Hence, we introduce CLIPScope, a zero-shot OOD\ndetection approach that normalizes the confidence score of a sample by class\nlikelihoods, akin to a Bayesian posterior update. Furthermore, CLIPScope\nincorporates a novel strategy to mine OOD classes from a large lexical\ndatabase. It selects class labels that are farthest and nearest to ID classes\nin terms of CLIP embedding distance to maximize coverage of OOD samples. We\nconduct extensive ablation studies and empirical evaluations, demonstrating\nstate of the art performance of CLIPScope across various OOD detection\nbenchmarks.\n","authors":["Hao Fu","Naman Patel","Prashanth Krishnamurthy","Farshad Khorrami"],"pdf_url":"https://arxiv.org/pdf/2405.14737v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02332v4","updated":"2024-11-10T05:34:31Z","published":"2024-03-04T18:58:11Z","title":"UniCtrl: Improving the Spatiotemporal Consistency of Text-to-Video\n  Diffusion Models via Training-Free Unified Attention Control","summary":"  Video Diffusion Models have been developed for video generation, usually\nintegrating text and image conditioning to enhance control over the generated\ncontent. Despite the progress, ensuring consistency across frames remains a\nchallenge, particularly when using text prompts as control conditions. To\naddress this problem, we introduce UniCtrl, a novel, plug-and-play method that\nis universally applicable to improve the spatiotemporal consistency and motion\ndiversity of videos generated by text-to-video models without additional\ntraining. UniCtrl ensures semantic consistency across different frames through\ncross-frame self-attention control, and meanwhile, enhances the motion quality\nand spatiotemporal consistency through motion injection and spatiotemporal\nsynchronization. Our experimental results demonstrate UniCtrl's efficacy in\nenhancing various text-to-video models, confirming its effectiveness and\nuniversality.\n","authors":["Tian Xia","Xuweiyi Chen","Sihan Xu"],"pdf_url":"https://arxiv.org/pdf/2403.02332v4.pdf","comment":"Accepted to TMLR | Project Page:\n  https://unified-attention-control.github.io/"},{"id":"http://arxiv.org/abs/2411.06365v1","updated":"2024-11-10T05:32:55Z","published":"2024-11-10T05:32:55Z","title":"Through the Curved Cover: Synthesizing Cover Aberrated Scenes with\n  Refractive Field","summary":"  Recent extended reality headsets and field robots have adopted covers to\nprotect the front-facing cameras from environmental hazards and falls. The\nsurface irregularities on the cover can lead to optical aberrations like\nblurring and non-parametric distortions. Novel view synthesis methods like NeRF\nand 3D Gaussian Splatting are ill-equipped to synthesize from sequences with\noptical aberrations. To address this challenge, we introduce SynthCover to\nenable novel view synthesis through protective covers for downstream extended\nreality applications. SynthCover employs a Refractive Field that estimates the\ncover's geometry, enabling precise analytical calculation of refracted rays.\nExperiments on synthetic and real-world scenes demonstrate our method's ability\nto accurately model scenes viewed through protective covers, achieving a\nsignificant improvement in rendering quality compared to prior methods. We also\nshow that the model can adjust well to various cover geometries with synthetic\nsequences captured with covers of different surface curvatures. To motivate\nfurther studies on this problem, we provide the benchmarked dataset containing\nreal and synthetic walkable scenes captured with protective cover optical\naberrations.\n","authors":["Liuyue Xie","Jiancong Guo","Laszlo A. Jeni","Zhiheng Jia","Mingyang Li","Yunwen Zhou","Chao Guo"],"pdf_url":"https://arxiv.org/pdf/2411.06365v1.pdf","comment":"WACV 2025"},{"id":"http://arxiv.org/abs/2411.06363v1","updated":"2024-11-10T05:12:24Z","published":"2024-11-10T05:12:24Z","title":"Layer-Wise Feature Metric of Semantic-Pixel Matching for Few-Shot\n  Learning","summary":"  In Few-Shot Learning (FSL), traditional metric-based approaches often rely on\nglobal metrics to compute similarity. However, in natural scenes, the spatial\narrangement of key instances is often inconsistent across images. This spatial\nmisalignment can result in mismatched semantic pixels, leading to inaccurate\nsimilarity measurements. To address this issue, we propose a novel method\ncalled the Layer-Wise Features Metric of Semantic-Pixel Matching (LWFM-SPM) to\nmake finer comparisons. Our method enhances model performance through two key\nmodules: (1) the Layer-Wise Embedding (LWE) Module, which refines the\ncross-correlation of image pairs to generate well-focused feature maps for each\nlayer; (2)the Semantic-Pixel Matching (SPM) Module, which aligns critical\npixels based on semantic embeddings using an assignment algorithm. We conducted\nextensive experiments to evaluate our method on four widely used few-shot\nclassification benchmarks: miniImageNet, tieredImageNet, CUB-200-2011, and\nCIFAR-FS. The results indicate that LWFM-SPM achieves competitive performance\nacross these benchmarks. Our code will be publicly available on\nhttps://github.com/Halo2Tang/Code-for-LWFM-SPM.\n","authors":["Hao Tang","Junhao Lu","Guoheng Huang","Ming Li","Xuhang Chen","Guo Zhong","Zhengguang Tan","Zinuo Li"],"pdf_url":"https://arxiv.org/pdf/2411.06363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09471v3","updated":"2024-11-10T04:11:02Z","published":"2024-03-14T15:10:54Z","title":"MambaTalk: Efficient Holistic Gesture Synthesis with Selective State\n  Space Models","summary":"  Gesture synthesis is a vital realm of human-computer interaction, with\nwide-ranging applications across various fields like film, robotics, and\nvirtual reality. Recent advancements have utilized the diffusion model and\nattention mechanisms to improve gesture synthesis. However, due to the high\ncomputational complexity of these techniques, generating long and diverse\nsequences with low latency remains a challenge. We explore the potential of\nstate space models (SSMs) to address the challenge, implementing a two-stage\nmodeling strategy with discrete motion priors to enhance the quality of\ngestures. Leveraging the foundational Mamba block, we introduce MambaTalk,\nenhancing gesture diversity and rhythm through multimodal integration.\nExtensive experiments demonstrate that our method matches or exceeds the\nperformance of state-of-the-art models.\n","authors":["Zunnan Xu","Yukang Lin","Haonan Han","Sicheng Yang","Ronghui Li","Yachao Zhang","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2403.09471v3.pdf","comment":"NeurlPS 2024, Camera Ready"},{"id":"http://arxiv.org/abs/2411.06353v1","updated":"2024-11-10T04:04:20Z","published":"2024-11-10T04:04:20Z","title":"Deep Active Learning in the Open World","summary":"  Machine learning models deployed in open-world scenarios often encounter\nunfamiliar conditions and perform poorly in unanticipated situations. As AI\nsystems advance and find application in safety-critical domains, effectively\nhandling out-of-distribution (OOD) data is crucial to building open-world\nlearning systems. In this work, we introduce ALOE, a novel active learning\nalgorithm for open-world environments designed to enhance model adaptation by\nincorporating new OOD classes via a two-stage approach. First, diversity\nsampling selects a representative set of examples, followed by energy-based OOD\ndetection to prioritize likely unknown classes for annotation. This strategy\naccelerates class discovery and learning, even under constrained annotation\nbudgets. Evaluations on three long-tailed image classification benchmarks\ndemonstrate that ALOE outperforms traditional active learning baselines,\neffectively expanding known categories while balancing annotation cost. Our\nfindings reveal a crucial tradeoff between enhancing known-class performance\nand discovering new classes, setting the stage for future advancements in\nopen-world machine learning.\n","authors":["Tian Xie","Jifan Zhang","Haoyue Bai","Robert Nowak"],"pdf_url":"https://arxiv.org/pdf/2411.06353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06347v1","updated":"2024-11-10T03:34:34Z","published":"2024-11-10T03:34:34Z","title":"Classification in Japanese Sign Language Based on Dynamic Facial\n  Expressions","summary":"  Sign language is a visual language expressed through hand movements and\nnon-manual markers. Non-manual markers include facial expressions and head\nmovements. These expressions vary across different nations. Therefore,\nspecialized analysis methods for each sign language are necessary. However,\nresearch on Japanese Sign Language (JSL) recognition is limited due to a lack\nof datasets. The development of recognition models that consider both manual\nand non-manual features of JSL is crucial for precise and smooth communication\nwith deaf individuals. In JSL, sentence types such as affirmative statements\nand questions are distinguished by facial expressions. In this paper, we\npropose a JSL recognition method that focuses on facial expressions. Our\nproposed method utilizes a neural network to analyze facial features and\nclassify sentence types. Through the experiments, we confirm our method's\neffectiveness by achieving a classification accuracy of 96.05%.\n","authors":["Yui Tatsumi","Shoko Tanaka","Shunsuke Akamatsu","Takahiro Shindo","Hiroshi Watanabe"],"pdf_url":"https://arxiv.org/pdf/2411.06347v1.pdf","comment":"2024 IEEE 13th Global Conference on Consumer Electronics (GCCE 2024)"},{"id":"http://arxiv.org/abs/2411.06346v1","updated":"2024-11-10T03:32:42Z","published":"2024-11-10T03:32:42Z","title":"Activation Map Compression through Tensor Decomposition for Deep\n  Learning","summary":"  Internet of Things and Deep Learning are synergetically and exponentially\ngrowing industrial fields with a massive call for their unification into a\ncommon framework called Edge AI. While on-device inference is a well-explored\ntopic in recent research, backpropagation remains an open challenge due to its\nprohibitive computational and memory costs compared to the extreme resource\nconstraints of embedded devices. Drawing on tensor decomposition research, we\ntackle the main bottleneck of backpropagation, namely the memory footprint of\nactivation map storage. We investigate and compare the effects of activation\ncompression using Singular Value Decomposition and its tensor variant,\nHigh-Order Singular Value Decomposition. The application of low-order\ndecomposition results in considerable memory savings while preserving the\nfeatures essential for learning, and also offers theoretical guarantees to\nconvergence. Experimental results obtained on main-stream architectures and\ntasks demonstrate Pareto-superiority over other state-of-the-art solutions, in\nterms of the trade-off between generalization and memory footprint.\n","authors":["Le-Trung Nguyen","Aël Quélennec","Enzo Tartaglione","Samuel Tardieu","Van-Tam Nguyen"],"pdf_url":"https://arxiv.org/pdf/2411.06346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06344v1","updated":"2024-11-10T03:20:00Z","published":"2024-11-10T03:20:00Z","title":"CityGuessr: City-Level Video Geo-Localization on a Global Scale","summary":"  Video geolocalization is a crucial problem in current times. Given just a\nvideo, ascertaining where it was captured from can have a plethora of\nadvantages. The problem of worldwide geolocalization has been tackled before,\nbut only using the image modality. Its video counterpart remains relatively\nunexplored. Meanwhile, video geolocalization has also garnered some attention\nin the recent past, but the existing methods are all restricted to specific\nregions. This motivates us to explore the problem of video geolocalization at a\nglobal scale. Hence, we propose a novel problem of worldwide video\ngeolocalization with the objective of hierarchically predicting the correct\ncity, state/province, country, and continent, given a video. However, no large\nscale video datasets that have extensive worldwide coverage exist, to train\nmodels for solving this problem. To this end, we introduce a new dataset,\nCityGuessr68k comprising of 68,269 videos from 166 cities all over the world.\nWe also propose a novel baseline approach to this problem, by designing a\ntransformer-based architecture comprising of an elegant Self-Cross Attention\nmodule for incorporating scenes as well as a TextLabel Alignment strategy for\ndistilling knowledge from textlabels in feature space. To further enhance our\nlocation prediction, we also utilize soft-scene labels. Finally we demonstrate\nthe performance of our method on our new dataset as well as Mapillary(MSLS).\nOur code and datasets are available at: https://github.com/ParthPK/CityGuessr\n","authors":["Parth Parag Kulkarni","Gaurav Kumar Nayak","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2411.06344v1.pdf","comment":"Accepted to ECVA Eurpoean Conference on Computer Vision(ECCV) 2024"},{"id":"http://arxiv.org/abs/2411.06343v1","updated":"2024-11-10T03:19:33Z","published":"2024-11-10T03:19:33Z","title":"A novel algorithm for optimizing bundle adjustment in image sequence\n  alignment","summary":"  The Bundle Adjustment (BA) model is commonly optimized using a nonlinear\nleast squares method, with the Levenberg-Marquardt (L-M) algorithm being a\ntypical choice. However, despite the L-M algorithm's effectiveness, its\nsensitivity to initial conditions often results in slower convergence when\napplied to poorly conditioned datasets, motivating the exploration of\nalternative optimization strategies. This paper introduces a novel algorithm\nfor optimizing the BA model in the context of image sequence alignment for\ncryo-electron tomography, utilizing optimal control theory to directly optimize\ngeneral nonlinear functions. The proposed Optimal Control Algorithm (OCA)\nexhibits superior convergence rates and effectively mitigates the oscillatory\nbehavior frequently observed in L-M algorithm. Extensive experiments on both\nsynthetic and real-world datasets were conducted to evaluate the algorithm's\nperformance. The results demonstrate that the OCA achieves faster convergence\ncompared to the L-M algorithm. Moreover, the incorporation of a bisection-based\nupdate procedure significantly enhances the OCA's performance, particularly in\npoorly initialized datasets. These findings indicate that the OCA can\nsubstantially improve the efficiency of 3D reconstructions in cryo-electron\ntomography.\n","authors":["Hailin Xu","Hongxia Wang","Huanshui Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23073v3","updated":"2024-11-10T02:31:09Z","published":"2024-10-30T14:46:35Z","title":"RSNet: A Light Framework for The Detection of Multi-scale Remote Sensing\n  Targets","summary":"  Recent advancements in synthetic aperture radar (SAR) ship detection using\ndeep learning have significantly improved accuracy and speed, yet effectively\ndetecting small objects in complex backgrounds with fewer parameters remains a\nchallenge. This letter introduces RSNet, a lightweight framework constructed to\nenhance ship detection in SAR imagery. To ensure accuracy with fewer\nparameters, we proposed Waveletpool-ContextGuided (WCG) as its backbone,\nguiding global context understanding through multi-scale wavelet features for\neffective detection in complex scenes. Additionally, Waveletpool-StarFusion\n(WSF) is introduced as the neck, employing a residual wavelet element-wise\nmultiplication structure to achieve higher dimensional nonlinear features\nwithout increasing network width. The Lightweight-Shared (LS) module is\ndesigned as detect components to achieve efficient detection through\nlightweight shared convolutional structure and multi-format compatibility.\nExperiments on the SAR Ship Detection Dataset (SSDD) and High-Resolution SAR\nImage Dataset (HRSID) demonstrate that RSNet achieves a strong balance between\nlightweight design and detection performance, surpassing many state-of-the-art\ndetectors, reaching 72.5\\% and 67.6\\% in \\textbf{\\(\\mathbf{mAP_{.50:.95}}\\)\n}respectively with 1.49M parameters. Our code will be released soon.\n","authors":["Hongyu Chen","Chengcheng Chen","Fei Wang","Yuhu Shi","Weiming Zeng"],"pdf_url":"https://arxiv.org/pdf/2410.23073v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05586v2","updated":"2024-11-10T02:20:47Z","published":"2024-10-08T01:00:09Z","title":"TeaserGen: Generating Teasers for Long Documentaries","summary":"  Teasers are an effective tool for promoting content in entertainment,\ncommercial and educational fields. However, creating an effective teaser for\nlong videos is challenging for it requires long-range multimodal modeling on\nthe input videos, while necessitating maintaining audiovisual alignments,\nmanaging scene changes and preserving factual accuracy for the output teasers.\nDue to the lack of a publicly-available dataset, progress along this research\ndirection has been hindered. In this work, we present DocumentaryNet, a\ncollection of 1,269 documentaries paired with their teasers, featuring\nmultimodal data streams of video, speech, music, sound effects and narrations.\nWith DocumentaryNet, we propose a new two-stage system for generating teasers\nfrom long documentaries. The proposed TeaserGen system first generates the\nteaser narration from the transcribed narration of the documentary using a\npretrained large language model, and then selects the most relevant visual\ncontent to accompany the generated narration through language-vision models.\nFor narration-video matching, we explore two approaches: a pretraining-based\nmodel using pretrained contrastive language-vision models and a deep sequential\nmodel that learns the mapping between the narrations and visuals. Our\nexperimental results show that the pretraining-based approach is more effective\nat identifying relevant visual content than directly trained deep\nautoregressive models.\n","authors":["Weihan Xu","Paul Pu Liang","Haven Kim","Julian McAuley","Taylor Berg-Kirkpatrick","Hao-Wen Dong"],"pdf_url":"https://arxiv.org/pdf/2410.05586v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.16201v2","updated":"2024-11-10T01:04:58Z","published":"2024-08-29T01:46:37Z","title":"Uni-3DAD: GAN-Inversion Aided Universal 3D Anomaly Detection on\n  Model-free Products","summary":"  Anomaly detection is a long-standing challenge in manufacturing systems.\nTraditionally, anomaly detection has relied on human inspectors. However, 3D\npoint clouds have gained attention due to their robustness to environmental\nfactors and their ability to represent geometric data. Existing 3D anomaly\ndetection methods generally fall into two categories. One compares scanned 3D\npoint clouds with design files, assuming these files are always available.\nHowever, such assumptions are often violated in many real-world applications\nwhere model-free products exist, such as fresh produce (i.e., ``Cookie\",\n``Potato\", etc.), dentures, bone, etc. The other category compares patches of\nscanned 3D point clouds with a library of normal patches named memory bank.\nHowever, those methods usually fail to detect incomplete shapes, which is a\nfairly common defect type (i.e., missing pieces of different products). The\nmain challenge is that missing areas in 3D point clouds represent the absence\nof scanned points. This makes it infeasible to compare the missing region with\nexisting point cloud patches in the memory bank. To address these two\nchallenges, we proposed a unified, unsupervised 3D anomaly detection framework\ncapable of identifying all types of defects on model-free products. Our method\nintegrates two detection modules: a feature-based detection module and a\nreconstruction-based detection module. Feature-based detection covers geometric\ndefects, such as dents, holes, and cracks, while the reconstruction-based\nmethod detects missing regions. Additionally, we employ a One-class Support\nVector Machine (OCSVM) to fuse the detection results from both modules. The\nresults demonstrate that (1) our proposed method outperforms the\nstate-of-the-art methods in identifying incomplete shapes and (2) it still\nmaintains comparable performance with the SOTA methods in detecting all other\ntypes of anomalies.\n","authors":["Jiayu Liu","Shancong Mou","Nathan Gaw","Yinan Wang"],"pdf_url":"https://arxiv.org/pdf/2408.16201v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06318v1","updated":"2024-11-10T00:35:14Z","published":"2024-11-10T00:35:14Z","title":"SEM-Net: Efficient Pixel Modelling for image inpainting with Spatially\n  Enhanced SSM","summary":"  Image inpainting aims to repair a partially damaged image based on the\ninformation from known regions of the images. \\revise{Achieving semantically\nplausible inpainting results is particularly challenging because it requires\nthe reconstructed regions to exhibit similar patterns to the semanticly\nconsistent regions}. This requires a model with a strong capacity to capture\nlong-range dependencies. Existing models struggle in this regard due to the\nslow growth of receptive field for Convolutional Neural Networks (CNNs) based\nmethods and patch-level interactions in Transformer-based methods, which are\nineffective for capturing long-range dependencies.\n  Motivated by this, we propose SEM-Net, a novel visual State Space model (SSM)\nvision network, modelling corrupted images at the pixel level while capturing\nlong-range dependencies (LRDs) in state space, achieving a linear computational\ncomplexity. To address the inherent lack of spatial awareness in SSM, we\nintroduce the Snake Mamba Block (SMB) and Spatially-Enhanced Feedforward\nNetwork. These innovations enable SEM-Net to outperform state-of-the-art\ninpainting methods on two distinct datasets, showing significant improvements\nin capturing LRDs and enhancement in spatial consistency. Additionally, SEM-Net\nachieves state-of-the-art performance on motion deblurring, demonstrating its\ngeneralizability. Our source code will be released in\nhttps://github.com/ChrisChen1023/SEM-Net.\n","authors":["Shuang Chen","Haozheng Zhang","Amir Atapour-Abarghouei","Hubert P. H. Shum"],"pdf_url":"https://arxiv.org/pdf/2411.06318v1.pdf","comment":"Accepted by WACV 2025"}],"Multimedia":[{"id":"http://arxiv.org/abs/2305.09381v8","updated":"2024-11-10T06:55:48Z","published":"2023-05-16T12:09:30Z","title":"AMD: Autoregressive Motion Diffusion","summary":"  Human motion generation aims to produce plausible human motion sequences\naccording to various conditional inputs, such as text or audio. Despite the\nfeasibility of existing methods in generating motion based on short prompts and\nsimple motion patterns, they encounter difficulties when dealing with long\nprompts or complex motions. The challenges are two-fold: 1) the scarcity of\nhuman motion-captured data for long prompts and complex motions. 2) the high\ndiversity of human motions in the temporal domain and the substantial\ndivergence of distributions from conditional modalities, leading to a\nmany-to-many mapping problem when generating motion with complex and long\ntexts. In this work, we address these gaps by 1) elaborating the first dataset\npairing long textual descriptions and 3D complex motions (HumanLong3D), and 2)\nproposing an autoregressive motion diffusion model (AMD). Specifically, AMD\nintegrates the text prompt at the current timestep with the text prompt and\naction sequences at the previous timestep as conditional information to predict\nthe current action sequences in an iterative manner. Furthermore, we present\nits generalization for X-to-Motion with \"No Modality Left Behind\", enabling the\ngeneration of high-definition and high-fidelity human motions based on\nuser-defined modality input.\n","authors":["Bo Han","Hao Peng","Minjing Dong","Yi Ren","Yixuan Shen","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2305.09381v8.pdf","comment":"accepted by AAAI2024. Official Code:\n  https://github.com/fluide1022/AMD"}]},"2024-11-09T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2411.06315v1","updated":"2024-11-09T23:57:53Z","published":"2024-11-09T23:57:53Z","title":"NeuReg: Domain-invariant 3D Image Registration on Human and Mouse Brains","summary":"  Medical brain imaging relies heavily on image registration to accurately\ncurate structural boundaries of brain features for various healthcare\napplications. Deep learning models have shown remarkable performance in image\nregistration in recent years. Still, they often struggle to handle the\ndiversity of 3D brain volumes, challenged by their structural and contrastive\nvariations and their imaging domains. In this work, we present NeuReg, a\nNeuro-inspired 3D image registration architecture with the feature of domain\ninvariance. NeuReg generates domain-agnostic representations of imaging\nfeatures and incorporates a shifting window-based Swin Transformer block as the\nencoder. This enables our model to capture the variations across brain imaging\nmodalities and species. We demonstrate a new benchmark in multi-domain publicly\navailable datasets comprising human and mouse 3D brain volumes. Extensive\nexperiments reveal that our model (NeuReg) outperforms the existing baseline\ndeep learning-based image registration models and provides a high-performance\nboost on cross-domain datasets, where models are trained on 'source-only'\ndomain and tested on completely 'unseen' target domains. Our work establishes a\nnew state-of-the-art for domain-agnostic 3D brain image registration,\nunderpinned by Neuro-inspired Transformer-based architecture.\n","authors":["Taha Razzaq","Asim Iqbal"],"pdf_url":"https://arxiv.org/pdf/2411.06315v1.pdf","comment":"15 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2411.06308v1","updated":"2024-11-09T23:17:42Z","published":"2024-11-09T23:17:42Z","title":"Exploring Out-of-distribution Detection for Sparse-view Computed\n  Tomography with Diffusion Models","summary":"  Recent works demonstrate the effectiveness of diffusion models as\nunsupervised solvers for inverse imaging problems. Sparse-view computed\ntomography (CT) has greatly benefited from these advancements, achieving\nimproved generalization without reliance on measurement parameters. However,\nthis comes at the cost of potential hallucinations, especially when handling\nout-of-distribution (OOD) data. To ensure reliability, it is essential to study\nOOD detection for CT reconstruction across both clinical and industrial\napplications. This need further extends to enabling the OOD detector to\nfunction effectively as an anomaly inspection tool. In this paper, we explore\nthe use of a diffusion model, trained to capture the target distribution for CT\nreconstruction, as an in-distribution prior. Building on recent research, we\nemploy the model to reconstruct partially diffused input images and assess\nOOD-ness through multiple reconstruction errors. Adapting this approach for\nsparse-view CT requires redefining the notions of \"input\" and \"reconstruction\nerror\". Here, we use filtered backprojection (FBP) reconstructions as input and\ninvestigate various definitions of reconstruction error. Our proof-of-concept\nexperiments on the MNIST dataset highlight both successes and failures,\ndemonstrating the potential and limitations of integrating such an OOD detector\ninto a CT reconstruction system. Our findings suggest that effective OOD\ndetection can be achieved by comparing measurements with forward-projected\nreconstructions, provided that reconstructions from noisy FBP inputs are\nconditioned on the measurements. However, conditioning can sometimes lead the\nOOD detector to inadvertently reconstruct OOD images well. To counter this, we\nintroduce a weighting approach that improves robustness against highly\ninformative OOD measurements, albeit with a trade-off in performance in certain\ncases.\n","authors":["Ezgi Demircan-Tureyen","Felix Lucka","Tristan van Leeuwen"],"pdf_url":"https://arxiv.org/pdf/2411.06308v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.21640v3","updated":"2024-11-09T22:35:52Z","published":"2024-07-31T14:41:10Z","title":"MSA$^2$Net: Multi-scale Adaptive Attention-guided Network for Medical\n  Image Segmentation","summary":"  Medical image segmentation involves identifying and separating object\ninstances in a medical image to delineate various tissues and structures, a\ntask complicated by the significant variations in size, shape, and density of\nthese features. Convolutional neural networks (CNNs) have traditionally been\nused for this task but have limitations in capturing long-range dependencies.\nTransformers, equipped with self-attention mechanisms, aim to address this\nproblem. However, in medical image segmentation it is beneficial to merge both\nlocal and global features to effectively integrate feature maps across various\nscales, capturing both detailed features and broader semantic elements for\ndealing with variations in structures. In this paper, we introduce MSA$^2$Net,\na new deep segmentation framework featuring an expedient design of\nskip-connections. These connections facilitate feature fusion by dynamically\nweighting and combining coarse-grained encoder features with fine-grained\ndecoder feature maps. Specifically, we propose a Multi-Scale Adaptive Spatial\nAttention Gate (MASAG), which dynamically adjusts the receptive field (Local\nand Global contextual information) to ensure that spatially relevant features\nare selectively highlighted while minimizing background distractions. Extensive\nevaluations involving dermatology, and radiological datasets demonstrate that\nour MSA$^2$Net outperforms state-of-the-art (SOTA) works or matches their\nperformance. The source code is publicly available at\nhttps://github.com/xmindflow/MSA-2Net.\n","authors":["Sina Ghorbani Kolahi","Seyed Kamal Chaharsooghi","Toktam Khatibi","Afshin Bozorgpour","Reza Azad","Moein Heidari","Ilker Hacihaliloglu","Dorit Merhof"],"pdf_url":"https://arxiv.org/pdf/2407.21640v3.pdf","comment":"Accepted at BMVC 2024. Supplementary materials included at the end of\n  the main paper (3 pages, 2 figures, 1 table)"},{"id":"http://arxiv.org/abs/2411.06297v1","updated":"2024-11-09T21:49:45Z","published":"2024-11-09T21:49:45Z","title":"Adaptive Aspect Ratios with Patch-Mixup-ViT-based Vehicle ReID","summary":"  Vision Transformers (ViTs) have shown exceptional performance in vehicle\nre-identification (ReID) tasks. However, non-square aspect ratios of image or\nvideo inputs can negatively impact re-identification accuracy. To address this\nchallenge, we propose a novel, human perception driven, and general ViT-based\nReID framework that fuses models trained on various aspect ratios. Our key\ncontributions are threefold: (i) We analyze the impact of aspect ratios on\nperformance using the VeRi-776 and VehicleID datasets, providing guidance for\ninput settings based on the distribution of original image aspect ratios. (ii)\nWe introduce patch-wise mixup strategy during ViT patchification (guided by\nspatial attention scores) and implement uneven stride for better alignment with\nobject aspect ratios. (iii) We propose a dynamic feature fusion ReID network to\nenhance model robustness. Our method outperforms state-of-the-art\ntransformer-based approaches on both datasets, with only a minimal increase in\ninference time per image.\n","authors":["Mei Qiu","Lauren Ann Christopher","Stanley Chien","Lingxi Li"],"pdf_url":"https://arxiv.org/pdf/2411.06297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06287v1","updated":"2024-11-09T21:10:55Z","published":"2024-11-09T21:10:55Z","title":"Hidden in Plain Sight: Evaluating Abstract Shape Recognition in\n  Vision-Language Models","summary":"  Despite the importance of shape perception in human vision, early neural\nimage classifiers relied less on shape information for object recognition than\nother (often spurious) features. While recent research suggests that current\nlarge Vision-Language Models (VLMs) exhibit more reliance on shape, we find\nthem to still be seriously limited in this regard. To quantify such\nlimitations, we introduce IllusionBench, a dataset that challenges current\ncutting-edge VLMs to decipher shape information when the shape is represented\nby an arrangement of visual elements in a scene. Our extensive evaluations\nreveal that, while these shapes are easily detectable by human annotators,\ncurrent VLMs struggle to recognize them, indicating important avenues for\nfuture work in developing more robust visual perception systems. The full\ndataset and codebase are available at:\n\\url{https://arshiahemmat.github.io/illusionbench/}\n","authors":["Arshia Hemmat","Adam Davies","Tom A. Lamb","Jianhao Yuan","Philip Torr","Ashkan Khakzar","Francesco Pinto"],"pdf_url":"https://arxiv.org/pdf/2411.06287v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14397v2","updated":"2024-11-09T21:01:48Z","published":"2022-12-29T18:07:56Z","title":"AttEntropy: On the Generalization Ability of Supervised Semantic\n  Segmentation Transformers to New Objects in New Domains","summary":"  In addition to impressive performance, vision transformers have demonstrated\nremarkable abilities to encode information they were not trained to extract.\nFor example, this information can be used to perform segmentation or\nsingle-view depth estimation even though the networks were only trained for\nimage recognition. We show that a similar phenomenon occurs when explicitly\ntraining transformers for semantic segmentation in a supervised manner for a\nset of categories: Once trained, they provide valuable information even about\ncategories absent from the training set. This information can be used to\nsegment objects from these never-seen-before classes in domains as varied as\nroad obstacles, aircraft parked at a terminal, lunar rocks, and maritime\nhazards.\n","authors":["Krzysztof Lis","Matthias Rottmann","Annika Mütze","Sina Honari","Pascal Fua","Mathieu Salzmann"],"pdf_url":"https://arxiv.org/pdf/2212.14397v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08164v2","updated":"2024-11-09T20:54:51Z","published":"2024-06-12T12:54:27Z","title":"ConMe: Rethinking Evaluation of Compositional Reasoning for Modern VLMs","summary":"  Compositional Reasoning (CR) entails grasping the significance of attributes,\nrelations, and word order. Recent Vision-Language Models (VLMs), comprising a\nvisual encoder and a Large Language Model (LLM) decoder, have demonstrated\nremarkable proficiency in such reasoning tasks. This prompts a crucial\nquestion: have VLMs effectively tackled the CR challenge? We conjecture that\nexisting CR benchmarks may not adequately push the boundaries of modern VLMs\ndue to the reliance on an LLM-only negative text generation pipeline.\nConsequently, the negatives produced either appear as outliers from the natural\nlanguage distribution learned by VLMs' LLM decoders or as improbable within the\ncorresponding image context. To address these limitations, we introduce ConMe\n-- a compositional reasoning benchmark and a novel data generation pipeline\nleveraging VLMs to produce `hard CR Q&A'. Through a new concept of VLMs\nconversing with each other to collaboratively expose their weaknesses, our\npipeline autonomously generates, evaluates, and selects challenging\ncompositional reasoning questions, establishing a robust CR benchmark, also\nsubsequently validated manually. Our benchmark provokes a noteworthy, up to\n33%, decrease in CR performance compared to preceding benchmarks, reinstating\nthe CR challenge even for state-of-the-art VLMs.\n","authors":["Irene Huang","Wei Lin","M. Jehanzeb Mirza","Jacob A. Hansen","Sivan Doveh","Victor Ion Butoi","Roei Herzig","Assaf Arbelle","Hilde Kuhene","Trevor Darrel","Chuang Gan","Aude Oliva","Rogerio Feris","Leonid Karlinsky"],"pdf_url":"https://arxiv.org/pdf/2406.08164v2.pdf","comment":"NeurIPS 2024 Camera Ready"},{"id":"http://arxiv.org/abs/2405.12369v3","updated":"2024-11-09T19:51:43Z","published":"2024-05-20T20:38:22Z","title":"AtomGS: Atomizing Gaussian Splatting for High-Fidelity Radiance Field","summary":"  3D Gaussian Splatting (3DGS) has recently advanced radiance field\nreconstruction by offering superior capabilities for novel view synthesis and\nreal-time rendering speed. However, its strategy of blending optimization and\nadaptive density control might lead to sub-optimal results; it can sometimes\nyield noisy geometry and blurry artifacts due to prioritizing optimizing large\nGaussians at the cost of adequately densifying smaller ones. To address this,\nwe introduce AtomGS, consisting of Atomized Proliferation and Geometry-Guided\nOptimization. The Atomized Proliferation constrains ellipsoid Gaussians of\nvarious sizes into more uniform-sized Atom Gaussians. The strategy enhances the\nrepresentation of areas with fine features by placing greater emphasis on\ndensification in accordance with scene details. In addition, we proposed a\nGeometry-Guided Optimization approach that incorporates an Edge-Aware Normal\nLoss. This optimization method effectively smooths flat surfaces while\npreserving intricate details. Our evaluation shows that AtomGS outperforms\nexisting state-of-the-art methods in rendering quality. Additionally, it\nachieves competitive accuracy in geometry reconstruction and offers a\nsignificant improvement in training speed over other SDF-based methods. More\ninteractive demos can be found in our website\n(https://rongliu-leo.github.io/AtomGS/).\n","authors":["Rong Liu","Rui Xu","Yue Hu","Meida Chen","Andrew Feng"],"pdf_url":"https://arxiv.org/pdf/2405.12369v3.pdf","comment":"BMVC 2024"},{"id":"http://arxiv.org/abs/2411.06236v1","updated":"2024-11-09T17:36:53Z","published":"2024-11-09T17:36:53Z","title":"Zero-Shot NAS via the Suppression of Local Entropy Decrease","summary":"  Architecture performance evaluation is the most time-consuming part of neural\narchitecture search (NAS). Zero-Shot NAS accelerates the evaluation by\nutilizing zero-cost proxies instead of training. Though effective, existing\nzero-cost proxies require invoking backpropagations or running networks on\ninput data, making it difficult to further accelerate the computation of\nproxies. To alleviate this issue, architecture topologies are used to evaluate\nthe performance of networks in this study. We prove that particular\narchitectural topologies decrease the local entropy of feature maps, which\ndegrades specific features to a bias, thereby reducing network performance.\nBased on this proof, architectural topologies are utilized to quantify the\nsuppression of local entropy decrease (SED) as a data-free and running-free\nproxy. Experimental results show that SED outperforms most state-of-the-art\nproxies in terms of architecture selection on five benchmarks, with computation\ntime reduced by three orders of magnitude. We further compare the SED-based NAS\nwith state-of-the-art proxies. SED-based NAS selects the architecture with\nhigher accuracy and fewer parameters in only one second. The theoretical\nanalyses of local entropy and experimental results demonstrate that the\nsuppression of local entropy decrease facilitates selecting optimal\narchitectures in Zero-Shot NAS.\n","authors":["Ning Wu","Han Huang","Yueting Xu","Zhifeng Hao"],"pdf_url":"https://arxiv.org/pdf/2411.06236v1.pdf","comment":"8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.06232v1","updated":"2024-11-09T16:49:59Z","published":"2024-11-09T16:49:59Z","title":"Crowd3D++: Robust Monocular Crowd Reconstruction with Upright Space","summary":"  This paper aims to reconstruct hundreds of people's 3D poses, shapes, and\nlocations from a single image with unknown camera parameters. Due to the small\nand highly varying 2D human scales, depth ambiguity, and perspective\ndistortion, no existing methods can achieve globally consistent reconstruction\nand accurate reprojection. To address these challenges, we first propose\nCrowd3D, which leverages a new concept, Human-scene Virtual Interaction Point\n(HVIP), to convert the complex 3D human localization into 2D-pixel localization\nwith robust camera and ground estimation to achieve globally consistent\nreconstruction. To achieve stable generalization on different camera FoVs\nwithout test-time optimization, we propose an extended version, Crowd3D++,\nwhich eliminates the influence of camera parameters and the cropping operation\nby the proposed canonical upright space and ground-aware normalization\ntransform. In the defined upright space, Crowd3D++ also designs an HVIPNet to\nregress 2D HVIP and infer the depths. Besides, we contribute two benchmark\ndatasets, LargeCrowd and SyntheticCrowd, for evaluating crowd reconstruction in\nlarge scenes. The source code and data will be made publicly available after\nacceptance.\n","authors":["Jing Huang","Hao Wen","Tianyi Zhou","Haozhe Lin","Yu-Kun Lai","Kun Li"],"pdf_url":"https://arxiv.org/pdf/2411.06232v1.pdf","comment":"14 pages including reference"},{"id":"http://arxiv.org/abs/2405.17928v5","updated":"2024-11-09T16:02:12Z","published":"2024-05-28T07:49:52Z","title":"Relational Self-supervised Distillation with Compact Descriptors for\n  Image Copy Detection","summary":"  Image copy detection is the task of detecting edited copies of any image\nwithin a reference database. While previous approaches have shown remarkable\nprogress, the large size of their networks and descriptors remains a\ndisadvantage, complicating their practical application. In this paper, we\npropose a novel method that achieves competitive performance by using a\nlightweight network and compact descriptors. By utilizing relational\nself-supervised distillation to transfer knowledge from a large network to a\nsmall network, we enable the training of lightweight networks with smaller\ndescriptor sizes. We introduce relational self-supervised distillation for\nflexible representation in a smaller feature space and apply contrastive\nlearning with a hard negative loss to prevent dimensional collapse. For the\nDISC2021 benchmark, ResNet-50 and EfficientNet-B0 are used as the teacher and\nstudent models, respectively, with micro average precision improving by\n5.0\\%/4.9\\%/5.9\\% for 64/128/256 descriptor sizes compared to the baseline\nmethod. The code is available at\n\\href{https://github.com/juntae9926/RDCD}{https://github.com/juntae9926/RDCD}.\n","authors":["Juntae Kim","Sungwon Woo","Jongho Nang"],"pdf_url":"https://arxiv.org/pdf/2405.17928v5.pdf","comment":"WACV 2025"},{"id":"http://arxiv.org/abs/2409.02917v2","updated":"2024-11-09T15:33:32Z","published":"2024-09-04T17:53:42Z","title":"UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from\n  Endoscopic Sparse Views","summary":"  Visualizing surgical scenes is crucial for revealing internal anatomical\nstructures during minimally invasive procedures. Novel View Synthesis is a\nvital technique that offers geometry and appearance reconstruction, enhancing\nunderstanding, planning, and decision-making in surgical scenes. Despite the\nimpressive achievements of Neural Radiance Field (NeRF), its direct application\nto surgical scenes produces unsatisfying results due to two challenges:\nendoscopic sparse views and significant photometric inconsistencies. In this\npaper, we propose uncertainty-aware conditional NeRF for novel view synthesis\nto tackle the severe shape-radiance ambiguity from sparse surgical views. The\ncore of UC-NeRF is to incorporate the multi-view uncertainty estimation to\ncondition the neural radiance field for modeling the severe photometric\ninconsistencies adaptively. Specifically, our UC-NeRF first builds a\nconsistency learner in the form of multi-view stereo network, to establish the\ngeometric correspondence from sparse views and generate uncertainty estimation\nand feature priors. In neural rendering, we design a base-adaptive NeRF network\nto exploit the uncertainty estimation for explicitly handling the photometric\ninconsistencies. Furthermore, an uncertainty-guided geometry distillation is\nemployed to enhance geometry learning. Experiments on the SCARED and Hamlyn\ndatasets demonstrate our superior performance in rendering appearance and\ngeometry, consistently outperforming the current state-of-the-art approaches.\nOur code will be released at https://github.com/wrld/UC-NeRF.\n","authors":["Jiaxin Guo","Jiangliu Wang","Ruofeng Wei","Di Kang","Qi Dou","Yun-hui Liu"],"pdf_url":"https://arxiv.org/pdf/2409.02917v2.pdf","comment":"Accepted to IEEE Transactions on Medical Imaging"},{"id":"http://arxiv.org/abs/2411.06206v1","updated":"2024-11-09T15:12:06Z","published":"2024-11-09T15:12:06Z","title":"Text2CAD: Text to 3D CAD Generation via Technical Drawings","summary":"  The generation of industrial Computer-Aided Design (CAD) models from user\nrequests and specifications is crucial to enhancing efficiency in modern\nmanufacturing. Traditional methods of CAD generation rely heavily on manual\ninputs and struggle with complex or non-standard designs, making them less\nsuited for dynamic industrial needs. To overcome these challenges, we introduce\nText2CAD, a novel framework that employs stable diffusion models tailored to\nautomate the generation process and efficiently bridge the gap between user\nspecifications in text and functional CAD models. This approach directly\ntranslates the user's textural descriptions into detailed isometric images,\nwhich are then precisely converted into orthographic views, e.g., top, front,\nand side, providing sufficient information to reconstruct 3D CAD models. This\nprocess not only streamlines the creation of CAD models from textual\ndescriptions but also ensures that the resulting models uphold physical and\ndimensional consistency essential for practical engineering applications. Our\nexperimental results show that Text2CAD effectively generates technical\ndrawings that are accurately translated into high-quality 3D CAD models,\nshowing substantial potential to revolutionize CAD automation in response to\nuser demands.\n","authors":["Mohsen Yavartanoo","Sangmin Hong","Reyhaneh Neshatavar","Kyoung Mu Lee"],"pdf_url":"https://arxiv.org/pdf/2411.06206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06197v1","updated":"2024-11-09T14:38:08Z","published":"2024-11-09T14:38:08Z","title":"Multi-object Tracking by Detection and Query: an efficient end-to-end\n  manner","summary":"  Multi-object tracking is advancing through two dominant paradigms:\ntraditional tracking by detection and newly emerging tracking by query. In this\nwork, we fuse them together and propose the tracking-by-detection-and-query\nparadigm, which is achieved by a Learnable Associator. Specifically, the basic\ninformation interaction module and the content-position alignment module are\nproposed for thorough information Interaction among object queries. Tracking\nresults are directly Decoded from these queries. Hence, we name the method as\nLAID. Compared to tracking-by-query models, LAID achieves competitive tracking\naccuracy with notably higher training efficiency. With regard to\ntracking-by-detection methods, experimental results on DanceTrack show that\nLAID significantly surpasses the state-of-the-art heuristic method by 3.9% on\nHOTA metric and 6.1% on IDF1 metric. On SportsMOT, LAID also achieves the best\nscore on HOTA metric. By holding low training cost, strong tracking\ncapabilities, and an elegant end-to-end approach all at once, LAID presents a\nforward-looking direction for the field.\n","authors":["Shukun Jia","Yichao Cao","Feng Yang","Xin Lu","Xiaobo Lu"],"pdf_url":"https://arxiv.org/pdf/2411.06197v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.07433v4","updated":"2024-11-09T14:22:08Z","published":"2024-08-14T10:08:46Z","title":"MagicFace: Training-free Universal-Style Human Image Customized\n  Synthesis","summary":"  Current human image customization methods leverage Stable Diffusion (SD) for\nits rich semantic prior. However, since SD is not specifically designed for\nhuman-oriented generation, these methods often require extensive fine-tuning on\nlarge-scale datasets, which renders them susceptible to overfitting and hinders\ntheir ability to personalize individuals with previously unseen styles.\nMoreover, these methods extensively focus on single-concept human image\nsynthesis and lack the flexibility to customize individuals using multiple\ngiven concepts, thereby impeding their broader practical application. This\npaper proposes MagicFace, a novel training-free method for multi-concept\nuniversal-style human image personalized synthesis. Our core idea is to\nsimulate how humans create images given specific concepts, i.e., first\nestablish a semantic layout considering factors such as concepts' shape and\nposture, then optimize details by comparing with concepts at the pixel level.\nTo implement this process, we introduce a coarse-to-fine generation pipeline,\ninvolving two sequential stages: semantic layout construction and concept\nfeature injection. This is achieved by our Reference-aware Self-Attention (RSA)\nand Region-grouped Blend Attention (RBA) mechanisms. In the first stage, RSA\nenables the latent image to query features from all reference concepts\nsimultaneously, extracting the overall semantic understanding to facilitate the\ninitial semantic layout establishment. In the second stage, we employ an\nattention-based semantic segmentation method to pinpoint the latent generated\nregions of all concepts at each step. Following this, RBA divides the pixels of\nthe latent image into semantic groups, with each group querying fine-grained\nfeatures from the corresponding reference concept. Extensive experiments\ndemonstrate the superiority of our MagicFace.\n","authors":["Yibin Wang","Weizhong Zhang","Cheng Jin"],"pdf_url":"https://arxiv.org/pdf/2408.07433v4.pdf","comment":"project page: https://codegoat24.github.io/MagicFace"},{"id":"http://arxiv.org/abs/2411.06184v1","updated":"2024-11-09T13:52:06Z","published":"2024-11-09T13:52:06Z","title":"Alleviating Hyperparameter-Tuning Burden in SVM Classifiers for\n  Pulmonary Nodules Diagnosis with Multi-Task Bayesian Optimization","summary":"  In the field of non-invasive medical imaging, radiomic features are utilized\nto measure tumor characteristics. However, these features can be affected by\nthe techniques used to discretize the images, ultimately impacting the accuracy\nof diagnosis. To investigate the influence of various image discretization\nmethods on diagnosis, it is common practice to evaluate multiple discretization\nstrategies individually. This approach often leads to redundant and\ntime-consuming tasks such as training predictive models and fine-tuning\nhyperparameters separately. This study examines the feasibility of employing\nmulti-task Bayesian optimization to accelerate the hyperparameters search for\nclassifying benign and malignant pulmonary nodules using RBF SVM. Our findings\nsuggest that multi-task Bayesian optimization significantly accelerates the\nsearch for hyperparameters in comparison to a single-task approach. To the best\nof our knowledge, this is the first investigation to utilize multi-task\nBayesian optimization in a critical medical context.\n","authors":["Wenhao Chi","Haiping Liu","Hongqiao Dong","Wenhua Liang","Bo Liu"],"pdf_url":"https://arxiv.org/pdf/2411.06184v1.pdf","comment":"12 pages, 4 figures, 37 references"},{"id":"http://arxiv.org/abs/2411.06181v1","updated":"2024-11-09T13:48:34Z","published":"2024-11-09T13:48:34Z","title":"Epi-NAF: Enhancing Neural Attenuation Fields for Limited-Angle CT with\n  Epipolar Consistency Conditions","summary":"  Neural field methods, initially successful in the inverse rendering domain,\nhave recently been extended to CT reconstruction, marking a paradigm shift from\ntraditional techniques. While these approaches deliver state-of-the-art results\nin sparse-view CT reconstruction, they struggle in limited-angle settings,\nwhere input projections are captured over a restricted angle range. We present\na novel loss term based on consistency conditions between corresponding\nepipolar lines in X-ray projection images, aimed at regularizing neural\nattenuation field optimization. By enforcing these consistency conditions, our\napproach, Epi-NAF, propagates supervision from input views within the\nlimited-angle range to predicted projections over the full cone-beam CT range.\nThis loss results in both qualitative and quantitative improvements in\nreconstruction compared to baseline methods.\n","authors":["Daniel Gilo","Tzofi Klinghoffer","Or Litany"],"pdf_url":"https://arxiv.org/pdf/2411.06181v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2410.01698v2","updated":"2024-11-09T13:08:42Z","published":"2024-10-02T16:05:15Z","title":"COSMIC: Compress Satellite Images Efficiently via Diffusion Compensation","summary":"  With the rapidly increasing number of satellites in space and their enhanced\ncapabilities, the amount of earth observation images collected by satellites is\nexceeding the transmission limits of satellite-to-ground links. Although\nexisting learned image compression solutions achieve remarkable performance by\nusing a sophisticated encoder to extract fruitful features as compression and\nusing a decoder to reconstruct, it is still hard to directly deploy those\ncomplex encoders on current satellites' embedded GPUs with limited computing\ncapability and power supply to compress images in orbit. In this paper, we\npropose COSMIC, a simple yet effective learned compression solution to transmit\nsatellite images. We first design a lightweight encoder (i.e. reducing FLOPs by\n2.6~5x) on satellite to achieve a high image compression ratio to save\nsatellite-to-ground links. Then, for reconstructions on the ground, to deal\nwith the feature extraction ability degradation due to simplifying encoders, we\npropose a diffusion-based model to compensate image details when decoding. Our\ninsight is that satellite's earth observation photos are not just images but\nindeed multi-modal data with a nature of Text-to-Image pairing since they are\ncollected with rich sensor data (e.g. coordinates, timestamp, etc.) that can be\nused as the condition for diffusion generation. Extensive experiments show that\nCOSMIC outperforms state-of-the-art baselines on both perceptual and distortion\nmetrics.\n","authors":["Ziyuan Zhang","Han Qiu","Maosen Zhang","Jun Liu","Bin Chen","Tianwei Zhang","Hewu Li"],"pdf_url":"https://arxiv.org/pdf/2410.01698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06173v1","updated":"2024-11-09T13:03:54Z","published":"2024-11-09T13:03:54Z","title":"LSSInst: Improving Geometric Modeling in LSS-Based BEV Perception with\n  Instance Representation","summary":"  With the attention gained by camera-only 3D object detection in autonomous\ndriving, methods based on Bird-Eye-View (BEV) representation especially derived\nfrom the forward view transformation paradigm, i.e., lift-splat-shoot (LSS),\nhave recently seen significant progress. The BEV representation formulated by\nthe frustum based on depth distribution prediction is ideal for learning the\nroad structure and scene layout from multi-view images. However, to retain\ncomputational efficiency, the compressed BEV representation such as in\nresolution and axis is inevitably weak in retaining the individual geometric\ndetails, undermining the methodological generality and applicability. With this\nin mind, to compensate for the missing details and utilize multi-view geometry\nconstraints, we propose LSSInst, a two-stage object detector incorporating BEV\nand instance representations in tandem. The proposed detector exploits\nfine-grained pixel-level features that can be flexibly integrated into existing\nLSS-based BEV networks. Having said that, due to the inherent gap between two\nrepresentation spaces, we design the instance adaptor for the BEV-to-instance\nsemantic coherence rather than pass the proposal naively. Extensive experiments\ndemonstrated that our proposed framework is of excellent generalization ability\nand performance, which boosts the performances of modern LSS-based BEV\nperception methods without bells and whistles and outperforms current LSS-based\nstate-of-the-art works on the large-scale nuScenes benchmark.\n","authors":["Weijie Ma","Jingwei Jiang","Yang Yang","Zehui Chen","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2411.06173v1.pdf","comment":"Accepted by 3DV 2025"},{"id":"http://arxiv.org/abs/2411.06160v1","updated":"2024-11-09T12:09:26Z","published":"2024-11-09T12:09:26Z","title":"Expansion Quantization Network: An Efficient Micro-emotion Annotation\n  and Detection Framework","summary":"  Text emotion detection constitutes a crucial foundation for advancing\nartificial intelligence from basic comprehension to the exploration of\nemotional reasoning. Most existing emotion detection datasets rely on manual\nannotations, which are associated with high costs, substantial subjectivity,\nand severe label imbalances. This is particularly evident in the inadequate\nannotation of micro-emotions and the absence of emotional intensity\nrepresentation, which fail to capture the rich emotions embedded in sentences\nand adversely affect the quality of downstream task completion. By proposing an\nall-labels and training-set label regression method, we map label values to\nenergy intensity levels, thereby fully leveraging the learning capabilities of\nmachine models and the interdependencies among labels to uncover multiple\nemotions within samples. This led to the establishment of the Emotion\nQuantization Network (EQN) framework for micro-emotion detection and\nannotation. Using five commonly employed sentiment datasets, we conducted\ncomparative experiments with various models, validating the broad applicability\nof our framework within NLP machine learning models. Based on the EQN\nframework, emotion detection and annotation are conducted on the GoEmotions\ndataset. A comprehensive comparison with the results from Google literature\ndemonstrates that the EQN framework possesses a high capability for automatic\ndetection and annotation of micro-emotions. The EQN framework is the first to\nachieve automatic micro-emotion annotation with energy-level scores, providing\nstrong support for further emotion detection analysis and the quantitative\nresearch of emotion computing.\n","authors":["Jingyi Zhou","Senlin Luo","Haofan Chen"],"pdf_url":"https://arxiv.org/pdf/2411.06160v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06142v1","updated":"2024-11-09T10:42:57Z","published":"2024-11-09T10:42:57Z","title":"Aquila-plus: Prompt-Driven Visual-Language Models for Pixel-Level Remote\n  Sensing Image Understanding","summary":"  The recent development of vision language models (VLMs) has led to\nsignificant advances in visual-language integration through visual instruction\ntuning, and they have rapidly evolved in the field of remote sensing image\nunderstanding, demonstrating their powerful capabilities. However, existing\nRSVLMs mainly focus on image-level or frame-level understanding, making it\ndifficult to achieve fine-grained pixel-level visual-language alignment.\nAdditionally, the lack of mask-based instructional data limits their further\ndevelopment. In this paper, we propose a mask-text instruction tuning method\ncalled Aquila-plus, which extends the capabilities of RSVLMs to achieve\npixel-level visual understanding by incorporating fine-grained mask regions\ninto language instructions. To achieve this, we first meticulously constructed\na mask region-text dataset containing 100K samples, and then designed a\nvisual-language model by injecting pixel-level representations into a large\nlanguage model (LLM). Specifically, Aquila-plus uses a convolutional CLIP as\nthe visual encoder and employs a mask-aware visual extractor to extract precise\nvisual mask features from high-resolution inputs. Experimental results\ndemonstrate that Aquila-plus outperforms existing methods in various region\nunderstanding tasks, showcasing its novel capabilities in pixel-level\ninstruction tuning.\n","authors":["Kaixuan Lu"],"pdf_url":"https://arxiv.org/pdf/2411.06142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17785v2","updated":"2024-11-09T10:26:38Z","published":"2024-10-23T11:35:44Z","title":"TranSPORTmer: A Holistic Approach to Trajectory Understanding in\n  Multi-Agent Sports","summary":"  Understanding trajectories in multi-agent scenarios requires addressing\nvarious tasks, including predicting future movements, imputing missing\nobservations, inferring the status of unseen agents, and classifying different\nglobal states. Traditional data-driven approaches often handle these tasks\nseparately with specialized models. We introduce TranSPORTmer, a unified\ntransformer-based framework capable of addressing all these tasks, showcasing\nits application to the intricate dynamics of multi-agent sports scenarios like\nsoccer and basketball. Using Set Attention Blocks, TranSPORTmer effectively\ncaptures temporal dynamics and social interactions in an equivariant manner.\nThe model's tasks are guided by an input mask that conceals missing or\nyet-to-be-predicted observations. Additionally, we introduce a CLS extra agent\nto classify states along soccer trajectories, including passes, possessions,\nuncontrolled states, and out-of-play intervals, contributing to an enhancement\nin modeling trajectories. Evaluations on soccer and basketball datasets show\nthat TranSPORTmer outperforms state-of-the-art task-specific models in player\nforecasting, player forecasting-imputation, ball inference, and ball\nimputation. https://youtu.be/8VtSRm8oGoE\n","authors":["Guillem Capellera","Luis Ferraz","Antonio Rubio","Antonio Agudo","Francesc Moreno-Noguer"],"pdf_url":"https://arxiv.org/pdf/2410.17785v2.pdf","comment":"Accepted to ACCV 2024"},{"id":"http://arxiv.org/abs/2408.10041v2","updated":"2024-11-09T09:33:54Z","published":"2024-08-19T14:34:17Z","title":"Implicit Gaussian Splatting with Efficient Multi-Level Tri-Plane\n  Representation","summary":"  Recent advancements in photo-realistic novel view synthesis have been\nsignificantly driven by Gaussian Splatting (3DGS). Nevertheless, the explicit\nnature of 3DGS data entails considerable storage requirements, highlighting a\npressing need for more efficient data representations. To address this, we\npresent Implicit Gaussian Splatting (IGS), an innovative hybrid model that\nintegrates explicit point clouds with implicit feature embeddings through a\nmulti-level tri-plane architecture. This architecture features 2D feature grids\nat various resolutions across different levels, facilitating continuous spatial\ndomain representation and enhancing spatial correlations among Gaussian\nprimitives. Building upon this foundation, we introduce a level-based\nprogressive training scheme, which incorporates explicit spatial\nregularization. This method capitalizes on spatial correlations to enhance both\nthe rendering quality and the compactness of the IGS representation.\nFurthermore, we propose a novel compression pipeline tailored for both point\nclouds and 2D feature grids, considering the entropy variations across\ndifferent levels. Extensive experimental evaluations demonstrate that our\nalgorithm can deliver high-quality rendering using only a few MBs, effectively\nbalancing storage efficiency and rendering fidelity, and yielding results that\nare competitive with the state-of-the-art.\n","authors":["Minye Wu","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2408.10041v2.pdf","comment":"Please note that the authors discovered configuration errors in the\n  comparisons within the experiment section, resulting in unreliable\n  quantitative results. We advise referencing the results in this paper with\n  caution"},{"id":"http://arxiv.org/abs/2411.06119v1","updated":"2024-11-09T08:58:57Z","published":"2024-11-09T08:58:57Z","title":"Scalable, Tokenization-Free Diffusion Model Architectures with Efficient\n  Initial Convolution and Fixed-Size Reusable Structures for On-Device Image\n  Generation","summary":"  Vision Transformers and U-Net architectures have been widely adopted in the\nimplementation of Diffusion Models. However, each architecture presents\nspecific challenges while realizing them on-device. Vision Transformers require\npositional embedding to maintain correspondence between the tokens processed by\nthe transformer, although they offer the advantage of using fixed-size,\nreusable repetitive blocks following tokenization. The U-Net architecture lacks\nthese attributes, as it utilizes variable-sized intermediate blocks for\ndown-convolution and up-convolution in the noise estimation backbone for the\ndiffusion process. To address these issues, we propose an architecture that\nutilizes a fixed-size, reusable transformer block as a core structure, making\nit more suitable for hardware implementation. Our architecture is characterized\nby low complexity, token-free design, absence of positional embeddings,\nuniformity, and scalability, making it highly suitable for deployment on mobile\nand resource-constrained devices. The proposed model exhibit competitive and\nconsistent performance across both unconditional and conditional image\ngeneration tasks. The model achieved a state-of-the-art FID score of 1.6 on\nunconditional image generation with the CelebA.\n","authors":["Sanchar Palit","Sathya Veera Reddy Dendi","Mallikarjuna Talluri","Raj Narayana Gadde"],"pdf_url":"https://arxiv.org/pdf/2411.06119v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2410.05915v2","updated":"2024-11-09T08:32:47Z","published":"2024-10-08T11:09:31Z","title":"Give me a hint: Can LLMs take a hint to solve math problems?","summary":"  While state-of-the-art LLMs have shown poor logical and basic mathematical\nreasoning, recent works try to improve their problem-solving abilities using\nprompting techniques. We propose giving \"hints\" to improve the language model's\nperformance on advanced mathematical problems, taking inspiration from how\nhumans approach math pedagogically. We also test robustness to adversarial\nhints and demonstrate their sensitivity to them. We demonstrate the\neffectiveness of our approach by evaluating various diverse LLMs, presenting\nthem with a broad set of problems of different difficulties and topics from the\nMATH dataset and comparing against techniques such as one-shot, few-shot, and\nchain of thought prompting.\n","authors":["Vansh Agrawal","Pratham Singla","Amitoj Singh Miglani","Shivank Garg","Ayush Mangal"],"pdf_url":"https://arxiv.org/pdf/2410.05915v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06106v1","updated":"2024-11-09T08:00:50Z","published":"2024-11-09T08:00:50Z","title":"Personalize to generalize: Towards a universal medical multi-modality\n  generalization through personalization","summary":"  Personalized medicine is a groundbreaking healthcare framework for the\n$21^{st}$ century, tailoring medical treatments to individuals based on unique\nclinical characteristics, including diverse medical imaging modalities. Given\nthe significant differences among these modalities due to distinct underlying\nimaging principles, generalization in multi-modal medical image tasks becomes\nsubstantially challenging. Previous methods addressing multi-modal\ngeneralization rarely consider personalization, primarily focusing on common\nanatomical information. This paper aims to bridge multi-modal generalization\nwith the concept of personalized medicine. Specifically, we propose a novel\napproach to derive a tractable form of the underlying personalized invariant\nrepresentation $\\mathbb{X}_h$ by leveraging individual-level constraints and a\nlearnable biological prior. We demonstrate the feasibility and benefits of\nlearning a personalized $\\mathbb{X}_h$, showing that this representation is\nhighly generalizable and transferable across various multi-modal medical tasks.\nOur method is rigorously validated on medical imaging modalities emphasizing\nboth physical structure and functional information, encompassing a range of\ntasks that require generalization. Extensive experimental results consistently\nshow that our approach significantly improves performance across diverse\nscenarios, confirming its effectiveness.\n","authors":["Zhaorui Tan","Xi Yang","Tan Pan","Tianyi Liu","Chen Jiang","Xin Guo","Qiufeng Wang","Anh Nguyen","Yuan Qi","Kaizhu Huang","Yuan Cheng"],"pdf_url":"https://arxiv.org/pdf/2411.06106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06098v1","updated":"2024-11-09T07:19:56Z","published":"2024-11-09T07:19:56Z","title":"LT-DARTS: An Architectural Approach to Enhance Deep Long-Tailed Learning","summary":"  Deep long-tailed recognition has been widely studied to address the issue of\nimbalanced data distributions in real-world scenarios. However, there has been\ninsufficient focus on the design of neural architectures, despite empirical\nevidence suggesting that architecture can significantly impact performance. In\nthis paper, we attempt to mitigate long-tailed issues through architectural\nimprovements. To simplify the design process, we utilize Differential\nArchitecture Search (DARTS) to achieve this goal. Unfortunately, existing DARTS\nmethods struggle to perform well in long-tailed scenarios. To tackle this\nchallenge, we introduce Long-Tailed Differential Architecture Search\n(LT-DARTS). Specifically, we conduct extensive experiments to explore\narchitectural components that demonstrate better performance on long-tailed\ndata and propose a new search space based on our observations. This ensures\nthat the architecture obtained through our search process incorporates superior\ncomponents. Additionally, we propose replacing the learnable linear classifier\nwith an Equiangular Tight Frame (ETF) classifier to further enhance our method.\nThis classifier effectively alleviates the biased search process and prevents\nperformance collapse. Extensive experimental evaluations demonstrate that our\napproach consistently improves upon existing methods from an orthogonal\nperspective and achieves state-of-the-art results with simple enhancements.\n","authors":["Yuhan Pan","Yanan Sun","Wei Gong"],"pdf_url":"https://arxiv.org/pdf/2411.06098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06091v1","updated":"2024-11-09T07:06:31Z","published":"2024-11-09T07:06:31Z","title":"Pattern Integration and Enhancement Vision Transformer for\n  Self-Supervised Learning in Remote Sensing","summary":"  Recent self-supervised learning (SSL) methods have demonstrated impressive\nresults in learning visual representations from unlabeled remote sensing\nimages. However, most remote sensing images predominantly consist of\nscenographic scenes containing multiple ground objects without explicit\nforeground targets, which limits the performance of existing SSL methods that\nfocus on foreground targets. This raises the question: Is there a method that\ncan automatically aggregate similar objects within scenographic remote sensing\nimages, thereby enabling models to differentiate knowledge embedded in various\ngeospatial patterns for improved feature representation? In this work, we\npresent the Pattern Integration and Enhancement Vision Transformer (PIEViT), a\nnovel self-supervised learning framework designed specifically for remote\nsensing imagery. PIEViT utilizes a teacher-student architecture to address both\nimage-level and patch-level tasks. It employs the Geospatial Pattern Cohesion\n(GPC) module to explore the natural clustering of patches, enhancing the\ndifferentiation of individual features. The Feature Integration Projection\n(FIP) module further refines masked token reconstruction using geospatially\nclustered patches. We validated PIEViT across multiple downstream tasks,\nincluding object detection, semantic segmentation, and change detection.\nExperiments demonstrated that PIEViT enhances the representation of internal\npatch features, providing significant improvements over existing\nself-supervised baselines. It achieves excellent results in object detection,\nland cover classification, and change detection, underscoring its robustness,\ngeneralization, and transferability for remote sensing image interpretation\ntasks.\n","authors":["Kaixuan Lu","Ruiqian Zhang","Xiao Huang","Yuxing Xie","Xiaogang Ning","Hanchao Zhang","Mengke Yuan","Pan Zhang","Tao Wang","Tongkui Liao"],"pdf_url":"https://arxiv.org/pdf/2411.06091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.17443v3","updated":"2024-11-09T06:46:41Z","published":"2024-08-30T17:52:55Z","title":"HERMES: temporal-coHERent long-forM understanding with Episodes and\n  Semantics","summary":"  Existing research often treats long-form videos as extended short videos,\nleading to several limitations: inadequate capture of long-range dependencies,\ninefficient processing of redundant information, and failure to extract\nhigh-level semantic concepts. To address these issues, we propose a novel\napproach that more accurately reflects human cognition. This paper introduces\nHERMES: temporal-coHERent long-forM understanding with Episodes and Semantics,\na model that simulates episodic memory accumulation to capture action sequences\nand reinforces them with semantic knowledge dispersed throughout the video. Our\nwork makes two key contributions: First, we develop an Episodic COmpressor\n(ECO) that efficiently aggregates crucial representations from micro to\nsemi-macro levels, overcoming the challenge of long-range dependencies. Second,\nwe propose a Semantics ReTRiever (SeTR) that enhances these aggregated\nrepresentations with semantic information by focusing on the broader context,\ndramatically reducing feature dimensionality while preserving relevant\nmacro-level information. This addresses the issues of redundancy and lack of\nhigh-level concept extraction. Extensive experiments demonstrate that HERMES\nachieves state-of-the-art performance across multiple long-video understanding\nbenchmarks in both zero-shot and fully-supervised settings.\n","authors":["Gueter Josmy Faure","Jia-Fong Yeh","Min-Hung Chen","Hung-Ting Su","Shang-Hong Lai","Winston H. Hsu"],"pdf_url":"https://arxiv.org/pdf/2408.17443v3.pdf","comment":"This is an improved and expanded version of our EVAL-FoMo Workshop at\n  ECCV'24 (v1 of this paper). Project page:\n  https://joslefaure.github.io/assets/html/hermes.html"},{"id":"http://arxiv.org/abs/2406.07520v2","updated":"2024-11-09T06:23:12Z","published":"2024-06-11T17:50:15Z","title":"Neural Gaffer: Relighting Any Object via Diffusion","summary":"  Single-image relighting is a challenging task that involves reasoning about\nthe complex interplay between geometry, materials, and lighting. Many prior\nmethods either support only specific categories of images, such as portraits,\nor require special capture conditions, like using a flashlight. Alternatively,\nsome methods explicitly decompose a scene into intrinsic components, such as\nnormals and BRDFs, which can be inaccurate or under-expressive. In this work,\nwe propose a novel end-to-end 2D relighting diffusion model, called Neural\nGaffer, that takes a single image of any object and can synthesize an accurate,\nhigh-quality relit image under any novel environmental lighting condition,\nsimply by conditioning an image generator on a target environment map, without\nan explicit scene decomposition. Our method builds on a pre-trained diffusion\nmodel, and fine-tunes it on a synthetic relighting dataset, revealing and\nharnessing the inherent understanding of lighting present in the diffusion\nmodel. We evaluate our model on both synthetic and in-the-wild Internet imagery\nand demonstrate its advantages in terms of generalization and accuracy.\nMoreover, by combining with other generative methods, our model enables many\ndownstream 2D tasks, such as text-based relighting and object insertion. Our\nmodel can also operate as a strong relighting prior for 3D tasks, such as\nrelighting a radiance field.\n","authors":["Haian Jin","Yuan Li","Fujun Luan","Yuanbo Xiangli","Sai Bi","Kai Zhang","Zexiang Xu","Jin Sun","Noah Snavely"],"pdf_url":"https://arxiv.org/pdf/2406.07520v2.pdf","comment":"Project Website: https://neural-gaffer.github.io"},{"id":"http://arxiv.org/abs/2404.00785v3","updated":"2024-11-09T05:55:34Z","published":"2024-03-31T20:08:23Z","title":"Disentangling Hippocampal Shape Variations: A Study of Neurological\n  Disorders Using Mesh Variational Autoencoder with Contrastive Learning","summary":"  This paper presents a comprehensive study focused on disentangling\nhippocampal shape variations from diffusion tensor imaging (DTI) datasets\nwithin the context of neurological disorders. Leveraging a Mesh Variational\nAutoencoder (VAE) enhanced with Supervised Contrastive Learning, our approach\naims to improve interpretability by disentangling two distinct latent variables\ncorresponding to age and the presence of diseases. In our ablation study, we\ninvestigate a range of VAE architectures and contrastive loss functions,\nshowcasing the enhanced disentanglement capabilities of our approach. This\nevaluation uses synthetic 3D torus mesh data and real 3D hippocampal mesh\ndatasets derived from the DTI hippocampal dataset. Our supervised\ndisentanglement model outperforms several state-of-the-art (SOTA) methods like\nattribute and guided VAEs in terms of disentanglement scores. Our model\ndistinguishes between age groups and disease status in patients with Multiple\nSclerosis (MS) using the hippocampus data. Our Mesh VAE with Supervised\nContrastive Learning shows the volume changes of the hippocampus of MS\npopulations at different ages, and the result is consistent with the current\nneuroimaging literature. This research provides valuable insights into the\nrelationship between neurological disorder and hippocampal shape changes in\ndifferent age groups of MS populations using a Mesh VAE with Supervised\nContrastive loss. Our code is available at\nhttps://github.com/Jakaria08/Explaining_Shape_Variability\n","authors":["Jakaria Rabbi","Johannes Kiechle","Christian Beaulieu","Nilanjan Ray","Dana Cobzas"],"pdf_url":"https://arxiv.org/pdf/2404.00785v3.pdf","comment":"Length: 26 pages and Accepted for publication in the Journal of\n  Machine Learning for Biomedical Imaging (MELBA)\n  https://melba-journal.org/2024:030"},{"id":"http://arxiv.org/abs/2411.06074v1","updated":"2024-11-09T05:31:56Z","published":"2024-11-09T05:31:56Z","title":"Aquila: A Hierarchically Aligned Visual-Language Model for Enhanced\n  Remote Sensing Image Comprehension","summary":"  Recently, large vision language models (VLMs) have made significant strides\nin visual language capabilities through visual instruction tuning, showing\ngreat promise in the field of remote sensing image interpretation. However,\nexisting remote sensing vision language models (RSVLMs) often fall short in\ncapturing the complex characteristics of remote sensing scenes, as they\ntypically rely on low resolution, single scale visual features and simplistic\nmethods to map visual features to language features. In this paper, we present\nAquila, an advanced visual language foundation model designed to enable richer\nvisual feature representation and more precise visual-language feature\nalignment for remote sensing images. Our approach introduces a learnable\nHierarchical Spatial Feature Integration (SFI) module that supports high\nresolution image inputs and aggregates multi scale visual features, allowing\nfor the detailed representation of complex visual information. Additionally,\nthe SFI module is repeatedly integrated into the layers of the large language\nmodel (LLM) to achieve deep visual language feature alignment, without\ncompromising the model's performance in natural language processing tasks.\nThese innovations, capturing detailed visual effects through higher resolution\nand multi scale input, and enhancing feature alignment significantly improve\nthe model's ability to learn from image text data. We validate the\neffectiveness of Aquila through extensive quantitative experiments and\nqualitative analyses, demonstrating its superior performance.\n","authors":["Kaixuan Lu","Ruiqian Zhang","Xiao Huang","Yuxing Xie"],"pdf_url":"https://arxiv.org/pdf/2411.06074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06071v1","updated":"2024-11-09T05:22:13Z","published":"2024-11-09T05:22:13Z","title":"GlocalCLIP: Object-agnostic Global-Local Prompt Learning for Zero-shot\n  Anomaly Detection","summary":"  Zero-shot anomaly detection (ZSAD) is crucial for detecting abnormal patterns\nin target datasets without using training samples, specifically in scenarios\nwhere there are distributional differences between the target domain and\ntraining data or where data scarcity arises because of restricted access.\nAlthough recently pretrained vision-language models demonstrate strong\nzero-shot performance across various visual tasks, they focus on learning class\nsemantics, which makes their direct application to ZSAD challenging. To address\nthis scenario, we propose GlocalCLIP, which uniquely separates global and local\nprompts and jointly optimizes them. This approach enables the object-agnostic\nglocal semantic prompt design to effectively capture general normal and\nanomalous patterns without dependency on specific objects in the image. We\nrefine the text prompts for more precise adjustments by utilizing deep-text\nprompt tuning in the text encoder. In the vision encoder, we apply V-V\nattention layers to capture detailed local image features. Finally, we\nintroduce glocal contrastive learning to improve the complementary learning of\nglobal and local prompts, effectively detecting abnormal patterns across\nvarious domains. The generalization performance of GlocalCLIP in ZSAD was\ndemonstrated on 15 real-world datasets from both the industrial and medical\ndomains, achieving superior performance compared to existing methods.\n","authors":["Jiyul Ham","Yonggon Jung","Jun-Geol Baek"],"pdf_url":"https://arxiv.org/pdf/2411.06071v1.pdf","comment":"28 pages, 33 figures"},{"id":"http://arxiv.org/abs/2411.06067v1","updated":"2024-11-09T04:51:17Z","published":"2024-11-09T04:51:17Z","title":"AI-Driven Stylization of 3D Environments","summary":"  In this system, we discuss methods to stylize a scene of 3D primitive objects\ninto a higher fidelity 3D scene using novel 3D representations like NeRFs and\n3D Gaussian Splatting. Our approach leverages existing image stylization\nsystems and image-to-3D generative models to create a pipeline that iteratively\nstylizes and composites 3D objects into scenes. We show our results on adding\ngenerated objects into a scene and discuss limitations.\n","authors":["Yuanbo Chen","Yixiao Kang","Yukun Song","Cyrus Vachha","Sining Huang"],"pdf_url":"https://arxiv.org/pdf/2411.06067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06048v1","updated":"2024-11-09T03:07:33Z","published":"2024-11-09T03:07:33Z","title":"An Empirical Analysis on Spatial Reasoning Capabilities of Large\n  Multimodal Models","summary":"  Large Multimodal Models (LMMs) have achieved strong performance across a\nrange of vision and language tasks. However, their spatial reasoning\ncapabilities are under-investigated. In this paper, we construct a novel VQA\ndataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and\nreasoning capabilities. Our analyses on object-relationship and multi-hop\nreasoning reveal several important findings. Firstly, bounding boxes and scene\ngraphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.\nSecondly, LMMs struggle more with questions posed from the human perspective\nthan the camera perspective about the image. Thirdly, chain of thought (CoT)\nprompting does not improve model performance on complex multi-hop questions\ninvolving spatial relations. % Moreover, spatial reasoning steps are much less\naccurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis\non GQA-spatial reveals that LMMs are much stronger at basic object detection\nthan complex spatial reasoning. We believe our benchmark dataset and in-depth\nanalyses can spark further research on LMMs spatial reasoning. Spatial-MM\nbenchmark is available at: https://github.com/FatemehShiri/Spatial-MM\n","authors":["Fatemeh Shiri","Xiao-Yu Guo","Mona Golestan Far","Xin Yu","Gholamreza Haffari","Yuan-Fang Li"],"pdf_url":"https://arxiv.org/pdf/2411.06048v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01412v5","updated":"2024-11-09T02:41:02Z","published":"2023-10-02T17:59:52Z","title":"DriveGPT4: Interpretable End-to-end Autonomous Driving via Large\n  Language Model","summary":"  Multimodal large language models (MLLMs) have emerged as a prominent area of\ninterest within the research community, given their proficiency in handling and\nreasoning with non-textual data, including images and videos. This study seeks\nto extend the application of MLLMs to the realm of autonomous driving by\nintroducing DriveGPT4, a novel interpretable end-to-end autonomous driving\nsystem based on LLMs. Capable of processing multi-frame video inputs and\ntextual queries, DriveGPT4 facilitates the interpretation of vehicle actions,\noffers pertinent reasoning, and effectively addresses a diverse range of\nquestions posed by users. Furthermore, DriveGPT4 predicts low-level vehicle\ncontrol signals in an end-to-end fashion.These advanced capabilities are\nachieved through the utilization of a bespoke visual instruction tuning\ndataset, specifically tailored for autonomous driving applications, in\nconjunction with a mix-finetuning training strategy. DriveGPT4 represents the\npioneering effort to leverage LLMs for the development of an interpretable\nend-to-end autonomous driving solution. Evaluations conducted on the BDD-X\ndataset showcase the superior qualitative and quantitative performance of\nDriveGPT4. Additionally, the fine-tuning of domain-specific data enables\nDriveGPT4 to yield close or even improved results in terms of autonomous\ndriving grounding when contrasted with GPT4-V.\n","authors":["Zhenhua Xu","Yujia Zhang","Enze Xie","Zhen Zhao","Yong Guo","Kwan-Yee. K. Wong","Zhenguo Li","Hengshuang Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.01412v5.pdf","comment":"Accepted by RA-L. The project page is available at\n  https://tonyxuqaq.github.io/projects/DriveGPT4/"}]},"2024-11-12T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2411.08037v1","updated":"2024-11-12T18:59:59Z","published":"2024-11-12T18:59:59Z","title":"Material Transforms from Disentangled NeRF Representations","summary":"  In this paper, we first propose a novel method for transferring material\ntransformations across different scenes. Building on disentangled Neural\nRadiance Field (NeRF) representations, our approach learns to map Bidirectional\nReflectance Distribution Functions (BRDF) from pairs of scenes observed in\nvarying conditions, such as dry and wet. The learned transformations can then\nbe applied to unseen scenes with similar materials, therefore effectively\nrendering the transformation learned with an arbitrary level of intensity.\nExtensive experiments on synthetic scenes and real-world objects validate the\neffectiveness of our approach, showing that it can learn various\ntransformations such as wetness, painting, coating, etc. Our results highlight\nnot only the versatility of our method but also its potential for practical\napplications in computer graphics. We publish our method implementation, along\nwith our synthetic/real datasets on\nhttps://github.com/astra-vision/BRDFTransform\n","authors":["Ivan Lopes","Jean-François Lalonde","Raoul de Charette"],"pdf_url":"https://arxiv.org/pdf/2411.08037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08034v1","updated":"2024-11-12T18:59:35Z","published":"2024-11-12T18:59:35Z","title":"Scaling Properties of Diffusion Models for Perceptual Tasks","summary":"  In this paper, we argue that iterative computation with diffusion models\noffers a powerful paradigm for not only generation but also visual perception\ntasks. We unify tasks such as depth estimation, optical flow, and segmentation\nunder image-to-image translation, and show how diffusion models benefit from\nscaling training and test-time compute for these perception tasks. Through a\ncareful analysis of these scaling behaviors, we present various techniques to\nefficiently train diffusion models for visual perception tasks. Our models\nachieve improved or comparable performance to state-of-the-art methods using\nsignificantly less data and compute. To use our code and models, see\nhttps://scaling-diffusion-perception.github.io .\n","authors":["Rahul Ravishankar","Zeeshan Patel","Jathushan Rajasegaran","Jitendra Malik"],"pdf_url":"https://arxiv.org/pdf/2411.08034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08033v1","updated":"2024-11-12T18:59:32Z","published":"2024-11-12T18:59:32Z","title":"GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D\n  Generation","summary":"  While 3D content generation has advanced significantly, existing methods\nstill face challenges with input formats, latent space design, and output\nrepresentations. This paper introduces a novel 3D generation framework that\naddresses these challenges, offering scalable, high-quality 3D generation with\nan interactive Point Cloud-structured Latent space. Our framework employs a\nVariational Autoencoder (VAE) with multi-view posed RGB-D(epth)-N(ormal)\nrenderings as input, using a unique latent space design that preserves 3D shape\ninformation, and incorporates a cascaded latent diffusion model for improved\nshape-texture disentanglement. The proposed method, GaussianAnything, supports\nmulti-modal conditional 3D generation, allowing for point cloud, caption, and\nsingle/multi-view image inputs. Notably, the newly proposed latent space\nnaturally enables geometry-texture disentanglement, thus allowing 3D-aware\nediting. Experimental results demonstrate the effectiveness of our approach on\nmultiple datasets, outperforming existing methods in both text- and\nimage-conditioned 3D generation.\n","authors":["Yushi Lan","Shangchen Zhou","Zhaoyang Lyu","Fangzhou Hong","Shuai Yang","Bo Dai","Xingang Pan","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2411.08033v1.pdf","comment":"project page: https://nirvanalan.github.io/projects/GA/"},{"id":"http://arxiv.org/abs/2411.08027v1","updated":"2024-11-12T18:56:58Z","published":"2024-11-12T18:56:58Z","title":"LLMPhy: Complex Physical Reasoning Using Large Language Models and World\n  Models","summary":"  Physical reasoning is an important skill needed for robotic agents when\noperating in the real world. However, solving such reasoning problems often\ninvolves hypothesizing and reflecting over complex multi-body interactions\nunder the effect of a multitude of physical forces and thus learning all such\ninteractions poses a significant hurdle for state-of-the-art machine learning\nframeworks, including large language models (LLMs). To study this problem, we\npropose a new physical reasoning task and a dataset, dubbed TraySim. Our task\ninvolves predicting the dynamics of several objects on a tray that is given an\nexternal impact -- the domino effect of the ensued object interactions and\ntheir dynamics thus offering a challenging yet controlled setup, with the goal\nof reasoning being to infer the stability of the objects after the impact. To\nsolve this complex physical reasoning task, we present LLMPhy, a zero-shot\nblack-box optimization framework that leverages the physics knowledge and\nprogram synthesis abilities of LLMs, and synergizes these abilities with the\nworld models built into modern physics engines. Specifically, LLMPhy uses an\nLLM to generate code to iteratively estimate the physical hyperparameters of\nthe system (friction, damping, layout, etc.) via an implicit\nanalysis-by-synthesis approach using a (non-differentiable) simulator in the\nloop and uses the inferred parameters to imagine the dynamics of the scene\ntowards solving the reasoning task. To show the effectiveness of LLMPhy, we\npresent experiments on our TraySim dataset to predict the steady-state poses of\nthe objects. Our results show that the combination of the LLM and the physics\nengine leads to state-of-the-art zero-shot physical reasoning performance,\nwhile demonstrating superior convergence against standard black-box\noptimization methods and better estimation of the physical parameters.\n","authors":["Anoop Cherian","Radu Corcodel","Siddarth Jain","Diego Romeres"],"pdf_url":"https://arxiv.org/pdf/2411.08027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17245v6","updated":"2024-11-12T18:50:19Z","published":"2023-11-28T21:39:20Z","title":"LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and\n  200+ FPS","summary":"  Recent advances in real-time neural rendering using point-based techniques\nhave enabled broader adoption of 3D representations. However, foundational\napproaches like 3D Gaussian Splatting impose substantial storage overhead, as\nStructure-from-Motion (SfM) points can grow to millions, often requiring\ngigabyte-level disk space for a single unbounded scene. This growth presents\nscalability challenges and hinders splatting efficiency. To address this, we\nintroduce LightGaussian, a method for transforming 3D Gaussians into a more\ncompact format. Inspired by Network Pruning, LightGaussian identifies Gaussians\nwith minimal global significance on scene reconstruction, and applies a pruning\nand recovery process to reduce redundancy while preserving visual quality.\nKnowledge distillation and pseudo-view augmentation then transfer spherical\nharmonic coefficients to a lower degree, yielding compact representations.\nGaussian Vector Quantization, based on each Gaussian's global significance,\nfurther lowers bitwidth with minimal accuracy loss. LightGaussian achieves an\naverage 15x compression rate while boosting FPS from 144 to 237 within the\n3D-GS framework, enabling efficient complex scene representation on the\nMip-NeRF 360 and Tank & Temple datasets. The proposed Gaussian pruning approach\nis also adaptable to other 3D representations (e.g., Scaffold-GS),\ndemonstrating strong generalization capabilities.\n","authors":["Zhiwen Fan","Kevin Wang","Kairun Wen","Zehao Zhu","Dejia Xu","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2311.17245v6.pdf","comment":"NeurIPS 2024, Project page: https://lightgaussian.github.io/"},{"id":"http://arxiv.org/abs/2411.08017v1","updated":"2024-11-12T18:49:06Z","published":"2024-11-12T18:49:06Z","title":"Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model\n  with Compact Wavelet Encodings","summary":"  Large-scale 3D generative models require substantial computational resources\nyet often fall short in capturing fine details and complex geometries at high\nresolutions. We attribute this limitation to the inefficiency of current\nrepresentations, which lack the compactness required to model the generative\nmodels effectively. To address this, we introduce a novel approach called\nWavelet Latent Diffusion, or WaLa, that encodes 3D shapes into wavelet-based,\ncompact latent encodings. Specifically, we compress a $256^3$ signed distance\nfield into a $12^3 \\times 4$ latent grid, achieving an impressive 2427x\ncompression ratio with minimal loss of detail. This high level of compression\nallows our method to efficiently train large-scale generative networks without\nincreasing the inference time. Our models, both conditional and unconditional,\ncontain approximately one billion parameters and successfully generate\nhigh-quality 3D shapes at $256^3$ resolution. Moreover, WaLa offers rapid\ninference, producing shapes within two to four seconds depending on the\ncondition, despite the model's scale. We demonstrate state-of-the-art\nperformance across multiple datasets, with significant improvements in\ngeneration quality, diversity, and computational efficiency. We open-source our\ncode and, to the best of our knowledge, release the largest pretrained 3D\ngenerative models across different modalities.\n","authors":["Aditya Sanghi","Aliasghar Khani","Pradyumna Reddy","Arianna Rampini","Derek Cheung","Kamal Rahimi Malekshan","Kanika Madan","Hooman Shayani"],"pdf_url":"https://arxiv.org/pdf/2411.08017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20099v2","updated":"2024-11-12T18:46:33Z","published":"2024-06-28T17:59:51Z","title":"Odd-One-Out: Anomaly Detection by Comparing with Neighbors","summary":"  This paper introduces a novel anomaly detection (AD) problem that focuses on\nidentifying `odd-looking' objects relative to the other instances in a given\nscene. In contrast to the traditional AD benchmarks, anomalies in our task are\nscene-specific, defined by the regular instances that make up the majority.\nSince object instances may be only partly visible from a single viewpoint, our\nsetting employs multiple views of each scene as input. To provide a testbed for\nfuture research in this task, we introduce two benchmarks, ToysAD-8K and\nPartsAD-15K. We propose a novel method that constructs 3D object-centric\nrepresentations from multiple 2D views for each instance and detects the\nanomalous ones through a cross-instance comparison. We rigorously analyze our\nmethod quantitatively and qualitatively on the presented benchmarks.\n","authors":["Ankan Bhunia","Changjian Li","Hakan Bilen"],"pdf_url":"https://arxiv.org/pdf/2406.20099v2.pdf","comment":"Codes & Dataset at https://github.com/VICO-UoE/OddOneOutAD"},{"id":"http://arxiv.org/abs/2411.08014v1","updated":"2024-11-12T18:44:13Z","published":"2024-11-12T18:44:13Z","title":"Artistic Neural Style Transfer Algorithms with Activation Smoothing","summary":"  The works of Gatys et al. demonstrated the capability of Convolutional Neural\nNetworks (CNNs) in creating artistic style images. This process of transferring\ncontent images in different styles is called Neural Style Transfer (NST). In\nthis paper, we re-implement image-based NST, fast NST, and arbitrary NST. We\nalso explore to utilize ResNet with activation smoothing in NST. Extensive\nexperimental results demonstrate that smoothing transformation can greatly\nimprove the quality of stylization results.\n","authors":["Xiangtian Li","Han Cao","Zhaoyang Zhang","Jiacheng Hu","Yuhui Jin","Zihao Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.08014v1.pdf","comment":"8 pages,7 figures"},{"id":"http://arxiv.org/abs/2411.07976v1","updated":"2024-11-12T17:55:39Z","published":"2024-11-12T17:55:39Z","title":"DINO-LG: A Task-Specific DINO Model for Coronary Calcium Scoring","summary":"  Coronary artery disease (CAD), one of the most common cause of mortality in\nthe world. Coronary artery calcium (CAC) scoring using computed tomography (CT)\nis key for risk assessment to prevent coronary disease. Previous studies on\nrisk assessment and calcification detection in CT scans primarily use\napproaches based on UNET architecture, frequently implemented on pre-built\nmodels. However, these models are limited by the availability of annotated CT\nscans containing CAC and suffering from imbalanced dataset, decreasing\nperformance of CAC segmentation and scoring. In this study, we extend this\napproach by incorporating the self-supervised learning (SSL) technique of DINO\n(self-distillation with no labels) to eliminate limitations of scarce annotated\ndata in CT scans. The DINO model's ability to train without requiring CAC area\nannotations enhances its robustness in generating distinct features. The DINO\nmodel is trained on to focus specifically on calcified areas by using labels,\naiming to generate features that effectively capture and highlight key\ncharacteristics. The label-guided DINO (DINO-LG) enhances classification by\ndistinguishing CT slices that contain calcification from those that do not,\nperforming 57% better than the standard DINO model in this task. CAC scoring\nand segmentation tasks are performed by a basic U-NET architecture, fed\nspecifically with CT slices containing calcified areas as identified by the\nDINO-LG model. This targeted identification performed by DINO-LG model improves\nCAC segmentation performance by approximately 10% and significant increase in\nCAC scoring accuracy.\n","authors":["Mahmut S. Gokmen","Cody Bumgardner","Caner Ozcan"],"pdf_url":"https://arxiv.org/pdf/2411.07976v1.pdf","comment":"Developed by Center for Applied Artificial Intelligence (CAAI),\n  University of Kentucky"},{"id":"http://arxiv.org/abs/2411.07975v1","updated":"2024-11-12T17:55:10Z","published":"2024-11-12T17:55:10Z","title":"JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified\n  Multimodal Understanding and Generation","summary":"  We present JanusFlow, a powerful framework that unifies image understanding\nand generation in a single model. JanusFlow introduces a minimalist\narchitecture that integrates autoregressive language models with rectified\nflow, a state-of-the-art method in generative modeling. Our key finding\ndemonstrates that rectified flow can be straightforwardly trained within the\nlarge language model framework, eliminating the need for complex architectural\nmodifications. To further improve the performance of our unified model, we\nadopt two key strategies: (i) decoupling the understanding and generation\nencoders, and (ii) aligning their representations during unified training.\nExtensive experiments show that JanusFlow achieves comparable or superior\nperformance to specialized models in their respective domains, while\nsignificantly outperforming existing unified approaches across standard\nbenchmarks. This work represents a step toward more efficient and versatile\nvision-language models.\n","authors":["Yiyang Ma","Xingchao Liu","Xiaokang Chen","Wen Liu","Chengyue Wu","Zhiyu Wu","Zizheng Pan","Zhenda Xie","Haowei Zhang","Xingkai yu","Liang Zhao","Yisong Wang","Jiaying Liu","Chong Ruan"],"pdf_url":"https://arxiv.org/pdf/2411.07975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07956v1","updated":"2024-11-12T17:31:51Z","published":"2024-11-12T17:31:51Z","title":"Commissioning An All-Sky Infrared Camera Array for Detection Of Airborne\n  Objects","summary":"  To date there is little publicly available scientific data on Unidentified\nAerial Phenomena (UAP) whose properties and kinematics purportedly reside\noutside the performance envelope of known phenomena. To address this\ndeficiency, the Galileo Project is designing, building, and commissioning a\nmulti-modal ground-based observatory to continuously monitor the sky and\nconduct a rigorous long-term aerial census of all aerial phenomena, including\nnatural and human-made. One of the key instruments is an all-sky infrared\ncamera array using eight uncooled long-wave infrared FLIR Boson 640 cameras.\nTheir calibration includes a novel extrinsic calibration method using airplane\npositions from Automatic Dependent Surveillance-Broadcast (ADS-B) data. We\nestablish a first baseline for the system performance over five months of field\noperation, using a real-world dataset derived from ADS-B data, synthetic 3-D\ntrajectories, and a hand-labelled real-world dataset. We report acceptance\nrates (e.g. viewable airplanes that are recorded) and detection efficiencies\n(e.g. recorded airplanes which are successfully detected) for a variety of\nweather conditions, range and aircraft size. We reconstruct $\\sim$500,000\ntrajectories of aerial objects from this commissioning period. A toy outlier\nsearch focused on large sinuosity of the 2-D reconstructed trajectories flags\nabout 16% of trajectories as outliers. After manual review, 144 trajectories\nremain ambiguous: they are likely mundane objects but cannot be elucidated at\nthis stage of development without distance and kinematics estimation or other\nsensor modalities. Our observed count of ambiguous outliers combined with\nsystematic uncertainties yields an upper limit of 18,271 outliers count for the\nfive-month interval at a 95% confidence level. This likelihood-based method to\nevaluate significance is applicable to all of our future outlier searches.\n","authors":["Laura Dominé","Ankit Biswas","Richard Cloete","Alex Delacroix","Andriy Fedorenko","Lucas Jacaruso","Ezra Kelderman","Eric Keto","Sarah Little","Abraham Loeb","Eric Masson","Mike Prior","Forrest Schultz","Matthew Szenher","Wes Watters","Abby White"],"pdf_url":"https://arxiv.org/pdf/2411.07956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07945v1","updated":"2024-11-12T17:17:33Z","published":"2024-11-12T17:17:33Z","title":"SimBase: A Simple Baseline for Temporal Video Grounding","summary":"  This paper presents SimBase, a simple yet effective baseline for temporal\nvideo grounding. While recent advances in temporal grounding have led to\nimpressive performance, they have also driven network architectures toward\ngreater complexity, with a range of methods to (1) capture temporal\nrelationships and (2) achieve effective multimodal fusion. In contrast, this\npaper explores the question: How effective can a simplified approach be? To\ninvestigate, we design SimBase, a network that leverages lightweight,\none-dimensional temporal convolutional layers instead of complex temporal\nstructures. For cross-modal interaction, SimBase only employs an element-wise\nproduct instead of intricate multimodal fusion. Remarkably, SimBase achieves\nstate-of-the-art results on two large-scale datasets. As a simple yet powerful\nbaseline, we hope SimBase will spark new ideas and streamline future\nevaluations in temporal video grounding.\n","authors":["Peijun Bao","Alex C. Kot"],"pdf_url":"https://arxiv.org/pdf/2411.07945v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2411.07941v1","updated":"2024-11-12T17:11:18Z","published":"2024-11-12T17:11:18Z","title":"DuoLift-GAN:Reconstructing CT from Single-view and Biplanar X-Rays with\n  Generative Adversarial Networks","summary":"  Computed tomography (CT) provides highly detailed three-dimensional (3D)\nmedical images but is costly, time-consuming, and often inaccessible in\nintraoperative settings (Organization et al. 2011). Recent advancements have\nexplored reconstructing 3D chest volumes from sparse 2D X-rays, such as\nsingle-view or orthogonal double-view images. However, current models tend to\nprocess 2D images in a planar manner, prioritizing visual realism over\nstructural accuracy. In this work, we introduce DuoLift Generative Adversarial\nNetworks (DuoLift-GAN), a novel architecture with dual branches that\nindependently elevate 2D images and their features into 3D representations.\nThese 3D outputs are merged into a unified 3D feature map and decoded into a\ncomplete 3D chest volume, enabling richer 3D information capture. We also\npresent a masked loss function that directs reconstruction towards critical\nanatomical regions, improving structural accuracy and visual quality. This\npaper demonstrates that DuoLift-GAN significantly enhances reconstruction\naccuracy while achieving superior visual realism compared to existing methods.\n","authors":["Zhaoxi Zhang","Yueliang Ying"],"pdf_url":"https://arxiv.org/pdf/2411.07941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07940v1","updated":"2024-11-12T17:09:20Z","published":"2024-11-12T17:09:20Z","title":"Automatic dataset shift identification to support root cause analysis of\n  AI performance drift","summary":"  Shifts in data distribution can substantially harm the performance of\nclinical AI models. Hence, various methods have been developed to detect the\npresence of such shifts at deployment time. However, root causes of dataset\nshifts are varied, and the choice of shift mitigation strategies is highly\ndependent on the precise type of shift encountered at test time. As such,\ndetecting test-time dataset shift is not sufficient: precisely identifying\nwhich type of shift has occurred is critical. In this work, we propose the\nfirst unsupervised dataset shift identification framework, effectively\ndistinguishing between prevalence shift (caused by a change in the label\ndistribution), covariate shift (caused by a change in input characteristics)\nand mixed shifts (simultaneous prevalence and covariate shifts). We discuss the\nimportance of self-supervised encoders for detecting subtle covariate shifts\nand propose a novel shift detector leveraging both self-supervised encoders and\ntask model outputs for improved shift detection. We report promising results\nfor the proposed shift identification framework across three different imaging\nmodalities (chest radiography, digital mammography, and retinal fundus images)\non five types of real-world dataset shifts, using four large publicly available\ndatasets.\n","authors":["Mélanie Roschewitz","Raghav Mehta","Charles Jones","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2411.07940v1.pdf","comment":"Code available at\n  https://github.com/biomedia-mira/shift_identification"},{"id":"http://arxiv.org/abs/2411.07936v1","updated":"2024-11-12T17:05:18Z","published":"2024-11-12T17:05:18Z","title":"Learning Disentangled Representations for Perceptual Point Cloud Quality\n  Assessment via Mutual Information Minimization","summary":"  No-Reference Point Cloud Quality Assessment (NR-PCQA) aims to objectively\nassess the human perceptual quality of point clouds without relying on\npristine-quality point clouds for reference. It is becoming increasingly\nsignificant with the rapid advancement of immersive media applications such as\nvirtual reality (VR) and augmented reality (AR). However, current NR-PCQA\nmodels attempt to indiscriminately learn point cloud content and distortion\nrepresentations within a single network, overlooking their distinct\ncontributions to quality information. To address this issue, we propose DisPA,\na novel disentangled representation learning framework for NR-PCQA. The\nframework trains a dual-branch disentanglement network to minimize mutual\ninformation (MI) between representations of point cloud content and distortion.\nSpecifically, to fully disentangle representations, the two branches adopt\ndifferent philosophies: the content-aware encoder is pretrained by a masked\nauto-encoding strategy, which can allow the encoder to capture semantic\ninformation from rendered images of distorted point clouds; the\ndistortion-aware encoder takes a mini-patch map as input, which forces the\nencoder to focus on low-level distortion patterns. Furthermore, we utilize an\nMI estimator to estimate the tight upper bound of the actual MI and further\nminimize it to achieve explicit representation disentanglement. Extensive\nexperimental results demonstrate that DisPA outperforms state-of-the-art\nmethods on multiple PCQA datasets.\n","authors":["Ziyu Shan","Yujie Zhang","Yipeng Liu","Yiling Xu"],"pdf_url":"https://arxiv.org/pdf/2411.07936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07918v1","updated":"2024-11-12T16:50:13Z","published":"2024-11-12T16:50:13Z","title":"Isometric Transformations for Image Augmentation in Mueller Matrix\n  Polarimetry","summary":"  Mueller matrix polarimetry captures essential information about polarized\nlight interactions with a sample, presenting unique challenges for data\naugmentation in deep learning due to its distinct structure. While\naugmentations are an effective and affordable way to enhance dataset diversity\nand reduce overfitting, standard transformations like rotations and flips do\nnot preserve the polarization properties in Mueller matrix images. To this end,\nwe introduce a versatile simulation framework that applies physically\nconsistent rotations and flips to Mueller matrices, tailored to maintain\npolarization fidelity. Our experimental results across multiple datasets reveal\nthat conventional augmentations can lead to misleading results when applied to\npolarimetric data, underscoring the necessity of our physics-based approach. In\nour experiments, we first compare our polarization-specific augmentations\nagainst real-world captures to validate their physical consistency. We then\napply these augmentations in a semantic segmentation task, achieving\nsubstantial improvements in model generalization and performance. This study\nunderscores the necessity of physics-informed data augmentation for\npolarimetric imaging in deep learning (DL), paving the way for broader adoption\nand more robust applications across diverse research in the field. In\nparticular, our framework unlocks the potential of DL models for polarimetric\ndatasets with limited sample sizes. Our code implementation is available at\ngithub.com/hahnec/polar_augment.\n","authors":["Christopher Hahne","Omar Rodriguez-Nunez","Éléa Gros","Théotim Lucas","Ekkehard Hewer","Tatiana Novikova","Theoni Maragkou","Philippe Schucht","Richard McKinley"],"pdf_url":"https://arxiv.org/pdf/2411.07918v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2411.05747v3","updated":"2024-11-12T16:42:02Z","published":"2024-11-08T18:08:33Z","title":"WavShadow: Wavelet Based Shadow Segmentation and Removal","summary":"  Shadow removal and segmentation remain challenging tasks in computer vision,\nparticularly in complex real world scenarios. This study presents a novel\napproach that enhances the ShadowFormer model by incorporating Masked\nAutoencoder (MAE) priors and Fast Fourier Convolution (FFC) blocks, leading to\nsignificantly faster convergence and improved performance. We introduce key\ninnovations: (1) integration of MAE priors trained on Places2 dataset for\nbetter context understanding, (2) adoption of Haar wavelet features for\nenhanced edge detection and multiscale analysis, and (3) implementation of a\nmodified SAM Adapter for robust shadow segmentation. Extensive experiments on\nthe challenging DESOBA dataset demonstrate that our approach achieves state of\nthe art results, with notable improvements in both convergence speed and shadow\nremoval quality.\n","authors":["Shreyans Jain","Viraj Vekaria","Karan Gandhi","Aadya Arora"],"pdf_url":"https://arxiv.org/pdf/2411.05747v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.07155v2","updated":"2024-11-12T16:39:29Z","published":"2024-05-12T04:18:10Z","title":"Meta-Learned Modality-Weighted Knowledge Distillation for Robust\n  Multi-Modal Learning with Missing Data","summary":"  In multi-modal learning, some modalities are more influential than others,\nand their absence can have a significant impact on classification/segmentation\naccuracy. Addressing this challenge, we propose a novel approach called\nMeta-learned Modality-weighted Knowledge Distillation (MetaKD), which enables\nmulti-modal models to maintain high accuracy even when key modalities are\nmissing. MetaKD adaptively estimates the importance weight of each modality\nthrough a meta-learning process. These learned importance weights guide a\npairwise modality-weighted knowledge distillation process, allowing\nhigh-importance modalities to transfer knowledge to lower-importance ones,\nresulting in robust performance despite missing inputs. Unlike previous methods\nin the field, which are often task-specific and require significant\nmodifications, our approach is designed to work in multiple tasks (e.g.,\nsegmentation and classification) with minimal adaptation. Experimental results\non five prevalent datasets, including three Brain Tumor Segmentation datasets\n(BraTS2018, BraTS2019 and BraTS2020), the Alzheimer's Disease Neuroimaging\nInitiative (ADNI) classification dataset and the Audiovision-MNIST\nclassification dataset, demonstrate the proposed model is able to outperform\nthe compared models by a large margin.\n","authors":["Hu Wang","Salma Hassan","Yuyuan Liu","Congbo Ma","Yuanhong Chen","Yutong Xie","Mostafa Salem","Yu Tian","Jodie Avery","Louise Hull","Ian Reid","Mohammad Yaqub","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2405.07155v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07901v1","updated":"2024-11-12T16:15:25Z","published":"2024-11-12T16:15:25Z","title":"TLDR: Traffic Light Detection using Fourier Domain Adaptation in Hostile\n  WeatheR","summary":"  The scarcity of comprehensive datasets in the traffic light detection and\nrecognition domain and the poor performance of state-of-the-art models under\nhostile weather conditions present significant challenges. To address these\nissues, this paper proposes a novel approach by merging two widely used\ndatasets, LISA and S2TLD. The merged dataset is further processed to tackle\nclass imbalance, a common problem in this domain. This merged dataset becomes\nour source domain. Synthetic rain and fog are added to the dataset to create\nour target domain. We employ Fourier Domain Adaptation (FDA) to create a final\ndataset with a minimized domain gap between the two datasets, helping the model\ntrained on this final dataset adapt to rainy and foggy weather conditions.\nAdditionally, we explore Semi-Supervised Learning (SSL) techniques to leverage\nthe available data more effectively. Experimental results demonstrate that\nmodels trained on FDA-augmented images outperform those trained without FDA\nacross confidence-dependent and independent metrics, like mAP50, mAP50-95,\nPrecision, and Recall. The best-performing model, YOLOv8, achieved a Precision\nincrease of 5.1860%, Recall increase of 14.8009%, mAP50 increase of 9.5074%,\nand mAP50-95 increase of 19.5035%. On average, percentage increases of 7.6892%\nin Precision, 19.9069% in Recall, 15.8506% in mAP50, and 23.8099% in mAP50-95\nwere observed across all models, highlighting the effectiveness of FDA in\nmitigating the impact of adverse weather conditions on model performance. These\nimprovements pave the way for real-world applications where reliable\nperformance in challenging environmental conditions is critical.\n","authors":["Ishaan Gakhar","Aryesh Guha","Aryaman Gupta","Amit Agarwal","Durga Toshniwal","Ujjwal Verma"],"pdf_url":"https://arxiv.org/pdf/2411.07901v1.pdf","comment":"Under Review at IEEE Transactions of Artificial Intelligence. 10\n  Pages, 7 Figures"},{"id":"http://arxiv.org/abs/2411.07899v1","updated":"2024-11-12T16:12:51Z","published":"2024-11-12T16:12:51Z","title":"Rendering-Oriented 3D Point Cloud Attribute Compression using Sparse\n  Tensor-based Transformer","summary":"  The evolution of 3D visualization techniques has fundamentally transformed\nhow we interact with digital content. At the forefront of this change is point\ncloud technology, offering an immersive experience that surpasses traditional\n2D representations. However, the massive data size of point clouds presents\nsignificant challenges in data compression. Current methods for lossy point\ncloud attribute compression (PCAC) generally focus on reconstructing the\noriginal point clouds with minimal error. However, for point cloud\nvisualization scenarios, the reconstructed point clouds with distortion still\nneed to undergo a complex rendering process, which affects the final\nuser-perceived quality. In this paper, we propose an end-to-end deep learning\nframework that seamlessly integrates PCAC with differentiable rendering,\ndenoted as rendering-oriented PCAC (RO-PCAC), directly targeting the quality of\nrendered multiview images for viewing. In a differentiable manner, the impact\nof the rendering process on the reconstructed point clouds is taken into\naccount. Moreover, we characterize point clouds as sparse tensors and propose a\nsparse tensor-based transformer, called SP-Trans. By aligning with the local\ndensity of the point cloud and utilizing an enhanced local attention mechanism,\nSP-Trans captures the intricate relationships within the point cloud, further\nimproving feature analysis and synthesis within the framework. Extensive\nexperiments demonstrate that the proposed RO-PCAC achieves state-of-the-art\ncompression performance, compared to existing reconstruction-oriented methods,\nincluding traditional, learning-based, and hybrid methods.\n","authors":["Xiao Huo","Junhui Ho","Shuai Wan","Fuzheng Yang"],"pdf_url":"https://arxiv.org/pdf/2411.07899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07893v1","updated":"2024-11-12T15:58:09Z","published":"2024-11-12T15:58:09Z","title":"Joint multi-dimensional dynamic attention and transformer for general\n  image restoration","summary":"  Outdoor images often suffer from severe degradation due to rain, haze, and\nnoise, impairing image quality and challenging high-level tasks. Current image\nrestoration methods struggle to handle complex degradation while maintaining\nefficiency. This paper introduces a novel image restoration architecture that\ncombines multi-dimensional dynamic attention and self-attention within a U-Net\nframework. To leverage the global modeling capabilities of transformers and the\nlocal modeling capabilities of convolutions, we integrate sole CNNs in the\nencoder-decoder and sole transformers in the latent layer. Additionally, we\ndesign convolutional kernels with selected multi-dimensional dynamic attention\nto capture diverse degraded inputs efficiently. A transformer block with\ntransposed self-attention further enhances global feature extraction while\nmaintaining efficiency. Extensive experiments demonstrate that our method\nachieves a better balance between performance and computational complexity\nacross five image restoration tasks: deraining, deblurring, denoising,\ndehazing, and enhancement, as well as superior performance for high-level\nvision tasks. The source code will be available at\nhttps://github.com/House-yuyu/MDDA-former.\n","authors":["Huan Zhang","Xu Zhang","Nian Cai","Jianglei Di","Yun Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07893v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07885v1","updated":"2024-11-12T15:47:17Z","published":"2024-11-12T15:47:17Z","title":"INTRABENCH: Interactive Radiological Benchmark","summary":"  Current interactive segmentation approaches, inspired by the success of\nMETA's Segment Anything model, have achieved notable advancements, however,\nthey come with substantial limitations that hinder their practical application\nin real clinical scenarios. These include unrealistic human interaction\nrequirements, such as slice-by-slice operations for 2D models on 3D data, a\nlack of iterative refinement, and insufficient evaluation experiments. These\nshortcomings prevent accurate assessment of model performance and lead to\ninconsistent outcomes across studies. IntRaBench overcomes these challenges by\noffering a comprehensive and reproducible framework for evaluating interactive\nsegmentation methods in realistic, clinically relevant scenarios. It includes\ndiverse datasets, target structures, and segmentation models, and provides a\nflexible codebase that allows seamless integration of new models and prompting\nstrategies. Additionally, we introduce advanced techniques to minimize\nclinician interaction, ensuring fair comparisons between 2D and 3D models. By\nopen-sourcing IntRaBench, we invite the research community to integrate their\nmodels and prompting techniques, ensuring continuous and transparent evaluation\nof interactive segmentation models in 3D medical imaging.\n","authors":["Constantin Ulrich","Tassilo Wald","Emily Tempus","Maximilian Rokuss","Paul F. Jaeger","Klaus Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2411.07885v1.pdf","comment":"Undergoing Peer-Review"},{"id":"http://arxiv.org/abs/2411.07873v1","updated":"2024-11-12T15:29:50Z","published":"2024-11-12T15:29:50Z","title":"Diverse capability and scaling of diffusion and auto-regressive models\n  when learning abstract rules","summary":"  Humans excel at discovering regular structures from limited samples and\napplying inferred rules to novel settings. We investigate whether modern\ngenerative models can similarly learn underlying rules from finite samples and\nperform reasoning through conditional sampling. Inspired by Raven's Progressive\nMatrices task, we designed GenRAVEN dataset, where each sample consists of\nthree rows, and one of 40 relational rules governing the object position,\nnumber, or attributes applies to all rows. We trained generative models to\nlearn the data distribution, where samples are encoded as integer arrays to\nfocus on rule learning. We compared two generative model families: diffusion\n(EDM, DiT, SiT) and autoregressive models (GPT2, Mamba). We evaluated their\nability to generate structurally consistent samples and perform panel\ncompletion via unconditional and conditional sampling. We found diffusion\nmodels excel at unconditional generation, producing more novel and consistent\nsamples from scratch and memorizing less, but performing less well in panel\ncompletion, even with advanced conditional sampling methods. Conversely,\nautoregressive models excel at completing missing panels in a rule-consistent\nmanner but generate less consistent samples unconditionally. We observe diverse\ndata scaling behaviors: for both model families, rule learning emerges at a\ncertain dataset size - around 1000s examples per rule. With more training data,\ndiffusion models improve both their unconditional and conditional generation\ncapabilities. However, for autoregressive models, while panel completion\nimproves with more training data, unconditional generation consistency\ndeclines. Our findings highlight complementary capabilities and limitations of\ndiffusion and autoregressive models in rule learning and reasoning tasks,\nsuggesting avenues for further research into their mechanisms and potential for\nhuman-like reasoning.\n","authors":["Binxu Wang","Jiaqi Shang","Haim Sompolinsky"],"pdf_url":"https://arxiv.org/pdf/2411.07873v1.pdf","comment":"12 pages, 5 figures. Accepted to NeurIPS2024 Workshop on System 2\n  Reasoning At Scale as long paper"},{"id":"http://arxiv.org/abs/2411.07863v1","updated":"2024-11-12T15:22:14Z","published":"2024-11-12T15:22:14Z","title":"CDXFormer: Boosting Remote Sensing Change Detection with Extended Long\n  Short-Term Memory","summary":"  In complex scenes and varied conditions, effectively integrating\nspatial-temporal context is crucial for accurately identifying changes.\nHowever, current RS-CD methods lack a balanced consideration of performance and\nefficiency. CNNs lack global context, Transformers have quadratic computational\ncomplexity, and Mambas are restricted by CUDA acceleration. In this paper, we\npropose CDXFormer, with a core component that is a powerful XLSTM-based feature\nenhancement layer, integrating the advantages of linear computational\ncomplexity, global context perception, and strong interpret-ability.\nSpecifically, we introduce a scale-specific Feature Enhancer layer,\nincorporating a Cross-Temporal Global Perceptron customized for\nsemantic-accurate deep features, and a Cross-Temporal Spatial Refiner\ncustomized for detail-rich shallow features. Additionally, we propose a\nCross-Scale Interactive Fusion module to progressively interact global change\nrepresentations with spatial responses. Extensive experimental results\ndemonstrate that CDXFormer achieves state-of-the-art performance across three\nbenchmark datasets, offering a compelling balance between efficiency and\naccuracy. Code is available at https://github.com/xwmaxwma/rschange.\n","authors":["Zhenkai Wu","Xiaowen Ma","Rongrong Lian","Zhentao Lin","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04492v4","updated":"2024-11-12T15:16:36Z","published":"2024-10-06T14:11:39Z","title":"Interpret Your Decision: Logical Reasoning Regularization for\n  Generalization in Visual Classification","summary":"  Vision models excel in image classification but struggle to generalize to\nunseen data, such as classifying images from unseen domains or discovering\nnovel categories. In this paper, we explore the relationship between logical\nreasoning and deep learning generalization in visual classification. A logical\nregularization termed L-Reg is derived which bridges a logical analysis\nframework to image classification. Our work reveals that L-Reg reduces the\ncomplexity of the model in terms of the feature distribution and classifier\nweights. Specifically, we unveil the interpretability brought by L-Reg, as it\nenables the model to extract the salient features, such as faces to persons,\nfor classification. Theoretical analysis and experiments demonstrate that L-Reg\nenhances generalization across various scenarios, including multi-domain\ngeneralization and generalized category discovery. In complex real-world\nscenarios where images span unknown classes and unseen domains, L-Reg\nconsistently improves generalization, highlighting its practical efficacy.\n","authors":["Zhaorui Tan","Xi Yang","Qiufeng Wang","Anh Nguyen","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.04492v4.pdf","comment":"Accepted by NeurIPS2024 as Spotlight"},{"id":"http://arxiv.org/abs/2407.06001v2","updated":"2024-11-12T15:14:41Z","published":"2024-07-08T14:53:07Z","title":"Pseudo-triplet Guided Few-shot Composed Image Retrieval","summary":"  Composed Image Retrieval (CIR) is a challenging task that aims to retrieve\nthe target image with a multimodal query, i.e., a reference image, and its\ncomplementary modification text. As previous supervised or zero-shot learning\nparadigms all fail to strike a good trade-off between the model's\ngeneralization ability and retrieval performance, recent researchers have\nintroduced the task of few-shot CIR (FS-CIR) and proposed a textual\ninversion-based network based on pretrained CLIP model to realize it. Despite\nits promising performance, the approach encounters two key limitations: simply\nrelying on the few annotated samples for CIR model training and\nindiscriminately selecting training triplets for CIR model fine-tuning. To\naddress these two limitations, we propose a novel two-stage pseudo triplet\nguided few-shot CIR scheme, dubbed PTG-FSCIR. In the first stage, we propose an\nattentive masking and captioning-based pseudo triplet generation method, to\nconstruct pseudo triplets from pure image data and use them to fulfill the\nCIR-task specific pertaining. In the second stage, we propose a challenging\ntriplet-based CIR fine-tuning method, where we design a pseudo modification\ntext-based sample challenging score estimation strategy and a robust top\nrange-based random sampling strategy for sampling robust challenging triplets\nto promote the model fine-tuning. Notably, our scheme is plug-and-play and\ncompatible with any existing supervised CIR models. We test our scheme across\ntwo backbones on three public datasets (i.e., FashionIQ, CIRR, and\nBirds-to-Words), achieving maximum improvements of 13.3%, 22.2%, and 17.4%\nrespectively, demonstrating our scheme's efficacy.\n","authors":["Bohan Hou","Haoqiang Lin","Haokun Wen","Meng Liu","Mingzhu Xu","Xuemeng Song"],"pdf_url":"https://arxiv.org/pdf/2407.06001v2.pdf","comment":"10pages"},{"id":"http://arxiv.org/abs/2411.07848v1","updated":"2024-11-12T15:01:40Z","published":"2024-11-12T15:01:40Z","title":"NL-SLAM for OC-VLN: Natural Language Grounded SLAM for Object-Centric\n  VLN","summary":"  Landmark-based navigation (e.g. go to the wooden desk) and relative\npositional navigation (e.g. move 5 meters forward) are distinct navigation\nchallenges solved very differently in existing robotics navigation methodology.\nWe present a new dataset, OC-VLN, in order to distinctly evaluate grounding\nobject-centric natural language navigation instructions in a method for\nperforming landmark-based navigation. We also propose Natural Language grounded\nSLAM (NL-SLAM), a method to ground natural language instruction to robot\nobservations and poses. We actively perform NL-SLAM in order to follow\nobject-centric natural language navigation instructions. Our methods leverage\npre-trained vision and language foundation models and require no task-specific\ntraining. We construct two strong baselines from state-of-the-art methods on\nrelated tasks, Object Goal Navigation and Vision Language Navigation, and we\nshow that our approach, NL-SLAM, outperforms these baselines across all our\nmetrics of success on OC-VLN. Finally, we successfully demonstrate the\neffectiveness of NL-SLAM for performing navigation instruction following in the\nreal world on a Boston Dynamics Spot robot.\n","authors":["Sonia Raychaudhuri","Duy Ta","Katrina Ashton","Angel X. Chang","Jiuguang Wang","Bernadette Bucher"],"pdf_url":"https://arxiv.org/pdf/2411.07848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12203v3","updated":"2024-11-12T15:00:37Z","published":"2024-03-18T19:25:57Z","title":"Bootstrapping Reinforcement Learning with Imitation for Vision-Based\n  Agile Flight","summary":"  Learning visuomotor policies for agile quadrotor flight presents significant\ndifficulties, primarily from inefficient policy exploration caused by\nhigh-dimensional visual inputs and the need for precise and low-latency\ncontrol. To address these challenges, we propose a novel approach that combines\nthe performance of Reinforcement Learning (RL) and the sample efficiency of\nImitation Learning (IL) in the task of vision-based autonomous drone racing.\nWhile RL provides a framework for learning high-performance controllers through\ntrial and error, it faces challenges with sample efficiency and computational\ndemands due to the high dimensionality of visual inputs. Conversely, IL\nefficiently learns from visual expert demonstrations, but it remains limited by\nthe expert's performance and state distribution. To overcome these limitations,\nour policy learning framework integrates the strengths of both approaches. Our\nframework contains three phases: training a teacher policy using RL with\nprivileged state information, distilling it into a student policy via IL, and\nadaptive fine-tuning via RL. Testing in both simulated and real-world scenarios\nshows our approach can not only learn in scenarios where RL from scratch fails\nbut also outperforms existing IL methods in both robustness and performance,\nsuccessfully navigating a quadrotor through a race course using only visual\ninformation. Videos of the experiments are available at\nhttps://rpg.ifi.uzh.ch/bootstrap-rl-with-il/index.html.\n","authors":["Jiaxu Xing","Angel Romero","Leonard Bauersfeld","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2403.12203v3.pdf","comment":"8th Annual Conference on Robot Learning (CoRL)"},{"id":"http://arxiv.org/abs/2401.11796v2","updated":"2024-11-12T14:58:37Z","published":"2024-01-22T09:53:20Z","title":"REVEX: A Unified Framework for Removal-Based Explainable Artificial\n  Intelligence in Video","summary":"  We developed REVEX, a removal-based video explanations framework. This work\nextends fine-grained explanation frameworks for computer vision data and adapts\nsix existing techniques to video by adding temporal information and local\nexplanations. The adapted methods were evaluated across networks, datasets,\nimage classes, and evaluation metrics. By decomposing explanation into steps,\nstrengths and weaknesses were revealed in the studied methods, for example, on\npixel clustering and perturbations in the input. Video LIME outperformed other\nmethods with deletion values up to 31\\% lower and insertion up to 30\\% higher,\ndepending on method and network. Video RISE achieved superior performance in\nthe average drop metric, with values 10\\% lower. In contrast,\nlocalization-based metrics revealed low performance across all methods, with\nsignificant variation depending on network. Pointing game accuracy reached\n53\\%, and IoU-based metrics remained below 20\\%. Drawing on the findings across\nXAI methods, we further examine the limitations of the employed XAI evaluation\nmetrics and highlight their suitability in different applications.\n","authors":["F. Xavier Gaya-Morey","Jose M. Buades-Rubio","I. Scott MacKenzie","Cristina Manresa-Yee"],"pdf_url":"https://arxiv.org/pdf/2401.11796v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00002v2","updated":"2024-11-12T14:55:50Z","published":"2024-07-10T15:03:00Z","title":"Transfer Learning for Wildlife Classification: Evaluating YOLOv8 against\n  DenseNet, ResNet, and VGGNet on a Custom Dataset","summary":"  This study evaluates the performance of various deep learning models,\nspecifically DenseNet, ResNet, VGGNet, and YOLOv8, for wildlife species\nclassification on a custom dataset. The dataset comprises 575 images of 23\nendangered species sourced from reputable online repositories. The study\nutilizes transfer learning to fine-tune pre-trained models on the dataset,\nfocusing on reducing training time and enhancing classification accuracy. The\nresults demonstrate that YOLOv8 outperforms other models, achieving a training\naccuracy of 97.39% and a validation F1-score of 96.50%. These findings suggest\nthat YOLOv8, with its advanced architecture and efficient feature extraction\ncapabilities, holds great promise for automating wildlife monitoring and\nconservation efforts.\n","authors":["Subek Sharma","Sisir Dhakal","Mansi Bhavsar"],"pdf_url":"https://arxiv.org/pdf/2408.00002v2.pdf","comment":"This is published in Journal of Artificial Intelligence and Capsule\n  Networks, December 2024, Volume 6, Issue 4, Pages 415-435"},{"id":"http://arxiv.org/abs/2410.20178v2","updated":"2024-11-12T14:45:18Z","published":"2024-10-26T13:19:57Z","title":"LLMs Can Evolve Continually on Modality for X-Modal Reasoning","summary":"  Multimodal Large Language Models (MLLMs) have gained significant attention\ndue to their impressive capabilities in multimodal understanding. However,\nexisting methods rely heavily on extensive modal-specific pretraining and\njoint-modal tuning, leading to significant computational burdens when expanding\nto new modalities. In this paper, we propose PathWeave, a flexible and scalable\nframework with modal-Path sWitching and ExpAnsion abilities that enables MLLMs\nto continually EVolve on modalities for $\\mathbb{X}$-modal reasoning. We\nleverage the concept of Continual Learning and develop an incremental training\nstrategy atop pre-trained MLLMs, enabling their expansion to new modalities\nusing uni-modal data, without executing joint-modal pretraining. In detail, a\nnovel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal and\ncross-modal adapters are seamlessly integrated to facilitate efficient modality\nalignment and collaboration. Additionally, an MoE-based gating module is\napplied between two types of adapters to further enhance the multimodal\ninteraction. To investigate the proposed method, we establish a challenging\nbenchmark called Continual Learning of Modality (MCL), which consists of\nhigh-quality QA data from five distinct modalities: image, video, audio, depth\nand point cloud. Extensive experiments demonstrate the effectiveness of the\nproposed AnA framework on learning plasticity and memory stability during\ncontinual learning. Furthermore, PathWeave performs comparably to\nstate-of-the-art MLLMs while concurrently reducing parameter training burdens\nby 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave\n","authors":["Jiazuo Yu","Haomiao Xiong","Lu Zhang","Haiwen Diao","Yunzhi Zhuge","Lanqing Hong","Dong Wang","Huchuan Lu","You He","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2410.20178v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07834v1","updated":"2024-11-12T14:36:06Z","published":"2024-11-12T14:36:06Z","title":"Towards Vision Mixture of Experts for Wildlife Monitoring on the Edge","summary":"  The explosion of IoT sensors in industrial, consumer and remote sensing use\ncases has come with unprecedented demand for computing infrastructure to\ntransmit and to analyze petabytes of data. Concurrently, the world is slowly\nshifting its focus towards more sustainable computing. For these reasons, there\nhas been a recent effort to reduce the footprint of related computing\ninfrastructure, especially by deep learning algorithms, for advanced insight\ngeneration. The `TinyML' community is actively proposing methods to save\ncommunication bandwidth and excessive cloud storage costs while reducing\nalgorithm inference latency and promoting data privacy. Such proposed\napproaches should ideally process multiple types of data, including time\nseries, audio, satellite images, and video, near the network edge as multiple\ndata streams has been shown to improve the discriminative ability of learning\nalgorithms, especially for generating fine grained results. Incidentally, there\nhas been recent work on data driven conditional computation of subnetworks that\nhas shown real progress in using a single model to share parameters among very\ndifferent types of inputs such as images and text, reducing the computation\nrequirement of multi-tower multimodal networks. Inspired by such line of work,\nwe explore similar per patch conditional computation for the first time for\nmobile vision transformers (vision only case), that will eventually be used for\nsingle-tower multimodal edge models. We evaluate the model on Cornell Sap\nSucker Woods 60, a fine grained bird species discrimination dataset. Our\ninitial experiments uses $4X$ fewer parameters compared to MobileViTV2-1.0 with\na $1$% accuracy drop on the iNaturalist '21 birds test data provided as part of\nthe SSW60 dataset.\n","authors":["Emmanuel Azuh Mensah","Anderson Lee","Haoran Zhang","Yitong Shan","Kurtis Heimerl"],"pdf_url":"https://arxiv.org/pdf/2411.07834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03677v4","updated":"2024-11-12T14:33:36Z","published":"2024-08-07T10:36:26Z","title":"L4DR: LiDAR-4DRadar Fusion for Weather-Robust 3D Object Detection","summary":"  LiDAR-based vision systems are integral for 3D object detection, which is\ncrucial for autonomous navigation. However, they suffer from performance\ndegradation in adverse weather conditions due to the quality deterioration of\nLiDAR point clouds. Fusing LiDAR with the weather-robust 4D radar sensor is\nexpected to solve this problem. However, the fusion of LiDAR and 4D radar is\nchallenging because they differ significantly in terms of data quality and the\ndegree of degradation in adverse weather. To address these issues, we introduce\nL4DR, a weather-robust 3D object detection method that effectively achieves\nLiDAR and 4D Radar fusion. Our L4DR includes Multi-Modal Encoding (MME) and\nForeground-Aware Denoising (FAD) technique to reconcile sensor gaps, which is\nthe first exploration of the complementarity of early fusion between LiDAR and\n4D radar. Additionally, we design an Inter-Modal and Intra-Modal ({IM}2 )\nparallel feature extraction backbone coupled with a Multi-Scale Gated Fusion\n(MSGF) module to counteract the varying degrees of sensor degradation under\nadverse weather conditions. Experimental evaluation on a VoD dataset with\nsimulated fog proves that L4DR is more adaptable to changing weather\nconditions. It delivers a significant performance increase under different fog\nlevels, improving the 3D mAP by up to 20.0% over the traditional LiDAR-only\napproach. Moreover, the results on the K-Radar dataset validate the consistent\nperformance improvement of L4DR in real-world adverse weather conditions.\n","authors":["Xun Huang","Ziyu Xu","Hai Wu","Jinlong Wang","Qiming Xia","Yan Xia","Jonathan Li","Kyle Gao","Chenglu Wen","Cheng Wang"],"pdf_url":"https://arxiv.org/pdf/2408.03677v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.15063v4","updated":"2024-11-12T14:29:09Z","published":"2024-08-27T13:47:31Z","title":"Adapting Segment Anything Model to Multi-modal Salient Object Detection\n  with Semantic Feature Fusion Guidance","summary":"  Although most existing multi-modal salient object detection (SOD) methods\ndemonstrate effectiveness through training models from scratch, the limited\nmulti-modal data hinders these methods from reaching optimality. In this paper,\nwe propose a novel framework to explore and exploit the powerful feature\nrepresentation and zero-shot generalization ability of the pre-trained Segment\nAnything Model (SAM) for multi-modal SOD. Despite serving as a recent vision\nfundamental model, driving the class-agnostic SAM to comprehend and detect\nsalient objects accurately is non-trivial, especially in challenging scenes. To\nthis end, we develop \\underline{SAM} with se\\underline{m}antic\nf\\underline{e}ature fu\\underline{s}ion guidanc\\underline{e} (Sammese), which\nincorporates multi-modal saliency-specific knowledge into SAM to adapt SAM to\nmulti-modal SOD tasks. However, it is difficult for SAM trained on single-modal\ndata to directly mine the complementary benefits of multi-modal inputs and\ncomprehensively utilize them to achieve accurate saliency prediction. To\naddress these issues, we first design a multi-modal complementary fusion module\nto extract robust multi-modal semantic features by integrating information from\nvisible and thermal or depth image pairs. Then, we feed the extracted\nmulti-modal semantic features into both the SAM image encoder and mask decoder\nfor fine-tuning and prompting, respectively. Specifically, in the image\nencoder, a multi-modal adapter is proposed to adapt the single-modal SAM to\nmulti-modal information. In the mask decoder, a semantic-geometric prompt\ngeneration strategy is proposed to produce corresponding embeddings with\nvarious saliency cues. Extensive experiments on both RGB-D and RGB-T SOD\nbenchmarks show the effectiveness of the proposed framework. The code will be\navailable at \\url{https://github.com/Angknpng/Sammese}.\n","authors":["Kunpeng Wang","Danying Lin","Chenglong Li","Zhengzheng Tu","Bin Luo"],"pdf_url":"https://arxiv.org/pdf/2408.15063v4.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.23091v3","updated":"2024-11-12T14:13:17Z","published":"2024-10-30T15:06:44Z","title":"CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for\n  Adversarial Defense","summary":"  Despite ongoing efforts to defend neural classifiers from adversarial\nattacks, they remain vulnerable, especially to unseen attacks. In contrast,\nhumans are difficult to be cheated by subtle manipulations, since we make\njudgments only based on essential factors. Inspired by this observation, we\nattempt to model label generation with essential label-causative factors and\nincorporate label-non-causative factors to assist data generation. For an\nadversarial example, we aim to discriminate the perturbations as non-causative\nfactors and make predictions only based on the label-causative factors.\nConcretely, we propose a casual diffusion model (CausalDiff) that adapts\ndiffusion models for conditional data generation and disentangles the two types\nof casual factors by learning towards a novel casual information bottleneck\nobjective. Empirically, CausalDiff has significantly outperformed\nstate-of-the-art defense methods on various unseen attacks, achieving an\naverage robustness of 86.39% (+4.01%) on CIFAR-10, 56.25% (+3.13%) on\nCIFAR-100, and 82.62% (+4.93%) on GTSRB (German Traffic Sign Recognition\nBenchmark).\n","authors":["Mingkun Zhang","Keping Bi","Wei Chen","Quanrun Chen","Jiafeng Guo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2410.23091v3.pdf","comment":"accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.03926v2","updated":"2024-11-12T14:04:53Z","published":"2024-11-06T13:57:53Z","title":"Act in Collusion: A Persistent Distributed Multi-Target Backdoor in\n  Federated Learning","summary":"  Federated learning, a novel paradigm designed to protect data privacy, is\nvulnerable to backdoor attacks due to its distributed nature. Current research\noften designs attacks based on a single attacker with a single backdoor,\noverlooking more realistic and complex threats in federated learning. We\npropose a more practical threat model for federated learning: the distributed\nmulti-target backdoor. In this model, multiple attackers control different\nclients, embedding various triggers and targeting different classes,\ncollaboratively implanting backdoors into the global model via central\naggregation. Empirical validation shows that existing methods struggle to\nmaintain the effectiveness of multiple backdoors in the global model. Our key\ninsight is that similar backdoor triggers cause parameter conflicts and\ninjecting new backdoors disrupts gradient directions, significantly weakening\nsome backdoors performance. To solve this, we propose a Distributed\nMulti-Target Backdoor Attack (DMBA), ensuring efficiency and persistence of\nbackdoors from different malicious clients. To avoid parameter conflicts, we\ndesign a multi-channel dispersed frequency trigger strategy to maximize trigger\ndifferences. To mitigate gradient interference, we introduce backdoor replay in\nlocal training to neutralize conflicting gradients. Extensive validation shows\nthat 30 rounds after the attack, Attack Success Rates of three different\nbackdoors from various clients remain above 93%. The code will be made publicly\navailable after the review period.\n","authors":["Tao Liu","Wu Yang","Chen Xu","Jiguang Lv","Huanran Wang","Yuhang Zhang","Shuchun Xu","Dapeng Man"],"pdf_url":"https://arxiv.org/pdf/2411.03926v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07802v1","updated":"2024-11-12T13:57:13Z","published":"2024-11-12T13:57:13Z","title":"Large-scale Remote Sensing Image Target Recognition and Automatic\n  Annotation","summary":"  This paper presents a method for object recognition and automatic labeling in\nlarge-area remote sensing images called LRSAA. The method integrates YOLOv11\nand MobileNetV3-SSD object detection algorithms through ensemble learning to\nenhance model performance. Furthermore, it employs Poisson disk sampling\nsegmentation techniques and the EIOU metric to optimize the training and\ninference processes of segmented images, followed by the integration of\nresults. This approach not only reduces the demand for computational resources\nbut also achieves a good balance between accuracy and speed. The source code\nfor this project has been made publicly available on\nhttps://github.com/anaerovane/LRSAA.\n","authors":["Wuzheng Dong"],"pdf_url":"https://arxiv.org/pdf/2411.07802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07799v1","updated":"2024-11-12T13:53:22Z","published":"2024-11-12T13:53:22Z","title":"Horticultural Temporal Fruit Monitoring via 3D Instance Segmentation and\n  Re-Identification using Point Clouds","summary":"  Robotic fruit monitoring is a key step toward automated agricultural\nproduction systems. Robots can significantly enhance plant and temporal fruit\nmonitoring by providing precise, high-throughput assessments that overcome the\nlimitations of traditional manual methods. Fruit monitoring is a challenging\ntask due to the significant variation in size, shape, orientation, and\nocclusion of fruits. Also, fruits may be harvested or newly grown between\nrecording sessions. Most methods are 2D image-based and they lack the 3D\nstructure, depth, and spatial information, which represent key aspects of fruit\nmonitoring. 3D colored point clouds, instead, can offer this information but\nthey introduce challenges such as their sparsity and irregularity. In this\npaper, we present a novel approach for temporal fruit monitoring that addresses\npoint clouds collected in a greenhouse over time. Our method segments fruits\nusing a learning-based instance segmentation approach directly on the point\ncloud. Each segmented fruit is processed by a 3D sparse convolutional neural\nnetwork to extract descriptors, which are used in an attention-based matching\nnetwork to associate fruits with their instances from previous data\ncollections. Experimental results on a real dataset of strawberries demonstrate\nthat our approach outperforms other methods for fruits re-identification over\ntime, allowing for precise temporal fruit monitoring in real and complex\nscenarios.\n","authors":["Daniel Fusaro","Federico Magistri","Jens Behley","Alberto Pretto","Cyrill Stachniss"],"pdf_url":"https://arxiv.org/pdf/2411.07799v1.pdf","comment":"Submitted to IEEE Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2411.07784v1","updated":"2024-11-12T13:33:26Z","published":"2024-11-12T13:33:26Z","title":"Interaction Asymmetry: A General Principle for Learning Composable\n  Abstractions","summary":"  Learning disentangled representations of concepts and re-composing them in\nunseen ways is crucial for generalizing to out-of-domain situations. However,\nthe underlying properties of concepts that enable such disentanglement and\ncompositional generalization remain poorly understood. In this work, we propose\nthe principle of interaction asymmetry which states: \"Parts of the same concept\nhave more complex interactions than parts of different concepts\". We formalize\nthis via block diagonality conditions on the $(n+1)$th order derivatives of the\ngenerator mapping concepts to observed data, where different orders of\n\"complexity\" correspond to different $n$. Using this formalism, we prove that\ninteraction asymmetry enables both disentanglement and compositional\ngeneralization. Our results unify recent theoretical results for learning\nconcepts of objects, which we show are recovered as special cases with\n$n\\!=\\!0$ or $1$. We provide results for up to $n\\!=\\!2$, thus extending these\nprior works to more flexible generator functions, and conjecture that the same\nproof strategies generalize to larger $n$. Practically, our theory suggests\nthat, to disentangle concepts, an autoencoder should penalize its latent\ncapacity and the interactions between concepts during decoding. We propose an\nimplementation of these criteria using a flexible Transformer-based VAE, with a\nnovel regularizer on the attention weights of the decoder. On synthetic image\ndatasets consisting of objects, we provide evidence that this model can achieve\ncomparable object disentanglement to existing models that use more explicit\nobject-centric priors.\n","authors":["Jack Brady","Julius von Kügelgen","Sébastien Lachapelle","Simon Buchholz","Thomas Kipf","Wieland Brendel"],"pdf_url":"https://arxiv.org/pdf/2411.07784v1.pdf","comment":"Preprint, under review"},{"id":"http://arxiv.org/abs/2407.00352v2","updated":"2024-11-12T13:01:48Z","published":"2024-06-29T07:53:47Z","title":"PhyTracker: An Online Tracker for Phytoplankton","summary":"  Phytoplankton, a crucial component of aquatic ecosystems, requires efficient\nmonitoring to understand marine ecological processes and environmental\nconditions. Traditional phytoplankton monitoring methods, relying on non-in\nsitu observations, are time-consuming and resource-intensive, limiting timely\nanalysis. To address these limitations, we introduce PhyTracker, an intelligent\nin situ tracking framework designed for automatic tracking of phytoplankton.\nPhyTracker overcomes significant challenges unique to phytoplankton monitoring,\nsuch as constrained mobility within water flow, inconspicuous appearance, and\nthe presence of impurities. Our method incorporates three innovative modules: a\nTexture-enhanced Feature Extraction (TFE) module, an Attention-enhanced\nTemporal Association (ATA) module, and a Flow-agnostic Movement Refinement\n(FMR) module. These modules enhance feature capture, differentiate between\nphytoplankton and impurities, and refine movement characteristics,\nrespectively. Extensive experiments on the PMOT dataset validate the\nsuperiority of PhyTracker in phytoplankton tracking, and additional tests on\nthe MOT dataset demonstrate its general applicability, outperforming\nconventional tracking methods. This work highlights key differences between\nphytoplankton and traditional objects, offering an effective solution for\nphytoplankton monitoring.\n","authors":["Yang Yu","Qingxuan Lv","Yuezun Li","Zhiqiang Wei","Junyu Dong"],"pdf_url":"https://arxiv.org/pdf/2407.00352v2.pdf","comment":"13pages,eleven figures"},{"id":"http://arxiv.org/abs/2411.07765v1","updated":"2024-11-12T12:58:33Z","published":"2024-11-12T12:58:33Z","title":"Novel View Synthesis with Pixel-Space Diffusion Models","summary":"  Synthesizing a novel view from a single input image is a challenging task.\nTraditionally, this task was approached by estimating scene depth, warping, and\ninpainting, with machine learning models enabling parts of the pipeline. More\nrecently, generative models are being increasingly employed in novel view\nsynthesis (NVS), often encompassing the entire end-to-end system. In this work,\nwe adapt a modern diffusion model architecture for end-to-end NVS in the pixel\nspace, substantially outperforming previous state-of-the-art (SOTA) techniques.\nWe explore different ways to encode geometric information into the network. Our\nexperiments show that while these methods may enhance performance, their impact\nis minor compared to utilizing improved generative models. Moreover, we\nintroduce a novel NVS training scheme that utilizes single-view datasets,\ncapitalizing on their relative abundance compared to their multi-view\ncounterparts. This leads to improved generalization capabilities to scenes with\nout-of-domain content.\n","authors":["Noam Elata","Bahjat Kawar","Yaron Ostrovsky-Berman","Miriam Farber","Ron Sokolovsky"],"pdf_url":"https://arxiv.org/pdf/2411.07765v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.09997v5","updated":"2024-11-12T12:56:33Z","published":"2023-07-19T14:10:55Z","title":"TUNeS: A Temporal U-Net with Self-Attention for Video-based Surgical\n  Phase Recognition","summary":"  To enable context-aware computer assistance in the operating room of the\nfuture, cognitive systems need to understand automatically which surgical phase\nis being performed by the medical team. The primary source of information for\nsurgical phase recognition is typically video, which presents two challenges:\nextracting meaningful features from the video stream and effectively modeling\ntemporal information in the sequence of visual features. For temporal modeling,\nattention mechanisms have gained popularity due to their ability to capture\nlong-range dependencies. In this paper, we explore design choices for attention\nin existing temporal models for surgical phase recognition and propose a novel\napproach that uses attention more effectively and does not require hand-crafted\nconstraints: TUNeS, an efficient and simple temporal model that incorporates\nself-attention at the core of a convolutional U-Net structure. In addition, we\npropose to train the feature extractor, a standard CNN, together with an LSTM\non preferably long video segments, i.e., with long temporal context. In our\nexperiments, almost all temporal models performed better on top of feature\nextractors that were trained with longer temporal context. On these\ncontextualized features, TUNeS achieves state-of-the-art results on the\nCholec80 dataset. This study offers new insights on how to use attention\nmechanisms to build accurate and efficient temporal models for surgical phase\nrecognition. Implementing automatic surgical phase recognition is essential to\nautomate the analysis and optimization of surgical workflows and to enable\ncontext-aware computer assistance during surgery, thus ultimately improving\npatient care.\n","authors":["Isabel Funke","Dominik Rivoir","Stefanie Krell","Stefanie Speidel"],"pdf_url":"https://arxiv.org/pdf/2307.09997v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07096v2","updated":"2024-11-12T12:45:03Z","published":"2024-11-11T16:18:28Z","title":"Extreme Rotation Estimation in the Wild","summary":"  We present a technique and benchmark dataset for estimating the relative 3D\norientation between a pair of Internet images captured in an extreme setting,\nwhere the images have limited or non-overlapping field of views. Prior work\ntargeting extreme rotation estimation assume constrained 3D environments and\nemulate perspective images by cropping regions from panoramic views. However,\nreal images captured in the wild are highly diverse, exhibiting variation in\nboth appearance and camera intrinsics. In this work, we propose a\nTransformer-based method for estimating relative rotations in extreme\nreal-world settings, and contribute the ExtremeLandmarkPairs dataset, assembled\nfrom scene-level Internet photo collections. Our evaluation demonstrates that\nour approach succeeds in estimating the relative rotations in a wide variety of\nextreme-view Internet image pairs, outperforming various baselines, including\ndedicated rotation estimation techniques and contemporary 3D reconstruction\nmethods.\n","authors":["Hana Bezalel","Dotan Ankri","Ruojin Cai","Hadar Averbuch-Elor"],"pdf_url":"https://arxiv.org/pdf/2411.07096v2.pdf","comment":"Project webpage:\n  https://tau-vailab.github.io/ExtremeRotationsInTheWild/"},{"id":"http://arxiv.org/abs/2411.07758v1","updated":"2024-11-12T12:35:34Z","published":"2024-11-12T12:35:34Z","title":"AdaSemiCD: An Adaptive Semi-Supervised Change Detection Method Based on\n  Pseudo-Label Evaluation","summary":"  Change Detection (CD) is an essential field in remote sensing, with a primary\nfocus on identifying areas of change in bi-temporal image pairs captured at\nvarying intervals of the same region by a satellite. The data annotation\nprocess for the CD task is both time-consuming and labor-intensive. To make\nbetter use of the scarce labeled data and abundant unlabeled data, we present\nan adaptive dynamic semi-supervised learning method, AdaSemiCD, to improve the\nuse of pseudo-labels and optimize the training process. Initially, due to the\nextreme class imbalance inherent in CD, the model is more inclined to focus on\nthe background class, and it is easy to confuse the boundary of the target\nobject. Considering these two points, we develop a measurable evaluation metric\nfor pseudo-labels that enhances the representation of information entropy by\nclass rebalancing and amplification of confusing areas to give a larger weight\nto prospects change objects. Subsequently, to enhance the reliability of\nsample-wise pseudo-labels, we introduce the AdaFusion module, which is capable\nof dynamically identifying the most uncertain region and substituting it with\nmore trustworthy content. Lastly, to ensure better training stability, we\nintroduce the AdaEMA module, which updates the teacher model using only batches\nof trusted samples. Experimental results from LEVIR-CD, WHU-CD, and CDD\ndatasets validate the efficacy and universality of our proposed adaptive\ntraining framework.\n","authors":["Ran Lingyan","Wen Dongcheng","Zhuo Tao","Zhang Shizhou","Zhang Xiuwei","Zhang Yanning"],"pdf_url":"https://arxiv.org/pdf/2411.07758v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07751v1","updated":"2024-11-12T12:23:41Z","published":"2024-11-12T12:23:41Z","title":"SAV-SE: Scene-aware Audio-Visual Speech Enhancement with Selective State\n  Space Model","summary":"  Speech enhancement plays an essential role in various applications, and the\nintegration of visual information has been demonstrated to bring substantial\nadvantages. However, the majority of current research concentrates on the\nexamination of facial and lip movements, which can be compromised or entirely\ninaccessible in scenarios where occlusions occur or when the camera view is\ndistant. Whereas contextual visual cues from the surrounding environment have\nbeen overlooked: for example, when we see a dog bark, our brain has the innate\nability to discern and filter out the barking noise. To this end, in this\npaper, we introduce a novel task, i.e. SAV-SE. To our best knowledge, this is\nthe first proposal to use rich contextual information from synchronized video\nas auxiliary cues to indicate the type of noise, which eventually improves the\nspeech enhancement performance. Specifically, we propose the VC-S$^2$E method,\nwhich incorporates the Conformer and Mamba modules for their complementary\nstrengths. Extensive experiments are conducted on public MUSIC, AVSpeech and\nAudioSet datasets, where the results demonstrate the superiority of VC-S$^2$E\nover other competitive methods. We will make the source code publicly\navailable. Project demo page: https://AVSEPage.github.io/\n","authors":["Xinyuan Qian","Jiaran Gao","Yaodan Zhang","Qiquan Zhang","Hexin Liu","Leibny Paola Garcia","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2411.07751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07750v1","updated":"2024-11-12T12:23:19Z","published":"2024-11-12T12:23:19Z","title":"LapGSR: Laplacian Reconstructive Network for Guided Thermal\n  Super-Resolution","summary":"  In the last few years, the fusion of multi-modal data has been widely studied\nfor various applications such as robotics, gesture recognition, and autonomous\nnavigation. Indeed, high-quality visual sensors are expensive, and\nconsumer-grade sensors produce low-resolution images. Researchers have\ndeveloped methods to combine RGB color images with non-visual data, such as\nthermal, to overcome this limitation to improve resolution. Fusing multiple\nmodalities to produce visually appealing, high-resolution images often requires\ndense models with millions of parameters and a heavy computational load, which\nis commonly attributed to the intricate architecture of the model.\n  We propose LapGSR, a multimodal, lightweight, generative model incorporating\nLaplacian image pyramids for guided thermal super-resolution. This approach\nuses a Laplacian Pyramid on RGB color images to extract vital edge information,\nwhich is then used to bypass heavy feature map computation in the higher layers\nof the model in tandem with a combined pixel and adversarial loss. LapGSR\npreserves the spatial and structural details of the image while also being\nefficient and compact. This results in a model with significantly fewer\nparameters than other SOTA models while demonstrating excellent results on two\ncross-domain datasets viz. ULB17-VT and VGTSR datasets.\n","authors":["Aditya Kasliwal","Ishaan Gakhar","Aryan Kamani","Pratinav Seth","Ujjwal Verma"],"pdf_url":"https://arxiv.org/pdf/2411.07750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07747v1","updated":"2024-11-12T12:18:18Z","published":"2024-11-12T12:18:18Z","title":"Constraint Learning for Parametric Point Cloud","summary":"  Parametric point clouds are sampled from CAD shapes, have become increasingly\nprevalent in industrial manufacturing. However, most existing point cloud\nlearning methods focus on the geometric features, such as local and global\nfeatures or developing efficient convolution operations, overlooking the\nimportant attribute of constraints inherent in CAD shapes, which limits these\nmethods' ability to fully comprehend CAD shapes. To address this issue, we\nanalyzed the effect of constraints, and proposed its deep learning-friendly\nrepresentation, after that, the Constraint Feature Learning Network (CstNet) is\ndeveloped to extract and leverage constraints. Our CstNet includes two stages.\nThe Stage 1 extracts constraints from B-Rep data or point cloud. The Stage 2\nleverages coordinates and constraints to enhance the comprehend of CAD shapes.\nAdditionally, we built up the Parametric 20,000 Multi-modal Dataset for the\nscarcity of labeled B-Rep datasets. Experiments demonstrate that our CstNet\nachieved state-of-the-art performance on both public and proposed CAD shapes\ndatasets. To the best of our knowledge, CstNet is the first constraint-based\nlearning method tailored for CAD shapes analysis.\n","authors":["Xi Cheng","Ruiqi Lei","Di Huang","Zhichao Liao","Fengyuan Piao","Yan Chen","Pingfa Feng","Long Zeng"],"pdf_url":"https://arxiv.org/pdf/2411.07747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07742v1","updated":"2024-11-12T12:07:27Z","published":"2024-11-12T12:07:27Z","title":"Efficient 3D Perception on Multi-Sweep Point Cloud with Gumbel Spatial\n  Pruning","summary":"  This paper studies point cloud perception within outdoor environments.\nExisting methods face limitations in recognizing objects located at a distance\nor occluded, due to the sparse nature of outdoor point clouds. In this work, we\nobserve a significant mitigation of this problem by accumulating multiple\ntemporally consecutive LiDAR sweeps, resulting in a remarkable improvement in\nperception accuracy. However, the computation cost also increases, hindering\nprevious approaches from utilizing a large number of LiDAR sweeps. To tackle\nthis challenge, we find that a considerable portion of points in the\naccumulated point cloud is redundant, and discarding these points has minimal\nimpact on perception accuracy. We introduce a simple yet effective Gumbel\nSpatial Pruning (GSP) layer that dynamically prunes points based on a learned\nend-to-end sampling. The GSP layer is decoupled from other network components\nand thus can be seamlessly integrated into existing point cloud network\narchitectures. Without incurring additional computational overhead, we increase\nthe number of LiDAR sweeps from 10, a common practice, to as many as 40.\nConsequently, there is a significant enhancement in perception performance. For\ninstance, in nuScenes 3D object detection and BEV map segmentation tasks, our\npruning strategy improves the vanilla TransL baseline and other baseline\nmethods.\n","authors":["Jianhao Li","Tianyu Sun","Xueqian Zhang","Zhongdao Wang","Bailan Feng","Hengshuang Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.07742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06911v2","updated":"2024-11-12T12:07:00Z","published":"2024-11-11T12:13:58Z","title":"Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI","summary":"  Segmentation of cardiac magnetic resonance images (MRI) is crucial for the\nanalysis and assessment of cardiac function, helping to diagnose and treat\nvarious cardiovascular diseases. Most recent techniques rely on deep learning\nand usually require an extensive amount of labeled data. To overcome this\nproblem, few-shot learning has the capability of reducing data dependency on\nlabeled data. In this work, we introduce a new method that merges few-shot\nlearning with a U-Net architecture and Gaussian Process Emulators (GPEs),\nenhancing data integration from a support set for improved performance. GPEs\nare trained to learn the relation between the support images and the\ncorresponding masks in latent space, facilitating the segmentation of unseen\nquery images given only a small labeled support set at inference. We test our\nmodel with the M&Ms-2 public dataset to assess its ability to segment the heart\nin cardiac magnetic resonance imaging from different orientations, and compare\nit with state-of-the-art unsupervised and few-shot methods. Our architecture\nshows higher DICE coefficients compared to these methods, especially in the\nmore challenging setups where the size of the support set is considerably\nsmall.\n","authors":["Bruno Viti","Franz Thaler","Kathrin Lisa Kapper","Martin Urschler","Martin Holler","Elias Karabelas"],"pdf_url":"https://arxiv.org/pdf/2411.06911v2.pdf","comment":"Accepted at Statistical Atlases and Computational Modeling of the\n  Heart (STACOM) Workshop 2024"},{"id":"http://arxiv.org/abs/2411.07740v1","updated":"2024-11-12T12:04:44Z","published":"2024-11-12T12:04:44Z","title":"3D Focusing-and-Matching Network for Multi-Instance Point Cloud\n  Registration","summary":"  Multi-instance point cloud registration aims to estimate the pose of all\ninstances of a model point cloud in the whole scene. Existing methods all adopt\nthe strategy of first obtaining the global correspondence and then clustering\nto obtain the pose of each instance. However, due to the cluttered and occluded\nobjects in the scene, it is difficult to obtain an accurate correspondence\nbetween the model point cloud and all instances in the scene. To this end, we\npropose a simple yet powerful 3D focusing-and-matching network for\nmulti-instance point cloud registration by learning the multiple pair-wise\npoint cloud registration. Specifically, we first present a 3D multi-object\nfocusing module to locate the center of each object and generate object\nproposals. By using self-attention and cross-attention to associate the model\npoint cloud with structurally similar objects, we can locate potential matching\ninstances by regressing object centers. Then, we propose a 3D dual masking\ninstance matching module to estimate the pose between the model point cloud and\neach object proposal. It performs instance mask and overlap mask masks to\naccurately predict the pair-wise correspondence. Extensive experiments on two\npublic benchmarks, Scan2CAD and ROBI, show that our method achieves a new\nstate-of-the-art performance on the multi-instance point cloud registration\ntask. Code is available at https://github.com/zlynpu/3DFMNet.\n","authors":["Liyuan Zhang","Le Hui","Qi Liu","Bo Li","Yuchao Dai"],"pdf_url":"https://arxiv.org/pdf/2411.07740v1.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07728v1","updated":"2024-11-12T11:39:05Z","published":"2024-11-12T11:39:05Z","title":"No-Reference Point Cloud Quality Assessment via Graph Convolutional\n  Network","summary":"  Three-dimensional (3D) point cloud, as an emerging visual media format, is\nincreasingly favored by consumers as it can provide more realistic visual\ninformation than two-dimensional (2D) data. Similar to 2D plane images and\nvideos, point clouds inevitably suffer from quality degradation and information\nloss through multimedia communication systems. Therefore, automatic point cloud\nquality assessment (PCQA) is of critical importance. In this work, we propose a\nnovel no-reference PCQA method by using a graph convolutional network (GCN) to\ncharacterize the mutual dependencies of multi-view 2D projected image contents.\nThe proposed GCN-based PCQA (GC-PCQA) method contains three modules, i.e.,\nmulti-view projection, graph construction, and GCN-based quality prediction.\nFirst, multi-view projection is performed on the test point cloud to obtain a\nset of horizontally and vertically projected images. Then, a\nperception-consistent graph is constructed based on the spatial relations among\ndifferent projected images. Finally, reasoning on the constructed graph is\nperformed by GCN to characterize the mutual dependencies and interactions\nbetween different projected images, and aggregate feature information of\nmulti-view projected images for final quality prediction. Experimental results\non two publicly available benchmark databases show that our proposed GC-PCQA\ncan achieve superior performance than state-of-the-art quality assessment\nmetrics. The code will be available at: https://github.com/chenwuwq/GC-PCQA.\n","authors":["Wu Chen","Qiuping Jiang","Wei Zhou","Feng Shao","Guangtao Zhai","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2411.07728v1.pdf","comment":"Accepted by IEEE Transactions on Multimedia"},{"id":"http://arxiv.org/abs/2411.07725v1","updated":"2024-11-12T11:32:56Z","published":"2024-11-12T11:32:56Z","title":"ALOcc: Adaptive Lifting-based 3D Semantic Occupancy and Cost\n  Volume-based Flow Prediction","summary":"  Vision-based semantic occupancy and flow prediction plays a crucial role in\nproviding spatiotemporal cues for real-world tasks, such as autonomous driving.\nExisting methods prioritize higher accuracy to cater to the demands of these\ntasks. In this work, we strive to improve performance by introducing a series\nof targeted improvements for 3D semantic occupancy prediction and flow\nestimation. First, we introduce an occlusion-aware adaptive lifting mechanism\nwith a depth denoising technique to improve the robustness of 2D-to-3D feature\ntransformation and reduce the reliance on depth priors. Second, we strengthen\nthe semantic consistency between 3D features and their original 2D modalities\nby utilizing shared semantic prototypes to jointly constrain both 2D and 3D\nfeatures. This is complemented by confidence- and category-based sampling\nstrategies to tackle long-tail challenges in 3D space. To alleviate the feature\nencoding burden in the joint prediction of semantics and flow, we propose a BEV\ncost volume-based prediction method that links flow and semantic features\nthrough a cost volume and employs a classification-regression supervision\nscheme to address the varying flow scales in dynamic scenes. Our purely\nconvolutional architecture framework, named ALOcc, achieves an optimal tradeoff\nbetween speed and accuracy achieving state-of-the-art results on multiple\nbenchmarks. On Occ3D and training without the camera visible mask, our ALOcc\nachieves an absolute gain of 2.5\\% in terms of RayIoU while operating at a\ncomparable speed compared to the state-of-the-art, using the same input size\n(256$\\times$704) and ResNet-50 backbone. Our method also achieves 2nd place in\nthe CVPR24 Occupancy and Flow Prediction Competition.\n","authors":["Dubing Chen","Jin Fang","Wencheng Han","Xinjing Cheng","Junbo Yin","Chenzhong Xu","Fahad Shahbaz Khan","Jianbing Shen"],"pdf_url":"https://arxiv.org/pdf/2411.07725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07719v1","updated":"2024-11-12T11:24:18Z","published":"2024-11-12T11:24:18Z","title":"EMPERROR: A Flexible Generative Perception Error Model for Probing\n  Self-Driving Planners","summary":"  To handle the complexities of real-world traffic, learning planners for\nself-driving from data is a promising direction. While recent approaches have\nshown great progress, they typically assume a setting in which the ground-truth\nworld state is available as input. However, when deployed, planning needs to be\nrobust to the long-tail of errors incurred by a noisy perception system, which\nis often neglected in evaluation. To address this, previous work has proposed\ndrawing adversarial samples from a perception error model (PEM) mimicking the\nnoise characteristics of a target object detector. However, these methods use\nsimple PEMs that fail to accurately capture all failure modes of detection. In\nthis paper, we present EMPERROR, a novel transformer-based generative PEM,\napply it to stress-test an imitation learning (IL)-based planner and show that\nit imitates modern detectors more faithfully than previous work. Furthermore,\nit is able to produce realistic noisy inputs that increase the planner's\ncollision rate by up to 85%, demonstrating its utility as a valuable tool for a\nmore complete evaluation of self-driving planners.\n","authors":["Niklas Hanselmann","Simon Doll","Marius Cordts","Hendrik P. A. Lensch","Andreas Geiger"],"pdf_url":"https://arxiv.org/pdf/2411.07719v1.pdf","comment":"Project page: https://lasnik.github.io/emperror/"},{"id":"http://arxiv.org/abs/2410.10563v2","updated":"2024-11-12T11:16:43Z","published":"2024-10-14T14:42:12Z","title":"MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks","summary":"  We present MEGA-Bench, an evaluation suite that scales multimodal evaluation\nto over 500 real-world tasks, to address the highly heterogeneous daily use\ncases of end users. Our objective is to optimize for a set of high-quality data\nsamples that cover a highly diverse and rich set of multimodal tasks, while\nenabling cost-effective and accurate model evaluation. In particular, we\ncollected 505 realistic tasks encompassing over 8,000 samples from 16 expert\nannotators to extensively cover the multimodal task space. Instead of unifying\nthese problems into standard multi-choice questions (like MMMU, MMBench, and\nMMT-Bench), we embrace a wide range of output formats like numbers, phrases,\ncode, \\LaTeX, coordinates, JSON, free-form, etc. To accommodate these formats,\nwe developed over 40 metrics to evaluate these tasks. Unlike existing\nbenchmarks, MEGA-Bench offers a fine-grained capability report across multiple\ndimensions (e.g., application, input type, output format, skill), allowing\nusers to interact with and visualize model capabilities in depth. We evaluate a\nwide variety of frontier vision-language models on MEGA-Bench to understand\ntheir capabilities across these dimensions.\n","authors":["Jiacheng Chen","Tianhao Liang","Sherman Siu","Zhengqing Wang","Kai Wang","Yubo Wang","Yuansheng Ni","Wang Zhu","Ziyan Jiang","Bohan Lyu","Dongfu Jiang","Xuan He","Yuan Liu","Hexiang Hu","Xiang Yue","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2410.10563v2.pdf","comment":"Technical report. Project page:\n  https://tiger-ai-lab.github.io/MEGA-Bench/. v2 includes more evaluated models\n  and a single-image setting"},{"id":"http://arxiv.org/abs/2407.08364v3","updated":"2024-11-12T10:56:38Z","published":"2024-07-11T10:18:54Z","title":"Scalar Function Topology Divergence: Comparing Topology of 3D Objects","summary":"  We propose a new topological tool for computer vision - Scalar Function\nTopology Divergence (SFTD), which measures the dissimilarity of multi-scale\ntopology between sublevel sets of two functions having a common domain.\nFunctions can be defined on an undirected graph or Euclidean space of any\ndimensionality. Most of the existing methods for comparing topology are based\non Wasserstein distance between persistence barcodes and they don't take into\naccount the localization of topological features. The minimization of SFTD\nensures that the corresponding topological features of scalar functions are\nlocated in the same places. The proposed tool provides useful visualizations\ndepicting areas where functions have topological dissimilarities. We provide\napplications of the proposed method to 3D computer vision. In particular,\nexperiments demonstrate that SFTD as an additional loss improves the\nreconstruction of cellular 3D shapes from 2D fluorescence microscopy images,\nand helps to identify topological errors in 3D segmentation. Additionally, we\nshow that SFTD outperforms Betti matching loss in 2D segmentation problems.\n","authors":["Ilya Trofimov","Daria Voronkova","Eduard Tulchinskii","Evgeny Burnaev","Serguei Barannikov"],"pdf_url":"https://arxiv.org/pdf/2407.08364v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.19287v3","updated":"2024-11-12T10:48:21Z","published":"2024-04-30T06:34:21Z","title":"Revisiting the Adversarial Robustness of Vision Language Models: a\n  Multimodal Perspective","summary":"  Pretrained vision-language models (VLMs) like CLIP exhibit exceptional\ngeneralization across diverse downstream tasks. While recent studies reveal\ntheir vulnerability to adversarial attacks, research to date has primarily\nfocused on enhancing the robustness of image encoders against image-based\nattacks, with defenses against text-based and multimodal attacks remaining\nlargely unexplored. To this end, this work presents the first comprehensive\nstudy on improving the adversarial robustness of VLMs against attacks targeting\nimage, text, and multimodal inputs. This is achieved by proposing multimodal\ncontrastive adversarial training (MMCoA). Such an approach strengthens the\nrobustness of both image and text encoders by aligning the clean text\nembeddings with adversarial image embeddings, and adversarial text embeddings\nwith clean image embeddings. The robustness of the proposed MMCoA is examined\nagainst existing defense methods over image, text, and multimodal attacks on\nthe CLIP model. Extensive experiments on 15 datasets across two tasks reveal\nthe characteristics of different adversarial defense methods under distinct\ndistribution shifts and dataset complexities across the three attack types.\nThis paves the way for a unified framework of adversarial robustness against\ndifferent modality attacks, opening up new possibilities for securing VLMs\nagainst multimodal attacks. The code is available at\nhttps://github.com/ElleZWQ/MMCoA.git.\n","authors":["Wanqi Zhou","Shuanghao Bai","Danilo P. Mandic","Qibin Zhao","Badong Chen"],"pdf_url":"https://arxiv.org/pdf/2404.19287v3.pdf","comment":"17 pages, 13 figures"},{"id":"http://arxiv.org/abs/2411.07708v1","updated":"2024-11-12T10:47:31Z","published":"2024-11-12T10:47:31Z","title":"Emotion Classification of Children Expressions","summary":"  This paper proposes a process for a classification model for the facial\nexpressions. The proposed process would aid in specific categorisation of\nchildren's emotions from 2 emotions namely 'Happy' and 'Sad'. Since the\nexisting emotion recognition systems algorithms primarily train on adult faces,\nthe model developed is achieved by using advanced concepts of models with\nSqueeze-andExcitation blocks, Convolutional Block Attention modules, and robust\ndata augmentation. Stable Diffusion image synthesis was used for expanding and\ndiversifying the data set generating realistic and various training samples.\nThe model designed using Batch Normalisation, Dropout, and SE Attention\nmechanisms for the classification of children's emotions achieved an accuracy\nrate of 89\\% due to these methods improving the precision of emotion\nrecognition in children. The relative importance of this issue is raised in\nthis study with an emphasis on the call for a more specific model in emotion\ndetection systems for the young generation with specific direction on how the\nyoung people can be assisted to manage emotions while online.\n","authors":["Sanchayan Vivekananthan"],"pdf_url":"https://arxiv.org/pdf/2411.07708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12036v2","updated":"2024-11-12T10:12:49Z","published":"2024-07-01T05:37:17Z","title":"Exploring Advanced Large Language Models with LLMsuite","summary":"  This tutorial explores the advancements and challenges in the development of\nLarge Language Models (LLMs) such as ChatGPT and Gemini. It addresses inherent\nlimitations like temporal knowledge cutoffs, mathematical inaccuracies, and the\ngeneration of incorrect information, proposing solutions like Retrieval\nAugmented Generation (RAG), Program-Aided Language Models (PAL), and frameworks\nsuch as ReAct and LangChain. The integration of these techniques enhances LLM\nperformance and reliability, especially in multi-step reasoning and complex\ntask execution. The paper also covers fine-tuning strategies, including\ninstruction fine-tuning, parameter-efficient methods like LoRA, and\nReinforcement Learning from Human Feedback (RLHF) as well as Reinforced\nSelf-Training (ReST). Additionally, it provides a comprehensive survey of\ntransformer architectures and training techniques for LLMs. The source code can\nbe accessed by contacting the author via email for a request.\n","authors":["Giorgio Roffo"],"pdf_url":"https://arxiv.org/pdf/2407.12036v2.pdf","comment":"Keywords: Language Model Benchmarking, Pre-Trained LLM Comparison,\n  LLM Performance Analysis, NLP Model Evaluation Tools, Public Dataset\n  Inference for LLMs, BLEU and ROUGE Metrics for LLM, Open Source LLM Testing\n  Tools, Large Language Model Evaluation Software, NLP Benchmarking Suite,\n  Comprehensive LLM Evaluation Toolkit"},{"id":"http://arxiv.org/abs/2411.07688v1","updated":"2024-11-12T10:12:12Z","published":"2024-11-12T10:12:12Z","title":"Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with\n  ImageRAG","summary":"  Ultra High Resolution (UHR) remote sensing imagery (RSI) (e.g. 100,000\n$\\times$ 100,000 pixels or more) poses a significant challenge for current\nRemote Sensing Multimodal Large Language Models (RSMLLMs). If choose to resize\nthe UHR image to standard input image size, the extensive spatial and\ncontextual information that UHR images contain will be neglected. Otherwise,\nthe original size of these images often exceeds the token limits of standard\nRSMLLMs, making it difficult to process the entire image and capture long-range\ndependencies to answer the query based on the abundant visual context. In this\npaper, we introduce ImageRAG for RS, a training-free framework to address the\ncomplexities of analyzing UHR remote sensing imagery. By transforming UHR\nremote sensing image analysis task to image's long context selection task, we\ndesign an innovative image contextual retrieval mechanism based on the\nRetrieval-Augmented Generation (RAG) technique, denoted as ImageRAG. ImageRAG's\ncore innovation lies in its ability to selectively retrieve and focus on the\nmost relevant portions of the UHR image as visual contexts that pertain to a\ngiven query. Fast path and slow path are proposed in this framework to handle\nthis task efficiently and effectively. ImageRAG allows RSMLLMs to manage\nextensive context and spatial information from UHR RSI, ensuring the analysis\nis both accurate and efficient.\n","authors":["Zilun Zhang","Haozhan Shen","Tiancheng Zhao","Yuhao Wang","Bin Chen","Yuxiang Cai","Yongheng Shang","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2411.07688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16620v3","updated":"2024-11-12T10:02:12Z","published":"2024-06-24T13:05:39Z","title":"OmAgent: A Multi-modal Agent Framework for Complex Video Understanding\n  with Task Divide-and-Conquer","summary":"  Recent advancements in Large Language Models (LLMs) have expanded their\ncapabilities to multimodal contexts, including comprehensive video\nunderstanding. However, processing extensive videos such as 24-hour CCTV\nfootage or full-length films presents significant challenges due to the vast\ndata and processing demands. Traditional methods, like extracting key frames or\nconverting frames to text, often result in substantial information loss. To\naddress these shortcomings, we develop OmAgent, efficiently stores and\nretrieves relevant video frames for specific queries, preserving the detailed\ncontent of videos. Additionally, it features an Divide-and-Conquer Loop capable\nof autonomous reasoning, dynamically invoking APIs and tools to enhance query\nprocessing and accuracy. This approach ensures robust video understanding,\nsignificantly reducing information loss. Experimental results affirm OmAgent's\nefficacy in handling various types of videos and complex tasks. Moreover, we\nhave endowed it with greater autonomy and a robust tool-calling system,\nenabling it to accomplish even more intricate tasks.\n","authors":["Lu Zhang","Tiancheng Zhao","Heting Ying","Yibo Ma","Kyusong Lee"],"pdf_url":"https://arxiv.org/pdf/2406.16620v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14208v2","updated":"2024-11-12T10:00:46Z","published":"2024-07-19T11:13:31Z","title":"Memory-Efficient Pseudo-Labeling for Online Source-Free Universal Domain\n  Adaptation using a Gaussian Mixture Model","summary":"  In practice, domain shifts are likely to occur between training and test\ndata, necessitating domain adaptation (DA) to adjust the pre-trained source\nmodel to the target domain. Recently, universal domain adaptation (UniDA) has\ngained attention for addressing the possibility of an additional category\n(label) shift between the source and target domain. This means new classes can\nappear in the target data, some source classes may no longer be present, or\nboth at the same time. For practical applicability, UniDA methods must handle\nboth source-free and online scenarios, enabling adaptation without access to\nthe source data and performing batch-wise updates in parallel with prediction.\nIn an online setting, preserving knowledge across batches is crucial. However,\nexisting methods often require substantial memory, which is impractical because\nmemory is limited and valuable, in particular on embedded systems. Therefore,\nwe consider memory-efficiency as an additional constraint. To achieve\nmemory-efficient online source-free universal domain adaptation (SF-UniDA), we\npropose a novel method that continuously captures the distribution of known\nclasses in the feature space using a Gaussian mixture model (GMM). This\napproach, combined with entropy-based out-of-distribution detection, allows for\nthe generation of reliable pseudo-labels. Finally, we combine a contrastive\nloss with a KL divergence loss to perform the adaptation. Our approach not only\nachieves state-of-the-art results in all experiments on the DomainNet and\nOffice-Home datasets but also significantly outperforms the existing methods on\nthe challenging VisDA-C dataset, setting a new benchmark for online SF-UniDA.\nOur code is available at https://github.com/pascalschlachter/GMM.\n","authors":["Pascal Schlachter","Simon Wagner","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2407.14208v2.pdf","comment":"Accepted at IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2025"},{"id":"http://arxiv.org/abs/2410.14265v2","updated":"2024-11-12T09:58:13Z","published":"2024-10-18T08:20:37Z","title":"HYPNOS : Highly Precise Foreground-focused Diffusion Finetuning for\n  Inanimate Objects","summary":"  In recent years, personalized diffusion-based text-to-image generative tasks\nhave been a hot topic in computer vision studies. A robust diffusion model is\ndetermined by its ability to perform near-perfect reconstruction of certain\nproduct outcomes given few related input samples. Unfortunately, the current\nprominent diffusion-based finetuning technique falls short in maintaining the\nforeground object consistency while being constrained to produce diverse\nbackgrounds in the image outcome. In the worst scenario, the overfitting issue\nmay occur, meaning that the foreground object is less controllable due to the\ncondition above, for example, the input prompt information is transferred\nambiguously to both foreground and background regions, instead of the supposed\nbackground region only. To tackle the issues above, we proposed Hypnos, a\nhighly precise foreground-focused diffusion finetuning technique. On the image\nlevel, this strategy works best for inanimate object generation tasks, and to\ndo so, Hypnos implements two main approaches, namely: (i) a content-centric\nprompting strategy and (ii) the utilization of our additional\nforeground-focused discriminative module. The utilized module is connected with\nthe diffusion model and finetuned with our proposed set of supervision\nmechanism. Combining the strategies above yielded to the foreground-background\ndisentanglement capability of the diffusion model. Our experimental results\nshowed that the proposed strategy gave a more robust performance and visually\npleasing results compared to the former technique. For better elaborations, we\nalso provided extensive studies to assess the fruitful outcomes above, which\nreveal how personalization behaves in regard to several training conditions.\n","authors":["Oliverio Theophilus Nathanael","Jonathan Samuel Lumentut","Nicholas Hans Muliawan","Edbert Valencio Angky","Felix Indra Kurniadi","Alfi Yusrotis Zakiyyah","Jeklin Harefa"],"pdf_url":"https://arxiv.org/pdf/2410.14265v2.pdf","comment":"26 pages, 12 figures, to appear on the Rich Media with Generative AI\n  workshop in conjunction with Asian Conference on Computer Vision (ACCV) 2024"},{"id":"http://arxiv.org/abs/2411.07685v1","updated":"2024-11-12T09:57:53Z","published":"2024-11-12T09:57:53Z","title":"Fast Disentangled Slim Tensor Learning for Multi-view Clustering","summary":"  Tensor-based multi-view clustering has recently received significant\nattention due to its exceptional ability to explore cross-view high-order\ncorrelations. However, most existing methods still encounter some limitations.\n(1) Most of them explore the correlations among different affinity matrices,\nmaking them unscalable to large-scale data. (2) Although some methods address\nit by introducing bipartite graphs, they may result in sub-optimal solutions\ncaused by an unstable anchor selection process. (3) They generally ignore the\nnegative impact of latent semantic-unrelated information in each view. To\ntackle these issues, we propose a new approach termed fast Disentangled Slim\nTensor Learning (DSTL) for multi-view clustering . Instead of focusing on the\nmulti-view graph structures, DSTL directly explores the high-order correlations\namong multi-view latent semantic representations based on matrix factorization.\nTo alleviate the negative influence of feature redundancy, inspired by robust\nPCA, DSTL disentangles the latent low-dimensional representation into a\nsemantic-unrelated part and a semantic-related part for each view.\nSubsequently, two slim tensors are constructed with tensor-based\nregularization. To further enhance the quality of feature disentanglement, the\nsemantic-related representations are aligned across views through a consensus\nalignment indicator. Our proposed model is computationally efficient and can be\nsolved effectively. Extensive experiments demonstrate the superiority and\nefficiency of DSTL over state-of-the-art approaches. The code of DSTL is\navailable at https://github.com/dengxu-nju/DSTL.\n","authors":["Deng Xu","Chao Zhang","Zechao Li","Chunlin Chen","Huaxiong Li"],"pdf_url":"https://arxiv.org/pdf/2411.07685v1.pdf","comment":"13 pages,6 figures, will be published to IEEE TMM"},{"id":"http://arxiv.org/abs/2411.07684v1","updated":"2024-11-12T09:56:42Z","published":"2024-11-12T09:56:42Z","title":"AI enhanced diagnosis of Peyronies disease a novel approach using\n  Computer Vision","summary":"  This study presents an innovative AI-driven tool for diagnosing Peyronie's\nDisease (PD), a condition that affects between 0.3% and 13.1% of men worldwide.\nOur method uses key point detection on both images and videos to measure penile\ncurvature angles, utilizing advanced computer vision techniques. This tool has\ndemonstrated high accuracy in identifying anatomical landmarks, validated\nagainst conventional goniometer measurements. Traditional PD diagnosis often\ninvolves subjective and invasive methods, which can lead to patient discomfort\nand inaccuracies. Our approach offers a precise, reliable, and non-invasive\ndiagnostic tool to address these drawbacks. The model distinguishes between PD\nand normal anatomical changes with a sensitivity of 96.7% and a specificity of\n100%. This advancement represents a significant improvement in urological\ndiagnostics, greatly enhancing the efficacy and convenience of PD assessment\nfor healthcare providers and patients.\n","authors":["Yudara Kularathne","Janitha Prathapa","Prarththanan Sothyrajah","Salomi Arasaratnam","Sithira Ambepitiya","Thanveer Ahamed","Dinuka Wijesundara"],"pdf_url":"https://arxiv.org/pdf/2411.07684v1.pdf","comment":"8 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2305.03989v3","updated":"2024-11-12T09:52:53Z","published":"2023-05-06T09:29:12Z","title":"LEO: Generative Latent Image Animator for Human Video Synthesis","summary":"  Spatio-temporal coherency is a major challenge in synthesizing high quality\nvideos, particularly in synthesizing human videos that contain rich global and\nlocal deformations. To resolve this challenge, previous approaches have\nresorted to different features in the generation process aimed at representing\nappearance and motion. However, in the absence of strict mechanisms to\nguarantee such disentanglement, a separation of motion from appearance has\nremained challenging, resulting in spatial distortions and temporal jittering\nthat break the spatio-temporal coherency. Motivated by this, we here propose\nLEO, a novel framework for human video synthesis, placing emphasis on\nspatio-temporal coherency. Our key idea is to represent motion as a sequence of\nflow maps in the generation process, which inherently isolate motion from\nappearance. We implement this idea via a flow-based image animator and a Latent\nMotion Diffusion Model (LMDM). The former bridges a space of motion codes with\nthe space of flow maps, and synthesizes video frames in a warp-and-inpaint\nmanner. LMDM learns to capture motion prior in the training data by\nsynthesizing sequences of motion codes. Extensive quantitative and qualitative\nanalysis suggests that LEO significantly improves coherent synthesis of human\nvideos over previous methods on the datasets TaichiHD, FaceForensics and\nCelebV-HQ. In addition, the effective disentanglement of appearance and motion\nin LEO allows for two additional tasks, namely infinite-length human video\nsynthesis, as well as content-preserving video editing.\n","authors":["Yaohui Wang","Xin Ma","Xinyuan Chen","Cunjian Chen","Antitza Dantcheva","Bo Dai","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2305.03989v3.pdf","comment":"IJCV 2024, Project webpage: https://wyhsirius.github.io/LEO-project/"},{"id":"http://arxiv.org/abs/2411.03239v2","updated":"2024-11-12T09:46:39Z","published":"2024-11-05T16:37:30Z","title":"Decoupling Fine Detail and Global Geometry for Compressed Depth Map\n  Super-Resolution","summary":"  Recovering high-quality depth maps from compressed sources has gained\nsignificant attention due to the limitations of consumer-grade depth cameras\nand the bandwidth restrictions during data transmission. However, current\nmethods still suffer from two challenges. First, bit-depth compression produces\na uniform depth representation in regions with subtle variations, hindering the\nrecovery of detailed information. Second, densely distributed random noise\nreduces the accuracy of estimating the global geometric structure of the scene.\nTo address these challenges, we propose a novel framework, termed\ngeometry-decoupled network (GDNet), for compressed depth map super-resolution\nthat decouples the high-quality depth map reconstruction process by handling\nglobal and detailed geometric features separately. To be specific, we propose\nthe fine geometry detail encoder (FGDE), which is designed to aggregate fine\ngeometry details in high-resolution low-level image features while\nsimultaneously enriching them with complementary information from\nlow-resolution context-level image features. In addition, we develop the global\ngeometry encoder (GGE) that aims at suppressing noise and extracting global\ngeometric information effectively via constructing compact feature\nrepresentation in a low-rank space. We conduct experiments on multiple\nbenchmark datasets, demonstrating that our GDNet significantly outperforms\ncurrent methods in terms of geometric consistency and detail recovery. In the\nECCV 2024 AIM Compressed Depth Upsampling Challenge, our solution won the 1st\nplace award. Our codes will be available.\n","authors":["Huan Zheng","Wencheng Han","Jianbing Shen"],"pdf_url":"https://arxiv.org/pdf/2411.03239v2.pdf","comment":"The 1st place award for the ECCV 2024 AIM Compressed Depth Upsampling\n  Challenge"},{"id":"http://arxiv.org/abs/2407.21341v3","updated":"2024-11-12T09:41:55Z","published":"2024-07-31T05:15:24Z","title":"High-throughput 3D shape completion of potato tubers on a harvester","summary":"  Potato yield is an important metric for farmers to further optimize their\ncultivation practices. Potato yield can be estimated on a harvester using an\nRGB-D camera that can estimate the three-dimensional (3D) volume of individual\npotato tubers. A challenge, however, is that the 3D shape derived from RGB-D\nimages is only partially completed, underestimating the actual volume. To\naddress this issue, we developed a 3D shape completion network, called CoRe++,\nwhich can complete the 3D shape from RGB-D images. CoRe++ is a deep learning\nnetwork that consists of a convolutional encoder and a decoder. The encoder\ncompresses RGB-D images into latent vectors that are used by the decoder to\ncomplete the 3D shape using the deep signed distance field network (DeepSDF).\nTo evaluate our CoRe++ network, we collected partial and complete 3D point\nclouds of 339 potato tubers on an operational harvester in Japan. On the 1425\nRGB-D images in the test set (representing 51 unique potato tubers), our\nnetwork achieved a completion accuracy of 2.8 mm on average. For volumetric\nestimation, the root mean squared error (RMSE) was 22.6 ml, and this was better\nthan the RMSE of the linear regression (31.1 ml) and the base model (36.9 ml).\nWe found that the RMSE can be further reduced to 18.2 ml when performing the 3D\nshape completion in the center of the RGB-D image. With an average 3D shape\ncompletion time of 10 milliseconds per tuber, we can conclude that CoRe++ is\nboth fast and accurate enough to be implemented on an operational harvester for\nhigh-throughput potato yield estimation. CoRe++'s high-throughput and accurate\nprocessing allows it to be applied to other tuber, fruit and vegetable crops,\nthereby enabling versatile, accurate and real-time yield monitoring in\nprecision agriculture. Our code, network weights and dataset are publicly\navailable at https://github.com/UTokyo-FieldPhenomics-Lab/corepp.git.\n","authors":["Pieter M. Blok","Federico Magistri","Cyrill Stachniss","Haozhou Wang","James Burridge","Wei Guo"],"pdf_url":"https://arxiv.org/pdf/2407.21341v3.pdf","comment":"20 pages, 11 figures, 6 tables"},{"id":"http://arxiv.org/abs/2411.07664v1","updated":"2024-11-12T09:30:02Z","published":"2024-11-12T09:30:02Z","title":"Evaluating the Generation of Spatial Relations in Text and Image\n  Generative Models","summary":"  Understanding spatial relations is a crucial cognitive ability for both\nhumans and AI. While current research has predominantly focused on the\nbenchmarking of text-to-image (T2I) models, we propose a more comprehensive\nevaluation that includes \\textit{both} T2I and Large Language Models (LLMs). As\nspatial relations are naturally understood in a visuo-spatial manner, we\ndevelop an approach to convert LLM outputs into an image, thereby allowing us\nto evaluate both T2I models and LLMs \\textit{visually}. We examined the spatial\nrelation understanding of 8 prominent generative models (3 T2I models and 5\nLLMs) on a set of 10 common prepositions, as well as assess the feasibility of\nautomatic evaluation methods. Surprisingly, we found that T2I models only\nachieve subpar performance despite their impressive general image-generation\nabilities. Even more surprisingly, our results show that LLMs are significantly\nmore accurate than T2I models in generating spatial relations, despite being\nprimarily trained on textual data. We examined reasons for model failures and\nhighlight gaps that can be filled to enable more spatially faithful\ngenerations.\n","authors":["Shang Hong Sim","Clarence Lee","Alvin Tan","Cheston Tan"],"pdf_url":"https://arxiv.org/pdf/2411.07664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07660v1","updated":"2024-11-12T09:22:00Z","published":"2024-11-12T09:22:00Z","title":"HMIL: Hierarchical Multi-Instance Learning for Fine-Grained Whole Slide\n  Image Classification","summary":"  Fine-grained classification of whole slide images (WSIs) is essential in\nprecision oncology, enabling precise cancer diagnosis and personalized\ntreatment strategies. The core of this task involves distinguishing subtle\nmorphological variations within the same broad category of gigapixel-resolution\nimages, which presents a significant challenge. While the multi-instance\nlearning (MIL) paradigm alleviates the computational burden of WSIs, existing\nMIL methods often overlook hierarchical label correlations, treating\nfine-grained classification as a flat multi-class classification task. To\novercome these limitations, we introduce a novel hierarchical multi-instance\nlearning (HMIL) framework. By facilitating on the hierarchical alignment of\ninherent relationships between different hierarchy of labels at instance and\nbag level, our approach provides a more structured and informative learning\nprocess. Specifically, HMIL incorporates a class-wise attention mechanism that\naligns hierarchical information at both the instance and bag levels.\nFurthermore, we introduce supervised contrastive learning to enhance the\ndiscriminative capability for fine-grained classification and a\ncurriculum-based dynamic weighting module to adaptively balance the\nhierarchical feature during training. Extensive experiments on our large-scale\ncytology cervical cancer (CCC) dataset and two public histology datasets, BRACS\nand PANDA, demonstrate the state-of-the-art class-wise and overall performance\nof our HMIL framework. Our source code is available at\nhttps://github.com/ChengJin-git/HMIL.\n","authors":["Cheng Jin","Luyang Luo","Huangjing Lin","Jun Hou","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07660v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.12183v2","updated":"2024-11-12T09:14:03Z","published":"2024-10-16T03:01:44Z","title":"TransAgent: Transfer Vision-Language Foundation Models with\n  Heterogeneous Agent Collaboration","summary":"  Vision-language foundation models (such as CLIP) have recently shown their\npower in transfer learning, owing to large-scale image-text pre-training.\nHowever, target domain data in the downstream tasks can be highly different\nfrom the pre-training phase, which makes it hard for such a single model to\ngeneralize well. Alternatively, there exists a wide range of expert models that\ncontain diversified vision and/or language knowledge pre-trained on different\nmodalities, tasks, networks, and datasets. Unfortunately, these models are\n\"isolated agents\" with heterogeneous structures, and how to integrate their\nknowledge for generalizing CLIP-like models has not been fully explored. To\nbridge this gap, we propose a general and concise TransAgent framework, which\ntransports the knowledge of the isolated agents in a unified manner, and\neffectively guides CLIP to generalize with multi-source knowledge distillation.\nWith such a distinct framework, we flexibly collaborate with 11 heterogeneous\nagents to empower vision-language foundation models, without further cost in\nthe inference phase. Finally, our TransAgent achieves state-of-the-art\nperformance on 11 visual recognition datasets. Under the same low-shot setting,\nit outperforms the popular CoOp with around 10% on average, and 20% on EuroSAT\nwhich contains large domain shifts.\n","authors":["Yiwei Guo","Shaobin Zhuang","Kunchang Li","Yu Qiao","Yali Wang"],"pdf_url":"https://arxiv.org/pdf/2410.12183v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07650v1","updated":"2024-11-12T09:02:11Z","published":"2024-11-12T09:02:11Z","title":"Understanding Audiovisual Deepfake Detection: Techniques, Challenges,\n  Human Factors and Perceptual Insights","summary":"  Deep Learning has been successfully applied in diverse fields, and its impact\non deepfake detection is no exception. Deepfakes are fake yet realistic\nsynthetic content that can be used deceitfully for political impersonation,\nphishing, slandering, or spreading misinformation. Despite extensive research\non unimodal deepfake detection, identifying complex deepfakes through joint\nanalysis of audio and visual streams remains relatively unexplored. To fill\nthis gap, this survey first provides an overview of audiovisual deepfake\ngeneration techniques, applications, and their consequences, and then provides\na comprehensive review of state-of-the-art methods that combine audio and\nvisual modalities to enhance detection accuracy, summarizing and critically\nanalyzing their strengths and limitations. Furthermore, we discuss existing\nopen source datasets for a deeper understanding, which can contribute to the\nresearch community and provide necessary information to beginners who want to\nanalyze deep learning-based audiovisual methods for video forensics. By\nbridging the gap between unimodal and multimodal approaches, this paper aims to\nimprove the effectiveness of deepfake detection strategies and guide future\nresearch in cybersecurity and media integrity.\n","authors":["Ammarah Hashmi","Sahibzada Adil Shahzad","Chia-Wen Lin","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07650v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12866v2","updated":"2024-11-12T08:59:30Z","published":"2024-04-19T13:05:37Z","title":"How Does the Textual Information Affect the Retrieval of Multimodal\n  In-Context Learning?","summary":"  The increase in parameter size of multimodal large language models (MLLMs)\nintroduces significant capabilities, particularly in-context learning, where\nMLLMs enhance task performance without updating pre-trained parameters. This\neffectiveness, however, hinges on the appropriate selection of in-context\nexamples, a process that is currently biased towards visual data, overlooking\ntextual information. Furthermore, the area of supervised retrievers for MLLMs,\ncrucial for optimal in-context example selection, continues to be\nuninvestigated. Our study offers an in-depth evaluation of the impact of\ntextual information on the unsupervised selection of in-context examples in\nmultimodal contexts, uncovering a notable sensitivity of retriever performance\nto the employed modalities. Responding to this, we introduce a novel supervised\nMLLM-retriever MSIER that employs a neural network to select examples that\nenhance multimodal in-context learning efficiency. This approach is validated\nthrough extensive testing across three distinct tasks, demonstrating the\nmethod's effectiveness. Additionally, we investigate the influence of\nmodalities on our supervised retrieval method's training and pinpoint factors\ncontributing to our model's success. This exploration paves the way for future\nadvancements, highlighting the potential for refined in-context learning in\nMLLMs through the strategic use of multimodal data.\n","authors":["Yang Luo","Zangwei Zheng","Zirui Zhu","Yang You"],"pdf_url":"https://arxiv.org/pdf/2404.12866v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.07649v1","updated":"2024-11-12T08:57:21Z","published":"2024-11-12T08:57:21Z","title":"Maritime Search and Rescue Missions with Aerial Images: A Survey","summary":"  The speed of response by search and rescue teams at sea is of vital\nimportance, as survival may depend on it. Recent technological advancements\nhave led to the development of more efficient systems for locating individuals\ninvolved in a maritime incident, such as the use of Unmanned Aerial Vehicles\n(UAVs) equipped with cameras and other integrated sensors. Over the past\ndecade, several researchers have contributed to the development of automatic\nsystems capable of detecting people using aerial images, particularly by\nleveraging the advantages of deep learning. In this article, we provide a\ncomprehensive review of the existing literature on this topic. We analyze the\nmethods proposed to date, including both traditional techniques and more\nadvanced approaches based on machine learning and neural networks.\nAdditionally, we take into account the use of synthetic data to cover a wider\nrange of scenarios without the need to deploy a team to collect data, which is\none of the major obstacles for these systems. Overall, this paper situates the\nreader in the field of detecting people at sea using aerial images by quickly\nidentifying the most suitable methodology for each scenario, as well as\nproviding an in-depth discussion and direction for future trends.\n","authors":["Juan P. Martinez-Esteso","Francisco J. Castellanos","Jorge Calvo-Zaragoza","Antonio Javier Gallego"],"pdf_url":"https://arxiv.org/pdf/2411.07649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07643v1","updated":"2024-11-12T08:53:49Z","published":"2024-11-12T08:53:49Z","title":"xCG: Explainable Cell Graphs for Survival Prediction in Non-Small Cell\n  Lung Cancer","summary":"  Understanding how deep learning models predict oncology patient risk can\nprovide critical insights into disease progression, support clinical\ndecision-making, and pave the way for trustworthy and data-driven precision\nmedicine. Building on recent advances in the spatial modeling of the tumor\nmicroenvironment using graph neural networks, we present an explainable cell\ngraph (xCG) approach for survival prediction. We validate our model on a public\ncohort of imaging mass cytometry (IMC) data for 416 cases of lung\nadenocarcinoma. We explain survival predictions in terms of known phenotypes on\nthe cell level by computing risk attributions over cell graphs, for which we\npropose an efficient grid-based layer-wise relevance propagation (LRP) method.\nOur ablation studies highlight the importance of incorporating the cancer stage\nand model ensembling to improve the quality of risk estimates. Our xCG method,\ntogether with the IMC data, is made publicly available to support further\nresearch.\n","authors":["Marvin Sextro","Gabriel Dernbach","Kai Standvoss","Simon Schallenberg","Frederick Klauschen","Klaus-Robert Müller","Maximilian Alber","Lukas Ruff"],"pdf_url":"https://arxiv.org/pdf/2411.07643v1.pdf","comment":"Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 11 pages"},{"id":"http://arxiv.org/abs/2411.06236v2","updated":"2024-11-12T08:51:40Z","published":"2024-11-09T17:36:53Z","title":"Zero-Shot NAS via the Suppression of Local Entropy Decrease","summary":"  Architecture performance evaluation is the most time-consuming part of neural\narchitecture search (NAS). Zero-Shot NAS accelerates the evaluation by\nutilizing zero-cost proxies instead of training. Though effective, existing\nzero-cost proxies require invoking backpropagations or running networks on\ninput data, making it difficult to further accelerate the computation of\nproxies. To alleviate this issue, architecture topologies are used to evaluate\nthe performance of networks in this study. We prove that particular\narchitectural topologies decrease the local entropy of feature maps, which\ndegrades specific features to a bias, thereby reducing network performance.\nBased on this proof, architectural topologies are utilized to quantify the\nsuppression of local entropy decrease (SED) as a data-free and running-free\nproxy. Experimental results show that SED outperforms most state-of-the-art\nproxies in terms of architecture selection on five benchmarks, with computation\ntime reduced by three orders of magnitude. We further compare the SED-based NAS\nwith state-of-the-art proxies. SED-based NAS selects the architecture with\nhigher accuracy and fewer parameters in only one second. The theoretical\nanalyses of local entropy and experimental results demonstrate that the\nsuppression of local entropy decrease facilitates selecting optimal\narchitectures in Zero-Shot NAS.\n","authors":["Ning Wu","Han Huang","Yueting Xu","Zhifeng Hao"],"pdf_url":"https://arxiv.org/pdf/2411.06236v2.pdf","comment":"8 pages, 2 figures. Corrected typos and latex template"},{"id":"http://arxiv.org/abs/2410.05814v2","updated":"2024-11-12T08:50:59Z","published":"2024-10-08T08:44:01Z","title":"CALoR: Towards Comprehensive Model Inversion Defense","summary":"  Model Inversion Attacks (MIAs) aim at recovering privacy-sensitive training\ndata from the knowledge encoded in the released machine learning models. Recent\nadvances in the MIA field have significantly enhanced the attack performance\nunder multiple scenarios, posing serious privacy risks of Deep Neural Networks\n(DNNs). However, the development of defense strategies against MIAs is\nrelatively backward to resist the latest MIAs and existing defenses fail to\nachieve further trade-off between model utility and model robustness. In this\npaper, we provide an in-depth analysis from the perspective of intrinsic\nvulnerabilities of MIAs, comprehensively uncovering the weaknesses inherent in\nthe basic pipeline, which are partially investigated in the previous defenses.\nBuilding upon these new insights, we propose a robust defense mechanism,\nintegrating Confidence Adaptation and Low-Rank compression(CALoR). Our method\nincludes a novel robustness-enhanced classification loss specially-designed for\nmodel inversion defenses and reveals the extraordinary effectiveness of\ncompressing the classification header. With CALoR, we can mislead the\noptimization objective, reduce the leaked information and impede the\nbackpropagation of MIAs, thus mitigating the risk of privacy leakage. Extensive\nexperimental results demonstrate that our method achieves state-of-the-art\n(SOTA) defense performance against MIAs and exhibits superior generalization to\nexisting defenses across various scenarios.\n","authors":["Hongyao Yu","Yixiang Qiu","Hao Fang","Bin Chen","Sijin Yu","Bin Wang","Shu-Tao Xia","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2410.05814v2.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2410.20806v3","updated":"2024-11-12T08:44:12Z","published":"2024-10-28T07:54:07Z","title":"Transformer-Based Tooth Alignment Prediction With Occlusion And\n  Collision Constraints","summary":"  The planning of digital orthodontic treatment requires providing tooth\nalignment, which not only consumes a lot of time and labor to determine\nmanually but also relays clinical experiences heavily. In this work, we\nproposed a lightweight tooth alignment neural network based on\nSwin-transformer. We first re-organized 3D point clouds based on virtual arch\nlines and converted them into order-sorted multi-channel textures, which\nimproves the accuracy and efficiency simultaneously. We then designed two new\nocclusal loss functions that quantitatively evaluate the occlusal relationship\nbetween the upper and lower jaws. They are important clinical constraints,\nfirst introduced to the best of our knowledge, and lead to cutting-edge\nprediction accuracy. To train our network, we collected a large digital\northodontic dataset that has 591 clinical cases, including various complex\nclinical cases. This dataset will benefit the community after its release since\nthere is no open dataset so far. Furthermore, we also proposed two new\northodontic dataset augmentation methods considering tooth spatial distribution\nand occlusion. We evaluated our method with this dataset and extensive\nexperiments, including comparisons with STAT methods and ablation studies, and\ndemonstrate the high prediction accuracy of our method.\n","authors":["ZhenXing Dong","JiaZhou Chen","YangHui Xu"],"pdf_url":"https://arxiv.org/pdf/2410.20806v3.pdf","comment":"Modify formatting errors, optimize content layout"},{"id":"http://arxiv.org/abs/2408.09984v2","updated":"2024-11-12T08:33:22Z","published":"2024-08-19T13:32:51Z","title":"Boosting Open-Domain Continual Learning via Leveraging Intra-domain\n  Category-aware Prototype","summary":"  Despite recent progress in enhancing the efficacy of Open-Domain Continual\nLearning (ODCL) in Vision-Language Models (VLM), failing to (1) correctly\nidentify the Task-ID of a test image and (2) use only the category set\ncorresponding to the Task-ID, while preserving the knowledge related to each\ndomain, cannot address the two primary challenges of ODCL: forgetting old\nknowledge and maintaining zero-shot capabilities, as well as the confusions\ncaused by category-relatedness between domains. In this paper, we propose a\nsimple yet effective solution: leveraging intra-domain category-aware\nprototypes for ODCL in CLIP (DPeCLIP), where the prototype is the key to\nbridging the above two processes. Concretely, we propose a training-free\nTask-ID discriminator method, by utilizing prototypes as classifiers for\nidentifying Task-IDs. Furthermore, to maintain the knowledge corresponding to\neach domain, we incorporate intra-domain category-aware prototypes as domain\nprior prompts into the training process. Extensive experiments conducted on 11\ndifferent datasets demonstrate the effectiveness of our approach, achieving\n2.37% and 1.14% average improvement in class-incremental and task-incremental\nsettings, respectively.\n","authors":["Yadong Lu","Shitian Zhao","Boxiang Yun","Dongsheng Jiang","Yin Li","Qingli Li","Yan Wang"],"pdf_url":"https://arxiv.org/pdf/2408.09984v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07635v1","updated":"2024-11-12T08:30:59Z","published":"2024-11-12T08:30:59Z","title":"Breaking the Low-Rank Dilemma of Linear Attention","summary":"  The Softmax attention mechanism in Transformer models is notoriously\ncomputationally expensive, particularly due to its quadratic complexity, posing\nsignificant challenges in vision applications. In contrast, linear attention\nprovides a far more efficient solution by reducing the complexity to linear\nlevels. However, compared to Softmax attention, linear attention often\nexperiences significant performance degradation. Our experiments indicate that\nthis performance drop is due to the low-rank nature of linear attention's\nfeature map, which hinders its ability to adequately model complex spatial\ninformation. In this paper, to break the low-rank dilemma of linear attention,\nwe conduct rank analysis from two perspectives: the KV buffer and the output\nfeatures. Consequently, we introduce Rank-Augmented Linear Attention (RALA),\nwhich rivals the performance of Softmax attention while maintaining linear\ncomplexity and high efficiency. Based on RALA, we construct the Rank-Augmented\nVision Linear Transformer (RAVLT). Extensive experiments demonstrate that RAVLT\nachieves excellent performance across various vision tasks. Specifically,\nwithout using any additional labels, data, or supervision during training,\nRAVLT achieves an 84.4% Top-1 accuracy on ImageNet-1k with only 26M parameters\nand 4.6G FLOPs. This result significantly surpasses previous linear attention\nmechanisms, fully illustrating the potential of RALA. Code will be available at\nhttps://github.com/qhfan/RALA.\n","authors":["Qihang Fan","Huaibo Huang","Ran He"],"pdf_url":"https://arxiv.org/pdf/2411.07635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05128v2","updated":"2024-11-12T08:24:47Z","published":"2024-07-06T16:34:25Z","title":"SCSA: Exploring the Synergistic Effects Between Spatial and Channel\n  Attention","summary":"  Channel and spatial attentions have respectively brought significant\nimprovements in extracting feature dependencies and spatial structure relations\nfor various downstream vision tasks. While their combination is more beneficial\nfor leveraging their individual strengths, the synergy between channel and\nspatial attentions has not been fully explored, lacking in fully harness the\nsynergistic potential of multi-semantic information for feature guidance and\nmitigation of semantic disparities. Our study attempts to reveal the\nsynergistic relationship between spatial and channel attention at multiple\nsemantic levels, proposing a novel Spatial and Channel Synergistic Attention\nmodule (SCSA). Our SCSA consists of two parts: the Shareable Multi-Semantic\nSpatial Attention (SMSA) and the Progressive Channel-wise Self-Attention\n(PCSA). SMSA integrates multi-semantic information and utilizes a progressive\ncompression strategy to inject discriminative spatial priors into PCSA's\nchannel self-attention, effectively guiding channel recalibration.\nAdditionally, the robust feature interactions based on the self-attention\nmechanism in PCSA further mitigate the disparities in multi-semantic\ninformation among different sub-features within SMSA. We conduct extensive\nexperiments on seven benchmark datasets, including classification on\nImageNet-1K, object detection on MSCOCO 2017, segmentation on ADE20K, and four\nother complex scene detection datasets. Our results demonstrate that our\nproposed SCSA not only surpasses the current state-of-the-art attention but\nalso exhibits enhanced generalization capabilities across various task\nscenarios. The code and models are available at:\nhttps://github.com/HZAI-ZJNU/SCSA.\n","authors":["Yunzhong Si","Huiying Xu","Xinzhong Zhu","Wenhao Zhang","Yao Dong","Yuxing Chen","Hongbo Li"],"pdf_url":"https://arxiv.org/pdf/2407.05128v2.pdf","comment":"We added experiments for the classification task and updated the\n  corresponding sections accordingly. The paper formatting has also been\n  revised"},{"id":"http://arxiv.org/abs/2411.07627v1","updated":"2024-11-12T08:17:15Z","published":"2024-11-12T08:17:15Z","title":"Leveraging Previous Steps: A Training-free Fast Solver for Flow\n  Diffusion","summary":"  Flow diffusion models (FDMs) have recently shown potential in generation\ntasks due to the high generation quality. However, the current ordinary\ndifferential equation (ODE) solver for FDMs, e.g., the Euler solver, still\nsuffers from slow generation since ODE solvers need many number function\nevaluations (NFE) to keep high-quality generation. In this paper, we propose a\nnovel training-free flow-solver to reduce NFE while maintaining high-quality\ngeneration. The key insight for the flow-solver is to leverage the previous\nsteps to reduce the NFE, where a cache is created to reuse these results from\nthe previous steps. Specifically, the Taylor expansion is first used to\napproximate the ODE. To calculate the high-order derivatives of Taylor\nexpansion, the flow-solver proposes to use the previous steps and a polynomial\ninterpolation to approximate it, where the number of orders we could\napproximate equals the number of previous steps we cached. We also prove that\nthe flow-solver has a more minor approximation error and faster generation\nspeed. Experimental results on the CIFAR-10, CelebA-HQ, LSUN-Bedroom,\nLSUN-Church, ImageNet, and real text-to-image generation prove the efficiency\nof the flow-solver. Specifically, the flow-solver improves the FID-30K from\n13.79 to 6.75, from 46.64 to 19.49 with $\\text{NFE}=10$ on CIFAR-10 and\nLSUN-Church, respectively.\n","authors":["Kaiyu Song","Hanjiang Lai"],"pdf_url":"https://arxiv.org/pdf/2411.07627v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07625v1","updated":"2024-11-12T08:14:39Z","published":"2024-11-12T08:14:39Z","title":"Unraveling the Connections between Flow Matching and Diffusion\n  Probabilistic Models in Training-free Conditional Generation","summary":"  Training-free conditional generation aims to leverage the unconditional\ndiffusion models to implement the conditional generation, where flow-matching\n(FM) and diffusion probabilistic models (DPMs) are two mature unconditional\ndiffusion models that achieve high-quality generation. Two questions were asked\nin this paper: What are the underlying connections between FM and DPMs in\ntraining-free conditional generation? Can we leverage DPMs to improve the\ntraining-free conditional generation for FM? We first show that a probabilistic\ndiffusion path can be associated with the FM and DPMs. Then, we reformulate the\nordinary differential equation (ODE) of FM based on the score function of DPMs,\nand thus, the conditions in FM can be incorporated as those in DPMs. Finally,\nwe propose two posterior sampling methods to estimate the conditional term and\nachieve a training-free conditional generation of FM. Experimental results show\nthat our proposed method could be implemented for various conditional\ngeneration tasks. Our method can generate higher-quality results than the\nstate-of-the-art methods.\n","authors":["Kaiyu Song","Hanjiang Lai"],"pdf_url":"https://arxiv.org/pdf/2411.07625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07621v1","updated":"2024-11-12T08:08:31Z","published":"2024-11-12T08:08:31Z","title":"Mix from Failure: Confusion-Pairing Mixup for Long-Tailed Recognition","summary":"  Long-tailed image recognition is a computer vision problem considering a\nreal-world class distribution rather than an artificial uniform. Existing\nmethods typically detour the problem by i) adjusting a loss function, ii)\ndecoupling classifier learning, or iii) proposing a new multi-head architecture\ncalled experts. In this paper, we tackle the problem from a different\nperspective to augment a training dataset to enhance the sample diversity of\nminority classes. Specifically, our method, namely Confusion-Pairing Mixup\n(CP-Mix), estimates the confusion distribution of the model and handles the\ndata deficiency problem by augmenting samples from confusion pairs in\nreal-time. In this way, CP-Mix trains the model to mitigate its weakness and\ndistinguish a pair of classes it frequently misclassifies. In addition, CP-Mix\nutilizes a novel mixup formulation to handle the bias in decision boundaries\nthat originated from the imbalanced dataset. Extensive experiments demonstrate\nthat CP-Mix outperforms existing methods for long-tailed image recognition and\nsuccessfully relieves the confusion of the classifier.\n","authors":["Youngseok Yoon","Sangwoo Hong","Hyungjoon Joo","Yao Qin","Haewon Jeong","Jungwoo Lee"],"pdf_url":"https://arxiv.org/pdf/2411.07621v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07619v1","updated":"2024-11-12T08:05:58Z","published":"2024-11-12T08:05:58Z","title":"Artificial Intelligence for Biomedical Video Generation","summary":"  As a prominent subfield of Artificial Intelligence Generated Content (AIGC),\nvideo generation has achieved notable advancements in recent years. The\nintroduction of Sora-alike models represents a pivotal breakthrough in video\ngeneration technologies, significantly enhancing the quality of synthesized\nvideos. Particularly in the realm of biomedicine, video generation technology\nhas shown immense potential such as medical concept explanation, disease\nsimulation, and biomedical data augmentation. In this article, we thoroughly\nexamine the latest developments in video generation models and explore their\napplications, challenges, and future opportunities in the biomedical sector. We\nhave conducted an extensive review and compiled a comprehensive list of\ndatasets from various sources to facilitate the development and evaluation of\nvideo generative models in biomedicine. Given the rapid progress in this field,\nwe have also created a github repository to regularly update the advances of\nbiomedical video generation at:\nhttps://github.com/Lee728243228/Biomedical-Video-Generation\n","authors":["Linyuan Li","Jianing Qiu","Anujit Saha","Lin Li","Poyuan Li","Mengxian He","Ziyu Guo","Wu Yuan"],"pdf_url":"https://arxiv.org/pdf/2411.07619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.18252v2","updated":"2024-11-12T08:01:04Z","published":"2024-04-28T17:18:41Z","title":"Improving Training-free Conditional Diffusion Model via Fisher\n  Information","summary":"  Training-free conditional diffusion models have received great attention in\nconditional image generation tasks. However, they require a computationally\nexpensive conditional score estimator to let the intermediate results of each\nstep in the reverse process toward the condition, which causes slow conditional\ngeneration. In this paper, we propose a novel Fisher information-based\nconditional diffusion (FICD) model to generate high-quality samples according\nto the condition. In particular, we further explore the conditional term from\nthe perspective of Fisher information, where we show Fisher information can act\nas a weight to measure the informativeness of the condition in each generation\nstep. According to this new perspective, we can control and gain more\ninformation along the conditional direction in the generation space. Thus, we\npropose the upper bound of the Fisher information to reformulate the\nconditional term, which increases the information gain and decreases the time\ncost. Experimental results also demonstrate that the proposed FICD can offer up\nto 2x speed-ups under the same sampling steps as most baselines. Meanwhile,\nFICD can improve the generation quality in various tasks compared to the\nbaselines with a low computation cost.\n","authors":["Kaiyu Song","Hanjiang Lai"],"pdf_url":"https://arxiv.org/pdf/2404.18252v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.16131v2","updated":"2024-11-12T07:55:34Z","published":"2024-01-29T12:56:11Z","title":"CIMIL-CRC: a clinically-informed multiple instance learning framework\n  for patient-level colorectal cancer molecular subtypes classification from\n  H\\&E stained images","summary":"  Treatment approaches for colorectal cancer (CRC) are highly dependent on the\nmolecular subtype, as immunotherapy has shown efficacy in cases with\nmicrosatellite instability (MSI) but is ineffective for the microsatellite\nstable (MSS) subtype. There is promising potential in utilizing deep neural\nnetworks (DNNs) to automate the differentiation of CRC subtypes by analyzing\nHematoxylin and Eosin (H\\&E) stained whole-slide images (WSIs). Due to the\nextensive size of WSIs, Multiple Instance Learning (MIL) techniques are\ntypically explored. However, existing MIL methods focus on identifying the most\nrepresentative image patches for classification, which may result in the loss\nof critical information. Additionally, these methods often overlook clinically\nrelevant information, like the tendency for MSI class tumors to predominantly\noccur on the proximal (right side) colon. We introduce `CIMIL-CRC', a DNN\nframework that: 1) solves the MSI/MSS MIL problem by efficiently combining a\npre-trained feature extraction model with principal component analysis (PCA) to\naggregate information from all patches, and 2) integrates clinical priors,\nparticularly the tumor location within the colon, into the model to enhance\npatient-level classification accuracy. We assessed our CIMIL-CRC method using\nthe average area under the curve (AUC) from a 5-fold cross-validation\nexperimental setup for model development on the TCGA-CRC-DX cohort, contrasting\nit with a baseline patch-level classification, MIL-only approach, and\nClinically-informed patch-level classification approach. Our CIMIL-CRC\noutperformed all methods (AUROC: $0.92\\pm0.002$ (95\\% CI 0.91-0.92), vs.\n$0.79\\pm0.02$ (95\\% CI 0.76-0.82), $0.86\\pm0.01$ (95\\% CI 0.85-0.88), and\n$0.87\\pm0.01$ (95\\% CI 0.86-0.88), respectively). The improvement was\nstatistically significant.\n","authors":["Hadar Hezi","Matan Gelber","Alexander Balabanov","Yosef E. Maruvka","Moti Freiman"],"pdf_url":"https://arxiv.org/pdf/2401.16131v2.pdf","comment":"Accepted to the journal 'Computer Methods and Programs in\n  Biomedicine'"},{"id":"http://arxiv.org/abs/2406.18054v2","updated":"2024-11-12T07:52:42Z","published":"2024-06-26T04:12:34Z","title":"Leveraging Pre-trained Models for FF-to-FFPE Histopathological Image\n  Translation","summary":"  The two primary types of Hematoxylin and Eosin (H&E) slides in histopathology\nare Formalin-Fixed Paraffin-Embedded (FFPE) and Fresh Frozen (FF). FFPE slides\noffer high quality histopathological images but require a labor-intensive\nacquisition process. In contrast, FF slides can be prepared quickly, but the\nimage quality is relatively poor. Our task is to translate FF images into FFPE\nstyle, thereby improving the image quality for diagnostic purposes. In this\npaper, we propose Diffusion-FFPE, a method for FF-to-FFPE histopathological\nimage translation using a pre-trained diffusion model. Specifically, we employ\na one-step diffusion model as the generator and fine-tune it with LoRA adapters\nusing adversarial learning objectives. To ensure that the model effectively\ncaptures both global structural information and local details, we propose a\nmulti-scale feature fusion (MFF) module. This module utilizes two VAE encoders\nto extract features of varying image sizes and performs feature fusion before\nfeeding them into the UNet. Furthermore, we utilize a pre-trained\nvision-language model for histopathology as the backbone for the discriminator\nto further improve performance We conducted FF-to-FFPE translation experiments\non the TCGA-NSCLC datasets, and our method achieved better performance compared\nto other methods. The code and models are released at\nhttps://github.com/QilaiZhang/Diffusion-FFPE.\n","authors":["Qilai Zhang","Jiawen Li","Peiran Liao","Jiali Hu","Tian Guan","Anjia Han","Yonghong He"],"pdf_url":"https://arxiv.org/pdf/2406.18054v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07232v2","updated":"2024-11-12T07:49:39Z","published":"2024-11-11T18:50:09Z","title":"Add-it: Training-Free Object Insertion in Images With Pretrained\n  Diffusion Models","summary":"  Adding Object into images based on text instructions is a challenging task in\nsemantic image editing, requiring a balance between preserving the original\nscene and seamlessly integrating the new object in a fitting location. Despite\nextensive efforts, existing models often struggle with this balance,\nparticularly with finding a natural location for adding an object in complex\nscenes. We introduce Add-it, a training-free approach that extends diffusion\nmodels' attention mechanisms to incorporate information from three key sources:\nthe scene image, the text prompt, and the generated image itself. Our weighted\nextended-attention mechanism maintains structural consistency and fine details\nwhile ensuring natural object placement. Without task-specific fine-tuning,\nAdd-it achieves state-of-the-art results on both real and generated image\ninsertion benchmarks, including our newly constructed \"Additing Affordance\nBenchmark\" for evaluating object placement plausibility, outperforming\nsupervised methods. Human evaluations show that Add-it is preferred in over 80%\nof cases, and it also demonstrates improvements in various automated metrics.\n","authors":["Yoad Tewel","Rinon Gal","Dvir Samuel","Yuval Atzmon","Lior Wolf","Gal Chechik"],"pdf_url":"https://arxiv.org/pdf/2411.07232v2.pdf","comment":"Project page is at https://research.nvidia.com/labs/par/addit/"},{"id":"http://arxiv.org/abs/2409.00606v3","updated":"2024-11-12T07:38:51Z","published":"2024-09-01T04:07:03Z","title":"Style Transfer: From Stitching to Neural Networks","summary":"  This article compares two style transfer methods in image processing: the\ntraditional method, which synthesizes new images by stitching together small\npatches from existing images, and a modern machine learning-based approach that\nuses a segmentation network to isolate foreground objects and apply style\ntransfer solely to the background. The traditional method excels in creating\nartistic abstractions but can struggle with seamlessness, whereas the machine\nlearning method preserves the integrity of foreground elements while enhancing\nthe background, offering improved aesthetic quality and computational\nefficiency. Our study indicates that machine learning-based methods are more\nsuited for real-world applications where detail preservation in foreground\nelements is essential.\n","authors":["Xinhe Xu","Zhuoer Wang","Yihan Zhang","Yizhou Liu","Zhaoyue Wang","Zhihao Xu","Muhan Zhao","Huaiying Luo"],"pdf_url":"https://arxiv.org/pdf/2409.00606v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07608v1","updated":"2024-11-12T07:30:32Z","published":"2024-11-12T07:30:32Z","title":"Quantum Information-Empowered Graph Neural Network for Hyperspectral\n  Change Detection","summary":"  Change detection (CD) is a critical remote sensing technique for identifying\nchanges in the Earth's surface over time. The outstanding substance\nidentifiability of hyperspectral images (HSIs) has significantly enhanced the\ndetection accuracy, making hyperspectral change detection (HCD) an essential\ntechnology. The detection accuracy can be further upgraded by leveraging the\ngraph structure of HSIs, motivating us to adopt the graph neural networks\n(GNNs) in solving HCD. For the first time, this work introduces quantum deep\nnetwork (QUEEN) into HCD. Unlike GNN and CNN, both extracting the\naffine-computing features, QUEEN provides fundamentally different\nunitary-computing features. We demonstrate that through the unitary feature\nextraction procedure, QUEEN provides radically new information for deciding\nwhether there is a change or not. Hierarchically, a graph feature learning\n(GFL) module exploits the graph structure of the bitemporal HSIs at the\nsuperpixel level, while a quantum feature learning (QFL) module learns the\nquantum features at the pixel level, as a complementary to GFL by preserving\npixel-level detailed spatial information not retained in the superpixels. In\nthe final classification stage, a quantum classifier is designed to cooperate\nwith a traditional fully connected classifier. The superior HCD performance of\nthe proposed QUEEN-empowered GNN (i.e., QUEEN-G) will be experimentally\ndemonstrated on real hyperspectral datasets.\n","authors":["Chia-Hsiang Lin","Tzu-Hsuan Lin","Jocelyn Chanussot"],"pdf_url":"https://arxiv.org/pdf/2411.07608v1.pdf","comment":"This work has been accepted by IEEE Transactions on Geoscience and\n  Remote Sensing (TGRS)"},{"id":"http://arxiv.org/abs/2411.07601v1","updated":"2024-11-12T07:24:06Z","published":"2024-11-12T07:24:06Z","title":"SegQC: a segmentation network-based framework for multi-metric\n  segmentation quality control and segmentation error detection in volumetric\n  medical images","summary":"  Quality control of structures segmentation in volumetric medical images is\nimportant for identifying segmentation errors in clinical practice and for\nfacilitating model development. This paper introduces SegQC, a novel framework\nfor segmentation quality estimation and segmentation error detection. SegQC\ncomputes an estimate measure of the quality of a segmentation in volumetric\nscans and in their individual slices and identifies possible segmentation error\nregions within a slice. The key components include: 1. SegQC-Net, a deep\nnetwork that inputs a scan and its segmentation mask and outputs segmentation\nerror probabilities for each voxel in the scan; 2. three new segmentation\nquality metrics, two overlap metrics and a structure size metric, computed from\nthe segmentation error probabilities; 3. a new method for detecting possible\nsegmentation errors in scan slices computed from the segmentation error\nprobabilities. We introduce a new evaluation scheme to measure segmentation\nerror discrepancies based on an expert radiologist corrections of automatically\nproduced segmentations that yields smaller observer variability and is closer\nto actual segmentation errors. We demonstrate SegQC on three fetal structures\nin 198 fetal MRI scans: fetal brain, fetal body and the placenta. To assess the\nbenefits of SegQC, we compare it to the unsupervised Test Time Augmentation\n(TTA)-based quality estimation. Our studies indicate that SegQC outperforms\nTTA-based quality estimation in terms of Pearson correlation and MAE for fetal\nbody and fetal brain structures segmentation. Our segmentation error detection\nmethod achieved recall and precision rates of 0.77 and 0.48 for fetal body, and\n0.74 and 0.55 for fetal brain segmentation error detection respectively. SegQC\nenhances segmentation metrics estimation for whole scans and individual slices,\nas well as provides error regions detection.\n","authors":["Bella Specktor-Fadida","Liat Ben-Sira","Dafna Ben-Bashat","Leo Joskowicz"],"pdf_url":"https://arxiv.org/pdf/2411.07601v1.pdf","comment":"28 pages, 9 figures"},{"id":"http://arxiv.org/abs/2404.13565v3","updated":"2024-11-12T07:21:04Z","published":"2024-04-21T07:34:44Z","title":"Exploring Diverse Methods in Visual Question Answering","summary":"  This study explores innovative methods for improving Visual Question\nAnswering (VQA) using Generative Adversarial Networks (GANs), autoencoders, and\nattention mechanisms. Leveraging a balanced VQA dataset, we investigate three\ndistinct strategies. Firstly, GAN-based approaches aim to generate answer\nembeddings conditioned on image and question inputs, showing potential but\nstruggling with more complex tasks. Secondly, autoencoder-based techniques\nfocus on learning optimal embeddings for questions and images, achieving\ncomparable results with GAN due to better ability on complex questions. Lastly,\nattention mechanisms, incorporating Multimodal Compact Bilinear pooling (MCB),\naddress language priors and attention modeling, albeit with a\ncomplexity-performance trade-off. This study underscores the challenges and\nopportunities in VQA and suggests avenues for future research, including\nalternative GAN formulations and attentional mechanisms.\n","authors":["Panfeng Li","Qikai Yang","Xieming Geng","Wenjing Zhou","Zhicheng Ding","Yi Nian"],"pdf_url":"https://arxiv.org/pdf/2404.13565v3.pdf","comment":"Accepted by 2024 5th International Conference on Electronic\n  Communication and Artificial Intelligence"},{"id":"http://arxiv.org/abs/2411.07584v1","updated":"2024-11-12T06:44:24Z","published":"2024-11-12T06:44:24Z","title":"Grounded Video Caption Generation","summary":"  We propose a new task, dataset and model for grounded video caption\ngeneration. This task unifies captioning and object grounding in video, where\nthe objects in the caption are grounded in the video via temporally consistent\nbounding boxes. We introduce the following contributions. First, we present a\ntask definition and a manually annotated test dataset for this task, referred\nto as GROunded Video Caption Generation (GROC). Second, we introduce a\nlarge-scale automatic annotation method leveraging an existing model for\ngrounded still image captioning together with an LLM for summarising\nframe-level captions into temporally consistent captions in video. Furthermore,\nwe prompt the LLM to track by language -- classifying noun phrases from the\nframe-level captions into noun phrases of the video-level generated caption. We\napply this approach to videos from the HowTo100M dataset, which results in a\nnew large-scale training dataset, called HowToGround, with automatically\nannotated captions and spatio-temporally consistent bounding boxes with\ncoherent natural language labels. Third, we introduce a new grounded video\ncaption generation model, called VideoGround, and train the model on the new\nautomatically annotated HowToGround dataset. Finally, results of our\nVideoGround model set the state of the art for the new task of grounded video\ncaption generation. We perform extensive ablations and demonstrate the\nimportance of key technical contributions of our model.\n","authors":["Evangelos Kazakos","Cordelia Schmid","Josef Sivic"],"pdf_url":"https://arxiv.org/pdf/2411.07584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06390v2","updated":"2024-11-12T06:41:21Z","published":"2024-11-10T08:23:27Z","title":"SplatFormer: Point Transformer for Robust 3D Gaussian Splatting","summary":"  3D Gaussian Splatting (3DGS) has recently transformed photorealistic\nreconstruction, achieving high visual fidelity and real-time performance.\nHowever, rendering quality significantly deteriorates when test views deviate\nfrom the camera angles used during training, posing a major challenge for\napplications in immersive free-viewpoint rendering and navigation. In this\nwork, we conduct a comprehensive evaluation of 3DGS and related novel view\nsynthesis methods under out-of-distribution (OOD) test camera scenarios. By\ncreating diverse test cases with synthetic and real-world datasets, we\ndemonstrate that most existing methods, including those incorporating various\nregularization techniques and data-driven priors, struggle to generalize\neffectively to OOD views. To address this limitation, we introduce SplatFormer,\nthe first point transformer model specifically designed to operate on Gaussian\nsplats. SplatFormer takes as input an initial 3DGS set optimized under limited\ntraining views and refines it in a single forward pass, effectively removing\npotential artifacts in OOD test views. To our knowledge, this is the first\nsuccessful application of point transformers directly on 3DGS sets, surpassing\nthe limitations of previous multi-scene training methods, which could handle\nonly a restricted number of input views during inference. Our model\nsignificantly improves rendering quality under extreme novel views, achieving\nstate-of-the-art performance in these challenging scenarios and outperforming\nvarious 3DGS regularization techniques, multi-scene models tailored for sparse\nview synthesis, and diffusion-based frameworks.\n","authors":["Yutong Chen","Marko Mihajlovic","Xiyi Chen","Yiming Wang","Sergey Prokudin","Siyu Tang"],"pdf_url":"https://arxiv.org/pdf/2411.06390v2.pdf","comment":"Code and dataset: https://github.com/ChenYutongTHU/SplatFormer\n  Project page: https://sergeyprokudin.github.io/splatformer/"},{"id":"http://arxiv.org/abs/2406.01956v3","updated":"2024-11-12T06:36:11Z","published":"2024-06-04T04:31:39Z","title":"Enhance Image-to-Image Generation with LLaVA-generated Prompts","summary":"  This paper presents a novel approach to enhance image-to-image generation by\nleveraging the multimodal capabilities of the Large Language and Vision\nAssistant (LLaVA). We propose a framework where LLaVA analyzes input images and\ngenerates textual descriptions, hereinafter LLaVA-generated prompts. These\nprompts, along with the original image, are fed into the image-to-image\ngeneration pipeline. This enriched representation guides the generation process\ntowards outputs that exhibit a stronger resemblance to the input image.\nExtensive experiments demonstrate the effectiveness of LLaVA-generated prompts\nin promoting image similarity. We observe a significant improvement in the\nvisual coherence between the generated and input images compared to traditional\nmethods. Future work will explore fine-tuning LLaVA prompts for increased\ncontrol over the creative process. By providing more specific details within\nthe prompts, we aim to achieve a delicate balance between faithfulness to the\noriginal image and artistic expression in the generated outputs.\n","authors":["Zhicheng Ding","Panfeng Li","Qikai Yang","Siyang Li"],"pdf_url":"https://arxiv.org/pdf/2406.01956v3.pdf","comment":"Accepted by 2024 5th International Conference on Information Science,\n  Parallel and Distributed Systems"},{"id":"http://arxiv.org/abs/2411.07581v1","updated":"2024-11-12T06:33:09Z","published":"2024-11-12T06:33:09Z","title":"Semantic segmentation on multi-resolution optical and microwave data\n  using deep learning","summary":"  Presently, deep learning and convolutional neural networks (CNNs) are widely\nused in the fields of image processing, image classification, object\nidentification and many more. In this work, we implemented convolutional neural\nnetwork based modified U-Net model and VGG-UNet model to automatically identify\nobjects from satellite imagery captured using high resolution Indian remote\nsensing satellites and then to pixel wise classify satellite data into various\nclasses. In this paper, Cartosat 2S (~1m spatial resolution) datasets were used\nand deep learning models were implemented to detect building shapes and ships\nfrom the test datasets with an accuracy of more than 95%. In another\nexperiment, microwave data (varied resolution) from RISAT-1 was taken as an\ninput and ships and trees were detected with an accuracy of >96% from these\ndatasets. For the classification of images into multiple-classes, deep learning\nmodel was trained on multispectral Cartosat images. Model generated results\nwere then tested using ground truth. Multi-label classification results were\nobtained with an accuracy (IoU) of better than 95%. Total six different\nproblems were attempted using deep learning models and IoU accuracies in the\nrange of 85% to 98% were achieved depending on the degree of complexity.\n","authors":["Jai G Singla","Bakul Vaghela"],"pdf_url":"https://arxiv.org/pdf/2411.07581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07579v1","updated":"2024-11-12T06:29:48Z","published":"2024-11-12T06:29:48Z","title":"Projecting Gaussian Ellipsoids While Avoiding Affine Projection\n  Approximation","summary":"  Recently, 3D Gaussian Splatting has dominated novel-view synthesis with its\nreal-time rendering speed and state-of-the-art rendering quality. However,\nduring the rendering process, the use of the Jacobian of the affine\napproximation of the projection transformation leads to inevitable errors,\nresulting in blurriness, artifacts and a lack of scene consistency in the final\nrendered images. To address this issue, we introduce an ellipsoid-based\nprojection method to calculate the projection of Gaussian ellipsoid on the\nimage plane, witch is the primitive of 3D Gaussian Splatting. As our proposed\nellipsoid-based projection method cannot handle Gaussian ellipsoids with camera\norigins inside them or parts lying below $z=0$ plane in the camera space, we\ndesigned a pre-filtering strategy. Experiments over multiple widely adopted\nbenchmark datasets show that using our ellipsoid-based projection method can\nenhance the rendering quality of 3D Gaussian Splatting and its extensions.\n","authors":["Han Qi","Tao Cai","Xiyue Han"],"pdf_url":"https://arxiv.org/pdf/2411.07579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07578v1","updated":"2024-11-12T06:29:35Z","published":"2024-11-12T06:29:35Z","title":"Atmospheric turbulence restoration by diffeomorphic image registration\n  and blind deconvolution","summary":"  A novel approach is presented in this paper to improve images which are\naltered by atmospheric turbulence. Two new algorithms are presented based on\ntwo combinations of a blind deconvolution block, an elastic registration block\nand a temporal filter block. The algorithms are tested on real images acquired\nin the desert in New Mexico by the NATO RTG40 group.\n","authors":["Jerome Gilles","Tristan Dagobert","Carlo De Franchis"],"pdf_url":"https://arxiv.org/pdf/2411.07578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07577v1","updated":"2024-11-12T06:29:27Z","published":"2024-11-12T06:29:27Z","title":"IR image databases generation under target intrinsic thermal variability\n  constraints","summary":"  This paper deals with the problem of infrared image database generation for\nATR assessment purposes. Huge databases are required to have quantitative and\nobjective performance evaluations. We propose a method which superimpose\ntargets and occultants on background under image quality metrics constraints to\ngenerate realistic images. We also propose a method to generate target\nsignatures with intrinsic thermal variability based on 3D models plated with\nreal infrared textures.\n","authors":["Jerome Gilles","Stephane Landeau","Tristan Dagobert","Philippe Chevalier","Christian Bolut"],"pdf_url":"https://arxiv.org/pdf/2411.07577v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2411.06695"},{"id":"http://arxiv.org/abs/2411.07575v1","updated":"2024-11-12T06:29:18Z","published":"2024-11-12T06:29:18Z","title":"Génération de bases de données images IR sous contraintes avec\n  variabilité thermique intrinsèque des cibles","summary":"  In this communication, we propose a method which permits to simulate images\nof targets in infrared imagery by superimposition of vehicle signatures in\nbackground, eventually with occultants. We develop a principle which authorizes\nus to generate different thermal configurations of target signatures. This\nmethod enables us to easily generate huge datasets for ATR algorithms\nperformance evaluation.\n","authors":["Jerome Gilles","Stephane Landeau","Tristan Dagobert","Philippe Chevalier","Christian Bolut"],"pdf_url":"https://arxiv.org/pdf/2411.07575v1.pdf","comment":"in French language, GRETSI Symposium on Signal and Image Processing,\n  Dijon, France, September 2009"},{"id":"http://arxiv.org/abs/2403.06443v2","updated":"2024-11-12T06:11:46Z","published":"2024-03-11T05:29:46Z","title":"Temporal-Mapping Photography for Event Cameras","summary":"  Event cameras, or Dynamic Vision Sensors (DVS) are novel neuromorphic sensors\nthat capture brightness changes as a continuous stream of \"events\" rather than\ntraditional intensity frames. Converting sparse events to dense intensity\nframes faithfully has long been an ill-posed problem. Previous methods have\nprimarily focused on converting events to video in dynamic scenes or with a\nmoving camera. In this paper, for the first time, we realize events to dense\nintensity image conversion using a stationary event camera in static scenes\nwith a transmittance adjustment device for brightness modulation. Different\nfrom traditional methods that mainly rely on event integration, the proposed\nEvent-Based Temporal Mapping Photography (EvTemMap) measures the time of event\nemitting for each pixel. Then, the resulting Temporal Matrix is converted to an\nintensity frame with a temporal mapping neural network. At the hardware level,\nthe proposed EvTemMap is implemented by combining a transmittance adjustment\ndevice with a DVS, named Adjustable Transmittance Dynamic Vision Sensor\n(AT-DVS). Additionally, we collected TemMat dataset under various conditions\nincluding low-light and high dynamic range scenes. The experimental results\nshowcase the high dynamic range, fine-grained details, and high-grayscale\nresolution of the proposed EvTemMap. The code and dataset are available in\nhttps://github.com/YuHanBaozju/EvTemMap\n","authors":["Yuhan Bao","Lei Sun","Yuqin Ma","Kaiwei Wang"],"pdf_url":"https://arxiv.org/pdf/2403.06443v2.pdf","comment":"18 pages, 10 figures, 1 Supplementary materials"},{"id":"http://arxiv.org/abs/2408.15241v2","updated":"2024-11-12T06:08:29Z","published":"2024-08-27T17:59:41Z","title":"GenRec: Unifying Video Generation and Recognition with Diffusion Models","summary":"  Video diffusion models are able to generate high-quality videos by learning\nstrong spatial-temporal priors on large-scale datasets. In this paper, we aim\nto investigate whether such priors derived from a generative process are\nsuitable for video recognition, and eventually joint optimization of generation\nand recognition. Building upon Stable Video Diffusion, we introduce GenRec, the\nfirst unified framework trained with a random-frame conditioning process so as\nto learn generalized spatial-temporal representations. The resulting framework\ncan naturally supports generation and recognition, and more importantly is\nrobust even when visual inputs contain limited information. Extensive\nexperiments demonstrate the efficacy of GenRec for both recognition and\ngeneration. In particular, GenRec achieves competitive recognition performance,\noffering 75.8% and 87.2% accuracy on SSV2 and K400, respectively. GenRec also\nperforms the best on class-conditioned image-to-video generation, achieving\n46.5 and 49.3 FVD scores on SSV2 and EK-100 datasets. Furthermore, GenRec\ndemonstrates extraordinary robustness in scenarios that only limited frames can\nbe observed. Code will be available at https://github.com/wengzejia1/GenRec.\n","authors":["Zejia Weng","Xitong Yang","Zhen Xing","Zuxuan Wu","Yu-Gang Jiang"],"pdf_url":"https://arxiv.org/pdf/2408.15241v2.pdf","comment":"19 pages, 6 figures, 12 tables"},{"id":"http://arxiv.org/abs/2411.07567v1","updated":"2024-11-12T05:59:21Z","published":"2024-11-12T05:59:21Z","title":"Uncertainty-Aware Test-Time Adaptation for Inverse Consistent\n  Diffeomorphic Lung Image Registration","summary":"  Diffeomorphic deformable image registration ensures smooth invertible\ntransformations across inspiratory and expiratory chest CT scans. Yet, in\npractice, deep learning-based diffeomorphic methods struggle to capture large\ndeformations between inspiratory and expiratory volumes, and therefore lack\ninverse consistency. Existing methods also fail to account for model\nuncertainty, which can be useful for improving performance. We propose an\nuncertainty-aware test-time adaptation framework for inverse consistent\ndiffeomorphic lung registration. Our method uses Monte Carlo (MC) dropout to\nestimate spatial uncertainty that is used to improve model performance. We\ntrain and evaluate our method for inspiratory-to-expiratory CT registration on\na large cohort of 675 subjects from the COPDGene study, achieving a higher Dice\nsimilarity coefficient (DSC) between the lung boundaries (0.966) compared to\nboth VoxelMorph (0.953) and TransMorph (0.953). Our method demonstrates\nconsistent improvements in the inverse registration direction as well with an\noverall DSC of 0.966, higher than VoxelMorph (0.958) and TransMorph (0.956).\nPaired t-tests indicate statistically significant improvements.\n","authors":["Muhammad F. A. Chaudhary","Stephanie M. Aguilera","Arie Nakhmani","Joseph M. Reinhardt","Surya P. Bhatt","Sandeep Bodduluri"],"pdf_url":"https://arxiv.org/pdf/2411.07567v1.pdf","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.10839v3","updated":"2024-11-12T05:33:05Z","published":"2024-06-16T08:20:12Z","title":"Reminding Multimodal Large Language Models of Object-aware Knowledge\n  with Retrieved Tags","summary":"  Despite recent advances in the general visual instruction-following ability\nof Multimodal Large Language Models (MLLMs), they still struggle with critical\nproblems when required to provide a precise and detailed response to a visual\ninstruction: (1) failure to identify novel objects or entities, (2) mention of\nnon-existent objects, and (3) neglect of object's attributed details. Intuitive\nsolutions include improving the size and quality of data or using larger\nfoundation models. They show effectiveness in mitigating these issues, but at\nan expensive cost of collecting a vast amount of new data and introducing a\nsignificantly larger model. Standing at the intersection of these approaches,\nwe examine the three object-oriented problems from the perspective of the\nimage-to-text mapping process by the multimodal connector. In this paper, we\nfirst identify the limitations of multimodal connectors stemming from\ninsufficient training data. Driven by this, we propose to enhance the mapping\nwith retrieval-augmented tag tokens, which contain rich object-aware\ninformation such as object names and attributes. With our Tag-grounded visual\ninstruction tuning with retrieval Augmentation (TUNA), we outperform baselines\nthat share the same language model and training data on 12 benchmarks.\nFurthermore, we show the zero-shot capability of TUNA when provided with\nspecific datastores.\n","authors":["Daiqing Qi","Handong Zhao","Zijun Wei","Sheng Li"],"pdf_url":"https://arxiv.org/pdf/2406.10839v3.pdf","comment":"Main Conference at EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.07556v1","updated":"2024-11-12T05:10:32Z","published":"2024-11-12T05:10:32Z","title":"Multi-task Feature Enhancement Network for No-Reference Image Quality\n  Assessment","summary":"  Due to the scarcity of labeled samples in Image Quality Assessment (IQA)\ndatasets, numerous recent studies have proposed multi-task based strategies,\nwhich explore feature information from other tasks or domains to boost the IQA\ntask. Nevertheless, multi-task strategies based No-Reference Image Quality\nAssessment (NR-IQA) methods encounter several challenges. First, existing\nmethods have not explicitly exploited texture details, which significantly\ninfluence the image quality. Second, multi-task methods conventionally\nintegrate features through simple operations such as addition or concatenation,\nthereby diminishing the network's capacity to accurately represent distorted\nfeatures. To tackle these challenges, we introduce a novel multi-task NR-IQA\nframework. Our framework consists of three key components: a high-frequency\nextraction network, a quality estimation network, and a distortion-aware\nnetwork. The high-frequency extraction network is designed to guide the model's\nfocus towards high-frequency information, which is highly related to the\ntexture details. Meanwhile, the distortion-aware network extracts\ndistortion-related features to distinguish different distortion types. To\neffectively integrate features from different tasks, a feature fusion module is\ndeveloped based on an attention mechanism. Empirical results from five standard\nIQA databases confirm that our method not only achieves high performance but\nalso exhibits robust generalization ability.\n","authors":["Li Yu"],"pdf_url":"https://arxiv.org/pdf/2411.07556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07555v1","updated":"2024-11-12T05:09:42Z","published":"2024-11-12T05:09:42Z","title":"GaussianCut: Interactive segmentation via graph cut for 3D Gaussian\n  Splatting","summary":"  We introduce GaussianCut, a new method for interactive multiview segmentation\nof scenes represented as 3D Gaussians. Our approach allows for selecting the\nobjects to be segmented by interacting with a single view. It accepts intuitive\nuser input, such as point clicks, coarse scribbles, or text. Using 3D Gaussian\nSplatting (3DGS) as the underlying scene representation simplifies the\nextraction of objects of interest which are considered to be a subset of the\nscene's Gaussians. Our key idea is to represent the scene as a graph and use\nthe graph-cut algorithm to minimize an energy function to effectively partition\nthe Gaussians into foreground and background. To achieve this, we construct a\ngraph based on scene Gaussians and devise a segmentation-aligned energy\nfunction on the graph to combine user inputs with scene properties. To obtain\nan initial coarse segmentation, we leverage 2D image/video segmentation models\nand further refine these coarse estimates using our graph construction. Our\nempirical evaluations show the adaptability of GaussianCut across a diverse set\nof scenes. GaussianCut achieves competitive performance with state-of-the-art\napproaches for 3D segmentation without requiring any additional\nsegmentation-aware training.\n","authors":["Umangi Jain","Ashkan Mirzaei","Igor Gilitschenski"],"pdf_url":"https://arxiv.org/pdf/2411.07555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07546v1","updated":"2024-11-12T04:50:10Z","published":"2024-11-12T04:50:10Z","title":"Contrastive Language Prompting to Ease False Positives in Medical\n  Anomaly Detection","summary":"  A pre-trained visual-language model, contrastive language-image pre-training\n(CLIP), successfully accomplishes various downstream tasks with text prompts,\nsuch as finding images or localizing regions within the image. Despite CLIP's\nstrong multi-modal data capabilities, it remains limited in specialized\nenvironments, such as medical applications. For this purpose, many CLIP\nvariants-i.e., BioMedCLIP, and MedCLIP-SAMv2-have emerged, but false positives\nrelated to normal regions persist. Thus, we aim to present a simple yet\nimportant goal of reducing false positives in medical anomaly detection. We\nintroduce a Contrastive LAnguage Prompting (CLAP) method that leverages both\npositive and negative text prompts. This straightforward approach identifies\npotential lesion regions by visual attention to the positive prompts in the\ngiven image. To reduce false positives, we attenuate attention on normal\nregions using negative prompts. Extensive experiments with the BMAD dataset,\nincluding six biomedical benchmarks, demonstrate that CLAP method enhances\nanomaly detection performance. Our future plans include developing an automated\nfine prompting method for more practical usage.\n","authors":["YeongHyeon Park","Myung Jin Kim","Hyeong Seok Kim"],"pdf_url":"https://arxiv.org/pdf/2411.07546v1.pdf","comment":"4 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2411.07544v1","updated":"2024-11-12T04:47:32Z","published":"2024-11-12T04:47:32Z","title":"Depthwise Separable Convolutions with Deep Residual Convolutions","summary":"  The recent advancement of edge computing enables researchers to optimize\nvarious deep learning architectures to employ them in edge devices. In this\nstudy, we aim to optimize Xception architecture which is one of the most\npopular deep learning algorithms for computer vision applications. The Xception\narchitecture is highly effective for object detection tasks. However, it comes\nwith a significant computational cost. The computational complexity of Xception\nsometimes hinders its deployment on resource-constrained edge devices. To\naddress this, we propose an optimized Xception architecture tailored for edge\ndevices, aiming for lightweight and efficient deployment. We incorporate the\ndepthwise separable convolutions with deep residual convolutions of the\nXception architecture to develop a small and efficient model for edge devices.\nThe resultant architecture reduces parameters, memory usage, and computational\nload. The proposed architecture is evaluated on the CIFAR 10 object detection\ndataset. The evaluation result of our experiment also shows the proposed\narchitecture is smaller in parameter size and requires less training time while\noutperforming Xception architecture performance.\n","authors":["Md Arid Hasan","Krishno Dey"],"pdf_url":"https://arxiv.org/pdf/2411.07544v1.pdf","comment":"Course Project Report"},{"id":"http://arxiv.org/abs/2411.07541v1","updated":"2024-11-12T04:40:27Z","published":"2024-11-12T04:40:27Z","title":"HiCoM: Hierarchical Coherent Motion for Streamable Dynamic Scene with 3D\n  Gaussian Splatting","summary":"  The online reconstruction of dynamic scenes from multi-view streaming videos\nfaces significant challenges in training, rendering and storage efficiency.\nHarnessing superior learning speed and real-time rendering capabilities, 3D\nGaussian Splatting (3DGS) has recently demonstrated considerable potential in\nthis field. However, 3DGS can be inefficient in terms of storage and prone to\noverfitting by excessively growing Gaussians, particularly with limited views.\nThis paper proposes an efficient framework, dubbed HiCoM, with three key\ncomponents. First, we construct a compact and robust initial 3DGS\nrepresentation using a perturbation smoothing strategy. Next, we introduce a\nHierarchical Coherent Motion mechanism that leverages the inherent non-uniform\ndistribution and local consistency of 3D Gaussians to swiftly and accurately\nlearn motions across frames. Finally, we continually refine the 3DGS with\nadditional Gaussians, which are later merged into the initial 3DGS to maintain\nconsistency with the evolving scene. To preserve a compact representation, an\nequivalent number of low-opacity Gaussians that minimally impact the\nrepresentation are removed before processing subsequent frames. Extensive\nexperiments conducted on two widely used datasets show that our framework\nimproves learning efficiency of the state-of-the-art methods by about $20\\%$\nand reduces the data storage by $85\\%$, achieving competitive free-viewpoint\nvideo synthesis quality but with higher robustness and stability. Moreover, by\nparallel learning multiple frames simultaneously, our HiCoM decreases the\naverage training wall time to $<2$ seconds per frame with negligible\nperformance degradation, substantially boosting real-world applicability and\nresponsiveness.\n","authors":["Qiankun Gao","Jiarui Meng","Chengxiang Wen","Jie Chen","Jian Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07541v1.pdf","comment":"Accepted to NeurIPS 2024; Code is avaliable at\n  https://github.com/gqk/HiCoM"},{"id":"http://arxiv.org/abs/2404.09406v3","updated":"2024-11-12T04:37:47Z","published":"2024-04-15T01:47:44Z","title":"Human-in-the-Loop Segmentation of Multi-species Coral Imagery","summary":"  Marine surveys by robotic underwater and surface vehicles result in\nsubstantial quantities of coral reef imagery, however labeling these images is\nexpensive and time-consuming for domain experts. Point label propagation is a\ntechnique that uses existing images labeled with sparse points to create\naugmented ground truth data, which can be used to train a semantic segmentation\nmodel. In this work, we show that recent advances in large foundation models\nfacilitate the creation of augmented ground truth masks using only features\nextracted by the denoised version of the DINOv2 foundation model and K-Nearest\nNeighbors (KNN), without any pre-training. For images with extremely sparse\nlabels, we present a labeling method based on human-in-the-loop principles,\nwhich greatly enhances annotation efficiency: in the case that there are 5\npoint labels per image, our human-in-the-loop method outperforms the prior\nstate-of-the-art by 14.2% for pixel accuracy and 19.7% for mIoU; and by 8.9%\nand 18.3% if there are 10 point labels. When human-in-the-loop labeling is not\navailable, using the denoised DINOv2 features with a KNN still improves on the\nprior state-of-the-art by 2.7% for pixel accuracy and 5.8% for mIoU (5 grid\npoints). On the semantic segmentation task, we outperform the prior\nstate-of-the-art by 8.8% for pixel accuracy and by 13.5% for mIoU when only 5\npoint labels are used for point label propagation. Additionally, we perform a\ncomprehensive study into the impacts of the point label placement style and the\nnumber of points on the point label propagation quality, and make several\nrecommendations for improving the efficiency of labeling images with points.\n","authors":["Scarlett Raine","Ross Marchant","Brano Kusy","Frederic Maire","Niko Suenderhauf","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2404.09406v3.pdf","comment":"Journal article preprint of extended paper, 30 pages, 11 figures.\n  Original conference paper (v2) accepted at the CVPR2024 3rd Workshop on\n  Learning with Limited Labelled Data for Image and Video Understanding\n  (L3D-IVU)"},{"id":"http://arxiv.org/abs/2407.01523v3","updated":"2024-11-12T04:37:44Z","published":"2024-07-01T17:59:26Z","title":"MMLongBench-Doc: Benchmarking Long-context Document Understanding with\n  Visualizations","summary":"  Understanding documents with rich layouts and multi-modal components is a\nlong-standing and practical task. Recent Large Vision-Language Models (LVLMs)\nhave made remarkable strides in various tasks, particularly in single-page\ndocument understanding (DU). However, their abilities on long-context DU remain\nan open problem. This work presents MMLongBench-Doc, a long-context,\nmulti-modal benchmark comprising 1,062 expert-annotated questions. Distinct\nfrom previous datasets, it is constructed upon 130 lengthy PDF-formatted\ndocuments with an average of 49.4 pages and 20,971 textual tokens. Towards\ncomprehensive evaluation, answers to these questions rely on pieces of evidence\nfrom (1) different sources (text, image, chart, table, and layout structure)\nand (2) various locations (i.e. page number). Moreover, 33.2% of the questions\nare cross-page questions requiring evidence across multiple pages. 22.8% of the\nquestions are designed to be unanswerable for detecting potential\nhallucinations. Experiments on 14 LVLMs demonstrate that long-context DU\ngreatly challenges current models. Notably, the best-performing model, GPT-4o,\nachieves an F1 score of only 42.7%, while the second-best, GPT-4V, scores\n31.4%. Furthermore, 12 LVLMs (all except GPT-4o and GPT-4V) even present worse\nperformance than their LLM counterparts which are fed with lossy-parsed OCR\ndocuments. These results validate the necessity of future research toward more\ncapable long-context LVLMs. Project Page:\nhttps://mayubo2333.github.io/MMLongBench-Doc\n","authors":["Yubo Ma","Yuhang Zang","Liangyu Chen","Meiqi Chen","Yizhu Jiao","Xinze Li","Xinyuan Lu","Ziyu Liu","Yan Ma","Xiaoyi Dong","Pan Zhang","Liangming Pan","Yu-Gang Jiang","Jiaqi Wang","Yixin Cao","Aixin Sun"],"pdf_url":"https://arxiv.org/pdf/2407.01523v3.pdf","comment":"Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Spotlight)"},{"id":"http://arxiv.org/abs/2409.01652v2","updated":"2024-11-12T04:33:26Z","published":"2024-09-03T06:45:22Z","title":"ReKep: Spatio-Temporal Reasoning of Relational Keypoint Constraints for\n  Robotic Manipulation","summary":"  Representing robotic manipulation tasks as constraints that associate the\nrobot and the environment is a promising way to encode desired robot behaviors.\nHowever, it remains unclear how to formulate the constraints such that they are\n1) versatile to diverse tasks, 2) free of manual labeling, and 3) optimizable\nby off-the-shelf solvers to produce robot actions in real-time. In this work,\nwe introduce Relational Keypoint Constraints (ReKep), a visually-grounded\nrepresentation for constraints in robotic manipulation. Specifically, ReKep is\nexpressed as Python functions mapping a set of 3D keypoints in the environment\nto a numerical cost. We demonstrate that by representing a manipulation task as\na sequence of Relational Keypoint Constraints, we can employ a hierarchical\noptimization procedure to solve for robot actions (represented by a sequence of\nend-effector poses in SE(3)) with a perception-action loop at a real-time\nfrequency. Furthermore, in order to circumvent the need for manual\nspecification of ReKep for each new task, we devise an automated procedure that\nleverages large vision models and vision-language models to produce ReKep from\nfree-form language instructions and RGB-D observations. We present system\nimplementations on a wheeled single-arm platform and a stationary dual-arm\nplatform that can perform a large variety of manipulation tasks, featuring\nmulti-stage, in-the-wild, bimanual, and reactive behaviors, all without\ntask-specific data or environment models. Website at\nhttps://rekep-robot.github.io/.\n","authors":["Wenlong Huang","Chen Wang","Yunzhu Li","Ruohan Zhang","Li Fei-Fei"],"pdf_url":"https://arxiv.org/pdf/2409.01652v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09729v2","updated":"2024-11-12T04:19:32Z","published":"2024-10-13T05:19:09Z","title":"MIRAGE: Multimodal Identification and Recognition of Annotations in\n  Indian General Prescriptions","summary":"  Hospitals in India still rely on handwritten medical records despite the\navailability of Electronic Medical Records (EMR), complicating statistical\nanalysis and record retrieval. Handwritten records pose a unique challenge,\nrequiring specialized data for training models to recognize medications and\ntheir recommendation patterns. While traditional handwriting recognition\napproaches employ 2-D LSTMs, recent studies have explored using Multimodal\nLarge Language Models (MLLMs) for OCR tasks. Building on this approach, we\nfocus on extracting medication names and dosages from simulated medical\nrecords. Our methodology MIRAGE (Multimodal Identification and Recognition of\nAnnotations in indian GEneral prescriptions) involves fine-tuning the QWEN VL,\nLLaVA 1.6 and Idefics2 models on 743,118 high resolution simulated medical\nrecord images-fully annotated from 1,133 doctors across India. Our approach\nachieves 82% accuracy in extracting medication names and dosages.\n","authors":["Tavish Mankash","V. S. Chaithanya Kota","Anish De","Praveen Prakash","Kshitij Jadhav"],"pdf_url":"https://arxiv.org/pdf/2410.09729v2.pdf","comment":"5 pages, 9 figures, 3 tables, submitted to ISBI 2025"},{"id":"http://arxiv.org/abs/2404.09227v2","updated":"2024-11-12T04:08:05Z","published":"2024-04-14T12:13:07Z","title":"DreamScape: 3D Scene Creation via Gaussian Splatting joint Correlation\n  Modeling","summary":"  Recent progress in text-to-3D creation has been propelled by integrating the\npotent prior of Diffusion Models from text-to-image generation into the 3D\ndomain. Nevertheless, generating 3D scenes characterized by multiple instances\nand intricate arrangements remains challenging. In this study, we present\nDreamScape, a method for creating highly consistent 3D scenes solely from\ntextual descriptions, leveraging the strong 3D representation capabilities of\nGaussian Splatting and the complex arrangement abilities of large language\nmodels (LLMs). Our approach involves a 3D Gaussian Guide ($3{DG^2}$) for scene\nrepresentation, consisting of semantic primitives (objects) and their spatial\ntransformations and relationships derived directly from text prompts using\nLLMs. This compositional representation allows for local-to-global optimization\nof the entire scene. A progressive scale control is tailored during local\nobject generation, ensuring that objects of different sizes and densities adapt\nto the scene, which addresses training instability issue arising from simple\nblending in the subsequent global optimization stage. To mitigate potential\nbiases of LLM priors, we model collision relationships between objects at the\nglobal level, enhancing physical correctness and overall realism. Additionally,\nto generate pervasive objects like rain and snow distributed extensively across\nthe scene, we introduce a sparse initialization and densification strategy.\nExperiments demonstrate that DreamScape offers high usability and\ncontrollability, enabling the generation of high-fidelity 3D scenes from only\ntext prompts and achieving state-of-the-art performance compared to other\nmethods.\n","authors":["Xuening Yuan","Hongyu Yang","Yueming Zhao","Di Huang"],"pdf_url":"https://arxiv.org/pdf/2404.09227v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17465v3","updated":"2024-11-12T03:27:41Z","published":"2024-03-26T07:55:16Z","title":"LaRE^2: Latent Reconstruction Error Based Method for Diffusion-Generated\n  Image Detection","summary":"  The evolution of Diffusion Models has dramatically improved image generation\nquality, making it increasingly difficult to differentiate between real and\ngenerated images. This development, while impressive, also raises significant\nprivacy and security concerns. In response to this, we propose a novel Latent\nREconstruction error guided feature REfinement method (LaRE^2) for detecting\nthe diffusion-generated images. We come up with the Latent Reconstruction Error\n(LaRE), the first reconstruction-error based feature in the latent space for\ngenerated image detection. LaRE surpasses existing methods in terms of feature\nextraction efficiency while preserving crucial cues required to differentiate\nbetween the real and the fake. To exploit LaRE, we propose an Error-Guided\nfeature REfinement module (EGRE), which can refine the image feature guided by\nLaRE to enhance the discriminativeness of the feature. Our EGRE utilizes an\nalign-then-refine mechanism, which effectively refines the image feature for\ngenerated-image detection from both spatial and channel perspectives. Extensive\nexperiments on the large-scale GenImage benchmark demonstrate the superiority\nof our LaRE^2, which surpasses the best SoTA method by up to 11.9%/12.1%\naverage ACC/AP across 8 different image generators. LaRE also surpasses\nexisting methods in terms of feature extraction cost, delivering an impressive\nspeed enhancement of 8 times. Code is available.\n","authors":["Yunpeng Luo","Junlong Du","Ke Yan","Shouhong Ding"],"pdf_url":"https://arxiv.org/pdf/2403.17465v3.pdf","comment":"CVPR 2024. Code is available at https://github.com/luo3300612/LaRE"},{"id":"http://arxiv.org/abs/2411.07516v1","updated":"2024-11-12T03:25:33Z","published":"2024-11-12T03:25:33Z","title":"SparrowVQE: Visual Question Explanation for Course Content Understanding","summary":"  Visual Question Answering (VQA) research seeks to create AI systems to answer\nnatural language questions in images, yet VQA methods often yield overly\nsimplistic and short answers. This paper aims to advance the field by\nintroducing Visual Question Explanation (VQE), which enhances the ability of\nVQA to provide detailed explanations rather than brief responses and address\nthe need for more complex interaction with visual content. We first created an\nMLVQE dataset from a 14-week streamed video machine learning course, including\n885 slide images, 110,407 words of transcripts, and 9,416 designed\nquestion-answer (QA) pairs. Next, we proposed a novel SparrowVQE, a small 3\nbillion parameters multimodal model. We trained our model with a three-stage\ntraining mechanism consisting of multimodal pre-training (slide images and\ntranscripts feature alignment), instruction tuning (tuning the pre-trained\nmodel with transcripts and QA pairs), and domain fine-tuning (fine-tuning slide\nimage and QA pairs). Eventually, our SparrowVQE can understand and connect\nvisual information using the SigLIP model with transcripts using the Phi-2\nlanguage model with an MLP adapter. Experimental results demonstrate that our\nSparrowVQE achieves better performance in our developed MLVQE dataset and\noutperforms state-of-the-art methods in the other five benchmark VQA datasets.\nThe source code is available at\n\\url{https://github.com/YoushanZhang/SparrowVQE}.\n","authors":["Jialu Li","Manish Kumar Thota","Ruslan Gokhman","Radek Holik","Youshan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07516v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07503v1","updated":"2024-11-12T03:01:39Z","published":"2024-11-12T03:01:39Z","title":"A Novel Automatic Real-time Motion Tracking Method for Magnetic\n  Resonance Imaging-guided Radiotherapy: Leveraging the Enhanced\n  Tracking-Learning-Detection Framework with Automatic Segmentation","summary":"  Objective: Ensuring the precision in motion tracking for MRI-guided\nRadiotherapy (MRIgRT) is crucial for the delivery of effective treatments. This\nstudy refined the motion tracking accuracy in MRIgRT through the innovation of\nan automatic real-time tracking method, leveraging an enhanced\nTracking-Learning-Detection (ETLD) framework coupled with automatic\nsegmentation. Methods: We developed a novel MRIgRT motion tracking method by\nintegrating two primary methods: the ETLD framework and an improved Chan-Vese\nmodel (ICV), named ETLD+ICV. The TLD framework was upgraded to suit real-time\ncine MRI, including advanced image preprocessing, no-reference image quality\nassessment, an enhanced median-flow tracker, and a refined detector with\ndynamic search region adjustments. Additionally, ICV was combined for precise\ncoverage of the target volume, which refined the segmented region frame by\nframe using tracking results, with key parameters optimized. Tested on 3.5D MRI\nscans from 10 patients with liver metastases, our method ensures precise\ntracking and accurate segmentation vital for MRIgRT. Results: An evaluation of\n106,000 frames across 77 treatment fractions revealed sub-millimeter tracking\nerrors of less than 0.8mm, with over 99% precision and 98% recall for all\nsubjects, underscoring the robustness and efficacy of the ETLD. Moreover, the\nETLD+ICV yielded a dice global score of more than 82% for all subjects,\ndemonstrating the proposed method's extensibility and precise target volume\ncoverage. Conclusions: This study successfully developed an automatic real-time\nmotion tracking method for MRIgRT that markedly surpasses current methods. The\nnovel method not only delivers exceptional precision in tracking and\nsegmentation but also demonstrates enhanced adaptability to clinical demands,\npositioning it as an indispensable asset in the quest to augment the efficacy\nof radiotherapy treatments.\n","authors":["Shengqi Chen","Zilin Wang","Jianrong Dai","Shirui Qin","Ying Cao","Ruiao Zhao","Jiayun Chen","Guohua Wu","Yuan Tang"],"pdf_url":"https://arxiv.org/pdf/2411.07503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.15364v2","updated":"2024-11-12T03:00:07Z","published":"2023-12-23T22:27:40Z","title":"WildScenes: A Benchmark for 2D and 3D Semantic Segmentation in\n  Large-scale Natural Environments","summary":"  Recent progress in semantic scene understanding has primarily been enabled by\nthe availability of semantically annotated bi-modal (camera and LiDAR) datasets\nin urban environments. However, such annotated datasets are also needed for\nnatural, unstructured environments to enable semantic perception for\napplications, including conservation, search and rescue, environment\nmonitoring, and agricultural automation. Therefore, we introduce $WildScenes$,\na bi-modal benchmark dataset consisting of multiple large-scale, sequential\ntraversals in natural environments, including semantic annotations in\nhigh-resolution 2D images and dense 3D LiDAR point clouds, and accurate 6-DoF\npose information. The data is (1) trajectory-centric with accurate localization\nand globally aligned point clouds, (2) calibrated and synchronized to support\nbi-modal training and inference, and (3) containing different natural\nenvironments over 6 months to support research on domain adaptation. Our 3D\nsemantic labels are obtained via an efficient, automated process that transfers\nthe human-annotated 2D labels from multiple views into 3D point cloud\nsequences, thus circumventing the need for expensive and time-consuming human\nannotation in 3D. We introduce benchmarks on 2D and 3D semantic segmentation\nand evaluate a variety of recent deep-learning techniques to demonstrate the\nchallenges in semantic segmentation in natural environments. We propose\ntrain-val-test splits for standard benchmarks as well as domain adaptation\nbenchmarks and utilize an automated split generation technique to ensure the\nbalance of class label distributions. The $WildScenes$ benchmark webpage is\nhttps://csiro-robotics.github.io/WildScenes, and the data is publicly available\nat https://data.csiro.au/collection/csiro:61541 .\n","authors":["Kavisha Vidanapathirana","Joshua Knights","Stephen Hausler","Mark Cox","Milad Ramezani","Jason Jooste","Ethan Griffiths","Shaheer Mohamed","Sridha Sridharan","Clinton Fookes","Peyman Moghadam"],"pdf_url":"https://arxiv.org/pdf/2312.15364v2.pdf","comment":"Accepted in the The International Journal of Robotics Research (IJRR)"},{"id":"http://arxiv.org/abs/2411.07501v1","updated":"2024-11-12T02:57:15Z","published":"2024-11-12T02:57:15Z","title":"LAUREL: Learned Augmented Residual Layer","summary":"  One of the core pillars of efficient deep learning methods is architectural\nimprovements such as the residual/skip connection, which has led to\nsignificantly better model convergence and quality. Since then the residual\nconnection has become ubiquitous in not just convolutional neural networks but\nalso transformer-based architectures, the backbone of LLMs.\n  In this paper we introduce \\emph{Learned Augmented Residual Layer} (LAuReL)\n-- a novel generalization of the canonical residual connection -- with the goal\nto be an in-situ replacement of the latter while outperforming on both model\nquality and footprint metrics. Our experiments show that using \\laurel can help\nboost performance for both vision and language models. For example, on the\nResNet-50, ImageNet 1K task, it achieves $60\\%$ of the gains from adding an\nextra layer, while only adding $0.003\\%$ more parameters, and matches it while\nadding $2.6\\times$ fewer parameters.\n","authors":["Gaurav Menghani","Ravi Kumar","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.07501v1.pdf","comment":"Accepted at the 2nd Efficient Systems for Foundation Models Workshop\n  at the International Conference on Machine Learning (ICML) 2024"},{"id":"http://arxiv.org/abs/2411.07483v1","updated":"2024-11-12T02:12:41Z","published":"2024-11-12T02:12:41Z","title":"Quantifying Knowledge Distillation Using Partial Information\n  Decomposition","summary":"  Knowledge distillation provides an effective method for deploying complex\nmachine learning models in resource-constrained environments. It typically\ninvolves training a smaller student model to emulate either the probabilistic\noutputs or the internal feature representations of a larger teacher model. By\ndoing so, the student model often achieves substantially better performance on\na downstream task compared to when it is trained independently. Nevertheless,\nthe teacher's internal representations can also encode noise or additional\ninformation that may not be relevant to the downstream task. This observation\nmotivates our primary question: What are the information-theoretic limits of\nknowledge transfer? To this end, we leverage a body of work in information\ntheory called Partial Information Decomposition (PID) to quantify the\ndistillable and distilled knowledge of a teacher's representation corresponding\nto a given student and a downstream task. Moreover, we demonstrate that this\nmetric can be practically used in distillation to address challenges caused by\nthe complexity gap between the teacher and the student representations.\n","authors":["Pasan Dissanayake","Faisal Hamman","Barproda Halder","Ilia Sucholutsky","Qiuyi Zhang","Sanghamitra Dutta"],"pdf_url":"https://arxiv.org/pdf/2411.07483v1.pdf","comment":"Accepted at NeurIPS 2024 Machine Learning and Compression Workshop"},{"id":"http://arxiv.org/abs/2406.06535v3","updated":"2024-11-12T02:10:13Z","published":"2024-04-23T03:11:08Z","title":"Utilizing Graph Generation for Enhanced Domain Adaptive Object Detection","summary":"  The problem of Domain Adaptive in the field of Object Detection involves the\ntransfer of object detection models from labeled source domains to unannotated\ntarget domains. Recent advancements in this field aim to address domain\ndiscrepancies by aligning pixel-pairs across domains within a non-Euclidean\ngraphical space, thereby minimizing semantic distribution variance. Despite\ntheir remarkable achievements, these methods often use coarse semantic\nrepresentations to model graphs, mainly due to ignoring non-informative\nelements and failing to focus on precise semantic alignment. Additionally, the\ngeneration of coarse graphs inherently introduces abnormal nodes, posing\nchallenges and potentially biasing domain adaptation outcomes. Consequently, we\npropose a framework, which utilizes the Graph Generation to enhance the quality\nof DAOD (\\method{}). Specifically, we introduce a Node Refinement module that\nutilizes a memory bank to reconstruct noisy sampled nodes while applying\ncontrastive regularization to noisy features. To enhance semantic alignment, we\npropose separating domain-specific styles from category invariance encoded\nwithin graph covariances, which allows us to selectively remove domain-specific\nstyles while preserving category-invariant information, thus facilitating more\naccurate semantic alignment across different domains. Furthermore, we propose a\nGraph Optimization adaptor, leveraging variational inference to mitigate the\nimpact of abnormal nodes. Extensive experimentation across three adaptation\nbenchmarks validates that \\method{} achieves state-of-the-art performance in\nthe task of unsupervised domain adaptation.\n","authors":["Mu Wang"],"pdf_url":"https://arxiv.org/pdf/2406.06535v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07478v1","updated":"2024-11-12T01:51:05Z","published":"2024-11-12T01:51:05Z","title":"GUS-IR: Gaussian Splatting with Unified Shading for Inverse Rendering","summary":"  Recovering the intrinsic physical attributes of a scene from images,\ngenerally termed as the inverse rendering problem, has been a central and\nchallenging task in computer vision and computer graphics. In this paper, we\npresent GUS-IR, a novel framework designed to address the inverse rendering\nproblem for complicated scenes featuring rough and glossy surfaces. This paper\nstarts by analyzing and comparing two prominent shading techniques popularly\nused for inverse rendering, forward shading and deferred shading, effectiveness\nin handling complex materials. More importantly, we propose a unified shading\nsolution that combines the advantages of both techniques for better\ndecomposition. In addition, we analyze the normal modeling in 3D Gaussian\nSplatting (3DGS) and utilize the shortest axis as normal for each particle in\nGUS-IR, along with a depth-related regularization, resulting in improved\ngeometric representation and better shape reconstruction. Furthermore, we\nenhance the probe-based baking scheme proposed by GS-IR to achieve more\naccurate ambient occlusion modeling to better handle indirect illumination.\nExtensive experiments have demonstrated the superior performance of GUS-IR in\nachieving precise intrinsic decomposition and geometric representation,\nsupporting many downstream tasks (such as relighting, retouching) in computer\nvision, graphics, and extended reality.\n","authors":["Zhihao Liang","Hongdong Li","Kui Jia","Kailing Guo","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07478v1.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2406.07520v3","updated":"2024-11-12T01:45:49Z","published":"2024-06-11T17:50:15Z","title":"Neural Gaffer: Relighting Any Object via Diffusion","summary":"  Single-image relighting is a challenging task that involves reasoning about\nthe complex interplay between geometry, materials, and lighting. Many prior\nmethods either support only specific categories of images, such as portraits,\nor require special capture conditions, like using a flashlight. Alternatively,\nsome methods explicitly decompose a scene into intrinsic components, such as\nnormals and BRDFs, which can be inaccurate or under-expressive. In this work,\nwe propose a novel end-to-end 2D relighting diffusion model, called Neural\nGaffer, that takes a single image of any object and can synthesize an accurate,\nhigh-quality relit image under any novel environmental lighting condition,\nsimply by conditioning an image generator on a target environment map, without\nan explicit scene decomposition. Our method builds on a pre-trained diffusion\nmodel, and fine-tunes it on a synthetic relighting dataset, revealing and\nharnessing the inherent understanding of lighting present in the diffusion\nmodel. We evaluate our model on both synthetic and in-the-wild Internet imagery\nand demonstrate its advantages in terms of generalization and accuracy.\nMoreover, by combining with other generative methods, our model enables many\ndownstream 2D tasks, such as text-based relighting and object insertion. Our\nmodel can also operate as a strong relighting prior for 3D tasks, such as\nrelighting a radiance field.\n","authors":["Haian Jin","Yuan Li","Fujun Luan","Yuanbo Xiangli","Sai Bi","Kai Zhang","Zexiang Xu","Jin Sun","Noah Snavely"],"pdf_url":"https://arxiv.org/pdf/2406.07520v3.pdf","comment":"Project Website: https://neural-gaffer.github.io"},{"id":"http://arxiv.org/abs/2405.14864v3","updated":"2024-11-12T01:31:41Z","published":"2024-05-23T17:59:40Z","title":"Video Diffusion Models are Training-free Motion Interpreter and\n  Controller","summary":"  Video generation primarily aims to model authentic and customized motion\nacross frames, making understanding and controlling the motion a crucial topic.\nMost diffusion-based studies on video motion focus on motion customization with\ntraining-based paradigms, which, however, demands substantial training\nresources and necessitates retraining for diverse models. Crucially, these\napproaches do not explore how video diffusion models encode cross-frame motion\ninformation in their features, lacking interpretability and transparency in\ntheir effectiveness. To answer this question, this paper introduces a novel\nperspective to understand, localize, and manipulate motion-aware features in\nvideo diffusion models. Through analysis using Principal Component Analysis\n(PCA), our work discloses that robust motion-aware feature already exists in\nvideo diffusion models. We present a new MOtion FeaTure (MOFT) by eliminating\ncontent correlation information and filtering motion channels. MOFT provides a\ndistinct set of benefits, including the ability to encode comprehensive motion\ninformation with clear interpretability, extraction without the need for\ntraining, and generalizability across diverse architectures. Leveraging MOFT,\nwe propose a novel training-free video motion control framework. Our method\ndemonstrates competitive performance in generating natural and faithful motion,\nproviding architecture-agnostic insights and applicability in a variety of\ndownstream tasks.\n","authors":["Zeqi Xiao","Yifan Zhou","Shuai Yang","Xingang Pan"],"pdf_url":"https://arxiv.org/pdf/2405.14864v3.pdf","comment":"Accepted by NeurIPS 2024. Project Page:\n  https://xizaoqu.github.io/moft/"},{"id":"http://arxiv.org/abs/2411.07472v1","updated":"2024-11-12T01:17:27Z","published":"2024-11-12T01:17:27Z","title":"Semi-Truths: A Large-Scale Dataset of AI-Augmented Images for Evaluating\n  Robustness of AI-Generated Image detectors","summary":"  Text-to-image diffusion models have impactful applications in art, design,\nand entertainment, yet these technologies also pose significant risks by\nenabling the creation and dissemination of misinformation. Although recent\nadvancements have produced AI-generated image detectors that claim robustness\nagainst various augmentations, their true effectiveness remains uncertain. Do\nthese detectors reliably identify images with different levels of augmentation?\nAre they biased toward specific scenes or data distributions? To investigate,\nwe introduce SEMI-TRUTHS, featuring 27,600 real images, 223,400 masks, and\n1,472,700 AI-augmented images that feature targeted and localized perturbations\nproduced using diverse augmentation techniques, diffusion models, and data\ndistributions. Each augmented image is accompanied by metadata for standardized\nand targeted evaluation of detector robustness. Our findings suggest that\nstate-of-the-art detectors exhibit varying sensitivities to the types and\ndegrees of perturbations, data distributions, and augmentation methods used,\noffering new insights into their performance and limitations. The code for the\naugmentation and evaluation pipeline is available at\nhttps://github.com/J-Kruk/SemiTruths.\n","authors":["Anisha Pal","Julia Kruk","Mansi Phute","Manognya Bhattaram","Diyi Yang","Duen Horng Chau","Judy Hoffman"],"pdf_url":"https://arxiv.org/pdf/2411.07472v1.pdf","comment":"Accepted at NeurIPS 2024 Track Datasets & Benchmarks Track"},{"id":"http://arxiv.org/abs/2404.08926v3","updated":"2024-11-12T01:16:04Z","published":"2024-04-13T08:27:10Z","title":"Diffusion Models Meet Remote Sensing: Principles, Methods, and\n  Perspectives","summary":"  As a newly emerging advance in deep generative models, diffusion models have\nachieved state-of-the-art results in many fields, including computer vision,\nnatural language processing, and molecule design. The remote sensing (RS)\ncommunity has also noticed the powerful ability of diffusion models and quickly\napplied them to a variety of tasks for image processing. Given the rapid\nincrease in research on diffusion models in the field of RS, it is necessary to\nconduct a comprehensive review of existing diffusion model-based RS papers, to\nhelp researchers recognize the potential of diffusion models and provide some\ndirections for further exploration. Specifically, this article first introduces\nthe theoretical background of diffusion models, and then systematically reviews\nthe applications of diffusion models in RS, including image generation,\nenhancement, and interpretation. Finally, the limitations of existing RS\ndiffusion models and worthy research directions for further exploration are\ndiscussed and summarized.\n","authors":["Yidan Liu","Jun Yue","Shaobo Xia","Pedram Ghamisi","Weiying Xie","Leyuan Fang"],"pdf_url":"https://arxiv.org/pdf/2404.08926v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07463v1","updated":"2024-11-12T00:54:26Z","published":"2024-11-12T00:54:26Z","title":"MSEG-VCUQ: Multimodal SEGmentation with Enhanced Vision Foundation\n  Models, Convolutional Neural Networks, and Uncertainty Quantification for\n  High-Speed Video Phase Detection Data","summary":"  Purpose: High-speed video (HSV) phase detection (PD) segmentation is vital in\nnuclear reactors, chemical processing, and electronics cooling for detecting\nvapor, liquid, and microlayer phases. Traditional segmentation models face\npixel-level accuracy and generalization issues in multimodal data. MSEG-VCUQ\nintroduces VideoSAM, a hybrid framework leveraging convolutional neural\nnetworks (CNNs) and transformer-based vision models to enhance segmentation\naccuracy and generalizability across complex multimodal PD tasks. Methods:\nVideoSAM combines U-Net CNN and the Segment Anything Model (SAM) for advanced\nfeature extraction and segmentation across diverse HSV PD modalities, spanning\nfluids like water, FC-72, nitrogen, and argon under varied heat flux\nconditions. The framework also incorporates uncertainty quantification (UQ) to\nassess pixel-based discretization errors, delivering reliable metrics such as\ncontact line density and dry area fraction under experimental conditions.\nResults: VideoSAM outperforms SAM and modality-specific CNN models in\nsegmentation accuracy, excelling in environments with complex phase boundaries,\noverlapping bubbles, and dynamic liquid-vapor interactions. Its hybrid\narchitecture supports cross-dataset generalization, adapting effectively to\nvarying modalities. The UQ module provides accurate error estimates, enhancing\nthe reliability of segmentation outputs for advanced HSV PD research.\nConclusion: MSEG-VCUQ, via VideoSAM, offers a robust solution for HSV PD\nsegmentation, addressing previous limitations with advanced deep learning and\nUQ techniques. The open-source datasets and tools introduced enable scalable,\nprecise, and adaptable segmentation for multimodal PD datasets, supporting\nadvancements in HSV analysis and autonomous experimentation.\n","authors":["Chika Maduabuchi","Ericmoore Jossou","Matteo Bucci"],"pdf_url":"https://arxiv.org/pdf/2411.07463v1.pdf","comment":"Under Review in EAAI"},{"id":"http://arxiv.org/abs/2411.07462v1","updated":"2024-11-12T00:53:20Z","published":"2024-11-12T00:53:20Z","title":"MureObjectStitch: Multi-reference Image Composition","summary":"  Generative image composition aims to regenerate the given foreground object\nin the background image to produce a realistic composite image. In this work,\nwe propose an effective finetuning strategy for generative image composition\nmodel, in which we finetune a pretrained model using one or more images\ncontaining the same foreground object. Moreover, we propose a multi-reference\nstrategy, which allows the model to take in multiple reference images of the\nforeground object. The experiments on MureCOM dataset verify the effectiveness\nof our method.\n","authors":["Jiaxuan Chen","Bo Zhang","Li Niu"],"pdf_url":"https://arxiv.org/pdf/2411.07462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07461v1","updated":"2024-11-12T00:52:52Z","published":"2024-11-12T00:52:52Z","title":"BLIP3-KALE: Knowledge Augmented Large-Scale Dense Captions","summary":"  We introduce BLIP3-KALE, a dataset of 218 million image-text pairs that\nbridges the gap between descriptive synthetic captions and factual web-scale\nalt-text. KALE augments synthetic dense image captions with web-scale alt-text\nto generate factually grounded image captions. Our two-stage approach leverages\nlarge vision-language models and language models to create knowledge-augmented\ncaptions, which are then used to train a specialized VLM for scaling up the\ndataset. We train vision-language models on KALE and demonstrate improvements\non vision-language tasks. Our experiments show the utility of KALE for training\nmore capable and knowledgeable multimodal models. We release the KALE dataset\nat https://huggingface.co/datasets/Salesforce/blip3-kale\n","authors":["Anas Awadalla","Le Xue","Manli Shu","An Yan","Jun Wang","Senthil Purushwalkam","Sheng Shen","Hannah Lee","Oscar Lo","Jae Sung Park","Etash Guha","Silvio Savarese","Ludwig Schmidt","Yejin Choi","Caiming Xiong","Ran Xu"],"pdf_url":"https://arxiv.org/pdf/2411.07461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03190v2","updated":"2024-11-12T00:37:33Z","published":"2024-10-04T07:05:16Z","title":"Tuning Timestep-Distilled Diffusion Model Using Pairwise Sample\n  Optimization","summary":"  Recent advancements in timestep-distilled diffusion models have enabled\nhigh-quality image generation that rivals non-distilled multi-step models, but\nwith significantly fewer inference steps. While such models are attractive for\napplications due to the low inference cost and latency, fine-tuning them with a\nnaive diffusion objective would result in degraded and blurry outputs. An\nintuitive alternative is to repeat the diffusion distillation process with a\nfine-tuned teacher model, which produces good results but is cumbersome and\ncomputationally intensive; the distillation training usually requires magnitude\nhigher of training compute compared to fine-tuning for specific image styles.\nIn this paper, we present an algorithm named pairwise sample optimization\n(PSO), which enables the direct fine-tuning of an arbitrary timestep-distilled\ndiffusion model. PSO introduces additional reference images sampled from the\ncurrent time-step distilled model, and increases the relative likelihood margin\nbetween the training images and reference images. This enables the model to\nretain its few-step generation ability, while allowing for fine-tuning of its\noutput distribution. We also demonstrate that PSO is a generalized formulation\nwhich can be flexibly extended to both offline-sampled and online-sampled\npairwise data, covering various popular objectives for diffusion model\npreference optimization. We evaluate PSO in both preference optimization and\nother fine-tuning tasks, including style transfer and concept customization. We\nshow that PSO can directly adapt distilled models to human-preferred generation\nwith both offline and online-generated pairwise preference image data. PSO also\ndemonstrates effectiveness in style transfer and concept customization by\ndirectly tuning timestep-distilled diffusion models.\n","authors":["Zichen Miao","Zhengyuan Yang","Kevin Lin","Ze Wang","Zicheng Liu","Lijuan Wang","Qiang Qiu"],"pdf_url":"https://arxiv.org/pdf/2410.03190v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02504v3","updated":"2024-11-12T00:21:00Z","published":"2024-05-03T22:33:46Z","title":"Functional Imaging Constrained Diffusion for Brain PET Synthesis from\n  Structural MRI","summary":"  Magnetic resonance imaging (MRI) and positron emission tomography (PET) are\nincreasingly used in multimodal analysis of neurodegenerative disorders. While\nMRI is broadly utilized in clinical settings, PET is less accessible. Many\nstudies have attempted to use deep generative models to synthesize PET from MRI\nscans. However, they often suffer from unstable training and inadequately\npreserve brain functional information conveyed by PET. To this end, we propose\na functional imaging constrained diffusion (FICD) framework for 3D brain PET\nimage synthesis with paired structural MRI as input condition, through a new\nconstrained diffusion model (CDM). The FICD introduces noise to PET and then\nprogressively removes it with CDM, ensuring high output fidelity throughout a\nstable training phase. The CDM learns to predict denoised PET with a functional\nimaging constraint introduced to ensure voxel-wise alignment between each\ndenoised PET and its ground truth. Quantitative and qualitative analyses\nconducted on 293 subjects with paired T1-weighted MRI and\n18F-fluorodeoxyglucose (FDG)-PET scans suggest that FICD achieves superior\nperformance in generating FDG-PET data compared to state-of-the-art methods. We\nfurther validate the effectiveness of the proposed FICD on data from a total of\n1,262 subjects through three downstream tasks, with experimental results\nsuggesting its utility and generalizability.\n","authors":["Minhui Yu","Mengqi Wu","Ling Yue","Andrea Bozoki","Mingxia Liu"],"pdf_url":"https://arxiv.org/pdf/2405.02504v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07449v1","updated":"2024-11-12T00:20:11Z","published":"2024-11-12T00:20:11Z","title":"Tracing the Roots: Leveraging Temporal Dynamics in Diffusion\n  Trajectories for Origin Attribution","summary":"  Diffusion models have revolutionized image synthesis, garnering significant\nresearch interest in recent years. Diffusion is an iterative algorithm in which\nsamples are generated step-by-step, starting from pure noise. This process\nintroduces the notion of diffusion trajectories, i.e., paths from the standard\nGaussian distribution to the target image distribution. In this context, we\nstudy discriminative algorithms operating on these trajectories. Specifically,\ngiven a pre-trained diffusion model, we consider the problem of classifying\nimages as part of the training dataset, generated by the model or originating\nfrom an external source. Our approach demonstrates the presence of patterns\nacross steps that can be leveraged for classification. We also conduct ablation\nstudies, which reveal that using higher-order gradient features to characterize\nthe trajectories leads to significant performance gains and more robust\nalgorithms.\n","authors":["Andreas Floros","Seyed-Mohsen Moosavi-Dezfooli","Pier Luigi Dragotti"],"pdf_url":"https://arxiv.org/pdf/2411.07449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.13632v3","updated":"2024-11-12T00:12:39Z","published":"2023-12-21T07:48:54Z","title":"TraceFL: Interpretability-Driven Debugging in Federated Learning via\n  Neuron Provenance","summary":"  In Federated Learning, clients train models on local data and send updates to\na central server, which aggregates them into a global model using a fusion\nalgorithm. This collaborative yet privacy-preserving training comes at a\ncost--FL developers face significant challenges in attributing global model\npredictions to specific clients. Localizing responsible clients is a crucial\nstep towards (a) excluding clients primarily responsible for incorrect\npredictions and (b) encouraging clients who contributed high-quality models to\ncontinue participating in the future. Existing ML explainability approaches are\ninherently inapplicable as they are designed for single-model, centralized\ntraining.\n  We introduce TraceFL, a fine-grained neuron provenance capturing mechanism\nthat identifies clients responsible for the global model's prediction by\ntracking the flow of information from individual clients to the global model.\nSince inference on different inputs activates a different set of neurons of the\nglobal model, TraceFL dynamically quantifies the significance of the global\nmodel's neurons in a given prediction. It then selectively picks a slice of the\nmost crucial neurons in the global model and maps them to the corresponding\nneurons in every participating client to determine each client's contribution,\nultimately localizing the responsible client. We evaluate TraceFL on six\ndatasets, including two real-world medical imaging datasets and four neural\nnetworks, including advanced models such as GPT. TraceFL achieves 99% accuracy\nin localizing the responsible client in FL tasks spanning both image and text\nclassification tasks. At a time when state-of-the-art ML debugging approaches\nare mostly domain-specific (e.g., image classification only), TraceFL is the\nfirst technique to enable highly accurate automated reasoning across a wide\nrange of FL applications.\n","authors":["Waris Gill","Ali Anwar","Muhammad Ali Gulzar"],"pdf_url":"https://arxiv.org/pdf/2312.13632v3.pdf","comment":"Accepted at 2025 IEEE/ACM 47th International Conference on Software\n  Engineering (ICSE)"},{"id":"http://arxiv.org/abs/2411.07445v1","updated":"2024-11-12T00:07:16Z","published":"2024-11-12T00:07:16Z","title":"All-in-one Weather-degraded Image Restoration via Adaptive\n  Degradation-aware Self-prompting Model","summary":"  Existing approaches for all-in-one weather-degraded image restoration suffer\nfrom inefficiencies in leveraging degradation-aware priors, resulting in\nsub-optimal performance in adapting to different weather conditions. To this\nend, we develop an adaptive degradation-aware self-prompting model (ADSM) for\nall-in-one weather-degraded image restoration. Specifically, our model employs\nthe contrastive language-image pre-training model (CLIP) to facilitate the\ntraining of our proposed latent prompt generators (LPGs), which represent three\ntypes of latent prompts to characterize the degradation type, degradation\nproperty and image caption. Moreover, we integrate the acquired\ndegradation-aware prompts into the time embedding of diffusion model to improve\ndegradation perception. Meanwhile, we employ the latent caption prompt to guide\nthe reverse sampling process using the cross-attention mechanism, thereby\nguiding the accurate image reconstruction. Furthermore, to accelerate the\nreverse sampling procedure of diffusion model and address the limitations of\nfrequency perception, we introduce a wavelet-oriented noise estimating network\n(WNE-Net). Extensive experiments conducted on eight publicly available datasets\ndemonstrate the effectiveness of our proposed approach in both task-specific\nand all-in-one applications.\n","authors":["Yuanbo Wen","Tao Gao","Ziqi Li","Jing Zhang","Kaihao Zhang","Ting Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08227v1","updated":"2024-11-12T22:43:16Z","published":"2024-11-12T22:43:16Z","title":"DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution\n  Detection","summary":"  Out-of-distribution (OOD) detection is essential for ensuring the robustness\nof machine learning models by identifying samples that deviate from the\ntraining distribution. While traditional OOD detection has primarily focused on\nsingle-modality inputs, such as images, recent advances in multimodal models\nhave demonstrated the potential of leveraging multiple modalities (e.g., video,\noptical flow, audio) to enhance detection performance. However, existing\nmethods often overlook intra-class variability within in-distribution (ID)\ndata, assuming that samples of the same class are perfectly cohesive and\nconsistent. This assumption can lead to performance degradation, especially\nwhen prediction discrepancies are uniformly amplified across all samples. To\naddress this issue, we propose Dynamic Prototype Updating (DPU), a novel\nplug-and-play framework for multimodal OOD detection that accounts for\nintra-class variations. Our method dynamically updates class center\nrepresentations for each class by measuring the variance of similar samples\nwithin each batch, enabling adaptive adjustments. This approach allows us to\namplify prediction discrepancies based on the updated class centers, thereby\nimproving the model's robustness and generalization across different\nmodalities. Extensive experiments on two tasks, five datasets, and nine base\nOOD algorithms demonstrate that DPU significantly improves OOD detection\nperformance, setting a new state-of-the-art in multimodal OOD detection, with\nimprovements of up to 80 percent in Far-OOD detection. To facilitate\naccessibility and reproducibility, our code is publicly available on GitHub.\n","authors":["Shawn Li","Huixian Gong","Hao Dong","Tiankai Yang","Zhengzhong Tu","Yue Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.08227v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08216v1","updated":"2024-11-12T22:16:50Z","published":"2024-11-12T22:16:50Z","title":"GTA: Global Tracklet Association for Multi-Object Tracking in Sports","summary":"  Multi-object tracking in sports scenarios has become one of the focal points\nin computer vision, experiencing significant advancements through the\nintegration of deep learning techniques. Despite these breakthroughs,\nchallenges remain, such as accurately re-identifying players upon re-entry into\nthe scene and minimizing ID switches. In this paper, we propose an\nappearance-based global tracklet association algorithm designed to enhance\ntracking performance by splitting tracklets containing multiple identities and\nconnecting tracklets seemingly from the same identity. This method can serve as\na plug-and-play refinement tool for any multi-object tracker to further boost\ntheir performance. The proposed method achieved a new state-of-the-art\nperformance on the SportsMOT dataset with HOTA score of 81.04%. Similarly, on\nthe SoccerNet dataset, our method enhanced multiple trackers' performance,\nconsistently increasing the HOTA score from 79.41% to 83.11%. These significant\nand consistent improvements across different trackers and datasets underscore\nour proposed method's potential impact on the application of sports player\ntracking. We open-source our project codebase at\nhttps://github.com/sjc042/gta-link.git.\n","authors":["Jiacheng Sun","Hsiang-Wei Huang","Cheng-Yen Yang","Zhongyu Jiang","Jenq-Neng Hwang"],"pdf_url":"https://arxiv.org/pdf/2411.08216v1.pdf","comment":"Accepted by ACCV 2024 MLCSA Workshop"},{"id":"http://arxiv.org/abs/2411.08196v1","updated":"2024-11-12T21:34:30Z","published":"2024-11-12T21:34:30Z","title":"Latent Space Disentanglement in Diffusion Transformers Enables Precise\n  Zero-shot Semantic Editing","summary":"  Diffusion Transformers (DiTs) have recently achieved remarkable success in\ntext-guided image generation. In image editing, DiTs project text and image\ninputs to a joint latent space, from which they decode and synthesize new\nimages. However, it remains largely unexplored how multimodal information\ncollectively forms this joint space and how they guide the semantics of the\nsynthesized images. In this paper, we investigate the latent space of DiT\nmodels and uncover two key properties: First, DiT's latent space is inherently\nsemantically disentangled, where different semantic attributes can be\ncontrolled by specific editing directions. Second, consistent semantic editing\nrequires utilizing the entire joint latent space, as neither encoded image nor\ntext alone contains enough semantic information. We show that these editing\ndirections can be obtained directly from text prompts, enabling precise\nsemantic control without additional training or mask annotations. Based on\nthese insights, we propose a simple yet effective Encode-Identify-Manipulate\n(EIM) framework for zero-shot fine-grained image editing. Specifically, we\nfirst encode both the given source image and the text prompt that describes the\nimage, to obtain the joint latent embedding. Then, using our proposed Hessian\nScore Distillation Sampling (HSDS) method, we identify editing directions that\ncontrol specific target attributes while preserving other image features. These\ndirections are guided by text prompts and used to manipulate the latent\nembeddings. Moreover, we propose a new metric to quantify the disentanglement\ndegree of the latent space of diffusion models. Extensive experiment results on\nour new curated benchmark dataset and analysis demonstrate DiT's\ndisentanglement properties and effectiveness of the EIM framework.\n","authors":["Zitao Shuai","Chenwei Wu","Zhengxu Tang","Bowen Song","Liyue Shen"],"pdf_url":"https://arxiv.org/pdf/2411.08196v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2408.13335"},{"id":"http://arxiv.org/abs/2411.08195v1","updated":"2024-11-12T21:33:11Z","published":"2024-11-12T21:33:11Z","title":"An Explainable Machine Learning Approach for Age and Gender Estimation\n  in Living Individuals Using Dental Biometrics","summary":"  Objectives: Age and gender estimation is crucial for various applications,\nincluding forensic investigations and anthropological studies. This research\naims to develop a predictive system for age and gender estimation in living\nindividuals, leveraging dental measurements such as Coronal Height (CH),\nCoronal Pulp Cavity Height (CPCH), and Tooth Coronal Index (TCI). Methods:\nMachine learning models were employed in our study, including Cat Boost\nClassifier (Catboost), Gradient Boosting Machine (GBM), Ada Boost Classifier\n(AdaBoost), Random Forest (RF), eXtreme Gradient Boosting (XGB), Light Gradient\nBoosting Machine (LGB), and Extra Trees Classifier (ETC), to analyze dental\ndata from 862 living individuals (459 males and 403 females). Specifically,\nperiapical radiographs from six teeth per individual were utilized, including\npremolars and molars from both maxillary and mandibular. A novel ensemble\nlearning technique was developed, which uses multiple models each tailored to\ndistinct dental metrics, to estimate age and gender accurately. Furthermore, an\nexplainable AI model has been created utilizing SHAP, enabling dental experts\nto make judicious decisions based on comprehensible insight. Results: The RF\nand XGB models were particularly effective, yielding the highest F1 score for\nage and gender estimation. Notably, the XGB model showed a slightly better\nperformance in age estimation, achieving an F1 score of 73.26%. A similar trend\nfor the RF model was also observed in gender estimation, achieving a F1 score\nof 77.53%. Conclusions: This study marks a significant advancement in dental\nforensic methods, showcasing the potential of machine learning to automate age\nand gender estimation processes with improved accuracy.\n","authors":["Mohsin Ali","Haider Raza","John Q Gan","Ariel Pokhojaev","Matanel Katz","Esra Kosan","Dian Agustin Wahjuningrum","Omnina Saleh","Rachel Sarig","Akhilanada Chaurasia"],"pdf_url":"https://arxiv.org/pdf/2411.08195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00169v2","updated":"2024-11-12T21:16:52Z","published":"2024-07-31T21:42:42Z","title":"Strike the Balance: On-the-Fly Uncertainty based User Interactions for\n  Long-Term Video Object Segmentation","summary":"  In this paper, we introduce a variant of video object segmentation (VOS) that\nbridges interactive and semi-automatic approaches, termed Lazy Video Object\nSegmentation (ziVOS). In contrast, to both tasks, which handle video object\nsegmentation in an off-line manner (i.e., pre-recorded sequences), we propose\nthrough ziVOS to target online recorded sequences. Here, we strive to strike a\nbalance between performance and robustness for long-term scenarios by\nsoliciting user feedback's on-the-fly during the segmentation process. Hence,\nwe aim to maximize the tracking duration of an object of interest, while\nrequiring minimal user corrections to maintain tracking over an extended\nperiod. We propose a competitive baseline, i.e., Lazy-XMem, as a reference for\nfuture works in ziVOS. Our proposed approach uses an uncertainty estimation of\nthe tracking state to determine whether a user interaction is necessary to\nrefine the model's prediction. To quantitatively assess the performance of our\nmethod and the user's workload, we introduce complementary metrics alongside\nthose already established in the field. We evaluate our approach using the\nrecently introduced LVOS dataset, which offers numerous long-term videos. Our\ncode is publicly available at https://github.com/Vujas-Eteph/LazyXMem.\n","authors":["Stéphane Vujasinović","Stefan Becker","Sebastian Bullinger","Norbert Scherer-Negenborn","Michael Arens","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2408.00169v2.pdf","comment":"Accepted at ACCV 2024"},{"id":"http://arxiv.org/abs/2411.08187v1","updated":"2024-11-12T21:12:51Z","published":"2024-11-12T21:12:51Z","title":"TractoEmbed: Modular Multi-level Embedding framework for white matter\n  tract segmentation","summary":"  White matter tract segmentation is crucial for studying brain structural\nconnectivity and neurosurgical planning. However, segmentation remains\nchallenging due to issues like class imbalance between major and minor tracts,\nstructural similarity, subject variability, symmetric streamlines between\nhemispheres etc. To address these challenges, we propose TractoEmbed, a modular\nmulti-level embedding framework, that encodes localized representations through\nlearning tasks in respective encoders. In this paper, TractoEmbed introduces a\nnovel hierarchical streamline data representation that captures maximum spatial\ninformation at each level i.e. individual streamlines, clusters, and patches.\nExperiments show that TractoEmbed outperforms state-of-the-art methods in white\nmatter tract segmentation across different datasets, and spanning various age\ngroups. The modular framework directly allows the integration of additional\nembeddings in future works.\n","authors":["Anoushkrit Goel","Bipanjit Singh","Ankita Joshi","Ranjeet Ranjan Jha","Chirag Ahuja","Aditya Nigam","Arnav Bhavsar"],"pdf_url":"https://arxiv.org/pdf/2411.08187v1.pdf","comment":"Accepted at 27th International Conference on Pattern Recognition\n  (ICPR), 2024 15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2408.07832v6","updated":"2024-11-12T20:51:07Z","published":"2024-07-31T14:49:35Z","title":"LADDER: Language Driven Slice Discovery and Error Rectification","summary":"  Error slice discovery associates structured patterns with model errors.\nExisting methods discover error slices by clustering the error-prone samples\nwith similar patterns or assigning discrete attributes to each sample for\npost-hoc analysis. While these methods aim for interpretability and easier\nmitigation through reweighting or rebalancing, they may not capture the full\ncomplexity of error patterns due to incomplete or missing attributes. Contrary\nto the existing approach, this paper utilizes the reasoning capabilities of the\nLarge Language Model (LLM) to analyze complex error patterns and generate\ntestable hypotheses. This paper proposes LADDER: Language Driven slice\nDiscovery and Error Rectification. It first projects the model's representation\ninto a language-aligned feature space (eg CLIP) to preserve semantics in the\noriginal model feature space. This ensures the accurate retrieval of sentences\nthat highlight the model's errors. Next, the LLM utilizes the sentences and\ngenerates hypotheses to discover error slices. Finally, we mitigate the error\nby fine-tuning the classification head by creating a group-balanced dataset\nusing the hypotheses. Our entire method does not require any attribute\nannotation, either explicitly or through external tagging models. We validate\nour method with \\textbf{five} image classification datasets.\n","authors":["Shantanu Ghosh","Rayan Syed","Chenyu Wang","Clare B. Poynton","Shyam Visweswaran","Kayhan Batmanghelich"],"pdf_url":"https://arxiv.org/pdf/2408.07832v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08171v1","updated":"2024-11-12T20:30:23Z","published":"2024-11-12T20:30:23Z","title":"Comprehensive and Comparative Analysis between Transfer Learning and\n  Custom Built VGG and CNN-SVM Models for Wildfire Detection","summary":"  Contemporary Artificial Intelligence (AI) and Machine Learning (ML) research\nplaces a significant emphasis on transfer learning, showcasing its\ntransformative potential in enhancing model performance across diverse domains.\nThis paper examines the efficiency and effectiveness of transfer learning in\nthe context of wildfire detection. Three purpose-built models -- Visual\nGeometry Group (VGG)-7, VGG-10, and Convolutional Neural Network (CNN)-Support\nVector Machine(SVM) CNN-SVM -- are rigorously compared with three pretrained\nmodels -- VGG-16, VGG-19, and Residual Neural Network (ResNet) ResNet101. We\ntrained and evaluated these models using a dataset that captures the\ncomplexities of wildfires, incorporating variables such as varying lighting\nconditions, time of day, and diverse terrains. The objective is to discern how\ntransfer learning performs against models trained from scratch in addressing\nthe intricacies of the wildfire detection problem. By assessing the performance\nmetrics, including accuracy, precision, recall, and F1 score, a comprehensive\nunderstanding of the advantages and disadvantages of transfer learning in this\nspecific domain is obtained. This study contributes valuable insights to the\nongoing discourse, guiding future directions in AI and ML research. Keywords:\nWildfire prediction, deep learning, machine learning fire, detection\n","authors":["Aditya V. Jonnalagadda","Hashim A. Hashim","Andrew Harris"],"pdf_url":"https://arxiv.org/pdf/2411.08171v1.pdf","comment":"In Proc. of the 2024 IEEE International Conference On Intelligent\n  Computing in Data Sciences"},{"id":"http://arxiv.org/abs/2411.08164v1","updated":"2024-11-12T20:15:32Z","published":"2024-11-12T20:15:32Z","title":"EAPCR: A Universal Feature Extractor for Scientific Data without\n  Explicit Feature Relation Patterns","summary":"  Conventional methods, including Decision Tree (DT)-based methods, have been\neffective in scientific tasks, such as non-image medical diagnostics, system\nanomaly detection, and inorganic catalysis efficiency prediction. However, most\ndeep-learning techniques have struggled to surpass or even match this level of\nsuccess as traditional machine-learning methods. The primary reason is that\nthese applications involve multi-source, heterogeneous data where features lack\nexplicit relationships. This contrasts with image data, where pixels exhibit\nspatial relationships; textual data, where words have sequential dependencies;\nand graph data, where nodes are connected through established associations. The\nabsence of explicit Feature Relation Patterns (FRPs) presents a significant\nchallenge for deep learning techniques in scientific applications that are not\nimage, text, and graph-based. In this paper, we introduce EAPCR, a universal\nfeature extractor designed for data without explicit FRPs. Tested across\nvarious scientific tasks, EAPCR consistently outperforms traditional methods\nand bridges the gap where deep learning models fall short. To further\ndemonstrate its robustness, we synthesize a dataset without explicit FRPs.\nWhile Kolmogorov-Arnold Network (KAN) and feature extractors like Convolutional\nNeural Networks (CNNs), Graph Convolutional Networks (GCNs), and Transformers\nstruggle, EAPCR excels, demonstrating its robustness and superior performance\nin scientific tasks without FRPs.\n","authors":["Zhuohang Yu","Ling An","Yansong Li","Yu Wu","Zeyu Dong","Zhangdi Liu","Le Gao","Zhenyu Zhang","Chichun Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.08164v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08158v1","updated":"2024-11-12T20:07:59Z","published":"2024-11-12T20:07:59Z","title":"TomoGRAF: A Robust and Generalizable Reconstruction Network for\n  Single-View Computed Tomography","summary":"  Computed tomography (CT) provides high spatial resolution visualization of 3D\nstructures for scientific and clinical applications. Traditional\nanalytical/iterative CT reconstruction algorithms require hundreds of angular\ndata samplings, a condition that may not be met in practice due to physical and\nmechanical limitations. Sparse view CT reconstruction has been proposed using\nconstrained optimization and machine learning methods with varying success,\nless so for ultra-sparse view CT reconstruction with one to two views. Neural\nradiance field (NeRF) is a powerful tool for reconstructing and rendering 3D\nnatural scenes from sparse views, but its direct application to 3D medical\nimage reconstruction has been minimally successful due to the differences\nbetween optical and X-ray photon transportation. Here, we develop a novel\nTomoGRAF framework incorporating the unique X-ray transportation physics to\nreconstruct high-quality 3D volumes using ultra-sparse projections without\nprior. TomoGRAF captures the CT imaging geometry, simulates the X-ray casting\nand tracing process, and penalizes the difference between simulated and ground\ntruth CT sub-volume during training. We evaluated the performance of TomoGRAF\non an unseen dataset of distinct imaging characteristics from the training data\nand demonstrated a vast leap in performance compared with state-of-the-art deep\nlearning and NeRF methods. TomoGRAF provides the first generalizable solution\nfor image-guided radiotherapy and interventional radiology applications, where\nonly one or a few X-ray views are available, but 3D volumetric information is\ndesired.\n","authors":["Di Xu","Yang Yang","Hengjie Liu","Qihui Lyu","Martina Descovich","Dan Ruan","Ke Sheng"],"pdf_url":"https://arxiv.org/pdf/2411.08158v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05249v5","updated":"2024-11-12T19:59:51Z","published":"2024-10-07T17:52:56Z","title":"LoTLIP: Improving Language-Image Pre-training for Long Text\n  Understanding","summary":"  Understanding long text is of great demands in practice but beyond the reach\nof most language-image pre-training (LIP) models. In this work, we empirically\nconfirm that the key reason causing such an issue is that the training images\nare usually paired with short captions, leaving certain tokens easily\novershadowed by salient tokens. Towards this problem, our initial attempt is to\nrelabel the data with long captions, however, directly learning with which may\nlead to performance degradation in understanding short text (e.g., in the image\nclassification task). Then, after incorporating corner tokens to aggregate\ndiverse textual information, we manage to help the model catch up to its\noriginal level of short text understanding yet greatly enhance its capability\nof long text understanding. We further look into whether the model can\ncontinuously benefit from longer captions and notice a clear trade-off between\nthe performance and the efficiency. Finally, we validate the effectiveness of\nour approach using a self-constructed large-scale dataset, which consists of\n100M long caption oriented text-image pairs. Our method demonstrates superior\nperformance in long-text-image retrieval tasks. The project page is available\nat https://wuw2019.github.io/lot-lip.\n","authors":["Wei Wu","Kecheng Zheng","Shuailei Ma","Fan Lu","Yuxin Guo","Yifei Zhang","Wei Chen","Qingpei Guo","Yujun Shen","Zheng-Jun Zha"],"pdf_url":"https://arxiv.org/pdf/2410.05249v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08128v1","updated":"2024-11-12T19:12:12Z","published":"2024-11-12T19:12:12Z","title":"CameraHMR: Aligning People with Perspective","summary":"  We address the challenge of accurate 3D human pose and shape estimation from\nmonocular images. The key to accuracy and robustness lies in high-quality\ntraining data. Existing training datasets containing real images with pseudo\nground truth (pGT) use SMPLify to fit SMPL to sparse 2D joint locations,\nassuming a simplified camera with default intrinsics. We make two contributions\nthat improve pGT accuracy. First, to estimate camera intrinsics, we develop a\nfield-of-view prediction model (HumanFoV) trained on a dataset of images\ncontaining people. We use the estimated intrinsics to enhance the 4D-Humans\ndataset by incorporating a full perspective camera model during SMPLify\nfitting. Second, 2D joints provide limited constraints on 3D body shape,\nresulting in average-looking bodies. To address this, we use the BEDLAM dataset\nto train a dense surface keypoint detector. We apply this detector to the\n4D-Humans dataset and modify SMPLify to fit the detected keypoints, resulting\nin significantly more realistic body shapes. Finally, we upgrade the HMR2.0\narchitecture to include the estimated camera parameters. We iterate model\ntraining and SMPLify fitting initialized with the previously trained model.\nThis leads to more accurate pGT and a new model, CameraHMR, with\nstate-of-the-art accuracy. Code and pGT are available for research purposes.\n","authors":["Priyanka Patel","Michael J. Black"],"pdf_url":"https://arxiv.org/pdf/2411.08128v1.pdf","comment":"3DV 2025"},{"id":"http://arxiv.org/abs/2411.08127v1","updated":"2024-11-12T19:09:45Z","published":"2024-11-12T19:09:45Z","title":"TIPO: Text to Image with Text Presampling for Prompt Optimization","summary":"  TIPO (Text to Image with text pre-sampling for Prompt Optimization) is an\ninnovative framework designed to enhance text-to-image (T2I) generation by\nlanguage model (LM) for automatic prompt engineering. By refining and extending\nuser-provided prompts, TIPO bridges the gap between simple inputs and the\ndetailed prompts required for high-quality image generation. Unlike previous\napproaches that rely on Large Language Models (LLMs) or reinforcement learning\n(RL), TIPO adjusts user input prompts with the distribution of a trained prompt\ndataset, eliminating the need for complex runtime cost via lightweight model.\nThis pre-sampling approach enables efficient and scalable prompt optimization,\ngrounded in the model's training distribution. Experimental results demonstrate\nTIPO's effectiveness in improving aesthetic scores, reducing image corruption,\nand better aligning generated images with dataset distributions. These findings\nhighlight the critical role of prompt engineering in T2I systems and open\navenues for broader applications of automatic prompt refinement.\n","authors":["Shih-Ying Yeh","Sang-Hyun Park","Giyeong Oh","Min Song","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2411.08127v1.pdf","comment":"21 pages, 13 figures"},{"id":"http://arxiv.org/abs/2411.08085v1","updated":"2024-11-12T16:52:51Z","published":"2024-11-12T16:52:51Z","title":"Deep Learning 2.0: Artificial Neurons That Matter -- Reject Correlation,\n  Embrace Orthogonality","summary":"  We introduce a yat-product-powered neural network, the Neural Matter Network\n(NMN), a breakthrough in deep learning that achieves non-linear pattern\nrecognition without activation functions. Our key innovation relies on the\nyat-product and yat-product, which naturally induces non-linearity by\nprojecting inputs into a pseudo-metric space, eliminating the need for\ntraditional activation functions while maintaining only a softmax layer for\nfinal class probability distribution. This approach simplifies network\narchitecture and provides unprecedented transparency into the network's\ndecision-making process. Our comprehensive empirical evaluation across\ndifferent datasets demonstrates that NMN consistently outperforms traditional\nMLPs. The results challenge the assumption that separate activation functions\nare necessary for effective deep-learning models. The implications of this work\nextend beyond immediate architectural benefits, by eliminating intermediate\nactivation functions while preserving non-linear capabilities, yat-MLP\nestablishes a new paradigm for neural network design that combines simplicity\nwith effectiveness. Most importantly, our approach provides unprecedented\ninsights into the traditionally opaque \"black-box\" nature of neural networks,\noffering a clearer understanding of how these models process and classify\ninformation.\n","authors":["Taha Bouhsine"],"pdf_url":"https://arxiv.org/pdf/2411.08085v1.pdf","comment":"Submitted to CVPR 2025"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2411.08027v1","updated":"2024-11-12T18:56:58Z","published":"2024-11-12T18:56:58Z","title":"LLMPhy: Complex Physical Reasoning Using Large Language Models and World\n  Models","summary":"  Physical reasoning is an important skill needed for robotic agents when\noperating in the real world. However, solving such reasoning problems often\ninvolves hypothesizing and reflecting over complex multi-body interactions\nunder the effect of a multitude of physical forces and thus learning all such\ninteractions poses a significant hurdle for state-of-the-art machine learning\nframeworks, including large language models (LLMs). To study this problem, we\npropose a new physical reasoning task and a dataset, dubbed TraySim. Our task\ninvolves predicting the dynamics of several objects on a tray that is given an\nexternal impact -- the domino effect of the ensued object interactions and\ntheir dynamics thus offering a challenging yet controlled setup, with the goal\nof reasoning being to infer the stability of the objects after the impact. To\nsolve this complex physical reasoning task, we present LLMPhy, a zero-shot\nblack-box optimization framework that leverages the physics knowledge and\nprogram synthesis abilities of LLMs, and synergizes these abilities with the\nworld models built into modern physics engines. Specifically, LLMPhy uses an\nLLM to generate code to iteratively estimate the physical hyperparameters of\nthe system (friction, damping, layout, etc.) via an implicit\nanalysis-by-synthesis approach using a (non-differentiable) simulator in the\nloop and uses the inferred parameters to imagine the dynamics of the scene\ntowards solving the reasoning task. To show the effectiveness of LLMPhy, we\npresent experiments on our TraySim dataset to predict the steady-state poses of\nthe objects. Our results show that the combination of the LLM and the physics\nengine leads to state-of-the-art zero-shot physical reasoning performance,\nwhile demonstrating superior convergence against standard black-box\noptimization methods and better estimation of the physical parameters.\n","authors":["Anoop Cherian","Radu Corcodel","Siddarth Jain","Diego Romeres"],"pdf_url":"https://arxiv.org/pdf/2411.08027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08024v1","updated":"2024-11-12T18:54:55Z","published":"2024-11-12T18:54:55Z","title":"Leonardo vindicated: Pythagorean trees for minimal reconstruction of the\n  natural branching structures","summary":"  Trees continue to fascinate with their natural beauty and as engineering\nmasterpieces optimal with respect to several independent criteria. Pythagorean\ntree is a well-known fractal design that realistically mimics the natural tree\nbranching structures. We study various types of Pythagorean-like fractal trees\nwith different shapes of the base, branching angles and relaxed scales in an\nattempt to identify and explain which variants are the closest match to the\nbranching structures commonly observed in the natural world. Pursuing\nsimultaneously the realism and minimalism of the fractal tree model, we have\ndeveloped a flexibly parameterised and fast algorithm to grow and visually\nexamine deep Pythagorean-inspired fractal trees with the capability to orderly\nover- or underestimate the Leonardo da Vinci's tree branching rule as well as\ncontrol various imbalances and branching angles. We tested the realism of the\ngenerated fractal tree images by means of the classification accuracy of\ndetecting natural tree with the transfer-trained deep Convolutional Neural\nNetworks (CNNs). Having empirically established the parameters of the fractal\ntrees that maximize the CNN's natural tree class classification accuracy we\nhave translated them back to the scales and angles of branches and came to the\ninteresting conclusions that support the da Vinci branching rule and golden\nratio based scaling for both the shape of the branch and imbalance between the\nchild branches, and claim the flexibly parameterized fractal trees can be used\nto generate artificial examples to train robust detectors of different species\nof trees.\n","authors":["Dymitr Ruta","Corrado Mio","Ernesto Damiani"],"pdf_url":"https://arxiv.org/pdf/2411.08024v1.pdf","comment":"22 pages, lots of hi res figures I had to reduce quality of,\n  submitting as a requirement to the Theory of Computing Journal"},{"id":"http://arxiv.org/abs/2411.08019v1","updated":"2024-11-12T18:50:35Z","published":"2024-11-12T18:50:35Z","title":"Language Models as Causal Effect Generators","summary":"  We present a framework for large language model (LLM) based data generation\nwith controllable causal structure. In particular, we define a procedure for\nturning any language model and any directed acyclic graph (DAG) into a\nsequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM\nis a causal model with user-defined structure and LLM-defined structural\nequations. We characterize how an SD-SCM allows sampling from observational,\ninterventional, and counterfactual distributions according to the desired\ncausal structure. We then leverage this procedure to propose a new type of\nbenchmark for causal inference methods, generating individual-level\ncounterfactual data without needing to manually specify functional\nrelationships between variables. We create an example benchmark consisting of\nthousands of datasets, and test a suite of popular estimation methods on these\ndatasets for average, conditional average, and individual treatment effect\nestimation, both with and without hidden confounding. Apart from generating\ndata, the same procedure also allows us to test for the presence of a causal\neffect that might be encoded in an LLM. This procedure can underpin auditing\nLLMs for misinformation, discrimination, or otherwise undesirable behavior. We\nbelieve SD-SCMs can serve as a useful tool in any application that would\nbenefit from sequential data with controllable causal structure.\n","authors":["Lucius E. J. Bynum","Kyunghyun Cho"],"pdf_url":"https://arxiv.org/pdf/2411.08019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08017v1","updated":"2024-11-12T18:49:06Z","published":"2024-11-12T18:49:06Z","title":"Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model\n  with Compact Wavelet Encodings","summary":"  Large-scale 3D generative models require substantial computational resources\nyet often fall short in capturing fine details and complex geometries at high\nresolutions. We attribute this limitation to the inefficiency of current\nrepresentations, which lack the compactness required to model the generative\nmodels effectively. To address this, we introduce a novel approach called\nWavelet Latent Diffusion, or WaLa, that encodes 3D shapes into wavelet-based,\ncompact latent encodings. Specifically, we compress a $256^3$ signed distance\nfield into a $12^3 \\times 4$ latent grid, achieving an impressive 2427x\ncompression ratio with minimal loss of detail. This high level of compression\nallows our method to efficiently train large-scale generative networks without\nincreasing the inference time. Our models, both conditional and unconditional,\ncontain approximately one billion parameters and successfully generate\nhigh-quality 3D shapes at $256^3$ resolution. Moreover, WaLa offers rapid\ninference, producing shapes within two to four seconds depending on the\ncondition, despite the model's scale. We demonstrate state-of-the-art\nperformance across multiple datasets, with significant improvements in\ngeneration quality, diversity, and computational efficiency. We open-source our\ncode and, to the best of our knowledge, release the largest pretrained 3D\ngenerative models across different modalities.\n","authors":["Aditya Sanghi","Aliasghar Khani","Pradyumna Reddy","Arianna Rampini","Derek Cheung","Kamal Rahimi Malekshan","Kanika Madan","Hooman Shayani"],"pdf_url":"https://arxiv.org/pdf/2411.08017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08013v1","updated":"2024-11-12T18:43:27Z","published":"2024-11-12T18:43:27Z","title":"Investigating the Effectiveness of Explainability Methods in Parkinson's\n  Detection from Speech","summary":"  Speech impairments in Parkinson's disease (PD) provide significant early\nindicators for diagnosis. While models for speech-based PD detection have shown\nstrong performance, their interpretability remains underexplored. This study\nsystematically evaluates several explainability methods to identify PD-specific\nspeech features, aiming to support the development of accurate, interpretable\nmodels for clinical decision-making in PD diagnosis and monitoring. Our\nmethodology involves (i) obtaining attributions and saliency maps using\nmainstream interpretability techniques, (ii) quantitatively evaluating the\nfaithfulness of these maps and their combinations obtained via union and\nintersection through a range of established metrics, and (iii) assessing the\ninformation conveyed by the saliency maps for PD detection from an auxiliary\nclassifier. Our results reveal that, while explanations are aligned with the\nclassifier, they often fail to provide valuable information for domain experts.\n","authors":["Eleonora Mancini","Francesco Paissan","Paolo Torroni","Cem Subakan","Mirco Ravanelli"],"pdf_url":"https://arxiv.org/pdf/2411.08013v1.pdf","comment":"The first two authors contributed equally to this research: author\n  order is alphabetical"},{"id":"http://arxiv.org/abs/2401.11555v2","updated":"2024-11-12T18:18:43Z","published":"2024-01-21T18:00:15Z","title":"VQC-Based Reinforcement Learning with Data Re-uploading: Performance and\n  Trainability","summary":"  Reinforcement Learning (RL) consists of designing agents that make\nintelligent decisions without human supervision. When used alongside function\napproximators such as Neural Networks (NNs), RL is capable of solving extremely\ncomplex problems. Deep Q-Learning, a RL algorithm that uses Deep NNs, achieved\nsuper-human performance in some specific tasks. Nonetheless, it is also\npossible to use Variational Quantum Circuits (VQCs) as function approximators\nin RL algorithms. This work empirically studies the performance and\ntrainability of such VQC-based Deep Q-Learning models in classic control\nbenchmark environments. More specifically, we research how data re-uploading\naffects both these metrics. We show that the magnitude and the variance of the\ngradients of these models remain substantial throughout training due to the\nmoving targets of Deep Q-Learning. Moreover, we empirically show that\nincreasing the number of qubits does not lead to an exponential vanishing\nbehavior of the magnitude and variance of the gradients for a PQC approximating\na 2-design, unlike what was expected due to the Barren Plateau Phenomenon. This\nhints at the possibility of VQCs being specially adequate for being used as\nfunction approximators in such a context.\n","authors":["Rodrigo Coelho","André Sequeira","Luís Paulo Santos"],"pdf_url":"https://arxiv.org/pdf/2401.11555v2.pdf","comment":"26 pages, 11 figures"},{"id":"http://arxiv.org/abs/2411.07990v1","updated":"2024-11-12T18:15:19Z","published":"2024-11-12T18:15:19Z","title":"Derivational Morphology Reveals Analogical Generalization in Large\n  Language Models","summary":"  What mechanisms underlie linguistic generalization in large language models\n(LLMs)? This question has attracted considerable attention, with most studies\nanalyzing the extent to which the language skills of LLMs resemble rules. As of\nyet, it is not known whether linguistic generalization in LLMs could equally\nwell be explained as the result of analogical processes, which can be\nformalized as similarity operations on stored exemplars. A key shortcoming of\nprior research is its focus on linguistic phenomena with a high degree of\nregularity, for which rule-based and analogical approaches make the same\npredictions. Here, we instead examine derivational morphology, specifically\nEnglish adjective nominalization, which displays notable variability. We\nintroduce a new method for investigating linguistic generalization in LLMs:\nfocusing on GPT-J, we fit cognitive models that instantiate rule-based and\nanalogical learning to the LLM training data and compare their predictions on a\nset of nonce adjectives with those of the LLM, allowing us to draw direct\nconclusions regarding underlying mechanisms. As expected, rule-based and\nanalogical models explain the predictions of GPT-J equally well for adjectives\nwith regular nominalization patterns. However, for adjectives with variable\nnominalization patterns, the analogical model provides a much better match.\nFurthermore, GPT-J's behavior is sensitive to the individual word frequencies,\neven for regular forms, a behavior that is consistent with an analogical\naccount of regular forms but not a rule-based one. These findings refute the\nhypothesis that GPT-J's linguistic generalization on adjective nominalization\ninvolves rules, suggesting similarity operations on stored exemplars as the\nunderlying mechanism. Overall, our study suggests that analogical processes\nplay a bigger role in the linguistic generalization of LLMs than previously\nthought.\n","authors":["Valentin Hofmann","Leonie Weissweiler","David Mortensen","Hinrich Schütze","Janet Pierrehumbert"],"pdf_url":"https://arxiv.org/pdf/2411.07990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02271v2","updated":"2024-11-12T18:11:30Z","published":"2024-11-04T17:03:52Z","title":"On the Utilization of Unique Node Identifiers in Graph Neural Networks","summary":"  Graph Neural Networks have inherent representational limitations due to their\nmessage-passing structure. Recent work has suggested that these limitations can\nbe overcome by using unique node identifiers (UIDs). Here we argue that despite\nthe advantages of UIDs, one of their disadvantages is that they lose the\ndesirable property of permutation-equivariance. We thus propose to focus on UID\nmodels that are permutation-equivariant, and present theoretical arguments for\ntheir advantages. Motivated by this, we propose a method to regularize UID\nmodels towards permutation equivariance, via a contrastive loss. We empirically\ndemonstrate that our approach improves generalization and extrapolation\nabilities while providing faster training convergence. On the recent BREC\nexpressiveness benchmark, our proposed method achieves state-of-the-art\nperformance compared to other random-based approaches.\n","authors":["Maya Bechler-Speicher","Moshe Eliasof","Carola-Bibiane Schönlieb","Ran Gilad-Bachrach","Amir Globerson"],"pdf_url":"https://arxiv.org/pdf/2411.02271v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07979v1","updated":"2024-11-12T17:58:40Z","published":"2024-11-12T17:58:40Z","title":"Exact, Tractable Gauss-Newton Optimization in Deep Reversible\n  Architectures Reveal Poor Generalization","summary":"  Second-order optimization has been shown to accelerate the training of deep\nneural networks in many applications, often yielding faster progress per\niteration on the training loss compared to first-order optimizers.However, the\ngeneralization properties of second-order methods are still being debated.\nTheoretical investigations have proved difficult to carry out outside the\ntractable settings of heavily simplified model classes -- thus, the relevance\nof existing theories to practical deep learning applications remains unclear.\nSimilarly, empirical studies in large-scale models and real datasets are\nsignificantly confounded by the necessity to approximate second-order updates\nin practice. It is often unclear whether the observed generalization behaviour\narises specifically from the second-order nature of the parameter updates, or\ninstead reflects the specific structured (e.g.\\ Kronecker) approximations used\nor any damping-based interpolation towards first-order updates. Here, we show\nfor the first time that exact Gauss-Newton (GN) updates take on a tractable\nform in a class of deep reversible architectures that are sufficiently\nexpressive to be meaningfully applied to common benchmark datasets. We exploit\nthis novel setting to study the training and generalization properties of the\nGN optimizer. We find that exact GN generalizes poorly. In the mini-batch\ntraining setting, this manifests as rapidly saturating progress even on the\n\\emph{training} loss, with parameter updates found to overfit each\nmini-batchatch without producing the features that would support generalization\nto other mini-batches. We show that our experiments run in the ``lazy'' regime,\nin which the neural tangent kernel (NTK) changes very little during the course\nof training. This behaviour is associated with having no significant changes in\nneural representations, explaining the lack of generalization.\n","authors":["Davide Buffelli","Jamie McGowan","Wangkun Xu","Alexandru Cioba","Da-shan Shiu","Guillaume Hennequin","Alberto Bernacchia"],"pdf_url":"https://arxiv.org/pdf/2411.07979v1.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07978v1","updated":"2024-11-12T17:58:34Z","published":"2024-11-12T17:58:34Z","title":"Doubly Robust Regression Discontinuity Designs","summary":"  This study introduces a doubly robust (DR) estimator for regression\ndiscontinuity (RD) designs. In RD designs, treatment effects are estimated in a\nquasi-experimental setting where treatment assignment depends on whether a\nrunning variable surpasses a predefined cutoff. A common approach in RD\nestimation is to apply nonparametric regression methods, such as local linear\nregression. In such an approach, the validity relies heavily on the consistency\nof nonparametric estimators and is limited by the nonparametric convergence\nrate, thereby preventing $\\sqrt{n}$-consistency. To address these issues, we\npropose the DR-RD estimator, which combines two distinct estimators for the\nconditional expected outcomes. If either of these estimators is consistent, the\ntreatment effect estimator remains consistent. Furthermore, due to the\ndebiasing effect, our proposed estimator achieves $\\sqrt{n}$-consistency if\nboth regression estimators satisfy certain mild conditions, which also\nsimplifies statistical inference.\n","authors":["Masahiro Kato"],"pdf_url":"https://arxiv.org/pdf/2411.07978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07971v1","updated":"2024-11-12T17:51:45Z","published":"2024-11-12T17:51:45Z","title":"Optimal Control of Mechanical Ventilators with Learned Respiratory\n  Dynamics","summary":"  Deciding on appropriate mechanical ventilator management strategies\nsignificantly impacts the health outcomes for patients with respiratory\ndiseases. Acute Respiratory Distress Syndrome (ARDS) is one such disease that\nrequires careful ventilator operation to be effectively treated. In this work,\nwe frame the management of ventilators for patients with ARDS as a sequential\ndecision making problem using the Markov decision process framework. We\nimplement and compare controllers based on clinical guidelines contained in the\nARDSnet protocol, optimal control theory, and learned latent dynamics\nrepresented as neural networks. The Pulse Physiology Engine's respiratory\ndynamics simulator is used to establish a repeatable benchmark, gather\nsimulated data, and quantitatively compare these controllers. We score\nperformance in terms of measured improvement in established ARDS health markers\n(pertaining to improved respiratory rate, oxygenation, and vital signs). Our\nresults demonstrate that techniques leveraging neural networks and optimal\ncontrol can automatically discover effective ventilation management strategies\nwithout access to explicit ventilator management procedures or guidelines (such\nas those defined in the ARDSnet protocol).\n","authors":["Isaac Ronald Ward","Dylan M. Asmar","Mansur Arief","Jana Krystofova Mike","Mykel J. Kochenderfer"],"pdf_url":"https://arxiv.org/pdf/2411.07971v1.pdf","comment":"2024 IEEE 37th International Symposium on Computer-Based Medical\n  Systems (CBMS), 7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.09434v2","updated":"2024-11-12T17:49:12Z","published":"2024-07-12T17:09:47Z","title":"Foundation Models for the Electric Power Grid","summary":"  Foundation models (FMs) currently dominate news headlines. They employ\nadvanced deep learning architectures to extract structural information\nautonomously from vast datasets through self-supervision. The resulting rich\nrepresentations of complex systems and dynamics can be applied to many\ndownstream applications. Therefore, FMs can find uses in electric power grids,\nchallenged by the energy transition and climate change. In this paper, we call\nfor the development of, and state why we believe in, the potential of FMs for\nelectric grids. We highlight their strengths and weaknesses amidst the\nchallenges of a changing grid. We argue that an FM learning from diverse grid\ndata and topologies could unlock transformative capabilities, pioneering a new\napproach in leveraging AI to redefine how we manage complexity and uncertainty\nin the electric grid. Finally, we discuss a power grid FM concept, namely\nGridFM, based on graph neural networks and show how different downstream tasks\nbenefit.\n","authors":["Hendrik F. Hamann","Thomas Brunschwiler","Blazhe Gjorgiev","Leonardo S. A. Martins","Alban Puech","Anna Varbella","Jonas Weiss","Juan Bernabe-Moreno","Alexandre Blondin Massé","Seong Choi","Ian Foster","Bri-Mathias Hodge","Rishabh Jain","Kibaek Kim","Vincent Mai","François Mirallès","Martin De Montigny","Octavio Ramos-Leaños","Hussein Suprême","Le Xie","El-Nasser S. Youssef","Arnaud Zinflou","Alexander J. Belyi","Ricardo J. Bessa","Bishnu Prasad Bhattarai","Johannes Schmude","Stanislav Sobolevsky"],"pdf_url":"https://arxiv.org/pdf/2407.09434v2.pdf","comment":"Major equal contributors: H.F.H., T.B., B.G., L.S.A.M., A.P., A.V.,\n  J.W.; Significant equal contributors: J.B., A.B.M., S.C., I.F., B.H., R.J.,\n  K.K., V.M., F.M., M.D.M., O.R., H.S., L.X., E.S.Y., A.Z.; Other equal\n  contributors: A.J.B., R.J.B., B.P.B., J.S., S.S; Lead contact: H.F.H"},{"id":"http://arxiv.org/abs/2411.07964v1","updated":"2024-11-12T17:41:16Z","published":"2024-11-12T17:41:16Z","title":"Sleep Staging from Airflow Signals Using Fourier Approximations of\n  Persistence Curves","summary":"  Sleep staging is a challenging task, typically manually performed by sleep\ntechnologists based on electroencephalogram and other biosignals of patients\ntaken during overnight sleep studies. Recent work aims to leverage automated\nalgorithms to perform sleep staging not based on electroencephalogram signals,\nbut rather based on the airflow signals of subjects. Prior work uses ideas from\ntopological data analysis (TDA), specifically Hermite function expansions of\npersistence curves (HEPC) to featurize airflow signals. However, finite order\nHEPC captures only partial information. In this work, we propose Fourier\napproximations of persistence curves (FAPC), and use this technique to perform\nsleep staging based on airflow signals. We analyze performance using an XGBoost\nmodel on 1155 pediatric sleep studies taken from the Nationwide Children's\nHospital Sleep DataBank (NCHSDB), and find that FAPC methods provide\ncomplimentary information to HEPC methods alone, leading to a 4.9% increase in\nperformance over baseline methods.\n","authors":["Shashank Manjunath","Hau-Tieng Wu","Aarti Sathyanarayana"],"pdf_url":"https://arxiv.org/pdf/2411.07964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07959v1","updated":"2024-11-12T17:36:20Z","published":"2024-11-12T17:36:20Z","title":"On the Convergence of Continual Federated Learning Using Incrementally\n  Aggregated Gradients","summary":"  The holy grail of machine learning is to enable Continual Federated Learning\n(CFL) to enhance the efficiency, privacy, and scalability of AI systems while\nlearning from streaming data. The primary challenge of a CFL system is to\novercome global catastrophic forgetting, wherein the accuracy of the global\nmodel trained on new tasks declines on the old tasks. In this work, we propose\nContinual Federated Learning with Aggregated Gradients (C-FLAG), a novel\nreplay-memory based federated strategy consisting of edge-based gradient\nupdates on memory and aggregated gradients on the current data. We provide\nconvergence analysis of the C-FLAG approach which addresses forgetting and bias\nwhile converging at a rate of $O(1/\\sqrt{T})$ over $T$ communication rounds. We\nformulate an optimization sub-problem that minimizes catastrophic forgetting,\ntranslating CFL into an iterative algorithm with adaptive learning rates that\nensure seamless learning across tasks. We empirically show that C-FLAG\noutperforms several state-of-the-art baselines on both task and\nclass-incremental settings with respect to metrics such as accuracy and\nforgetting.\n","authors":["Satish Kumar Keshri","Nazreen Shah","Ranjitha Prasad"],"pdf_url":"https://arxiv.org/pdf/2411.07959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07957v1","updated":"2024-11-12T17:34:38Z","published":"2024-11-12T17:34:38Z","title":"Tukey g-and-h neural network regression for non-Gaussian data","summary":"  This paper addresses non-Gaussian regression with neural networks via the use\nof the Tukey g-and-h distribution.The Tukey g-and-h transform is a flexible\nparametric transform with two parameters $g$ and $h$ which, when applied to a\nstandard normal random variable, introduces both skewness and kurtosis,\nresulting in a distribution commonly called the Tukey g-and-h distribution.\nSpecific values of $g$ and $h$ produce good approximations to other families of\ndistributions, such as the Cauchy and student-t distributions. The flexibility\nof the Tukey g-and-h distribution has driven its popularity in the statistical\ncommunity, in applied sciences and finance. In this work we consider the\ntraining of a neural network to predict the parameters of a Tukey g-and-h\ndistribution in a regression framework via the minimization of the\ncorresponding negative log-likelihood, despite the latter having no closed-form\nexpression. We demonstrate the efficiency of our procedure in simulated\nexamples and apply our method to a real-world dataset of global crop yield for\nseveral types of crops. Finally, we show how we can carry out a goodness-of-fit\nanalysis between the predicted distributions and the test data. A Pytorch\nimplementation is made available on Github and as a Pypi package.\n","authors":["Arthur P. Guillaumin","Natalia Efremova"],"pdf_url":"https://arxiv.org/pdf/2411.07957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07954v1","updated":"2024-11-12T17:30:31Z","published":"2024-11-12T17:30:31Z","title":"Learning Memory Mechanisms for Decision Making through Demonstrations","summary":"  In Partially Observable Markov Decision Processes, integrating an agent's\nhistory into memory poses a significant challenge for decision-making.\nTraditional imitation learning, relying on observation-action pairs for expert\ndemonstrations, fails to capture the expert's memory mechanisms used in\ndecision-making. To capture memory processes as demonstrations, we introduce\nthe concept of \\textbf{memory dependency pairs} $(p, q)$ indicating that events\nat time $p$ are recalled for decision-making at time $q$. We introduce\n\\textbf{AttentionTuner} to leverage memory dependency pairs in Transformers and\nfind significant improvements across several tasks compared to standard\nTransformers when evaluated on Memory Gym and the Long-term Memory Benchmark.\nCode is available at https://github.com/WilliamYue37/AttentionTuner .\n","authors":["William Yue","Bo Liu","Peter Stone"],"pdf_url":"https://arxiv.org/pdf/2411.07954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07942v1","updated":"2024-11-12T17:11:46Z","published":"2024-11-12T17:11:46Z","title":"Towards Low-bit Communication for Tensor Parallel LLM Inference","summary":"  Tensor parallelism provides an effective way to increase server large\nlanguage model (LLM) inference efficiency despite adding an additional\ncommunication cost. However, as server LLMs continue to scale in size, they\nwill need to be distributed across more devices, magnifying the communication\ncost. One way to approach this problem is with quantization, but current\nmethods for LLMs tend to avoid quantizing the features that tensor parallelism\nneeds to communicate. Taking advantage of consistent outliers in communicated\nfeatures, we introduce a quantization method that reduces communicated values\non average from 16 bits to 4.2 bits while preserving nearly all of the original\nperformance. For instance, our method maintains around 98.0% and 99.5% of Gemma\n2 27B's and Llama 2 13B's original performance, respectively, averaged across\nall tasks we evaluated on.\n","authors":["Harry Dong","Tyler Johnson","Minsik Cho","Emad Soroush"],"pdf_url":"https://arxiv.org/pdf/2411.07942v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07934v1","updated":"2024-11-12T17:04:56Z","published":"2024-11-12T17:04:56Z","title":"Doubly Mild Generalization for Offline Reinforcement Learning","summary":"  Offline Reinforcement Learning (RL) suffers from the extrapolation error and\nvalue overestimation. From a generalization perspective, this issue can be\nattributed to the over-generalization of value functions or policies towards\nout-of-distribution (OOD) actions. Significant efforts have been devoted to\nmitigating such generalization, and recent in-sample learning approaches have\nfurther succeeded in entirely eschewing it. Nevertheless, we show that mild\ngeneralization beyond the dataset can be trusted and leveraged to improve\nperformance under certain conditions. To appropriately exploit generalization\nin offline RL, we propose Doubly Mild Generalization (DMG), comprising (i) mild\naction generalization and (ii) mild generalization propagation. The former\nrefers to selecting actions in a close neighborhood of the dataset to maximize\nthe Q values. Even so, the potential erroneous generalization can still be\npropagated, accumulated, and exacerbated by bootstrapping. In light of this,\nthe latter concept is introduced to mitigate the generalization propagation\nwithout impeding the propagation of RL learning signals. Theoretically, DMG\nguarantees better performance than the in-sample optimal policy in the oracle\ngeneralization scenario. Even under worst-case generalization, DMG can still\ncontrol value overestimation at a certain level and lower bound the\nperformance. Empirically, DMG achieves state-of-the-art performance across\nGym-MuJoCo locomotion tasks and challenging AntMaze tasks. Moreover, benefiting\nfrom its flexibility in both generalization aspects, DMG enjoys a seamless\ntransition from offline to online learning and attains strong online\nfine-tuning performance.\n","authors":["Yixiu Mao","Qi Wang","Yun Qu","Yuhang Jiang","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2411.07934v1.pdf","comment":"Accepted to NeurIPS 2024. arXiv admin note: substantial text overlap\n  with arXiv:2410.19400"},{"id":"http://arxiv.org/abs/2411.07933v1","updated":"2024-11-12T17:04:12Z","published":"2024-11-12T17:04:12Z","title":"Prediction of Acoustic Communication Performance for AUVs using Gaussian\n  Process Classification","summary":"  Cooperating autonomous underwater vehicles (AUVs) often rely on acoustic\ncommunication to coordinate their actions effectively. However, the reliability\nof underwater acoustic communication decreases as the communication range\nbetween vehicles increases. Consequently, teams of cooperating AUVs typically\nmake conservative assumptions about the maximum range at which they can\ncommunicate reliably. To address this limitation, we propose a novel approach\nthat involves learning a map representing the probability of successful\ncommunication based on the locations of the transmitting and receiving\nvehicles. This probabilistic communication map accounts for factors such as the\nrange between vehicles, environmental noise, and multi-path effects at a given\nlocation. In pursuit of this goal, we investigate the application of Gaussian\nprocess binary classification to generate the desired communication map. We\nspecialize existing results to this specific binary classification problem and\nexplore methods to incorporate uncertainty in vehicle location into the mapping\nprocess. Furthermore, we compare the prediction performance of the probability\ncommunication map generated using binary classification with that of a\nsignal-to-noise ratio (SNR) communication map generated using Gaussian process\nregression. Our approach is experimentally validated using communication and\nnavigation data collected during trials with a pair of Virginia Tech 690 AUVs.\n","authors":["Yifei Gao","Harun Yetkin","McMahon James","Daniel J. Stilwell"],"pdf_url":"https://arxiv.org/pdf/2411.07933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01897v2","updated":"2024-11-12T16:48:29Z","published":"2024-11-04T09:04:11Z","title":"LE-PDE++: Mamba for accelerating PDEs Simulations","summary":"  Partial Differential Equations are foundational in modeling science and\nnatural systems such as fluid dynamics and weather forecasting. The Latent\nEvolution of PDEs method is designed to address the computational intensity of\nclassical and deep learning-based PDE solvers by proposing a scalable and\nefficient alternative. To enhance the efficiency and accuracy of LE-PDE, we\nincorporate the Mamba model, an advanced machine learning model known for its\npredictive efficiency and robustness in handling complex dynamic systems with a\nprogressive learning strategy. The LE-PDE was tested on several benchmark\nproblems. The method demonstrated a marked reduction in computational time\ncompared to traditional solvers and standalone deep learning models while\nmaintaining high accuracy in predicting system behavior over time. Our method\ndoubles the inference speed compared to the LE-PDE while retaining the same\nlevel of parameter efficiency, making it well-suited for scenarios requiring\nlong-term predictions.\n","authors":["Aoming Liang","Zhaoyang Mu","Qi liu","Ruipeng Li","Mingming Ge","Dixia Fan"],"pdf_url":"https://arxiv.org/pdf/2411.01897v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03497v2","updated":"2024-11-12T16:44:24Z","published":"2024-08-07T01:37:10Z","title":"Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and\n  Tabnet with SMOTEENN","summary":"  Bank credit risk is a significant challenge in modern financial transactions,\nand the ability to identify qualified credit card holders among a large number\nof applicants is crucial for the profitability of a bank'sbank's credit card\nbusiness. In the past, screening applicants'applicants' conditions often\nrequired a significant amount of manual labor, which was time-consuming and\nlabor-intensive. Although the accuracy and reliability of previously used ML\nmodels have been continuously improving, the pursuit of more reliable and\npowerful AI intelligent models is undoubtedly the unremitting pursuit by major\nbanks in the financial industry. In this study, we used a dataset of over\n40,000 records provided by a commercial bank as the research object. We\ncompared various dimensionality reduction techniques such as PCA and T-SNE for\npreprocessing high-dimensional datasets and performed in-depth adaptation and\ntuning of distributed models such as LightGBM and XGBoost, as well as deep\nmodels like Tabnet. After a series of research and processing, we obtained\nexcellent research results by combining SMOTEENN with these techniques. The\nexperiments demonstrated that LightGBM combined with PCA and SMOTEENN\ntechniques can assist banks in accurately predicting potential high-quality\ncustomers, showing relatively outstanding performance compared to other models.\n","authors":["Chang Yu","Yixin Jin","Qianwen Xing","Ye Zhang","Shaobo Guo","Shuchen Meng"],"pdf_url":"https://arxiv.org/pdf/2408.03497v2.pdf","comment":"8 pagess on IEEE ICPICS"},{"id":"http://arxiv.org/abs/2406.04658v3","updated":"2024-11-12T16:44:20Z","published":"2024-06-07T05:56:43Z","title":"Advanced Payment Security System:XGBoost, LightGBM and SMOTE Integrated","summary":"  With the rise of various online and mobile payment systems, transaction fraud\nhas become a significant threat to financial security. This study explores the\napplication of advanced machine learning models, specifically based on XGBoost\nand LightGBM, for developing a more accurate and robust Payment Security\nProtection Model. To enhance data reliability, we meticulously processed the\ndata sources and applied SMOTE (Synthetic Minority Over-sampling Technique) to\naddress class imbalance and improve data representation. By selecting highly\ncorrelated features, we aimed to strengthen the training process and boost\nmodel performance. We conducted thorough performance evaluations of our\nproposed models, comparing them against traditional methods including Random\nForest, Neural Network, and Logistic Regression. Using metrics such as\nPrecision, Recall, and F1 Score, we rigorously assessed their effectiveness.\nOur detailed analyses and comparisons reveal that the combination of SMOTE with\nXGBoost and LightGBM offers a highly efficient and powerful mechanism for\npayment security protection. Moreover, the integration of XGBoost and LightGBM\nin a Local Ensemble model further demonstrated outstanding performance. After\nincorporating SMOTE, the new combined model achieved a significant improvement\nof nearly 6\\% over traditional models and around 5\\% over its sub-models,\nshowcasing remarkable results.\n","authors":["Qi Zheng","Chang Yu","Jin Cao","Yongshun Xu","Qianwen Xing","Yinxin Jin"],"pdf_url":"https://arxiv.org/pdf/2406.04658v3.pdf","comment":"This paper is received by https://ieee-metacom.org"},{"id":"http://arxiv.org/abs/2406.03733v4","updated":"2024-11-12T16:44:14Z","published":"2024-06-06T04:12:57Z","title":"Credit Card Fraud Detection Using Advanced Transformer Model","summary":"  With the proliferation of various online and mobile payment systems, credit\ncard fraud has emerged as a significant threat to financial security. This\nstudy focuses on innovative applications of the latest Transformer models for\nmore robust and precise fraud detection. To ensure the reliability of the data,\nwe meticulously processed the data sources, balancing the dataset to address\nthe issue of data sparsity significantly. We also selected highly correlated\nvectors to strengthen the training process.To guarantee the reliability and\npracticality of the new Transformer model, we conducted performance comparisons\nwith several widely adopted models, including Support Vector Machine (SVM),\nRandom Forest, Neural Network, and Logistic Regression. We rigorously compared\nthese models using metrics such as Precision, Recall, and F1 Score. Through\nthese detailed analyses and comparisons, we present to the readers a highly\nefficient and powerful anti-fraud mechanism with promising prospects. The\nresults demonstrate that the Transformer model not only excels in traditional\napplications but also shows great potential in niche areas like fraud\ndetection, offering a substantial advancement in the field.\n","authors":["Chang Yu","Yongshun Xu","Jin Cao","Ye Zhang","Yinxin Jin","Mengran Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.03733v4.pdf","comment":"This paper have been received by https://ieee-metacom.org/"},{"id":"http://arxiv.org/abs/2410.00256v2","updated":"2024-11-12T16:43:41Z","published":"2024-09-30T21:56:16Z","title":"Enhanced Credit Score Prediction Using Ensemble Deep Learning Model","summary":"  In contemporary economic society, credit scores are crucial for every\nparticipant. A robust credit evaluation system is essential for the\nprofitability of core businesses such as credit cards, loans, and investments\nfor commercial banks and the financial sector. This paper combines\nhigh-performance models like XGBoost and LightGBM, already widely used in\nmodern banking systems, with the powerful TabNet model. We have developed a\npotent model capable of accurately determining credit score levels by\nintegrating Random Forest, XGBoost, and TabNet, and through the stacking\ntechnique in ensemble modeling. This approach surpasses the limitations of\nsingle models and significantly advances the precise credit score prediction.\nIn the following sections, we will explain the techniques we used and\nthoroughly validate our approach by comprehensively comparing a series of\nmetrics such as Precision, Recall, F1, and AUC. By integrating Random Forest,\nXGBoost, and with the TabNet deep learning architecture, these models\ncomplement each other, demonstrating exceptionally strong overall performance.\n","authors":["Qianwen Xing","Chang Yu","Sining Huang","Qi Zheng","Xingyu Mu","Mengying Sun"],"pdf_url":"https://arxiv.org/pdf/2410.00256v2.pdf","comment":"This paper have been accepted by sci of AI Journal"},{"id":"http://arxiv.org/abs/2305.16945v3","updated":"2024-11-12T16:23:50Z","published":"2023-05-26T14:00:12Z","title":"Levin Tree Search with Context Models","summary":"  Levin Tree Search (LTS) is a search algorithm that makes use of a policy (a\nprobability distribution over actions) and comes with a theoretical guarantee\non the number of expansions before reaching a goal node, depending on the\nquality of the policy. This guarantee can be used as a loss function, which we\ncall the LTS loss, to optimize neural networks representing the policy\n(LTS+NN). In this work we show that the neural network can be substituted with\nparameterized context models originating from the online compression literature\n(LTS+CM). We show that the LTS loss is convex under this new model, which\nallows for using standard convex optimization tools, and obtain convergence\nguarantees to the optimal parameters in an online setting for a given set of\nsolution trajectories -- guarantees that cannot be provided for neural\nnetworks. The new LTS+CM algorithm compares favorably against LTS+NN on several\nbenchmarks: Sokoban (Boxoban), The Witness, and the 24-Sliding Tile puzzle\n(STP). The difference is particularly large on STP, where LTS+NN fails to solve\nmost of the test instances while LTS+CM solves each test instance in a fraction\nof a second. Furthermore, we show that LTS+CM is able to learn a policy that\nsolves the Rubik's cube in only a few hundred expansions, which considerably\nimproves upon previous machine learning techniques.\n","authors":["Laurent Orseau","Marcus Hutter","Levi H. S. Lelis"],"pdf_url":"https://arxiv.org/pdf/2305.16945v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.18438v3","updated":"2024-11-12T15:57:13Z","published":"2023-11-30T10:39:47Z","title":"Piecewise Linearity of Min-Norm Solution Map of a Nonconvexly\n  Regularized Convex Sparse Model","summary":"  It is well known that the minimum $\\ell_2$-norm solution of the convex LASSO\nmodel, say $\\mathbf{x}_{\\star}$, is a continuous piecewise linear function of\nthe regularization parameter $\\lambda$, and its signed sparsity pattern is\nconstant within each linear piece. The current study is an extension of this\nclassic result, proving that the aforementioned properties extend to the\nmin-norm solution map $\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$, where\n$\\mathbf{y}$ is the observed signal, for a generalization of LASSO termed the\nscaled generalized minimax concave (sGMC) model. The sGMC model adopts a\nnonconvex debiased variant of the $\\ell_1$-norm as sparse regularizer, but its\nobjective function is overall-convex. Based on the geometric properties of\n$\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$, we propose an extension of the least\nangle regression (LARS) algorithm, which iteratively computes the closed-form\nexpression of $\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$ in each linear zone.\nUnder suitable conditions, the proposed algorithm provably obtains the whole\nsolution map $\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$ within finite iterations.\nNotably, our proof techniques for establishing continuity and piecewise\nlinearity of $\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$ are novel, and they lead\nto two side contributions: (a) our proofs establish continuity of the sGMC\nsolution set as a set-valued mapping of $(\\mathbf{y},\\lambda)$; (b) to prove\npiecewise linearity and piecewise constant sparsity pattern of\n$\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$, we do not require any assumption that\nprevious work relies on (whereas to prove some additional properties of\n$\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$, we use a different set of assumptions\nfrom previous work).\n","authors":["Yi Zhang","Isao Yamada"],"pdf_url":"https://arxiv.org/pdf/2311.18438v3.pdf","comment":"40 pages. Submitted to journal"},{"id":"http://arxiv.org/abs/2403.00043v2","updated":"2024-11-12T15:54:29Z","published":"2024-02-29T14:50:58Z","title":"RiNALMo: General-Purpose RNA Language Models Can Generalize Well on\n  Structure Prediction Tasks","summary":"  While RNA has recently been recognized as an interesting small-molecule drug\ntarget, many challenges remain to be addressed before we take full advantage of\nit. This emphasizes the necessity to improve our understanding of its\nstructures and functions. Over the years, sequencing technologies have produced\nan enormous amount of unlabeled RNA data, which hides a huge potential.\nMotivated by the successes of protein language models, we introduce RiboNucleic\nAcid Language Model (RiNALMo) to unveil the hidden code of RNA. RiNALMo is the\nlargest RNA language model to date, with 650M parameters pre-trained on 36M\nnon-coding RNA sequences from several databases. It can extract hidden\nknowledge and capture the underlying structure information implicitly embedded\nwithin the RNA sequences. RiNALMo achieves state-of-the-art results on several\ndownstream tasks. Notably, we show that its generalization capabilities\novercome the inability of other deep learning methods for secondary structure\nprediction to generalize on unseen RNA families.\n","authors":["Rafael Josip Penić","Tin Vlašić","Roland G. Huber","Yue Wan","Mile Šikić"],"pdf_url":"https://arxiv.org/pdf/2403.00043v2.pdf","comment":"31 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.07889v1","updated":"2024-11-12T15:51:35Z","published":"2024-11-12T15:51:35Z","title":"A Stochastic Optimization Framework for Private and Fair Learning From\n  Decentralized Data","summary":"  Machine learning models are often trained on sensitive data (e.g., medical\nrecords and race/gender) that is distributed across different \"silos\" (e.g.,\nhospitals). These federated learning models may then be used to make\nconsequential decisions, such as allocating healthcare resources. Two key\nchallenges emerge in this setting: (i) maintaining the privacy of each person's\ndata, even if other silos or an adversary with access to the central server\ntries to infer this data; (ii) ensuring that decisions are fair to different\ndemographic groups (e.g., race/gender). In this paper, we develop a novel\nalgorithm for private and fair federated learning (FL). Our algorithm satisfies\ninter-silo record-level differential privacy (ISRL-DP), a strong notion of\nprivate FL requiring that silo i's sent messages satisfy record-level\ndifferential privacy for all i. Our framework can be used to promote different\nfairness notions, including demographic parity and equalized odds. We prove\nthat our algorithm converges under mild smoothness assumptions on the loss\nfunction, whereas prior work required strong convexity for convergence. As a\nbyproduct of our analysis, we obtain the first convergence guarantee for\nISRL-DP nonconvex-strongly concave min-max FL. Experiments demonstrate the\nstate-of-the-art fairness-accuracy tradeoffs of our algorithm across different\nprivacy levels.\n","authors":["Devansh Gupta","A. S. Poornash","Andrew Lowy","Meisam Razaviyayn"],"pdf_url":"https://arxiv.org/pdf/2411.07889v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07885v1","updated":"2024-11-12T15:47:17Z","published":"2024-11-12T15:47:17Z","title":"INTRABENCH: Interactive Radiological Benchmark","summary":"  Current interactive segmentation approaches, inspired by the success of\nMETA's Segment Anything model, have achieved notable advancements, however,\nthey come with substantial limitations that hinder their practical application\nin real clinical scenarios. These include unrealistic human interaction\nrequirements, such as slice-by-slice operations for 2D models on 3D data, a\nlack of iterative refinement, and insufficient evaluation experiments. These\nshortcomings prevent accurate assessment of model performance and lead to\ninconsistent outcomes across studies. IntRaBench overcomes these challenges by\noffering a comprehensive and reproducible framework for evaluating interactive\nsegmentation methods in realistic, clinically relevant scenarios. It includes\ndiverse datasets, target structures, and segmentation models, and provides a\nflexible codebase that allows seamless integration of new models and prompting\nstrategies. Additionally, we introduce advanced techniques to minimize\nclinician interaction, ensuring fair comparisons between 2D and 3D models. By\nopen-sourcing IntRaBench, we invite the research community to integrate their\nmodels and prompting techniques, ensuring continuous and transparent evaluation\nof interactive segmentation models in 3D medical imaging.\n","authors":["Constantin Ulrich","Tassilo Wald","Emily Tempus","Maximilian Rokuss","Paul F. Jaeger","Klaus Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2411.07885v1.pdf","comment":"Undergoing Peer-Review"},{"id":"http://arxiv.org/abs/2310.05327v2","updated":"2024-11-12T15:34:57Z","published":"2023-10-09T01:18:07Z","title":"Provable Compositional Generalization for Object-Centric Learning","summary":"  Learning representations that generalize to novel compositions of known\nconcepts is crucial for bridging the gap between human and machine perception.\nOne prominent effort is learning object-centric representations, which are\nwidely conjectured to enable compositional generalization. Yet, it remains\nunclear when this conjecture will be true, as a principled theoretical or\nempirical understanding of compositional generalization is lacking. In this\nwork, we investigate when compositional generalization is guaranteed for\nobject-centric representations through the lens of identifiability theory. We\nshow that autoencoders that satisfy structural assumptions on the decoder and\nenforce encoder-decoder consistency will learn object-centric representations\nthat provably generalize compositionally. We validate our theoretical result\nand highlight the practical relevance of our assumptions through experiments on\nsynthetic image data.\n","authors":["Thaddäus Wiedemer","Jack Brady","Alexander Panfilov","Attila Juhos","Matthias Bethge","Wieland Brendel"],"pdf_url":"https://arxiv.org/pdf/2310.05327v2.pdf","comment":"Oral at ICLR 2024. The first four authors contributed equally"},{"id":"http://arxiv.org/abs/2306.10084v3","updated":"2024-11-12T15:32:40Z","published":"2023-06-16T11:57:11Z","title":"Convolutional and Deep Learning based techniques for Time Series Ordinal\n  Classification","summary":"  Time Series Classification (TSC) covers the supervised learning problem where\ninput data is provided in the form of series of values observed through\nrepeated measurements over time, and whose objective is to predict the category\nto which they belong. When the class values are ordinal, classifiers that take\nthis into account can perform better than nominal classifiers. Time Series\nOrdinal Classification (TSOC) is the field covering this gap, yet unexplored in\nthe literature. There are a wide range of time series problems showing an\nordered label structure, and TSC techniques that ignore the order relationship\ndiscard useful information. Hence, this paper presents a first benchmarking of\nTSOC methodologies, exploiting the ordering of the target labels to boost the\nperformance of current TSC state-of-the-art. Both convolutional- and deep\nlearning-based methodologies (among the best performing alternatives for\nnominal TSC) are adapted for TSOC. For the experiments, a selection of 29\nordinal problems from two well-known archives has been made. In this way, this\npaper contributes to the establishment of the state-of-the-art in TSOC. The\nresults obtained by ordinal versions are found to be significantly better than\ncurrent nominal TSC techniques in terms of ordinal performance metrics,\noutlining the importance of considering the ordering of the labels when dealing\nwith this kind of problems.\n","authors":["Rafael Ayllón-Gavilán","David Guijo-Rubio","Pedro Antonio Gutiérrez","Anthony Bagnall","César Hervás-Martínez"],"pdf_url":"https://arxiv.org/pdf/2306.10084v3.pdf","comment":"13 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.00171v2","updated":"2024-11-12T15:30:15Z","published":"2024-09-30T19:18:34Z","title":"Basis-to-Basis Operator Learning Using Function Encoders","summary":"  We present Basis-to-Basis (B2B) operator learning, a novel approach for\nlearning operators on Hilbert spaces of functions based on the foundational\nideas of function encoders. We decompose the task of learning operators into\ntwo parts: learning sets of basis functions for both the input and output\nspaces and learning a potentially nonlinear mapping between the coefficients of\nthe basis functions. B2B operator learning circumvents many challenges of prior\nworks, such as requiring data to be at fixed locations, by leveraging classic\ntechniques such as least squares to compute the coefficients. It is especially\npotent for linear operators, where we compute a mapping between bases as a\nsingle matrix transformation with a closed-form solution. Furthermore, with\nminimal modifications and using the deep theoretical connections between\nfunction encoders and functional analysis, we derive operator learning\nalgorithms that are directly analogous to eigen-decomposition and singular\nvalue decomposition. We empirically validate B2B operator learning on seven\nbenchmark operator learning tasks and show that it demonstrates a\ntwo-orders-of-magnitude improvement in accuracy over existing approaches on\nseveral benchmark tasks.\n","authors":["Tyler Ingebrand","Adam J. Thorpe","Somdatta Goswami","Krishna Kumar","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2410.00171v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07873v1","updated":"2024-11-12T15:29:50Z","published":"2024-11-12T15:29:50Z","title":"Diverse capability and scaling of diffusion and auto-regressive models\n  when learning abstract rules","summary":"  Humans excel at discovering regular structures from limited samples and\napplying inferred rules to novel settings. We investigate whether modern\ngenerative models can similarly learn underlying rules from finite samples and\nperform reasoning through conditional sampling. Inspired by Raven's Progressive\nMatrices task, we designed GenRAVEN dataset, where each sample consists of\nthree rows, and one of 40 relational rules governing the object position,\nnumber, or attributes applies to all rows. We trained generative models to\nlearn the data distribution, where samples are encoded as integer arrays to\nfocus on rule learning. We compared two generative model families: diffusion\n(EDM, DiT, SiT) and autoregressive models (GPT2, Mamba). We evaluated their\nability to generate structurally consistent samples and perform panel\ncompletion via unconditional and conditional sampling. We found diffusion\nmodels excel at unconditional generation, producing more novel and consistent\nsamples from scratch and memorizing less, but performing less well in panel\ncompletion, even with advanced conditional sampling methods. Conversely,\nautoregressive models excel at completing missing panels in a rule-consistent\nmanner but generate less consistent samples unconditionally. We observe diverse\ndata scaling behaviors: for both model families, rule learning emerges at a\ncertain dataset size - around 1000s examples per rule. With more training data,\ndiffusion models improve both their unconditional and conditional generation\ncapabilities. However, for autoregressive models, while panel completion\nimproves with more training data, unconditional generation consistency\ndeclines. Our findings highlight complementary capabilities and limitations of\ndiffusion and autoregressive models in rule learning and reasoning tasks,\nsuggesting avenues for further research into their mechanisms and potential for\nhuman-like reasoning.\n","authors":["Binxu Wang","Jiaqi Shang","Haim Sompolinsky"],"pdf_url":"https://arxiv.org/pdf/2411.07873v1.pdf","comment":"12 pages, 5 figures. Accepted to NeurIPS2024 Workshop on System 2\n  Reasoning At Scale as long paper"},{"id":"http://arxiv.org/abs/2411.07863v1","updated":"2024-11-12T15:22:14Z","published":"2024-11-12T15:22:14Z","title":"CDXFormer: Boosting Remote Sensing Change Detection with Extended Long\n  Short-Term Memory","summary":"  In complex scenes and varied conditions, effectively integrating\nspatial-temporal context is crucial for accurately identifying changes.\nHowever, current RS-CD methods lack a balanced consideration of performance and\nefficiency. CNNs lack global context, Transformers have quadratic computational\ncomplexity, and Mambas are restricted by CUDA acceleration. In this paper, we\npropose CDXFormer, with a core component that is a powerful XLSTM-based feature\nenhancement layer, integrating the advantages of linear computational\ncomplexity, global context perception, and strong interpret-ability.\nSpecifically, we introduce a scale-specific Feature Enhancer layer,\nincorporating a Cross-Temporal Global Perceptron customized for\nsemantic-accurate deep features, and a Cross-Temporal Spatial Refiner\ncustomized for detail-rich shallow features. Additionally, we propose a\nCross-Scale Interactive Fusion module to progressively interact global change\nrepresentations with spatial responses. Extensive experimental results\ndemonstrate that CDXFormer achieves state-of-the-art performance across three\nbenchmark datasets, offering a compelling balance between efficiency and\naccuracy. Code is available at https://github.com/xwmaxwma/rschange.\n","authors":["Zhenkai Wu","Xiaowen Ma","Rongrong Lian","Zhentao Lin","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04492v4","updated":"2024-11-12T15:16:36Z","published":"2024-10-06T14:11:39Z","title":"Interpret Your Decision: Logical Reasoning Regularization for\n  Generalization in Visual Classification","summary":"  Vision models excel in image classification but struggle to generalize to\nunseen data, such as classifying images from unseen domains or discovering\nnovel categories. In this paper, we explore the relationship between logical\nreasoning and deep learning generalization in visual classification. A logical\nregularization termed L-Reg is derived which bridges a logical analysis\nframework to image classification. Our work reveals that L-Reg reduces the\ncomplexity of the model in terms of the feature distribution and classifier\nweights. Specifically, we unveil the interpretability brought by L-Reg, as it\nenables the model to extract the salient features, such as faces to persons,\nfor classification. Theoretical analysis and experiments demonstrate that L-Reg\nenhances generalization across various scenarios, including multi-domain\ngeneralization and generalized category discovery. In complex real-world\nscenarios where images span unknown classes and unseen domains, L-Reg\nconsistently improves generalization, highlighting its practical efficacy.\n","authors":["Zhaorui Tan","Xi Yang","Qiufeng Wang","Anh Nguyen","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.04492v4.pdf","comment":"Accepted by NeurIPS2024 as Spotlight"},{"id":"http://arxiv.org/abs/2411.07854v1","updated":"2024-11-12T15:06:06Z","published":"2024-11-12T15:06:06Z","title":"Tucano: Advancing Neural Text Generation for Portuguese","summary":"  Significant advances have been made in natural language processing in recent\nyears. However, our current deep learning approach to language modeling\nrequires substantial resources in terms of data and computation. One of the\nside effects of this data-hungry paradigm is the current schism between\nlanguages, separating those considered high-resource, where most of the\ndevelopment happens and resources are available, and the low-resource ones,\nwhich struggle to attain the same level of performance and autonomy. This study\naims to introduce a new set of resources to stimulate the future development of\nneural text generation in Portuguese. In this work, we document the development\nof GigaVerbo, a concatenation of deduplicated Portuguese text corpora amounting\nto 200 billion tokens. Via this corpus, we trained a series of\ndecoder-transformers named Tucano. Our models perform equal or superior to\nother Portuguese and multilingual language models of similar size in several\nPortuguese benchmarks. The evaluation of our models also reveals that model\nperformance on many currently available benchmarks used by the Portuguese NLP\ncommunity has little to no correlation with the scaling of token ingestion\nduring training, highlighting the limitations of such evaluations when it comes\nto the assessment of Portuguese generative language models. All derivatives of\nour study are openly released on GitHub and Hugging Face. See\nhttps://nkluge-correa.github.io/Tucano/\n","authors":["Nicholas Kluge Corrêa","Aniket Sen","Sophia Falk","Shiza Fatimah"],"pdf_url":"https://arxiv.org/pdf/2411.07854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07853v1","updated":"2024-11-12T15:06:04Z","published":"2024-11-12T15:06:04Z","title":"Evidential time-to-event prediction model with well-calibrated\n  uncertainty estimation","summary":"  Time-to-event analysis, or Survival analysis, provides valuable insights into\nclinical prognosis and treatment recommendations. However, this task is\ntypically more challenging than other regression tasks due to the censored\nobservations. Moreover, concerns regarding the reliability of predictions\npersist among clinicians, mainly attributed to the absence of confidence\nassessment, robustness, and calibration of prediction. To address those\nchallenges, we introduce an evidential regression model designed especially for\ntime-to-event prediction tasks, with which the most plausible event time, is\ndirectly quantified by aggregated Gaussian random fuzzy numbers (GRFNs). The\nGRFNs are a newly introduced family of random fuzzy subsets of the real line\nthat generalizes both Gaussian random variables and Gaussian possibility\ndistributions. Different from conventional methods that construct models based\non strict data distribution, e.g., proportional hazard function, our model only\nassumes the event time is encoded in a real line GFRN without any strict\ndistribution assumption, therefore offering more flexibility in complex data\nscenarios. Furthermore, the epistemic and aleatory uncertainty regarding the\nevent time is quantified within the aggregated GRFN as well. Our model can,\ntherefore, provide more detailed clinical decision-making guidance with two\nmore degrees of information. The model is fit by minimizing a generalized\nnegative log-likelihood function that accounts for data censoring based on\nuncertainty evidence reasoning. Experimental results on simulated datasets with\nvarying data distributions and censoring scenarios, as well as on real-world\ndatasets across diverse clinical settings and tasks, demonstrate that our model\nachieves both accurate and reliable performance, outperforming state-of-the-art\nmethods.\n","authors":["Ling Huang","Yucheng Xing","Swapnil Mishra","Thierry Denoeux","Mengling Feng"],"pdf_url":"https://arxiv.org/pdf/2411.07853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05225v5","updated":"2024-11-12T15:05:00Z","published":"2024-06-07T19:25:02Z","title":"A Manifold Perspective on the Statistical Generalization of Graph Neural\n  Networks","summary":"  Graph Neural Networks (GNNs) extend convolutional neural networks to operate\non graphs. Despite their impressive performances in various graph learning\ntasks, the theoretical understanding of their generalization capability is\nstill lacking. Previous GNN generalization bounds ignore the underlying graph\nstructures, often leading to bounds that increase with the number of nodes -- a\nbehavior contrary to the one experienced in practice. In this paper, we take a\nmanifold perspective to establish the statistical generalization theory of GNNs\non graphs sampled from a manifold in the spectral domain. As demonstrated\nempirically, we prove that the generalization bounds of GNNs decrease linearly\nwith the size of the graphs in the logarithmic scale, and increase linearly\nwith the spectral continuity constants of the filter functions. Notably, our\ntheory explains both node-level and graph-level tasks. Our result has two\nimplications: i) guaranteeing the generalization of GNNs to unseen data over\nmanifolds; ii) providing insights into the practical design of GNNs, i.e.,\nrestrictions on the discriminability of GNNs are necessary to obtain a better\ngeneralization performance. We demonstrate our generalization bounds of GNNs\nusing synthetic and multiple real-world datasets.\n","authors":["Zhiyang Wang","Juan Cervino","Alejandro Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2406.05225v5.pdf","comment":"37 pages,25 figures, 10 tables"},{"id":"http://arxiv.org/abs/2402.11658v3","updated":"2024-11-12T15:03:48Z","published":"2024-02-18T17:32:53Z","title":"Dynamic planning in hierarchical active inference","summary":"  By dynamic planning, we refer to the ability of the human brain to infer and\nimpose motor trajectories related to cognitive decisions. A recent paradigm,\nactive inference, brings fundamental insights into the adaptation of biological\norganisms, constantly striving to minimize prediction errors to restrict\nthemselves to life-compatible states. Over the past years, many studies have\nshown how human and animal behaviors could be explained in terms of active\ninference - either as discrete decision-making or continuous motor control -\ninspiring innovative solutions in robotics and artificial intelligence. Still,\nthe literature lacks a comprehensive outlook on effectively planning realistic\nactions in changing environments. Setting ourselves the goal of modeling\ncomplex tasks such as tool use, we delve into the topic of dynamic planning in\nactive inference, keeping in mind two crucial aspects of biological behavior:\nthe capacity to understand and exploit affordances for object manipulation, and\nto learn the hierarchical interactions between the self and the environment,\nincluding other agents. We start from a simple unit and gradually describe more\nadvanced structures, comparing recently proposed design choices and providing\nbasic examples. This study distances itself from traditional views centered on\nneural networks and reinforcement learning, and points toward a yet unexplored\ndirection in active inference: hybrid representations in hierarchical models.\n","authors":["Matteo Priorelli","Ivilin Peev Stoianov"],"pdf_url":"https://arxiv.org/pdf/2402.11658v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12203v3","updated":"2024-11-12T15:00:37Z","published":"2024-03-18T19:25:57Z","title":"Bootstrapping Reinforcement Learning with Imitation for Vision-Based\n  Agile Flight","summary":"  Learning visuomotor policies for agile quadrotor flight presents significant\ndifficulties, primarily from inefficient policy exploration caused by\nhigh-dimensional visual inputs and the need for precise and low-latency\ncontrol. To address these challenges, we propose a novel approach that combines\nthe performance of Reinforcement Learning (RL) and the sample efficiency of\nImitation Learning (IL) in the task of vision-based autonomous drone racing.\nWhile RL provides a framework for learning high-performance controllers through\ntrial and error, it faces challenges with sample efficiency and computational\ndemands due to the high dimensionality of visual inputs. Conversely, IL\nefficiently learns from visual expert demonstrations, but it remains limited by\nthe expert's performance and state distribution. To overcome these limitations,\nour policy learning framework integrates the strengths of both approaches. Our\nframework contains three phases: training a teacher policy using RL with\nprivileged state information, distilling it into a student policy via IL, and\nadaptive fine-tuning via RL. Testing in both simulated and real-world scenarios\nshows our approach can not only learn in scenarios where RL from scratch fails\nbut also outperforms existing IL methods in both robustness and performance,\nsuccessfully navigating a quadrotor through a race course using only visual\ninformation. Videos of the experiments are available at\nhttps://rpg.ifi.uzh.ch/bootstrap-rl-with-il/index.html.\n","authors":["Jiaxu Xing","Angel Romero","Leonard Bauersfeld","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2403.12203v3.pdf","comment":"8th Annual Conference on Robot Learning (CoRL)"},{"id":"http://arxiv.org/abs/2402.14585v2","updated":"2024-11-12T14:58:48Z","published":"2024-02-22T14:38:52Z","title":"Bandits with Abstention under Expert Advice","summary":"  We study the classic problem of prediction with expert advice under bandit\nfeedback. Our model assumes that one action, corresponding to the learner's\nabstention from play, has no reward or loss on every trial. We propose the CBA\nalgorithm, which exploits this assumption to obtain reward bounds that can\nsignificantly improve those of the classical Exp4 algorithm. We can view our\nproblem as the aggregation of confidence-rated predictors when the learner has\nthe option of abstention from play. Importantly, we are the first to achieve\nbounds on the expected cumulative reward for general confidence-rated\npredictors. In the special case of specialists we achieve a novel reward bound,\nsignificantly improving previous bounds of SpecialistExp (treating abstention\nas another action). As an example application, we discuss learning unions of\nballs in a finite metric space. In this contextual setting, we devise an\nefficient implementation of CBA, reducing the runtime from quadratic to almost\nlinear in the number of contexts. Preliminary experiments show that CBA\nimproves over existing bandit algorithms.\n","authors":["Stephen Pasteris","Alberto Rumi","Maximilian Thiessen","Shota Saito","Atsushi Miyauchi","Fabio Vitale","Mark Herbster"],"pdf_url":"https://arxiv.org/pdf/2402.14585v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14803v3","updated":"2024-11-12T14:57:08Z","published":"2024-10-18T18:19:56Z","title":"DistRL: An Asynchronous Distributed Reinforcement Learning Framework for\n  On-Device Control Agents","summary":"  On-device control agents, especially on mobile devices, are responsible for\noperating mobile devices to fulfill users' requests, enabling seamless and\nintuitive interactions. Integrating Multimodal Large Language Models (MLLMs)\ninto these agents enhances their ability to understand and execute complex\ncommands, thereby improving user experience. However, fine-tuning MLLMs for\non-device control presents significant challenges due to limited data\navailability and inefficient online training processes. This paper introduces\nDistRL, a novel framework designed to enhance the efficiency of online RL\nfine-tuning for mobile device control agents. DistRL employs centralized\ntraining and decentralized data acquisition to ensure efficient fine-tuning in\nthe context of dynamic online interactions. Additionally, the framework is\nbacked by our tailor-made RL algorithm, which effectively balances exploration\nwith the prioritized utilization of collected data to ensure stable and robust\ntraining. Our experiments show that, on average, DistRL delivers a 3X\nimprovement in training efficiency and enables training data collection 2.4X\nfaster than the leading synchronous multi-machine methods. Notably, after\ntraining, DistRL achieves a 20% relative improvement in success rate compared\nto state-of-the-art methods on general Android tasks from an open benchmark,\nsignificantly outperforming existing approaches while maintaining the same\ntraining time. These results validate DistRL as a scalable and efficient\nsolution, offering substantial improvements in both training efficiency and\nagent performance for real-world, in-the-wild device control tasks.\n","authors":["Taiyi Wang","Zhihao Wu","Jianheng Liu","Jianye Hao","Jun Wang","Kun Shao"],"pdf_url":"https://arxiv.org/pdf/2410.14803v3.pdf","comment":"Paper and Appendix, 25 pages"},{"id":"http://arxiv.org/abs/2410.20178v2","updated":"2024-11-12T14:45:18Z","published":"2024-10-26T13:19:57Z","title":"LLMs Can Evolve Continually on Modality for X-Modal Reasoning","summary":"  Multimodal Large Language Models (MLLMs) have gained significant attention\ndue to their impressive capabilities in multimodal understanding. However,\nexisting methods rely heavily on extensive modal-specific pretraining and\njoint-modal tuning, leading to significant computational burdens when expanding\nto new modalities. In this paper, we propose PathWeave, a flexible and scalable\nframework with modal-Path sWitching and ExpAnsion abilities that enables MLLMs\nto continually EVolve on modalities for $\\mathbb{X}$-modal reasoning. We\nleverage the concept of Continual Learning and develop an incremental training\nstrategy atop pre-trained MLLMs, enabling their expansion to new modalities\nusing uni-modal data, without executing joint-modal pretraining. In detail, a\nnovel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal and\ncross-modal adapters are seamlessly integrated to facilitate efficient modality\nalignment and collaboration. Additionally, an MoE-based gating module is\napplied between two types of adapters to further enhance the multimodal\ninteraction. To investigate the proposed method, we establish a challenging\nbenchmark called Continual Learning of Modality (MCL), which consists of\nhigh-quality QA data from five distinct modalities: image, video, audio, depth\nand point cloud. Extensive experiments demonstrate the effectiveness of the\nproposed AnA framework on learning plasticity and memory stability during\ncontinual learning. Furthermore, PathWeave performs comparably to\nstate-of-the-art MLLMs while concurrently reducing parameter training burdens\nby 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave\n","authors":["Jiazuo Yu","Haomiao Xiong","Lu Zhang","Haiwen Diao","Yunzhi Zhuge","Lanqing Hong","Dong Wang","Huchuan Lu","You He","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2410.20178v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07837v1","updated":"2024-11-12T14:41:07Z","published":"2024-11-12T14:41:07Z","title":"FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for\n  Scalable Training","summary":"  With the increase in the number of parameters in large language models, the\nprocess of pre-training and fine-tuning increasingly demands larger volumes of\nGPU memory. A significant portion of this memory is typically consumed by the\noptimizer state. To overcome this challenge, recent approaches such as low-rank\nadaptation (LoRA (Hu et al., 2021)), low-rank gradient projection (GaLore (Zhao\net al., 2024)), and blockwise optimization (BAdam (Luo et al., 2024)) have been\nproposed. However, in all these algorithms, the $\\textit{effective rank of the\nweight updates remains low-rank}$, which can lead to a substantial loss of\ninformation from the gradient. This loss can be critically important,\nespecially during the pre-training stage. In this paper, we introduce\n$\\texttt{FRUGAL}$ ($\\textbf{F}$ull-$\\textbf{R}$ank $\\textbf{U}$pdates with\n$\\textbf{G}$r$\\textbf{A}$dient sp$\\textbf{L}$itting), a new memory-efficient\noptimization framework. $\\texttt{FRUGAL}$ leverages gradient splitting to\nperform low-dimensional updates using advanced algorithms (such as Adam), while\nupdates along the remaining directions are executed via state-free methods like\nSGD or signSGD (Bernstein et al., 2018). Our framework can be integrated with\nvarious low-rank update selection techniques, including GaLore and BAdam. We\nprovide theoretical convergence guarantees for our framework when using SGDM\nfor low-dimensional updates and SGD for state-free updates. Additionally, our\nmethod consistently outperforms concurrent approaches across various fixed\nmemory budgets, achieving state-of-the-art results in pre-training and\nfine-tuning tasks while balancing memory efficiency and performance metrics.\n","authors":["Philip Zmushko","Aleksandr Beznosikov","Martin Takáč","Samuel Horváth"],"pdf_url":"https://arxiv.org/pdf/2411.07837v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12550v2","updated":"2024-11-12T14:39:29Z","published":"2024-07-17T13:31:13Z","title":"UniTE: A Survey and Unified Pipeline for Pre-training Spatiotemporal\n  Trajectory Embeddings","summary":"  Spatiotemporal trajectories are sequences of timestamped locations, which\nenable a variety of analyses that in turn enable important real-world\napplications. It is common to map trajectories to vectors, called embeddings,\nbefore subsequent analyses. Thus, the qualities of embeddings are very\nimportant. Methods for pre-training embeddings, which leverage unlabeled\ntrajectories for training universal embeddings, have shown promising\napplicability across different tasks, thus attracting considerable interest.\nHowever, research progress on this topic faces two key challenges: a lack of a\ncomprehensive overview of existing methods, resulting in several related\nmethods not being well-recognized, and the absence of a unified pipeline,\ncomplicating the development of new methods and the analysis of methods.\n  We present UniTE, a survey and a unified pipeline for this domain. In doing\nso, we present a comprehensive list of existing methods for pre-training\ntrajectory embeddings, which includes methods that either explicitly or\nimplicitly employ pre-training techniques. Further, we present a unified and\nmodular pipeline with publicly available underlying code, simplifying the\nprocess of constructing and evaluating methods for pre-training trajectory\nembeddings. Additionally, we contribute a selection of experimental results\nusing the proposed pipeline on real-world datasets. Implementation of the\npipeline is publicly available at https://github.com/Logan-Lin/UniTE.\n","authors":["Yan Lin","Zeyu Zhou","Yicheng Liu","Haochen Lv","Haomin Wen","Tianyi Li","Yushuai Li","Christian S. Jensen","Shengnan Guo","Youfang Lin","Huaiyu Wan"],"pdf_url":"https://arxiv.org/pdf/2407.12550v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07832v1","updated":"2024-11-12T14:27:45Z","published":"2024-11-12T14:27:45Z","title":"Dynamical-VAE-based Hindsight to Learn the Causal Dynamics of\n  Factored-POMDPs","summary":"  Learning representations of underlying environmental dynamics from partial\nobservations is a critical challenge in machine learning. In the context of\nPartially Observable Markov Decision Processes (POMDPs), state representations\nare often inferred from the history of past observations and actions. We\ndemonstrate that incorporating future information is essential to accurately\ncapture causal dynamics and enhance state representations. To address this, we\nintroduce a Dynamical Variational Auto-Encoder (DVAE) designed to learn causal\nMarkovian dynamics from offline trajectories in a POMDP. Our method employs an\nextended hindsight framework that integrates past, current, and multi-step\nfuture information within a factored-POMDP setting. Empirical results reveal\nthat this approach uncovers the causal graph governing hidden state transitions\nmore effectively than history-based and typical hindsight-based models.\n","authors":["Chao Han","Debabrota Basu","Michael Mangan","Eleni Vasilaki","Aditya Gilra"],"pdf_url":"https://arxiv.org/pdf/2411.07832v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07828v1","updated":"2024-11-12T14:23:52Z","published":"2024-11-12T14:23:52Z","title":"Suite-IN: Aggregating Motion Features from Apple Suite for Robust\n  Inertial Navigation","summary":"  With the rapid development of wearable technology, devices like smartphones,\nsmartwatches, and headphones equipped with IMUs have become essential for\napplications such as pedestrian positioning. However, traditional pedestrian\ndead reckoning (PDR) methods struggle with diverse motion patterns, while\nrecent data-driven approaches, though improving accuracy, often lack robustness\ndue to reliance on a single device.In our work, we attempt to enhance the\npositioning performance using the low-cost commodity IMUs embedded in the\nwearable devices. We propose a multi-device deep learning framework named\nSuite-IN, aggregating motion data from Apple Suite for inertial navigation.\nMotion data captured by sensors on different body parts contains both local and\nglobal motion information, making it essential to reduce the negative effects\nof localized movements and extract global motion representations from multiple\ndevices.\n","authors":["Lan Sun","Songpengcheng Xia","Junyuan Deng","Jiarui Yang","Zengyuan Lai","Qi Wu","Ling Pei"],"pdf_url":"https://arxiv.org/pdf/2411.07828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07826v1","updated":"2024-11-12T14:22:16Z","published":"2024-11-12T14:22:16Z","title":"Efficient Federated Finetuning of Tiny Transformers with\n  Resource-Constrained Devices","summary":"  In recent years, Large Language Models (LLMs) through Transformer structures\nhave dominated many machine learning tasks, especially text processing.\nHowever, these models require massive amounts of data for training and induce\nhigh resource requirements, particularly in terms of the large number of\nFloating Point Operations (FLOPs) and the high amounts of memory needed. To\nfine-tune such a model in a parameter-efficient way, techniques like Adapter or\nLoRA have been developed. However, we observe that the application of LoRA,\nwhen used in federated learning (FL), while still being parameter-efficient, is\nmemory and FLOP inefficient. Based on that observation, we develop a novel\nlayer finetuning scheme that allows devices in cross-device FL to make use of\npretrained neural networks (NNs) while adhering to given resource constraints.\nWe show that our presented scheme outperforms the current state of the art when\ndealing with homogeneous or heterogeneous computation and memory constraints\nand is on par with LoRA regarding limited communication, thereby achieving\nsignificantly higher accuracies in FL training.\n","authors":["Kilian Pfeiffer","Mohamed Aboelenien Ahmed","Ramin Khalili","Jörg Henkel"],"pdf_url":"https://arxiv.org/pdf/2411.07826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03163v2","updated":"2024-11-12T14:18:51Z","published":"2024-11-05T15:07:20Z","title":"Efficient Hamiltonian, structure and trace distance learning of Gaussian\n  states","summary":"  In this work, we initiate the study of Hamiltonian learning for positive\ntemperature bosonic Gaussian states, the quantum generalization of the widely\nstudied problem of learning Gaussian graphical models. We obtain efficient\nprotocols, both in sample and computational complexity, for the task of\ninferring the parameters of their underlying quadratic Hamiltonian under the\nassumption of bounded temperature, squeezing, displacement and maximal degree\nof the interaction graph. Our protocol only requires heterodyne measurements,\nwhich are often experimentally feasible, and has a sample complexity that\nscales logarithmically with the number of modes. Furthermore, we show that it\nis possible to learn the underlying interaction graph in a similar setting and\nsample complexity. Taken together, our results put the status of the quantum\nHamiltonian learning problem for continuous variable systems in a much more\nadvanced state when compared to spins, where state-of-the-art results are\neither unavailable or quantitatively inferior to ours. In addition, we use our\ntechniques to obtain the first results on learning Gaussian states in trace\ndistance with a quadratic scaling in precision and polynomial in the number of\nmodes, albeit imposing certain restrictions on the Gaussian states. Our main\ntechnical innovations are several continuity bounds for the covariance and\nHamiltonian matrix of a Gaussian state, which are of independent interest,\ncombined with what we call the local inversion technique. In essence, the local\ninversion technique allows us to reliably infer the Hamiltonian of a Gaussian\nstate by only estimating in parallel submatrices of the covariance matrix whose\nsize scales with the desired precision, but not the number of modes. This way\nwe bypass the need to obtain precise global estimates of the covariance matrix,\ncontrolling the sample complexity.\n","authors":["Marco Fanizza","Cambyse Rouzé","Daniel Stilck França"],"pdf_url":"https://arxiv.org/pdf/2411.03163v2.pdf","comment":"43 pages, 1 figure. Corrections to Lemma 4.1. Main results are\n  unchanged"},{"id":"http://arxiv.org/abs/2411.07816v1","updated":"2024-11-12T14:09:16Z","published":"2024-11-12T14:09:16Z","title":"Dual-Criterion Model Aggregation in Federated Learning: Balancing Data\n  Quantity and Quality","summary":"  Federated learning (FL) has become one of the key methods for\nprivacy-preserving collaborative learning, as it enables the transfer of models\nwithout requiring local data exchange. Within the FL framework, an aggregation\nalgorithm is recognized as one of the most crucial components for ensuring the\nefficacy and security of the system. Existing average aggregation algorithms\ntypically assume that all client-trained data holds equal value or that weights\nare based solely on the quantity of data contributed by each client. In\ncontrast, alternative approaches involve training the model locally after\naggregation to enhance adaptability. However, these approaches fundamentally\nignore the inherent heterogeneity between different clients' data and the\ncomplexity of variations in data at the aggregation stage, which may lead to a\nsuboptimal global model.\n  To address these issues, this study proposes a novel dual-criterion weighted\naggregation algorithm involving the quantity and quality of data from the\nclient node. Specifically, we quantify the data used for training and perform\nmultiple rounds of local model inference accuracy evaluation on a specialized\ndataset to assess the data quality of each client. These two factors are\nutilized as weights within the aggregation process, applied through a\ndynamically weighted summation of these two factors. This approach allows the\nalgorithm to adaptively adjust the weights, ensuring that every client can\ncontribute to the global model, regardless of their data's size or initial\nquality. Our experiments show that the proposed algorithm outperforms several\nexisting state-of-the-art aggregation approaches on both a general-purpose\nopen-source dataset, CIFAR-10, and a dataset specific to visual obstacle\navoidance.\n","authors":["Haizhou Zhang","Xianjia Yu","Tomi Westerlund"],"pdf_url":"https://arxiv.org/pdf/2411.07816v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2411.07806v1","updated":"2024-11-12T14:01:08Z","published":"2024-11-12T14:01:08Z","title":"Federated Low-Rank Adaptation with Differential Privacy over Wireless\n  Networks","summary":"  Fine-tuning large pre-trained foundation models (FMs) on distributed edge\ndevices presents considerable computational and privacy challenges. Federated\nfine-tuning (FedFT) mitigates some privacy issues by facilitating collaborative\nmodel training without the need to share raw data. To lessen the computational\nburden on resource-limited devices, combining low-rank adaptation (LoRA) with\nfederated learning enables parameter-efficient fine-tuning. Additionally, the\nsplit FedFT architecture partitions an FM between edge devices and a central\nserver, reducing the necessity for complete model deployment on individual\ndevices. However, the risk of privacy eavesdropping attacks in FedFT remains a\nconcern, particularly in sensitive areas such as healthcare and finance. In\nthis paper, we propose a split FedFT framework with differential privacy (DP)\nover wireless networks, where the inherent wireless channel noise in the uplink\ntransmission is utilized to achieve DP guarantees without adding an extra\nartificial noise. We shall investigate the impact of the wireless noise on\nconvergence performance of the proposed framework. We will also show that by\nupdating only one of the low-rank matrices in the split FedFT with DP, the\nproposed method can mitigate the noise amplification effect. Simulation results\nwill demonstrate that the proposed framework achieves higher accuracy under\nstrict privacy budgets compared to baseline methods.\n","authors":["Tianqu Kang","Zixin Wang","Hengtao He","Jun Zhang","Shenghui Song","Khaled B. Letaief"],"pdf_url":"https://arxiv.org/pdf/2411.07806v1.pdf","comment":"6 pages, 3 figures, submitted to IEEE ICC 2025"},{"id":"http://arxiv.org/abs/2408.12970v2","updated":"2024-11-12T13:56:33Z","published":"2024-08-23T10:36:08Z","title":"SUMO: Search-Based Uncertainty Estimation for Model-Based Offline\n  Reinforcement Learning","summary":"  The performance of offline reinforcement learning (RL) suffers from the\nlimited size and quality of static datasets. Model-based offline RL addresses\nthis issue by generating synthetic samples through a dynamics model to enhance\noverall performance. To evaluate the reliability of the generated samples,\nuncertainty estimation methods are often employed. However, model ensemble, the\nmost commonly used uncertainty estimation method, is not always the best\nchoice. In this paper, we propose a \\textbf{S}earch-based \\textbf{U}ncertainty\nestimation method for \\textbf{M}odel-based \\textbf{O}ffline RL (SUMO) as an\nalternative. SUMO characterizes the uncertainty of synthetic samples by\nmeasuring their cross entropy against the in-distribution dataset samples, and\nuses an efficient search-based method for implementation. In this way, SUMO can\nachieve trustworthy uncertainty estimation. We integrate SUMO into several\nmodel-based offline RL algorithms including MOPO and Adapted MOReL (AMOReL),\nand provide theoretical analysis for them. Extensive experimental results on\nD4RL datasets demonstrate that SUMO can provide more accurate uncertainty\nestimation and boost the performance of base algorithms. These indicate that\nSUMO could be a better uncertainty estimator for model-based offline RL when\nused in either reward penalty or trajectory truncation. Our code is available\nand will be open-source for further research and development.\n","authors":["Zhongjian Qiao","Jiafei Lyu","Kechen Jiao","Qi Liu","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2408.12970v2.pdf","comment":"Submitted to AAAI2025"},{"id":"http://arxiv.org/abs/2411.07800v1","updated":"2024-11-12T13:54:13Z","published":"2024-11-12T13:54:13Z","title":"Kernel-based retrieval models for hyperspectral image data optimized\n  with Kernel Flows","summary":"  Kernel-based statistical methods are efficient, but their performance depends\nheavily on the selection of kernel parameters. In literature, the optimization\nstudies on kernel-based chemometric methods is limited and often reduced to\ngrid searching. Previously, the authors introduced Kernel Flows (KF) to learn\nkernel parameters for Kernel Partial Least-Squares (K-PLS) regression. KF is\neasy to implement and helps minimize overfitting. In cases of high collinearity\nbetween spectra and biogeophysical quantities in spectroscopy, simpler methods\nlike Principal Component Regression (PCR) may be more suitable. In this study,\nwe propose a new KF-type approach to optimize Kernel Principal Component\nRegression (K-PCR) and test it alongside KF-PLS. Both methods are benchmarked\nagainst non-linear regression techniques using two hyperspectral remote sensing\ndatasets.\n","authors":["Zina-Sabrina Duma","Tuomas Sihvonen","Jouni Susiluoto","Otto Lamminpää","Heikki Haario","Satu-Pia Reinikainen"],"pdf_url":"https://arxiv.org/pdf/2411.07800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08770v3","updated":"2024-11-12T13:50:05Z","published":"2024-08-16T14:25:20Z","title":"Pessimistic Iterative Planning for Robust POMDPs","summary":"  Robust POMDPs extend classical POMDPs to handle model uncertainty.\nSpecifically, robust POMDPs exhibit so-called uncertainty sets on the\ntransition and observation models, effectively defining ranges of\nprobabilities. Policies for robust POMDPs must be (1) memory-based to account\nfor partial observability and (2) robust against model uncertainty to account\nfor the worst-case instances from the uncertainty sets. To compute such robust\nmemory-based policies, we propose the pessimistic iterative planning (PIP)\nframework, which alternates between two main steps: (1) selecting a pessimistic\n(non-robust) POMDP via worst-case probability instances from the uncertainty\nsets; and (2) computing a finite-state controller (FSC) for this pessimistic\nPOMDP. We evaluate the performance of this FSC on the original robust POMDP and\nuse this evaluation in step (1) to select the next pessimistic POMDP. Within\nPIP, we propose the rFSCNet algorithm. In each iteration, rFSCNet finds an FSC\nthrough a recurrent neural network by using supervision policies optimized for\nthe pessimistic POMDP. The empirical evaluation in four benchmark environments\nshowcases improved robustness against several baseline methods and competitive\nperformance compared to a state-of-the-art robust POMDP solver.\n","authors":["Maris F. L. Galesloot","Marnix Suilen","Thiago D. Simão","Steven Carr","Matthijs T. J. Spaan","Ufuk Topcu","Nils Jansen"],"pdf_url":"https://arxiv.org/pdf/2408.08770v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07796v1","updated":"2024-11-12T13:46:58Z","published":"2024-11-12T13:46:58Z","title":"PatchCTG: Patch Cardiotocography Transformer for Antepartum Fetal Health\n  Monitoring","summary":"  Antepartum Cardiotocography (CTG) is vital for fetal health monitoring, but\ntraditional methods like the Dawes-Redman system are often limited by high\ninter-observer variability, leading to inconsistent interpretations and\npotential misdiagnoses. This paper introduces PatchCTG, a transformer-based\nmodel specifically designed for CTG analysis, employing patch-based\ntokenisation, instance normalisation and channel-independent processing to\ncapture essential local and global temporal dependencies within CTG signals.\nPatchCTG was evaluated on the Oxford Maternity (OXMAT) dataset, comprising over\n20,000 CTG traces across diverse clinical outcomes after applying the inclusion\nand exclusion criteria. With extensive hyperparameter optimisation, PatchCTG\nachieved an AUC of 77%, with specificity of 88% and sensitivity of 57% at\nYouden's index threshold, demonstrating adaptability to various clinical needs.\nTesting across varying temporal thresholds showed robust predictive\nperformance, particularly with finetuning on data closer to delivery, achieving\na sensitivity of 52% and specificity of 88% for near-delivery cases. These\nfindings suggest the potential of PatchCTG to enhance clinical decision-making\nin antepartum care by providing a reliable, objective tool for fetal health\nassessment. The source code is available at\nhttps://github.com/jaleedkhan/PatchCTG.\n","authors":["M. Jaleed Khan","Manu Vatish","Gabriel Davis Jones"],"pdf_url":"https://arxiv.org/pdf/2411.07796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00426v2","updated":"2024-11-12T13:41:47Z","published":"2024-08-01T09:57:48Z","title":"A Cross-Domain Benchmark for Active Learning","summary":"  Active Learning (AL) deals with identifying the most informative samples for\nlabeling to reduce data annotation costs for supervised learning tasks. AL\nresearch suffers from the fact that lifts from literature generalize poorly and\nthat only a small number of repetitions of experiments are conducted. To\novercome these obstacles, we propose CDALBench, the first active learning\nbenchmark which includes tasks in computer vision, natural language processing\nand tabular learning. Furthermore, by providing an efficient, greedy oracle,\nCDALBench can be evaluated with 50 runs for each experiment. We show, that both\nthe cross-domain character and a large amount of repetitions are crucial for\nsophisticated evaluation of AL research. Concretely, we show that the\nsuperiority of specific methods varies over the different domains, making it\nimportant to evaluate Active Learning with a cross-domain benchmark.\nAdditionally, we show that having a large amount of runs is crucial. With only\nconducting three runs as often done in the literature, the superiority of\nspecific methods can strongly vary with the specific runs. This effect is so\nstrong, that, depending on the seed, even a well-established method's\nperformance can be significantly better and significantly worse than random for\nthe same dataset.\n","authors":["Thorben Werner","Johannes Burchert","Maximilian Stubbemann","Lars Schmidt-Thieme"],"pdf_url":"https://arxiv.org/pdf/2408.00426v2.pdf","comment":"Accepted at NeurIPS 24 in the Benchmarks and Datasets Track. Updated\n  version of paper \"Toward Comparable Active Learning\" (arXiv:2311.18356).\n  \"Toward Comparable Active Learning\" is deprecated, please use this version.\n  arXiv admin note: text overlap with arXiv:2311.18356; text overlap with\n  arXiv:2301.10625 by other authors"},{"id":"http://arxiv.org/abs/2310.04361v4","updated":"2024-11-12T13:35:37Z","published":"2023-10-06T16:34:51Z","title":"Exploiting Activation Sparsity with Dense to Dynamic-k\n  Mixture-of-Experts Conversion","summary":"  Transformer models can face practical limitations due to their high\ncomputational requirements. At the same time, such models exhibit significant\nactivation sparsity, which can be leveraged to reduce the inference cost by\nconverting parts of the network into equivalent Mixture-of-Experts (MoE)\nlayers. Despite the crucial role played by activation sparsity, its impact on\nthis process remains unexplored. We demonstrate that the efficiency of the\nconversion can be significantly enhanced by a proper regularization of the\nactivation sparsity of the base model. Moreover, motivated by the high variance\nof the number of activated neurons for different inputs, we introduce a more\neffective dynamic-$k$ expert selection rule that adjusts the number of executed\nexperts on a per-token basis. To achieve further savings, we extend this\napproach to multi-head attention projections. Finally, we develop an efficient\nimplementation that translates these computational savings into actual\nwall-clock speedup. The proposed method, Dense to Dynamic-$k$\nMixture-of-Experts (D2DMoE), outperforms existing approaches on common NLP and\nvision tasks, reducing inference cost by up to 60% without significantly\nimpacting performance.\n","authors":["Filip Szatkowski","Bartosz Wójcik","Mikołaj Piórczyński","Simone Scardapane"],"pdf_url":"https://arxiv.org/pdf/2310.04361v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07784v1","updated":"2024-11-12T13:33:26Z","published":"2024-11-12T13:33:26Z","title":"Interaction Asymmetry: A General Principle for Learning Composable\n  Abstractions","summary":"  Learning disentangled representations of concepts and re-composing them in\nunseen ways is crucial for generalizing to out-of-domain situations. However,\nthe underlying properties of concepts that enable such disentanglement and\ncompositional generalization remain poorly understood. In this work, we propose\nthe principle of interaction asymmetry which states: \"Parts of the same concept\nhave more complex interactions than parts of different concepts\". We formalize\nthis via block diagonality conditions on the $(n+1)$th order derivatives of the\ngenerator mapping concepts to observed data, where different orders of\n\"complexity\" correspond to different $n$. Using this formalism, we prove that\ninteraction asymmetry enables both disentanglement and compositional\ngeneralization. Our results unify recent theoretical results for learning\nconcepts of objects, which we show are recovered as special cases with\n$n\\!=\\!0$ or $1$. We provide results for up to $n\\!=\\!2$, thus extending these\nprior works to more flexible generator functions, and conjecture that the same\nproof strategies generalize to larger $n$. Practically, our theory suggests\nthat, to disentangle concepts, an autoencoder should penalize its latent\ncapacity and the interactions between concepts during decoding. We propose an\nimplementation of these criteria using a flexible Transformer-based VAE, with a\nnovel regularizer on the attention weights of the decoder. On synthetic image\ndatasets consisting of objects, we provide evidence that this model can achieve\ncomparable object disentanglement to existing models that use more explicit\nobject-centric priors.\n","authors":["Jack Brady","Julius von Kügelgen","Sébastien Lachapelle","Simon Buchholz","Thomas Kipf","Wieland Brendel"],"pdf_url":"https://arxiv.org/pdf/2411.07784v1.pdf","comment":"Preprint, under review"},{"id":"http://arxiv.org/abs/2408.08074v2","updated":"2024-11-12T13:26:39Z","published":"2024-08-15T11:01:35Z","title":"A Survey on Integrated Sensing, Communication, and Computation","summary":"  The forthcoming generation of wireless technology, 6G, aims to usher in an\nera of ubiquitous intelligent services, where everything is interconnected and\nintelligent. This vision requires the seamless integration of three fundamental\nmodules: Sensing for information acquisition, communication for information\nsharing, and computation for information processing and decision-making. These\nmodules are intricately linked, especially in complex tasks such as edge\nlearning and inference. However, the performance of these modules is\ninterdependent, creating a resource competition for time, energy, and\nbandwidth. Existing techniques like integrated communication and computation\n(ICC), integrated sensing and computation (ISC), and integrated sensing and\ncommunication (ISAC) have made partial strides in addressing this challenge,\nbut they fall short of meeting the extreme performance requirements. To\novercome these limitations, it is essential to develop new techniques that\ncomprehensively integrate sensing, communication, and computation. This\nintegrated approach, known as Integrated Sensing, Communication, and\nComputation (ISCC), offers a systematic perspective for enhancing task\nperformance. This paper begins with a comprehensive survey of historic and\nrelated techniques such as ICC, ISC, and ISAC, highlighting their strengths and\nlimitations. It then discusses the benefits, functions, and challenges of ISCC.\nSubsequently, the state-of-the-art signal designs for ISCC, along with network\nresource management strategies specifically tailored for ISCC are explored.\nFurthermore, this paper discusses the exciting research opportunities that lie\nahead for implementing ISCC in future advanced networks, and the unresolved\nissues requiring further investigation. ISCC is expected to unlock the full\npotential of intelligent connectivity, paving the way for groundbreaking\napplications and services.\n","authors":["Dingzhu Wen","Yong Zhou","Xiaoyang Li","Yuanming Shi","Kaibin Huang","Khaled B. Letaief"],"pdf_url":"https://arxiv.org/pdf/2408.08074v2.pdf","comment":"In this version, a series of discussions have been added.The\n  benefits, functions, and challenges of ISCC are investigated using a new\n  section. Moreover, the unresolved issues of ISCC have been discussed"},{"id":"http://arxiv.org/abs/2411.07773v1","updated":"2024-11-12T13:14:09Z","published":"2024-11-12T13:14:09Z","title":"Likelihood as a Performance Gauge for Retrieval-Augmented Generation","summary":"  Recent work finds that retrieval-augmented generation with large language\nmodels is prone to be influenced by the order of retrieved documents in the\ncontext. However, the lack of in-depth analysis limits the use of this\nphenomenon for prompt engineering in practice. In this study, we posit that\nlikelihoods serve as an effective gauge for language model performance. Through\nexperiments on two question-answering datasets with a variety of\nstate-of-the-art language models, we reveal correlations between answer\naccuracy and the likelihood of the question at both the corpus level and the\ninstance level. In addition, we find that question likelihood can also indicate\nthe position of the task-relevant information in the context. Based on these\nfindings, we propose two methods that use question likelihood as a gauge for\nselecting and constructing prompts that lead to better performance. We\ndemonstrate their effectiveness with experiments. In addition, our\nlikelihood-based methods are efficient, as they only need to compute the\nlikelihood of the input, requiring much fewer language model passes than\nheuristic prompt engineering methods that require generating responses. Our\nanalysis deepens our understanding of how input prompts affect model\nperformance and provides a promising direction for efficient prompt\noptimization.\n","authors":["Tianyu Liu","Jirui Qi","Paul He","Arianna Bisazza","Mrinmaya Sachan","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07773v1.pdf","comment":"Under review at NAACL 2025. Code is available at\n  https://github.com/lyutyuh/poptimizer"},{"id":"http://arxiv.org/abs/2411.07772v1","updated":"2024-11-12T13:13:20Z","published":"2024-11-12T13:13:20Z","title":"Automatic Album Sequencing","summary":"  Album sequencing is a critical part of the album production process.\nRecently, a data-driven approach was proposed that sequences general\ncollections of independent media by extracting the narrative essence of the\nitems in the collections. While this approach implies an album sequencing\ntechnique, it is not widely accessible to a less technical audience, requiring\nadvanced knowledge of machine learning techniques to use. To address this, we\nintroduce a new user-friendly web-based tool that allows a less technical\naudience to upload music tracks, execute this technique in one click, and\nsubsequently presents the result in a clean visualization to the user. To both\nincrease the number of templates available to the user and address shortcomings\nof previous work, we also introduce a new direct transformer-based album\nsequencing method. We find that our more direct method outperforms a random\nbaseline but does not reach the same performance as the narrative essence\napproach. Both methods are included in our web-based user interface, and this\n-- alongside a full copy of our implementation -- is publicly available at\nhttps://github.com/dylanashley/automatic-album-sequencing\n","authors":["Vincent Herrmann","Dylan R. Ashley","Jürgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2411.07772v1.pdf","comment":"presented as a late breaking demo in the 25th International Society\n  for Music Information Retrieval Conference; 3 pages in main text, 3 figures\n  in main text; source code available at\n  https://github.com/dylanashley/automatic-album-sequencing"},{"id":"http://arxiv.org/abs/2411.07762v1","updated":"2024-11-12T12:52:04Z","published":"2024-11-12T12:52:04Z","title":"ASER: Activation Smoothing and Error Reconstruction for Large Language\n  Model Quantization","summary":"  Quantization stands as a pivotal technique for large language model (LLM)\nserving, yet it poses significant challenges particularly in achieving\neffective low-bit quantization. The limited numerical mapping makes the\nquantized model produce a non-trivial error, bringing out intolerable\nperformance degration. This paper is anchored in the basic idea of model\ncompression objectives, and delves into the layer-wise error distribution of\nLLMs during post-training quantization. Subsequently, we introduce ASER, an\nalgorithm consisting of (1) Error Reconstruction: low-rank compensation for\nquantization error with LoRA-style matrices constructed by whitening SVD; (2)\nActivation Smoothing: outlier extraction to gain smooth activation and better\nerror compensation. ASER is capable of quantizing typical LLMs to low-bit ones,\nparticularly preserving accuracy even in W4A8 per-channel setup. Experimental\nresults show that ASER is competitive among the state-of-the-art quantization\nalgorithms, showing potential to activation quantization, with minor overhead.\n","authors":["Weibo Zhao","Yubin Shi","Xinyu Lyu","Wanchen Sui","Shen Li","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2411.07762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07760v1","updated":"2024-11-12T12:49:41Z","published":"2024-11-12T12:49:41Z","title":"Navigation with QPHIL: Quantizing Planner for Hierarchical Implicit\n  Q-Learning","summary":"  Offline Reinforcement Learning (RL) has emerged as a powerful alternative to\nimitation learning for behavior modeling in various domains, particularly in\ncomplex navigation tasks. An existing challenge with Offline RL is the\nsignal-to-noise ratio, i.e. how to mitigate incorrect policy updates due to\nerrors in value estimates. Towards this, multiple works have demonstrated the\nadvantage of hierarchical offline RL methods, which decouples high-level path\nplanning from low-level path following. In this work, we present a novel\nhierarchical transformer-based approach leveraging a learned quantizer of the\nspace. This quantization enables the training of a simpler zone-conditioned\nlow-level policy and simplifies planning, which is reduced to discrete\nautoregressive prediction. Among other benefits, zone-level reasoning in\nplanning enables explicit trajectory stitching rather than implicit stitching\nbased on noisy value function estimates. By combining this transformer-based\nplanner with recent advancements in offline RL, our proposed approach achieves\nstate-of-the-art results in complex long-distance navigation environments.\n","authors":["Alexi Canesse","Mathieu Petitbois","Ludovic Denoyer","Sylvain Lamprier","Rémy Portelas"],"pdf_url":"https://arxiv.org/pdf/2411.07760v1.pdf","comment":"Under review. Code will be released upon acceptance"},{"id":"http://arxiv.org/abs/2411.02199v4","updated":"2024-11-12T12:44:02Z","published":"2024-11-04T15:54:32Z","title":"Provably Transformers Harness Multi-Concept Word Semantics for Efficient\n  In-Context Learning","summary":"  Transformer-based large language models (LLMs) have displayed remarkable\ncreative prowess and emergence capabilities. Existing empirical studies have\nrevealed a strong connection between these LLMs' impressive emergence abilities\nand their in-context learning (ICL) capacity, allowing them to solve new tasks\nusing only task-specific prompts without further fine-tuning. On the other\nhand, existing empirical and theoretical studies also show that there is a\nlinear regularity of the multi-concept encoded semantic representation behind\ntransformer-based LLMs. However, existing theoretical work fail to build up an\nunderstanding of the connection between this regularity and the innovative\npower of ICL. Additionally, prior work often focuses on simplified, unrealistic\nscenarios involving linear transformers or unrealistic loss functions, and they\nachieve only linear or sub-linear convergence rates. In contrast, this work\nprovides a fine-grained mathematical analysis to show how transformers leverage\nthe multi-concept semantics of words to enable powerful ICL and excellent\nout-of-distribution ICL abilities, offering insights into how transformers\ninnovate solutions for certain unseen tasks encoded with multiple cross-concept\nsemantics. Inspired by empirical studies on the linear latent geometry of LLMs,\nthe analysis is based on a concept-based low-noise sparse coding prompt model.\nLeveraging advanced techniques, this work showcases the exponential 0-1 loss\nconvergence over the highly non-convex training dynamics, which pioneeringly\nincorporates the challenges of softmax self-attention, ReLU-activated MLPs, and\ncross-entropy loss. Empirical simulations corroborate the theoretical findings.\n","authors":["Dake Bu","Wei Huang","Andi Han","Atsushi Nitanda","Taiji Suzuki","Qingfu Zhang","Hau-San Wong"],"pdf_url":"https://arxiv.org/pdf/2411.02199v4.pdf","comment":"Accepted by the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2404.19664v4","updated":"2024-11-12T12:43:42Z","published":"2024-04-30T15:57:41Z","title":"Towards Generalist Robot Learning from Internet Video: A Survey","summary":"  Scaling deep learning to massive, diverse internet data has yielded\nremarkably general capabilities in visual and natural language understanding\nand generation. However, data has remained scarce and challenging to collect in\nrobotics, seeing robot learning struggle to obtain similarly general\ncapabilities. Promising Learning from Videos (LfV) methods aim to address the\nrobotics data bottleneck by augmenting traditional robot data with large-scale\ninternet video data. This video data offers broad foundational information\nregarding physical behaviour and the underlying physics of the world, and thus\ncan be highly informative for a generalist robot.\n  In this survey, we present a thorough overview of the emerging field of LfV.\nWe outline fundamental concepts, including the benefits and challenges of LfV.\nWe provide a comprehensive review of current methods for extracting knowledge\nfrom large-scale internet video, addressing key challenges in LfV, and boosting\ndownstream robot and reinforcement learning via the use of video data. The\nsurvey concludes with a critical discussion of challenges and opportunities in\nLfV. Here, we advocate for scalable foundation model approaches that can\nleverage the full range of available internet video to improve the learning of\nrobot policies and dynamics models. We hope this survey can inform and catalyse\nfurther LfV research, driving progress towards the development of\ngeneral-purpose robots.\n","authors":["Robert McCarthy","Daniel C. H. Tan","Dominik Schmidt","Fernando Acero","Nathan Herr","Yilun Du","Thomas G. Thuruthel","Zhibin Li"],"pdf_url":"https://arxiv.org/pdf/2404.19664v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07753v1","updated":"2024-11-12T12:24:48Z","published":"2024-11-12T12:24:48Z","title":"Spatially Regularized Graph Attention Autoencoder Framework for\n  Detecting Rainfall Extremes","summary":"  We introduce a novel Graph Attention Autoencoder (GAE) with spatial\nregularization to address the challenge of scalable anomaly detection in\nspatiotemporal rainfall data across India from 1990 to 2015. Our model\nleverages a Graph Attention Network (GAT) to capture spatial dependencies and\ntemporal dynamics in the data, further enhanced by a spatial regularization\nterm ensuring geographic coherence. We construct two graph datasets employing\nrainfall, pressure, and temperature attributes from the Indian Meteorological\nDepartment and ERA5 Reanalysis on Single Levels, respectively. Our network\noperates on graph representations of the data, where nodes represent geographic\nlocations, and edges, inferred through event synchronization, denote\nsignificant co-occurrences of rainfall events. Through extensive experiments,\nwe demonstrate that our GAE effectively identifies anomalous rainfall patterns\nacross the Indian landscape. Our work paves the way for sophisticated\nspatiotemporal anomaly detection methodologies in climate science, contributing\nto better climate change preparedness and response strategies.\n","authors":["Mihir Agarwal","Progyan Das","Udit Bhatia"],"pdf_url":"https://arxiv.org/pdf/2411.07753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06911v2","updated":"2024-11-12T12:07:00Z","published":"2024-11-11T12:13:58Z","title":"Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI","summary":"  Segmentation of cardiac magnetic resonance images (MRI) is crucial for the\nanalysis and assessment of cardiac function, helping to diagnose and treat\nvarious cardiovascular diseases. Most recent techniques rely on deep learning\nand usually require an extensive amount of labeled data. To overcome this\nproblem, few-shot learning has the capability of reducing data dependency on\nlabeled data. In this work, we introduce a new method that merges few-shot\nlearning with a U-Net architecture and Gaussian Process Emulators (GPEs),\nenhancing data integration from a support set for improved performance. GPEs\nare trained to learn the relation between the support images and the\ncorresponding masks in latent space, facilitating the segmentation of unseen\nquery images given only a small labeled support set at inference. We test our\nmodel with the M&Ms-2 public dataset to assess its ability to segment the heart\nin cardiac magnetic resonance imaging from different orientations, and compare\nit with state-of-the-art unsupervised and few-shot methods. Our architecture\nshows higher DICE coefficients compared to these methods, especially in the\nmore challenging setups where the size of the support set is considerably\nsmall.\n","authors":["Bruno Viti","Franz Thaler","Kathrin Lisa Kapper","Martin Urschler","Martin Holler","Elias Karabelas"],"pdf_url":"https://arxiv.org/pdf/2411.06911v2.pdf","comment":"Accepted at Statistical Atlases and Computational Modeling of the\n  Heart (STACOM) Workshop 2024"},{"id":"http://arxiv.org/abs/2411.07087v2","updated":"2024-11-12T12:03:07Z","published":"2024-11-11T16:04:49Z","title":"OCMDP: Observation-Constrained Markov Decision Process","summary":"  In many practical applications, decision-making processes must balance the\ncosts of acquiring information with the benefits it provides. Traditional\ncontrol systems often assume full observability, an unrealistic assumption when\nobservations are expensive. We tackle the challenge of simultaneously learning\nobservation and control strategies in such cost-sensitive environments by\nintroducing the Observation-Constrained Markov Decision Process (OCMDP), where\nthe policy influences the observability of the true state. To manage the\ncomplexity arising from the combined observation and control actions, we\ndevelop an iterative, model-free deep reinforcement learning algorithm that\nseparates the sensing and control components of the policy. This decomposition\nenables efficient learning in the expanded action space by focusing on when and\nwhat to observe, as well as determining optimal control actions, without\nrequiring knowledge of the environment's dynamics. We validate our approach on\na simulated diagnostic task and a realistic healthcare environment using\nHeartPole. Given both scenarios, the experimental results demonstrate that our\nmodel achieves a substantial reduction in observation costs on average,\nsignificantly outperforming baseline methods by a notable margin in efficiency.\n","authors":["Taiyi Wang","Jianheng Liu","Bryan Lee","Zhihao Wu","Yu Wu"],"pdf_url":"https://arxiv.org/pdf/2411.07087v2.pdf","comment":"Full paper, 14 Pages"},{"id":"http://arxiv.org/abs/2408.12308v3","updated":"2024-11-12T11:45:35Z","published":"2024-08-22T11:34:34Z","title":"Deep Learning with CNNs: A Compact Holistic Tutorial with Focus on\n  Supervised Regression (Preprint)","summary":"  In this tutorial, we present a compact and holistic discussion of Deep\nLearning with a focus on Convolutional Neural Networks (CNNs) and supervised\nregression. While there are numerous books and articles on the individual\ntopics we cover, comprehensive and detailed tutorials that address Deep\nLearning from a foundational yet rigorous and accessible perspective are rare.\nMost resources on CNNs are either too advanced, focusing on cutting-edge\narchitectures, or too narrow, addressing only specific applications like image\nclassification.This tutorial not only summarizes the most relevant concepts but\nalso provides an in-depth exploration of each, offering a complete yet agile\nset of ideas. Moreover, we highlight the powerful synergy between learning\ntheory, statistic, and machine learning, which together underpin the Deep\nLearning and CNN frameworks. We aim for this tutorial to serve as an optimal\nresource for students, professors, and anyone interested in understanding the\nfoundations of Deep Learning. Upon acceptance we will provide an accompanying\nrepository under\n\\href{https://github.com/neoglez/deep-learning-tutorial}{https://github.com/neoglez/deep-learning-tutorial}\n  Keywords: Tutorial, Deep Learning, Convolutional Neural Networks, Machine\nLearning.\n","authors":["Yansel Gonzalez Tejeda","Helmut A. Mayer"],"pdf_url":"https://arxiv.org/pdf/2408.12308v3.pdf","comment":"Submitted to the journal Machine Learning and Knowledge Extraction"},{"id":"http://arxiv.org/abs/2411.07729v1","updated":"2024-11-12T11:41:38Z","published":"2024-11-12T11:41:38Z","title":"Exploring the loss landscape of regularized neural networks via convex\n  duality","summary":"  We discuss several aspects of the loss landscape of regularized neural\nnetworks: the structure of stationary points, connectivity of optimal\nsolutions, path with nonincreasing loss to arbitrary global optimum, and the\nnonuniqueness of optimal solutions, by casting the problem into an equivalent\nconvex problem and considering its dual. Starting from two-layer neural\nnetworks with scalar output, we first characterize the solution set of the\nconvex problem using its dual and further characterize all stationary points.\nWith the characterization, we show that the topology of the global optima goes\nthrough a phase transition as the width of the network changes, and construct\ncounterexamples where the problem may have a continuum of optimal solutions.\nFinally, we show that the solution set characterization and connectivity\nresults can be extended to different architectures, including two-layer\nvector-valued neural networks and parallel three-layer neural networks.\n","authors":["Sungyoon Kim","Aaron Mishkin","Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2411.07729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07724v1","updated":"2024-11-12T11:30:53Z","published":"2024-11-12T11:30:53Z","title":"Convergence Rate Analysis of LION","summary":"  The LION (evoLved sIgn mOmeNtum) optimizer for deep neural network training\nwas found by Google via program search, with the simple sign update yet showing\nimpressive performance in training large scale networks. Although previous\nstudies have investigated its convergence properties, a comprehensive analysis,\nespecially the convergence rate, is still desirable. Recognizing that LION can\nbe regarded as solving a specific constrained problem, this paper focuses on\ndemonstrating its convergence to the Karush-Kuhn-Tucker (KKT) point at the rate\nof $\\cal O(\\sqrt{d}K^{-1/4})$ measured by gradient $\\ell_1$ norm, where $d$ is\nthe problem dimension and $K$ is the number of iteration steps. Step further,\nwe remove the constraint and establish that LION converges to the critical\npoint of the general unconstrained problem at the same rate. This rate not only\ndelivers the currently optimal dependence on the problem dimension $d$ but also\ntightly matches the theoretical lower bound for nonconvex stochastic\noptimization algorithms, which is typically measured using the gradient\n$\\ell_2$ norm, with respect to the number of iterations $K$. Through extensive\nexperiments, we not only demonstrate that LION achieves lower loss and higher\nperformance compared to standard SGD, but also empirically confirm that the\ngradient $\\ell_1/\\ell_2$ norm ratio aligns with $\\Theta(\\sqrt{d})$, thus\nproving that our convergence rate matches the theoretical lower bound with\nrespect to $d$ in the empirical sense.\n","authors":["Yiming Dong","Huan Li","Zhouchen Lin"],"pdf_url":"https://arxiv.org/pdf/2411.07724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07719v1","updated":"2024-11-12T11:24:18Z","published":"2024-11-12T11:24:18Z","title":"EMPERROR: A Flexible Generative Perception Error Model for Probing\n  Self-Driving Planners","summary":"  To handle the complexities of real-world traffic, learning planners for\nself-driving from data is a promising direction. While recent approaches have\nshown great progress, they typically assume a setting in which the ground-truth\nworld state is available as input. However, when deployed, planning needs to be\nrobust to the long-tail of errors incurred by a noisy perception system, which\nis often neglected in evaluation. To address this, previous work has proposed\ndrawing adversarial samples from a perception error model (PEM) mimicking the\nnoise characteristics of a target object detector. However, these methods use\nsimple PEMs that fail to accurately capture all failure modes of detection. In\nthis paper, we present EMPERROR, a novel transformer-based generative PEM,\napply it to stress-test an imitation learning (IL)-based planner and show that\nit imitates modern detectors more faithfully than previous work. Furthermore,\nit is able to produce realistic noisy inputs that increase the planner's\ncollision rate by up to 85%, demonstrating its utility as a valuable tool for a\nmore complete evaluation of self-driving planners.\n","authors":["Niklas Hanselmann","Simon Doll","Marius Cordts","Hendrik P. A. Lensch","Andreas Geiger"],"pdf_url":"https://arxiv.org/pdf/2411.07719v1.pdf","comment":"Project page: https://lasnik.github.io/emperror/"},{"id":"http://arxiv.org/abs/2405.07863v3","updated":"2024-11-12T11:18:43Z","published":"2024-05-13T15:50:39Z","title":"RLHF Workflow: From Reward Modeling to Online RLHF","summary":"  We present the workflow of Online Iterative Reinforcement Learning from Human\nFeedback (RLHF) in this technical report, which is widely reported to\noutperform its offline counterpart by a large margin in the recent large\nlanguage model (LLM) literature. However, existing open-source RLHF projects\nare still largely confined to the offline learning setting. In this technical\nreport, we aim to fill in this gap and provide a detailed recipe that is easy\nto reproduce for online iterative RLHF. In particular, since online human\nfeedback is usually infeasible for open-source communities with limited\nresources, we start by constructing preference models using a diverse set of\nopen-source datasets and use the constructed proxy preference model to\napproximate human feedback. Then, we discuss the theoretical insights and\nalgorithmic principles behind online iterative RLHF, followed by a detailed\npractical implementation. Our trained LLM achieves impressive performance on\nLLM chatbot benchmarks, including AlpacaEval-2, Arena-Hard, and MT-Bench, as\nwell as other academic benchmarks such as HumanEval and TruthfulQA. We have\nshown that supervised fine-tuning (SFT) and iterative RLHF can obtain\nstate-of-the-art performance with fully open-source datasets. Further, we have\nmade our models, curated datasets, and comprehensive step-by-step code\nguidebooks publicly available. Please refer to\nhttps://github.com/RLHFlow/RLHF-Reward-Modeling and\nhttps://github.com/RLHFlow/Online-RLHF for more detailed information.\n","authors":["Hanze Dong","Wei Xiong","Bo Pang","Haoxiang Wang","Han Zhao","Yingbo Zhou","Nan Jiang","Doyen Sahoo","Caiming Xiong","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.07863v3.pdf","comment":"Published in Transactions on Machine Learning Research (09/2024)"},{"id":"http://arxiv.org/abs/2201.07395v4","updated":"2024-11-12T11:12:46Z","published":"2022-01-19T03:08:33Z","title":"Overview frequency principle/spectral bias in deep learning","summary":"  Understanding deep learning is increasingly emergent as it penetrates more\nand more into industry and science. In recent years, a research line from\nFourier analysis sheds lights on this magical \"black box\" by showing a\nFrequency Principle (F-Principle or spectral bias) of the training behavior of\ndeep neural networks (DNNs) -- DNNs often fit functions from low to high\nfrequency during the training. The F-Principle is first demonstrated by\nonedimensional synthetic data followed by the verification in high-dimensional\nreal datasets. A series of works subsequently enhance the validity of the\nF-Principle. This low-frequency implicit bias reveals the strength of neural\nnetwork in learning low-frequency functions as well as its deficiency in\nlearning high-frequency functions. Such understanding inspires the design of\nDNN-based algorithms in practical problems, explains experimental phenomena\nemerging in various scenarios, and further advances the study of deep learning\nfrom the frequency perspective. Although incomplete, we provide an overview of\nF-Principle and propose some open problems for future research.\n","authors":["Zhi-Qin John Xu","Yaoyu Zhang","Tao Luo"],"pdf_url":"https://arxiv.org/pdf/2201.07395v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06736v2","updated":"2024-11-12T11:09:18Z","published":"2024-11-11T06:04:53Z","title":"Mr.Steve: Instruction-Following Agents in Minecraft with What-Where-When\n  Memory","summary":"  Significant advances have been made in developing general-purpose embodied AI\nin environments like Minecraft through the adoption of LLM-augmented\nhierarchical approaches. While these approaches, which combine high-level\nplanners with low-level controllers, show promise, low-level controllers\nfrequently become performance bottlenecks due to repeated failures. In this\npaper, we argue that the primary cause of failure in many low-level controllers\nis the absence of an episodic memory system. To address this, we introduce Mr.\nSteve (Memory Recall Steve-1), a novel low-level controller equipped with Place\nEvent Memory (PEM), a form of episodic memory that captures what, where, and\nwhen information from episodes. This directly addresses the main limitation of\nthe popular low-level controller, Steve-1. Unlike previous models that rely on\nshort-term memory, PEM organizes spatial and event-based data, enabling\nefficient recall and navigation in long-horizon tasks. Additionally, we propose\nan Exploration Strategy and a Memory-Augmented Task Solving Framework, allowing\nagents to alternate between exploration and task-solving based on recalled\nevents. Our approach significantly improves task-solving and exploration\nefficiency compared to existing methods. We will release our code and demos on\nthe project page: https://sites.google.com/view/mr-steve.\n","authors":["Junyeong Park","Junmo Cho","Sungjin Ahn"],"pdf_url":"https://arxiv.org/pdf/2411.06736v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.08364v3","updated":"2024-11-12T10:56:38Z","published":"2024-07-11T10:18:54Z","title":"Scalar Function Topology Divergence: Comparing Topology of 3D Objects","summary":"  We propose a new topological tool for computer vision - Scalar Function\nTopology Divergence (SFTD), which measures the dissimilarity of multi-scale\ntopology between sublevel sets of two functions having a common domain.\nFunctions can be defined on an undirected graph or Euclidean space of any\ndimensionality. Most of the existing methods for comparing topology are based\non Wasserstein distance between persistence barcodes and they don't take into\naccount the localization of topological features. The minimization of SFTD\nensures that the corresponding topological features of scalar functions are\nlocated in the same places. The proposed tool provides useful visualizations\ndepicting areas where functions have topological dissimilarities. We provide\napplications of the proposed method to 3D computer vision. In particular,\nexperiments demonstrate that SFTD as an additional loss improves the\nreconstruction of cellular 3D shapes from 2D fluorescence microscopy images,\nand helps to identify topological errors in 3D segmentation. Additionally, we\nshow that SFTD outperforms Betti matching loss in 2D segmentation problems.\n","authors":["Ilya Trofimov","Daria Voronkova","Eduard Tulchinskii","Evgeny Burnaev","Serguei Barannikov"],"pdf_url":"https://arxiv.org/pdf/2407.08364v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07711v1","updated":"2024-11-12T10:55:30Z","published":"2024-11-12T10:55:30Z","title":"OWLed: Outlier-weighed Layerwise Pruning for Efficient Autonomous\n  Driving Framework","summary":"  The integration of Large Language Models (LLMs) into autonomous driving\nsystems offers promising enhancements in environmental understanding and\ndecision-making. However, the substantial computational demands of deploying\nLLMs locally on vehicles render this approach unfeasible for real-world\nautomotive applications. To address this challenge, we introduce OWLed, the\nOutlier-Weighed Layerwise Pruning for Efficient Autonomous Driving Framework\nthat leverages outlier-weighted layerwise sparsity for model compression. Our\nmethod assigns non-uniform sparsity ratios to different layers based on the\ndistribution of outlier features, significantly reducing the model size without\nthe need for fine-tuning. To ensure the compressed model adapts well to\nautonomous driving tasks, we incorporate driving environment data into both the\ncalibration and pruning processes. Our empirical studies reveal that the\nencoder component is more sensitive to pruning than the LLM, highlighting its\ncritical role in the system. Experimental results demonstrate that OWLed\noutperforms existing methods in perception, action prediction, and language\nunderstanding while substantially lowering computational requirements. These\nfindings underscore the potential of combining advanced pruning techniques with\nLLMs to develop efficient and robust autonomous driving systems capable of\nhandling complex scenarios. Code will be made publicly available.\n","authors":["Jiaxi Li","Lu Yin","Xilu Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07711v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2411.07700v1","updated":"2024-11-12T10:26:44Z","published":"2024-11-12T10:26:44Z","title":"Test Where Decisions Matter: Importance-driven Testing for Deep\n  Reinforcement Learning","summary":"  In many Deep Reinforcement Learning (RL) problems, decisions in a trained\npolicy vary in significance for the expected safety and performance of the\npolicy. Since RL policies are very complex, testing efforts should concentrate\non states in which the agent's decisions have the highest impact on the\nexpected outcome. In this paper, we propose a novel model-based method to\nrigorously compute a ranking of state importance across the entire state space.\nWe then focus our testing efforts on the highest-ranked states. In this paper,\nwe focus on testing for safety. However, the proposed methods can be easily\nadapted to test for performance. In each iteration, our testing framework\ncomputes optimistic and pessimistic safety estimates. These estimates provide\nlower and upper bounds on the expected outcomes of the policy execution across\nall modeled states in the state space. Our approach divides the state space\ninto safe and unsafe regions upon convergence, providing clear insights into\nthe policy's weaknesses. Two important properties characterize our approach.\n(1) Optimal Test-Case Selection: At any time in the testing process, our\napproach evaluates the policy in the states that are most critical for safety.\n(2) Guaranteed Safety: Our approach can provide formal verification guarantees\nover the entire state space by sampling only a fraction of the policy. Any\nsafety properties assured by the pessimistic estimate are formally proven to\nhold for the policy. We provide a detailed evaluation of our framework on\nseveral examples, showing that our method discovers unsafe policy behavior with\nlow testing effort.\n","authors":["Stefan Pranger","Hana Chockler","Martin Tappler","Bettina Könighofer"],"pdf_url":"https://arxiv.org/pdf/2411.07700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02487v2","updated":"2024-11-12T10:03:37Z","published":"2024-08-05T14:09:30Z","title":"LiCoEval: Evaluating LLMs on License Compliance in Code Generation","summary":"  Recent advances in Large Language Models (LLMs) have revolutionized code\ngeneration, leading to widespread adoption of AI coding tools by developers.\nHowever, LLMs can generate license-protected code without providing the\nnecessary license information, leading to potential intellectual property\nviolations during software production. This paper addresses the critical, yet\nunderexplored, issue of license compliance in LLM-generated code by\nestablishing a benchmark to evaluate the ability of LLMs to provide accurate\nlicense information for their generated code. To establish this benchmark, we\nconduct an empirical study to identify a reasonable standard for \"striking\nsimilarity\" that excludes the possibility of independent creation, indicating a\ncopy relationship between the LLM output and certain open-source code. Based on\nthis standard, we propose LiCoEval, to evaluate the license compliance\ncapabilities of LLMs, i.e., the ability to provide accurate license or\ncopyright information when they generate code with striking similarity to\nalready existing copyrighted code. Using LiCoEval, we evaluate 14 popular LLMs,\nfinding that even top-performing LLMs produce a non-negligible proportion\n(0.88% to 2.01%) of code strikingly similar to existing open-source\nimplementations. Notably, most LLMs fail to provide accurate license\ninformation, particularly for code under copyleft licenses. These findings\nunderscore the urgent need to enhance LLM compliance capabilities in code\ngeneration tasks. Our study provides a foundation for future research and\ndevelopment to improve license compliance in AI-assisted software development,\ncontributing to both the protection of open-source software copyrights and the\nmitigation of legal risks for LLM users.\n","authors":["Weiwei Xu","Kai Gao","Hao He","Minghui Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.02487v2.pdf","comment":"The 47th International Conference on Software Engineering(ICSE 2025)"},{"id":"http://arxiv.org/abs/2405.17544v2","updated":"2024-11-12T09:57:28Z","published":"2024-05-27T18:00:00Z","title":"Towards Human-AI Complementarity with Prediction Sets","summary":"  Decision support systems based on prediction sets have proven to be effective\nat helping human experts solve classification tasks. Rather than providing\nsingle-label predictions, these systems provide sets of label predictions\nconstructed using conformal prediction, namely prediction sets, and ask human\nexperts to predict label values from these sets. In this paper, we first show\nthat the prediction sets constructed using conformal prediction are, in\ngeneral, suboptimal in terms of average accuracy. Then, we show that the\nproblem of finding the optimal prediction sets under which the human experts\nachieve the highest average accuracy is NP-hard. More strongly, unless P = NP,\nwe show that the problem is hard to approximate to any factor less than the\nsize of the label set. However, we introduce a simple and efficient greedy\nalgorithm that, for a large class of expert models and non-conformity scores,\nis guaranteed to find prediction sets that provably offer equal or greater\nperformance than those constructed using conformal prediction. Further, using a\nsimulation study with both synthetic and real expert predictions, we\ndemonstrate that, in practice, our greedy algorithm finds near-optimal\nprediction sets offering greater performance than conformal prediction.\n","authors":["Giovanni De Toni","Nastaran Okati","Suhas Thejaswi","Eleni Straitouri","Manuel Gomez-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2405.17544v2.pdf","comment":"Published in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2407.19872v3","updated":"2024-11-12T09:57:00Z","published":"2024-07-29T10:43:15Z","title":"OpenUAS: Embeddings of Cities in Japan with Anchor Data for Cross-city\n  Analysis of Area Usage Patterns","summary":"  We publicly release OpenUAS, a dataset of area embeddings based on urban\nusage patterns, including embeddings for over 1.3 million 50-meter square\nmeshes covering a total area of 3,300 square kilometers. This dataset is\nvaluable for analyzing area functions in fields such as market analysis, urban\nplanning, transportation infrastructure, and infection prediction. It captures\nthe characteristics of each area in the city, such as office districts and\nresidential areas, by employing an area embedding technique that utilizes\nlocation information typically obtained by GPS. Numerous area embedding\ntechniques have been proposed, and while the public release of such embedding\ndatasets is technically feasible, it has not been realized. One reason for this\nis that previous methods could not embed areas from different cities and\nperiods into the same embedding space without sharing raw location data. We\naddress this issue by developing an anchoring method that establishes anchors\nwithin a shared embedding space. We publicly release this anchor dataset along\nwith area embedding datasets from several periods in eight major Japanese\ncities.\n","authors":["Naoki Tamura","Kazuyuki Shoji","Shin Katayama","Kenta Urano","Takuro Yonezawa","Nobuo Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2407.19872v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06797v2","updated":"2024-11-12T09:54:07Z","published":"2023-07-13T15:08:44Z","title":"Fast and Functional Structured Data Generators Rooted in\n  Out-of-Equilibrium Physics","summary":"  In this study, we address the challenge of using energy-based models to\nproduce high-quality, label-specific data in complex structured datasets, such\nas population genetics, RNA or protein sequences data. Traditional training\nmethods encounter difficulties due to inefficient Markov chain Monte Carlo\nmixing, which affects the diversity of synthetic data and increases generation\ntimes. To address these issues, we use a novel training algorithm that exploits\nnon-equilibrium effects. This approach, applied on the Restricted Boltzmann\nMachine, improves the model's ability to correctly classify samples and\ngenerate high-quality synthetic data in only a few sampling steps. The\neffectiveness of this method is demonstrated by its successful application to\nfour different types of data: handwritten digits, mutations of human genomes\nclassified by continental origin, functionally characterized sequences of an\nenzyme protein family, and homologous RNA sequences from specific taxonomies.\n","authors":["Alessandra Carbone","Aurélien Decelle","Lorenzo Rosset","Beatriz Seoane"],"pdf_url":"https://arxiv.org/pdf/2307.06797v2.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2411.07681v1","updated":"2024-11-12T09:52:40Z","published":"2024-11-12T09:52:40Z","title":"What Do Learning Dynamics Reveal About Generalization in LLM Reasoning?","summary":"  Despite the remarkable capabilities of modern large language models (LLMs),\nthe mechanisms behind their problem-solving abilities remain elusive. In this\nwork, we aim to better understand how the learning dynamics of LLM finetuning\nshapes downstream generalization. Our analysis focuses on reasoning tasks,\nwhose problem structure allows us to distinguish between memorization (the\nexact replication of reasoning steps from the training data) and performance\n(the correctness of the final solution). We find that a model's generalization\nbehavior can be effectively characterized by a training metric we call\npre-memorization train accuracy: the accuracy of model samples on training\nqueries before they begin to copy the exact reasoning steps from the training\nset. On the dataset level, this metric is able to reliably predict test\naccuracy, achieving $R^2$ of around or exceeding 0.9 across various models\n(Llama3 8, Gemma2 9B), datasets (GSM8k, MATH), and training configurations. On\na per-example level, this metric is also indicative of whether individual model\npredictions are robust to perturbations in the training query. By connecting a\nmodel's learning behavior to its generalization, pre-memorization train\naccuracy can guide targeted improvements to training strategies. We focus on\ndata curation as an example, and show that prioritizing examples with low\npre-memorization accuracy leads to 1.5-2x improvements in data efficiency\ncompared to i.i.d. data scaling, and outperforms other standard data curation\ntechniques.\n","authors":["Katie Kang","Amrith Setlur","Dibya Ghosh","Jacob Steinhardt","Claire Tomlin","Sergey Levine","Aviral Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.07681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02066v4","updated":"2024-11-12T09:50:15Z","published":"2024-09-03T17:13:55Z","title":"Robust Clustering on High-Dimensional Data with Stochastic Quantization","summary":"  This paper addresses the limitations of conventional vector quantization\nalgorithms, particularly K-Means and its variant K-Means++, and investigates\nthe Stochastic Quantization (SQ) algorithm as a scalable alternative for\nhigh-dimensional unsupervised and semi-supervised learning tasks. Traditional\nclustering algorithms often suffer from inefficient memory utilization during\ncomputation, necessitating the loading of all data samples into memory, which\nbecomes impractical for large-scale datasets. While variants such as Mini-Batch\nK-Means partially mitigate this issue by reducing memory usage, they lack\nrobust theoretical convergence guarantees due to the non-convex nature of\nclustering problems. In contrast, the Stochastic Quantization algorithm\nprovides strong theoretical convergence guarantees, making it a robust\nalternative for clustering tasks. We demonstrate the computational efficiency\nand rapid convergence of the algorithm on an image classification problem with\npartially labeled data, comparing model accuracy across various ratios of\nlabeled to unlabeled data. To address the challenge of high dimensionality, we\nemploy a Triplet Network to encode images into low-dimensional representations\nin a latent space, which serve as a basis for comparing the efficiency of both\nthe Stochastic Quantization algorithm and traditional quantization algorithms.\nFurthermore, we enhance the algorithm's convergence speed by introducing\nmodifications with an adaptive learning rate.\n","authors":["Anton Kozyriev","Vladimir Norkin"],"pdf_url":"https://arxiv.org/pdf/2409.02066v4.pdf","comment":"22 pages, 5 figures, to be published in the International Scientific\n  Technical Journal \"Problems of Control and Informatics\""},{"id":"http://arxiv.org/abs/2411.07679v1","updated":"2024-11-12T09:49:16Z","published":"2024-11-12T09:49:16Z","title":"Safe Exploitative Play with Untrusted Type Beliefs","summary":"  The combination of the Bayesian game and learning has a rich history, with\nthe idea of controlling a single agent in a system composed of multiple agents\nwith unknown behaviors given a set of types, each specifying a possible\nbehavior for the other agents. The idea is to plan an agent's own actions with\nrespect to those types which it believes are most likely to maximize the\npayoff. However, the type beliefs are often learned from past actions and\nlikely to be incorrect. With this perspective in mind, we consider an agent in\na game with type predictions of other components, and investigate the impact of\nincorrect beliefs to the agent's payoff. In particular, we formally define a\ntradeoff between risk and opportunity by comparing the payoff obtained against\nthe optimal payoff, which is represented by a gap caused by trusting or\ndistrusting the learned beliefs. Our main results characterize the tradeoff by\nestablishing upper and lower bounds on the Pareto front for both normal-form\nand stochastic Bayesian games, with numerical results provided.\n","authors":["Tongxin Li","Tinashe Handina","Shaolei Ren","Adam Wierman"],"pdf_url":"https://arxiv.org/pdf/2411.07679v1.pdf","comment":"26 pages, NeurIPS 2024"},{"id":"http://arxiv.org/abs/2403.17351v2","updated":"2024-11-12T09:46:25Z","published":"2024-03-26T03:29:42Z","title":"Learn from Heterophily: Heterophilous Information-enhanced Graph Neural\n  Network","summary":"  Under circumstances of heterophily, where nodes with different labels tend to\nbe connected based on semantic meanings, Graph Neural Networks (GNNs) often\nexhibit suboptimal performance. Current studies on graph heterophily mainly\nfocus on aggregation calibration or neighbor extension and address the\nheterophily issue by utilizing node features or structural information to\nimprove GNN representations. In this paper, we propose and demonstrate that the\nvaluable semantic information inherent in heterophily can be utilized\neffectively in graph learning by investigating the distribution of neighbors\nfor each individual node within the graph. The theoretical analysis is carried\nout to demonstrate the efficacy of the idea in enhancing graph learning. Based\non this analysis, we propose HiGNN, an innovative approach that constructs an\nadditional new graph structure, that integrates heterophilous information by\nleveraging node distribution to enhance connectivity between nodes that share\nsimilar semantic characteristics. We conduct empirical assessments on node\nclassification tasks using both homophilous and heterophilous benchmark\ndatasets and compare HiGNN to popular GNN baselines and SoTA methods,\nconfirming the effectiveness in improving graph representations. In addition,\nby incorporating heterophilous information, we demonstrate a notable\nenhancement in existing GNN-based approaches, and the homophily degree across\nreal-world datasets, thus affirming the efficacy of our approach.\n","authors":["Yilun Zheng","Jiahao Xu","Lihui Chen"],"pdf_url":"https://arxiv.org/pdf/2403.17351v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19178v2","updated":"2024-11-12T09:42:13Z","published":"2024-05-29T15:18:39Z","title":"Model-independent cosmological inference post DESI DR1 BAO measurements","summary":"  In this work, we implement Gaussian process regression to reconstruct the\nexpansion history of the universe in a model-agnostic manner, using the\nPantheon-Plus SN-Ia compilation in combination with two different BAO\nmeasurements (SDSS-IV and DESI DR1). In both the reconstructions, the\n$\\Lambda$CDM model is always included in the 95\\% confidence intervals. We find\nevidence that the DESI LRG data at $z_{\\text{eff}} = 0.51$ is not an outlier\nwithin our model-independent framework. We study the $\\mathcal{O}m$-diagnostics\nand the evolution of the total equation of state (EoS) of our universe, which\nhint towards the possibility of a quintessence-like dark energy scenario with a\nvery slowly varying EoS, and a phantom-crossing in higher $z$. The entire\nexercise is later complemented by considering two more SN-Ia compilations -\nDES-5YR and Union3 - in combination with DESI BAO. Reconstruction with the DESI\nBAO + DES-5YR SN data sets predicts that the $\\Lambda$CDM model lies outside\nthe 3$\\sigma$ confidence levels, whereas with DESI BAO + Union3 data, the\n$\\Lambda$CDM model is always included within 1$\\sigma$. We also report\nconstraints on $H_0 r_d$ from our model-agnostic analysis, independent of the\npre-recombination physics. Our results point towards an $\\approx$ 2$\\sigma$\ndiscrepancy between the DESI + Pantheon-Plus and DESI + DES-5YR data sets,\nwhich calls for further investigation.\n","authors":["Purba Mukherjee","Anjan Ananda Sen"],"pdf_url":"https://arxiv.org/pdf/2405.19178v2.pdf","comment":"10 pages, 6 sets of figures. Accepted for publication in PRD"},{"id":"http://arxiv.org/abs/2411.07672v1","updated":"2024-11-12T09:39:22Z","published":"2024-11-12T09:39:22Z","title":"Rethinking Structure Learning For Graph Neural Networks","summary":"  To improve the performance of Graph Neural Networks (GNNs), Graph Structure\nLearning (GSL) has been extensively applied to reconstruct or refine original\ngraph structures, effectively addressing issues like heterophily,\nover-squashing, and noisy structures. While GSL is generally thought to improve\nGNN performance, it often leads to longer training times and more\nhyperparameter tuning. Besides, the distinctions among current GSL methods\nremain ambiguous from the perspective of GNN training, and there is a lack of\ntheoretical analysis to quantify their effectiveness. Recent studies further\nsuggest that, under fair comparisons with the same hyperparameter tuning, GSL\ndoes not consistently outperform baseline GNNs. This motivates us to ask a\ncritical question: is GSL really useful for GNNs? To address this question,\nthis paper makes two key contributions. First, we propose a new GSL framework,\nwhich includes three steps: GSL base (the representation used for GSL)\nconstruction, new structure construction, and view fusion, to better understand\nthe effectiveness of GSL in GNNs. Second, after graph convolution, we analyze\nthe differences in mutual information (MI) between node representations derived\nfrom the original topology and those from the newly constructed topology.\nSurprisingly, our empirical observations and theoretical analysis show that no\nmatter which type of graph structure construction methods are used, after\nfeeding the same GSL bases to the newly constructed graph, there is no MI gain\ncompared to the original GSL bases. To fairly reassess the effectiveness of\nGSL, we conduct ablation experiments and find that it is the pretrained GSL\nbases that enhance GNN performance, and in most cases, GSL cannot improve GNN\nperformance. This finding encourages us to rethink the essential components in\nGNNs, such as self-training and structural encoding, in GNN design rather than\nGSL.\n","authors":["Yilun Zheng","Zhuofan Zhang","Ziming Wang","Xiang Li","Sitao Luan","Xiaojiang Peng","Lihui Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07663v1","updated":"2024-11-12T09:28:55Z","published":"2024-11-12T09:28:55Z","title":"Is Graph Convolution Always Beneficial For Every Feature?","summary":"  Graph Neural Networks (GNNs) have demonstrated strong capabilities in\nprocessing structured data. While traditional GNNs typically treat each feature\ndimension equally during graph convolution, we raise an important question: Is\nthe graph convolution operation equally beneficial for each feature? If not,\nthe convolution operation on certain feature dimensions can possibly lead to\nharmful effects, even worse than the convolution-free models. In prior studies,\nto assess the impacts of graph convolution on features, people proposed metrics\nbased on feature homophily to measure feature consistency with the graph\ntopology. However, these metrics have shown unsatisfactory alignment with GNN\nperformance and have not been effectively employed to guide feature selection\nin GNNs. To address these limitations, we introduce a novel metric, Topological\nFeature Informativeness (TFI), to distinguish between GNN-favored and\nGNN-disfavored features, where its effectiveness is validated through both\ntheoretical analysis and empirical observations. Based on TFI, we propose a\nsimple yet effective Graph Feature Selection (GFS) method, which processes\nGNN-favored and GNN-disfavored features separately, using GNNs and non-GNN\nmodels. Compared to original GNNs, GFS significantly improves the extraction of\nuseful topological information from each feature with comparable computational\ncosts. Extensive experiments show that after applying GFS to 8 baseline and\nstate-of-the-art (SOTA) GNN architectures across 10 datasets, 83.75% of the\nGFS-augmented cases show significant performance boosts. Furthermore, our\nproposed TFI metric outperforms other feature selection methods. These results\nvalidate the effectiveness of both GFS and TFI. Additionally, we demonstrate\nthat GFS's improvements are robust to hyperparameter tuning, highlighting its\npotential as a universal method for enhancing various GNN architectures.\n","authors":["Yilun Zheng","Xiang Li","Sitao Luan","Xiaojiang Peng","Lihui Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13848v2","updated":"2024-11-12T09:21:13Z","published":"2024-03-18T10:44:22Z","title":"Smooth Sensitivity for Learning Differentially-Private yet Accurate Rule\n  Lists","summary":"  Differentially-private (DP) mechanisms can be embedded into the design of a\nmachine learning algorithm to protect the resulting model against privacy\nleakage. However, this often comes with a significant loss of accuracy due to\nthe noise added to enforce DP. In this paper, we aim at improving this\ntrade-off for a popular class of machine learning algorithms leveraging the\nGini impurity as an information gain criterion to greedily build interpretable\nmodels such as decision trees or rule lists. To this end, we establish the\nsmooth sensitivity of the Gini impurity, which can be used to obtain thorough\nDP guarantees while adding noise scaled with tighter magnitude. We illustrate\nthe applicability of this mechanism by integrating it within a greedy algorithm\nproducing rule list models, motivated by the fact that such models remain\nunderstudied in the DP literature. Our theoretical analysis and experimental\nresults confirm that the DP rule lists models integrating smooth sensitivity\nhave higher accuracy that those using other DP frameworks based on global\nsensitivity, for identical privacy budgets.\n","authors":["Timothée Ly","Julien Ferry","Marie-José Huguet","Sébastien Gambs","Ulrich Aivodji"],"pdf_url":"https://arxiv.org/pdf/2403.13848v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06890v2","updated":"2024-11-12T09:12:42Z","published":"2024-11-11T11:42:48Z","title":"SPARTAN: A Sparse Transformer Learning Local Causation","summary":"  Causal structures play a central role in world models that flexibly adapt to\nchanges in the environment. While recent works motivate the benefits of\ndiscovering local causal graphs for dynamics modelling, in this work we\ndemonstrate that accurately capturing these relationships in complex settings\nremains challenging for the current state-of-the-art. To remedy this\nshortcoming, we postulate that sparsity is a critical ingredient for the\ndiscovery of such local causal structures. To this end we present the SPARse\nTrANsformer World model (SPARTAN), a Transformer-based world model that learns\nlocal causal structures between entities in a scene. By applying sparsity\nregularisation on the attention pattern between object-factored tokens, SPARTAN\nidentifies sparse local causal models that accurately predict future object\nstates. Furthermore, we extend our model to capture sparse interventions with\nunknown targets on the dynamics of the environment. This results in a highly\ninterpretable world model that can efficiently adapt to changes. Empirically,\nwe evaluate SPARTAN against the current state-of-the-art in object-centric\nworld models on observation-based environments and demonstrate that our model\ncan learn accurate local causal graphs and achieve significantly improved\nfew-shot adaptation to changes in the dynamics of the environment as well as\nrobustness against removing irrelevant distractors.\n","authors":["Anson Lei","Bernhard Schölkopf","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2411.06890v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07650v1","updated":"2024-11-12T09:02:11Z","published":"2024-11-12T09:02:11Z","title":"Understanding Audiovisual Deepfake Detection: Techniques, Challenges,\n  Human Factors and Perceptual Insights","summary":"  Deep Learning has been successfully applied in diverse fields, and its impact\non deepfake detection is no exception. Deepfakes are fake yet realistic\nsynthetic content that can be used deceitfully for political impersonation,\nphishing, slandering, or spreading misinformation. Despite extensive research\non unimodal deepfake detection, identifying complex deepfakes through joint\nanalysis of audio and visual streams remains relatively unexplored. To fill\nthis gap, this survey first provides an overview of audiovisual deepfake\ngeneration techniques, applications, and their consequences, and then provides\na comprehensive review of state-of-the-art methods that combine audio and\nvisual modalities to enhance detection accuracy, summarizing and critically\nanalyzing their strengths and limitations. Furthermore, we discuss existing\nopen source datasets for a deeper understanding, which can contribute to the\nresearch community and provide necessary information to beginners who want to\nanalyze deep learning-based audiovisual methods for video forensics. By\nbridging the gap between unimodal and multimodal approaches, this paper aims to\nimprove the effectiveness of deepfake detection strategies and guide future\nresearch in cybersecurity and media integrity.\n","authors":["Ammarah Hashmi","Sahibzada Adil Shahzad","Chia-Wen Lin","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07650v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07643v1","updated":"2024-11-12T08:53:49Z","published":"2024-11-12T08:53:49Z","title":"xCG: Explainable Cell Graphs for Survival Prediction in Non-Small Cell\n  Lung Cancer","summary":"  Understanding how deep learning models predict oncology patient risk can\nprovide critical insights into disease progression, support clinical\ndecision-making, and pave the way for trustworthy and data-driven precision\nmedicine. Building on recent advances in the spatial modeling of the tumor\nmicroenvironment using graph neural networks, we present an explainable cell\ngraph (xCG) approach for survival prediction. We validate our model on a public\ncohort of imaging mass cytometry (IMC) data for 416 cases of lung\nadenocarcinoma. We explain survival predictions in terms of known phenotypes on\nthe cell level by computing risk attributions over cell graphs, for which we\npropose an efficient grid-based layer-wise relevance propagation (LRP) method.\nOur ablation studies highlight the importance of incorporating the cancer stage\nand model ensembling to improve the quality of risk estimates. Our xCG method,\ntogether with the IMC data, is made publicly available to support further\nresearch.\n","authors":["Marvin Sextro","Gabriel Dernbach","Kai Standvoss","Simon Schallenberg","Frederick Klauschen","Klaus-Robert Müller","Maximilian Alber","Lukas Ruff"],"pdf_url":"https://arxiv.org/pdf/2411.07643v1.pdf","comment":"Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 11 pages"},{"id":"http://arxiv.org/abs/2411.06236v2","updated":"2024-11-12T08:51:40Z","published":"2024-11-09T17:36:53Z","title":"Zero-Shot NAS via the Suppression of Local Entropy Decrease","summary":"  Architecture performance evaluation is the most time-consuming part of neural\narchitecture search (NAS). Zero-Shot NAS accelerates the evaluation by\nutilizing zero-cost proxies instead of training. Though effective, existing\nzero-cost proxies require invoking backpropagations or running networks on\ninput data, making it difficult to further accelerate the computation of\nproxies. To alleviate this issue, architecture topologies are used to evaluate\nthe performance of networks in this study. We prove that particular\narchitectural topologies decrease the local entropy of feature maps, which\ndegrades specific features to a bias, thereby reducing network performance.\nBased on this proof, architectural topologies are utilized to quantify the\nsuppression of local entropy decrease (SED) as a data-free and running-free\nproxy. Experimental results show that SED outperforms most state-of-the-art\nproxies in terms of architecture selection on five benchmarks, with computation\ntime reduced by three orders of magnitude. We further compare the SED-based NAS\nwith state-of-the-art proxies. SED-based NAS selects the architecture with\nhigher accuracy and fewer parameters in only one second. The theoretical\nanalyses of local entropy and experimental results demonstrate that the\nsuppression of local entropy decrease facilitates selecting optimal\narchitectures in Zero-Shot NAS.\n","authors":["Ning Wu","Han Huang","Yueting Xu","Zhifeng Hao"],"pdf_url":"https://arxiv.org/pdf/2411.06236v2.pdf","comment":"8 pages, 2 figures. Corrected typos and latex template"},{"id":"http://arxiv.org/abs/2410.05814v2","updated":"2024-11-12T08:50:59Z","published":"2024-10-08T08:44:01Z","title":"CALoR: Towards Comprehensive Model Inversion Defense","summary":"  Model Inversion Attacks (MIAs) aim at recovering privacy-sensitive training\ndata from the knowledge encoded in the released machine learning models. Recent\nadvances in the MIA field have significantly enhanced the attack performance\nunder multiple scenarios, posing serious privacy risks of Deep Neural Networks\n(DNNs). However, the development of defense strategies against MIAs is\nrelatively backward to resist the latest MIAs and existing defenses fail to\nachieve further trade-off between model utility and model robustness. In this\npaper, we provide an in-depth analysis from the perspective of intrinsic\nvulnerabilities of MIAs, comprehensively uncovering the weaknesses inherent in\nthe basic pipeline, which are partially investigated in the previous defenses.\nBuilding upon these new insights, we propose a robust defense mechanism,\nintegrating Confidence Adaptation and Low-Rank compression(CALoR). Our method\nincludes a novel robustness-enhanced classification loss specially-designed for\nmodel inversion defenses and reveals the extraordinary effectiveness of\ncompressing the classification header. With CALoR, we can mislead the\noptimization objective, reduce the leaked information and impede the\nbackpropagation of MIAs, thus mitigating the risk of privacy leakage. Extensive\nexperimental results demonstrate that our method achieves state-of-the-art\n(SOTA) defense performance against MIAs and exhibits superior generalization to\nexisting defenses across various scenarios.\n","authors":["Hongyao Yu","Yixiang Qiu","Hao Fang","Bin Chen","Sijin Yu","Bin Wang","Shu-Tao Xia","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2410.05814v2.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2411.07641v1","updated":"2024-11-12T08:46:43Z","published":"2024-11-12T08:46:43Z","title":"Top-$nσ$: Not All Logits Are You Need","summary":"  Large language models (LLMs) typically employ greedy decoding or\nlow-temperature sampling for reasoning tasks, reflecting a perceived trade-off\nbetween diversity and accuracy. We challenge this convention by introducing\ntop-$n\\sigma$, a novel sampling method that operates directly on pre-softmax\nlogits by leveraging a statistical threshold. Our key insight is that logits\nnaturally separate into a Gaussian-distributed noisy region and a distinct\ninformative region, enabling efficient token filtering without complex\nprobability manipulations. Unlike existing methods (e.g., top-$p$, min-$p$)\nthat inadvertently include more noise tokens at higher temperatures,\ntop-$n\\sigma$ maintains a stable sampling space regardless of temperature\nscaling. We also provide a theoretical analysis of top-$n\\sigma$ to better\nunderstand its behavior. The extensive experimental results across four\nreasoning-focused datasets demonstrate that our method not only outperforms\nexisting sampling approaches but also surpasses greedy decoding, while\nmaintaining consistent performance even at high temperatures.\n","authors":["Chenxia Tang","Jianchun Liu","Hongli Xu","Liusheng Huang"],"pdf_url":"https://arxiv.org/pdf/2411.07641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10944v5","updated":"2024-11-12T08:31:22Z","published":"2023-11-18T02:44:33Z","title":"Deception Detection from Linguistic and Physiological Data Streams Using\n  Bimodal Convolutional Neural Networks","summary":"  Deception detection is gaining increasing interest due to ethical and\nsecurity concerns. This paper explores the application of convolutional neural\nnetworks for the purpose of multimodal deception detection. We use a dataset\nbuilt by interviewing 104 subjects about two topics, with one truthful and one\nfalsified response from each subject about each topic. In particular, we make\nthree main contributions. First, we extract linguistic and physiological\nfeatures from this data to train and construct the neural network models.\nSecond, we propose a fused convolutional neural network model using both\nmodalities in order to achieve an improved overall performance. Third, we\ncompare our new approach with earlier methods designed for multimodal deception\ndetection. We find that our system outperforms regular classification methods;\nour results indicate the feasibility of using neural networks for deception\ndetection even in the presence of limited amounts of data.\n","authors":["Panfeng Li","Mohamed Abouelenien","Rada Mihalcea","Zhicheng Ding","Qikai Yang","Yiming Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.10944v5.pdf","comment":"Accepted by 2024 5th International Conference on Information Science,\n  Parallel and Distributed Systems"},{"id":"http://arxiv.org/abs/2411.07634v1","updated":"2024-11-12T08:27:27Z","published":"2024-11-12T08:27:27Z","title":"Exploring Multi-Agent Reinforcement Learning for Unrelated Parallel\n  Machine Scheduling","summary":"  Scheduling problems pose significant challenges in resource, industry, and\noperational management. This paper addresses the Unrelated Parallel Machine\nScheduling Problem (UPMS) with setup times and resources using a Multi-Agent\nReinforcement Learning (MARL) approach. The study introduces the Reinforcement\nLearning environment and conducts empirical analyses, comparing MARL with\nSingle-Agent algorithms. The experiments employ various deep neural network\npolicies for single- and Multi-Agent approaches. Results demonstrate the\nefficacy of the Maskable extension of the Proximal Policy Optimization (PPO)\nalgorithm in Single-Agent scenarios and the Multi-Agent PPO algorithm in\nMulti-Agent setups. While Single-Agent algorithms perform adequately in reduced\nscenarios, Multi-Agent approaches reveal challenges in cooperative learning but\na scalable capacity. This research contributes insights into applying MARL\ntechniques to scheduling optimization, emphasizing the need for algorithmic\nsophistication balanced with scalability for intelligent scheduling solutions.\n","authors":["Maria Zampella","Urtzi Otamendi","Xabier Belaunzaran","Arkaitz Artetxe","Igor G. Olaizola","Giuseppe Longo","Basilio Sierra"],"pdf_url":"https://arxiv.org/pdf/2411.07634v1.pdf","comment":"11 pages, 5 figures, 4 tables, article submitted to a journal"},{"id":"http://arxiv.org/abs/2310.06929v2","updated":"2024-11-12T08:24:28Z","published":"2023-10-10T18:32:11Z","title":"Stochastic Super-resolution of Cosmological Simulations with Denoising\n  Diffusion Models","summary":"  In recent years, deep learning models have been successfully employed for\naugmenting low-resolution cosmological simulations with small-scale\ninformation, a task known as \"super-resolution\". So far, these cosmological\nsuper-resolution models have relied on generative adversarial networks (GANs),\nwhich can achieve highly realistic results, but suffer from various\nshortcomings (e.g. low sample diversity). We introduce denoising diffusion\nmodels as a powerful generative model for super-resolving cosmic large-scale\nstructure predictions (as a first proof-of-concept in two dimensions). To\nobtain accurate results down to small scales, we develop a new \"filter-boosted\"\ntraining approach that redistributes the importance of different scales in the\npixel-wise training objective. We demonstrate that our model not only produces\nconvincing super-resolution images and power spectra consistent at the percent\nlevel, but is also able to reproduce the diversity of small-scale features\nconsistent with a given low-resolution simulation. This enables uncertainty\nquantification for the generated small-scale features, which is critical for\nthe usefulness of such super-resolution models as a viable surrogate model for\ncosmic structure formation.\n","authors":["Andreas Schanz","Florian List","Oliver Hahn"],"pdf_url":"https://arxiv.org/pdf/2310.06929v2.pdf","comment":"9 pages, 8 figures, to be submitted to OJA, comments welcome"},{"id":"http://arxiv.org/abs/2402.07314v3","updated":"2024-11-12T08:24:10Z","published":"2024-02-11T21:44:21Z","title":"Online Iterative Reinforcement Learning from Human Feedback with General\n  Preference Model","summary":"  We investigate Reinforcement Learning from Human Feedback (RLHF) in the\ncontext of a general preference oracle. In particular, we do not assume the\nexistence of a reward function and an oracle preference signal drawn from the\nBradley-Terry model as most of the prior works do. We consider a standard\nmathematical formulation, the reverse-KL regularized minimax game between two\nLLMs for RLHF under general preference oracle. The learning objective of this\nformulation is to find a policy so that it is consistently preferred by the\nKL-regularized preference oracle over any competing LLMs. We show that this\nframework is strictly more general than the reward-based one, and propose\nsample-efficient algorithms for both the offline learning from a pre-collected\npreference dataset and online learning where we can query the preference oracle\nalong the way of training. Empirical studies verify the effectiveness of the\nproposed framework.\n","authors":["Chenlu Ye","Wei Xiong","Yuheng Zhang","Hanze Dong","Nan Jiang","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.07314v3.pdf","comment":"RLHF, Preference Learning, Alignment for LLMs"},{"id":"http://arxiv.org/abs/2405.06219v3","updated":"2024-11-12T08:18:45Z","published":"2024-05-10T03:06:24Z","title":"SKVQ: Sliding-window Key and Value Cache Quantization for Large Language\n  Models","summary":"  Large language models (LLMs) can now handle longer sequences of tokens,\nenabling complex tasks like book understanding and generating lengthy novels.\nHowever, the key-value (KV) cache required for LLMs consumes substantial memory\nas context length increasing, becoming the bottleneck for deployment. In this\npaper, we present a strategy called SKVQ, which stands for sliding-window KV\ncache quantization, to address the issue of extremely low bitwidth KV cache\nquantization. To achieve this, SKVQ rearranges the channels of the KV cache in\norder to improve the similarity of channels in quantization groups, and applies\nclipped dynamic quantization at the group level. Additionally, SKVQ ensures\nthat the most recent window tokens in the KV cache are preserved with high\nprecision. This helps maintain the accuracy of a small but important portion of\nthe KV cache.SKVQ achieves high compression ratios while maintaining accuracy.\nOur evaluation on LLMs demonstrates that SKVQ surpasses previous quantization\napproaches, allowing for quantization of the KV cache to 2-bit keys and 1.5-bit\nvalues with minimal loss of accuracy. With SKVQ, it is possible to process\ncontext lengths of up to 1M on an 80GB memory GPU for a 7b model and up to 7\ntimes faster decoding.\n","authors":["Haojie Duanmu","Zhihang Yuan","Xiuhong Li","Jiangfei Duan","Xingcheng Zhang","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2405.06219v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06634v2","updated":"2024-11-12T07:52:33Z","published":"2024-08-13T04:53:31Z","title":"Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM\n  Approach","summary":"  Accurate stock market predictions following earnings reports are crucial for\ninvestors. Traditional methods, particularly classical machine learning models,\nstruggle with these predictions because they cannot effectively process and\ninterpret extensive textual data contained in earnings reports and often\noverlook nuances that influence market movements. This paper introduces an\nadvanced approach by employing Large Language Models (LLMs) instruction\nfine-tuned with a novel combination of instruction-based techniques and\nquantized low-rank adaptation (QLoRA) compression. Our methodology integrates\n'base factors', such as financial metric growth and earnings transcripts, with\n'external factors', including recent market indices performances and analyst\ngrades, to create a rich, supervised dataset. This comprehensive dataset\nenables our models to achieve superior predictive performance in terms of\naccuracy, weighted F1, and Matthews correlation coefficient (MCC), especially\nevident in the comparison with benchmarks such as GPT-4. We specifically\nhighlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases\nsignificant improvements over baseline models. The paper also discusses the\npotential of expanding the output capabilities to include a 'Hold' option and\nextending the prediction horizon, aiming to accommodate various investment\nstyles and time frames. This study not only demonstrates the power of\nintegrating cutting-edge AI with fine-tuned financial data but also paves the\nway for future research in enhancing AI-driven financial analysis tools.\n","authors":["Haowei Ni","Shuchen Meng","Xupeng Chen","Ziqing Zhao","Andi Chen","Panfeng Li","Shiyao Zhang","Qifu Yin","Yuanqing Wang","Yuxi Chan"],"pdf_url":"https://arxiv.org/pdf/2408.06634v2.pdf","comment":"Accepted by 2024 6th International Conference on Data-driven\n  Optimization of Complex Systems"},{"id":"http://arxiv.org/abs/2411.07232v2","updated":"2024-11-12T07:49:39Z","published":"2024-11-11T18:50:09Z","title":"Add-it: Training-Free Object Insertion in Images With Pretrained\n  Diffusion Models","summary":"  Adding Object into images based on text instructions is a challenging task in\nsemantic image editing, requiring a balance between preserving the original\nscene and seamlessly integrating the new object in a fitting location. Despite\nextensive efforts, existing models often struggle with this balance,\nparticularly with finding a natural location for adding an object in complex\nscenes. We introduce Add-it, a training-free approach that extends diffusion\nmodels' attention mechanisms to incorporate information from three key sources:\nthe scene image, the text prompt, and the generated image itself. Our weighted\nextended-attention mechanism maintains structural consistency and fine details\nwhile ensuring natural object placement. Without task-specific fine-tuning,\nAdd-it achieves state-of-the-art results on both real and generated image\ninsertion benchmarks, including our newly constructed \"Additing Affordance\nBenchmark\" for evaluating object placement plausibility, outperforming\nsupervised methods. Human evaluations show that Add-it is preferred in over 80%\nof cases, and it also demonstrates improvements in various automated metrics.\n","authors":["Yoad Tewel","Rinon Gal","Dvir Samuel","Yuval Atzmon","Lior Wolf","Gal Chechik"],"pdf_url":"https://arxiv.org/pdf/2411.07232v2.pdf","comment":"Project page is at https://research.nvidia.com/labs/par/addit/"},{"id":"http://arxiv.org/abs/2410.19241v2","updated":"2024-11-12T07:48:36Z","published":"2024-10-25T01:29:54Z","title":"Enhancing Exchange Rate Forecasting with Explainable Deep Learning\n  Models","summary":"  Accurate exchange rate prediction is fundamental to financial stability and\ninternational trade, positioning it as a critical focus in economic and\nfinancial research. Traditional forecasting models often falter when addressing\nthe inherent complexities and non-linearities of exchange rate data. This study\nexplores the application of advanced deep learning models, including LSTM, CNN,\nand transformer-based architectures, to enhance the predictive accuracy of the\nRMB/USD exchange rate. Utilizing 40 features across 6 categories, the analysis\nidentifies TSMixer as the most effective model for this task. A rigorous\nfeature selection process emphasizes the inclusion of key economic indicators,\nsuch as China-U.S. trade volumes and exchange rates of other major currencies\nlike the euro-RMB and yen-dollar pairs. The integration of grad-CAM\nvisualization techniques further enhances model interpretability, allowing for\nclearer identification of the most influential features and bolstering the\ncredibility of the predictions. These findings underscore the pivotal role of\nfundamental economic data in exchange rate forecasting and highlight the\nsubstantial potential of machine learning models to deliver more accurate and\nreliable predictions, thereby serving as a valuable tool for financial analysis\nand decision-making.\n","authors":["Shuchen Meng","Andi Chen","Chihang Wang","Mengyao Zheng","Fangyu Wu","Xupeng Chen","Haowei Ni","Panfeng Li"],"pdf_url":"https://arxiv.org/pdf/2410.19241v2.pdf","comment":"Accepted by 2024 5th International Conference on Machine Learning and\n  Computer Application"},{"id":"http://arxiv.org/abs/2404.13812v4","updated":"2024-11-12T07:44:20Z","published":"2024-04-22T01:16:11Z","title":"A Comparative Study on Enhancing Prediction in Social Network\n  Advertisement through Data Augmentation","summary":"  In the ever-evolving landscape of social network advertising, the volume and\naccuracy of data play a critical role in the performance of predictive models.\nHowever, the development of robust predictive algorithms is often hampered by\nthe limited size and potential bias present in real-world datasets. This study\npresents and explores a generative augmentation framework of social network\nadvertising data. Our framework explores three generative models for data\naugmentation - Generative Adversarial Networks (GANs), Variational Autoencoders\n(VAEs), and Gaussian Mixture Models (GMMs) - to enrich data availability and\ndiversity in the context of social network advertising analytics effectiveness.\nBy performing synthetic extensions of the feature space, we find that through\ndata augmentation, the performance of various classifiers has been\nquantitatively improved. Furthermore, we compare the relative performance gains\nbrought by each data augmentation technique, providing insights for\npractitioners to select appropriate techniques to enhance model performance.\nThis paper contributes to the literature by showing that synthetic data\naugmentation alleviates the limitations imposed by small or imbalanced datasets\nin the field of social network advertising. At the same time, this article also\nprovides a comparative perspective on the practicality of different data\naugmentation methods, thereby guiding practitioners to choose appropriate\ntechniques to enhance model performance.\n","authors":["Qikai Yang","Panfeng Li","Xinhe Xu","Zhicheng Ding","Wenjing Zhou","Yi Nian"],"pdf_url":"https://arxiv.org/pdf/2404.13812v4.pdf","comment":"Accepted by 2024 4th International Conference on Machine Learning and\n  Intelligent Systems Engineering (MLISE)"},{"id":"http://arxiv.org/abs/2411.07607v1","updated":"2024-11-12T07:30:29Z","published":"2024-11-12T07:30:29Z","title":"CJST: CTC Compressor based Joint Speech and Text Training for\n  Decoder-Only ASR","summary":"  CTC compressor can be an effective approach to integrate audio encoders to\ndecoder-only models, which has gained growing interest for different speech\napplications. In this work, we propose a novel CTC compressor based joint\nspeech and text training (CJST) framework for decoder-only ASR. CJST matches\nspeech and text modalities from both directions by exploring a simple modality\nadaptor and several features of the CTC compressor, including sequence\ncompression, on-the-fly forced peaky alignment and CTC class embeddings.\nExperimental results on the Librispeech and TED-LIUM2 corpora show that the\nproposed CJST achieves an effective text injection without the need of duration\nhandling, leading to the best performance for both in-domain and cross-domain\nscenarios. We also provide a comprehensive study on CTC compressor, covering\nvarious compression modes, edge case handling and behavior under both clean and\nnoisy data conditions, which reveals the most robust setting to use CTC\ncompressor for decoder-only models.\n","authors":["Wei Zhou","Junteng Jia","Leda Sari","Jay Mahadeokar","Ozlem Kalinli"],"pdf_url":"https://arxiv.org/pdf/2411.07607v1.pdf","comment":"submitted to ICASSP2025"},{"id":"http://arxiv.org/abs/2406.12199v3","updated":"2024-11-12T07:28:08Z","published":"2024-06-18T01:55:37Z","title":"Time Series Modeling for Heart Rate Prediction: From ARIMA to\n  Transformers","summary":"  Cardiovascular disease (CVD) is a leading cause of death globally,\nnecessitating precise forecasting models for monitoring vital signs like heart\nrate, blood pressure, and ECG. Traditional models, such as ARIMA and Prophet,\nare limited by their need for manual parameter tuning and challenges in\nhandling noisy, sparse, and highly variable medical data. This study\ninvestigates advanced deep learning models, including LSTM, and\ntransformer-based architectures, for predicting heart rate time series from the\nMIT-BIH Database. Results demonstrate that deep learning models, particularly\nPatchTST, significantly outperform traditional models across multiple metrics,\ncapturing complex patterns and dependencies more effectively. This research\nunderscores the potential of deep learning to enhance patient monitoring and\nCVD management, suggesting substantial clinical benefits. Future work should\nextend these findings to larger, more diverse datasets and real-world clinical\napplications to further validate and optimize model performance.\n","authors":["Haowei Ni","Shuchen Meng","Xieming Geng","Panfeng Li","Zhuoying Li","Xupeng Chen","Xiaotong Wang","Shiyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.12199v3.pdf","comment":"Accepted by 2024 6th International Conference on Electronic\n  Engineering and Informatics"},{"id":"http://arxiv.org/abs/2411.07602v1","updated":"2024-11-12T07:24:41Z","published":"2024-11-12T07:24:41Z","title":"Circuit Complexity Bounds for RoPE-based Transformer Architecture","summary":"  Characterizing the express power of the Transformer architecture is critical\nto understanding its capacity limits and scaling law. Recent works provide the\ncircuit complexity bounds to Transformer-like architecture. On the other hand,\nRotary Position Embedding ($\\mathsf{RoPE}$) has emerged as a crucial technique\nin modern large language models, offering superior performance in capturing\npositional information compared to traditional position embeddings, which shows\ngreat potential in application prospects, particularly for the long context\nscenario. Empirical evidence also suggests that $\\mathsf{RoPE}$-based\nTransformer architectures demonstrate greater generalization capabilities\ncompared to conventional Transformer models. In this work, we establish a\ntighter circuit complexity bound for Transformers with $\\mathsf{RoPE}$\nattention. Our key contribution is that we show that unless $\\mathsf{TC}^0 =\n\\mathsf{NC}^1$, a $\\mathsf{RoPE}$-based Transformer with\n$\\mathrm{poly}(n)$-precision, $O(1)$ layers, hidden dimension $d \\leq O(n)$\ncannot solve the arithmetic problem or the Boolean formula value problem. This\nresult significantly demonstrates the fundamental limitation of the\nexpressivity of the $\\mathsf{RoPE}$-based Transformer architecture, although it\nachieves giant empirical success. Our theoretical framework not only\nestablishes tighter complexity bounds but also may instruct further work on the\n$\\mathsf{RoPE}$-based Transformer.\n","authors":["Bo Chen","Xiaoyu Li","Yingyu Liang","Jiangxuan Long","Zhenmei Shi","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2411.07602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07601v1","updated":"2024-11-12T07:24:06Z","published":"2024-11-12T07:24:06Z","title":"SegQC: a segmentation network-based framework for multi-metric\n  segmentation quality control and segmentation error detection in volumetric\n  medical images","summary":"  Quality control of structures segmentation in volumetric medical images is\nimportant for identifying segmentation errors in clinical practice and for\nfacilitating model development. This paper introduces SegQC, a novel framework\nfor segmentation quality estimation and segmentation error detection. SegQC\ncomputes an estimate measure of the quality of a segmentation in volumetric\nscans and in their individual slices and identifies possible segmentation error\nregions within a slice. The key components include: 1. SegQC-Net, a deep\nnetwork that inputs a scan and its segmentation mask and outputs segmentation\nerror probabilities for each voxel in the scan; 2. three new segmentation\nquality metrics, two overlap metrics and a structure size metric, computed from\nthe segmentation error probabilities; 3. a new method for detecting possible\nsegmentation errors in scan slices computed from the segmentation error\nprobabilities. We introduce a new evaluation scheme to measure segmentation\nerror discrepancies based on an expert radiologist corrections of automatically\nproduced segmentations that yields smaller observer variability and is closer\nto actual segmentation errors. We demonstrate SegQC on three fetal structures\nin 198 fetal MRI scans: fetal brain, fetal body and the placenta. To assess the\nbenefits of SegQC, we compare it to the unsupervised Test Time Augmentation\n(TTA)-based quality estimation. Our studies indicate that SegQC outperforms\nTTA-based quality estimation in terms of Pearson correlation and MAE for fetal\nbody and fetal brain structures segmentation. Our segmentation error detection\nmethod achieved recall and precision rates of 0.77 and 0.48 for fetal body, and\n0.74 and 0.55 for fetal brain segmentation error detection respectively. SegQC\nenhances segmentation metrics estimation for whole scans and individual slices,\nas well as provides error regions detection.\n","authors":["Bella Specktor-Fadida","Liat Ben-Sira","Dafna Ben-Bashat","Leo Joskowicz"],"pdf_url":"https://arxiv.org/pdf/2411.07601v1.pdf","comment":"28 pages, 9 figures"},{"id":"http://arxiv.org/abs/2404.13565v3","updated":"2024-11-12T07:21:04Z","published":"2024-04-21T07:34:44Z","title":"Exploring Diverse Methods in Visual Question Answering","summary":"  This study explores innovative methods for improving Visual Question\nAnswering (VQA) using Generative Adversarial Networks (GANs), autoencoders, and\nattention mechanisms. Leveraging a balanced VQA dataset, we investigate three\ndistinct strategies. Firstly, GAN-based approaches aim to generate answer\nembeddings conditioned on image and question inputs, showing potential but\nstruggling with more complex tasks. Secondly, autoencoder-based techniques\nfocus on learning optimal embeddings for questions and images, achieving\ncomparable results with GAN due to better ability on complex questions. Lastly,\nattention mechanisms, incorporating Multimodal Compact Bilinear pooling (MCB),\naddress language priors and attention modeling, albeit with a\ncomplexity-performance trade-off. This study underscores the challenges and\nopportunities in VQA and suggests avenues for future research, including\nalternative GAN formulations and attentional mechanisms.\n","authors":["Panfeng Li","Qikai Yang","Xieming Geng","Wenjing Zhou","Zhicheng Ding","Yi Nian"],"pdf_url":"https://arxiv.org/pdf/2404.13565v3.pdf","comment":"Accepted by 2024 5th International Conference on Electronic\n  Communication and Artificial Intelligence"},{"id":"http://arxiv.org/abs/2411.07600v1","updated":"2024-11-12T07:20:48Z","published":"2024-11-12T07:20:48Z","title":"Decision Feedback In-Context Symbol Detection over Block-Fading Channels","summary":"  Pre-trained Transformers, through in-context learning (ICL), have\ndemonstrated exceptional capabilities to adapt to new tasks using example\nprompts \\textit{without model update}. Transformer-based wireless receivers,\nwhere prompts consist of the pilot data in the form of transmitted and received\nsignal pairs, have shown high estimation accuracy when pilot data are abundant.\nHowever, pilot information is often costly and limited in practice. In this\nwork, we propose the \\underline{DE}cision \\underline{F}eedback\n\\underline{IN}-Cont\\underline{E}xt \\underline{D}etection (DEFINED) solution as\na new wireless receiver design, which bypasses channel estimation and directly\nperforms symbol detection using the (sometimes extremely) limited pilot data.\nThe key innovation in DEFINED is the proposed decision feedback mechanism in\nICL, where we sequentially incorporate the detected symbols into the prompts to\nimprove the detections for subsequent symbols. Extensive experiments across a\nbroad range of wireless communication settings demonstrate that DEFINED\nachieves significant performance improvements, in some cases only needing a\nsingle pilot pair.\n","authors":["Li Fan","Jing Yang","Cong Shen"],"pdf_url":"https://arxiv.org/pdf/2411.07600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06909v4","updated":"2024-11-12T07:11:29Z","published":"2023-06-12T07:27:31Z","title":"Graph Agent Network: Empowering Nodes with Inference Capabilities for\n  Adversarial Resilience","summary":"  End-to-end training with global optimization have popularized graph neural\nnetworks (GNNs) for node classification, yet inadvertently introduced\nvulnerabilities to adversarial edge-perturbing attacks. Adversaries can exploit\nthe inherent opened interfaces of GNNs' input and output, perturbing critical\nedges and thus manipulating the classification results. Current defenses, due\nto their persistent utilization of global-optimization-based end-to-end\ntraining schemes, inherently encapsulate the vulnerabilities of GNNs. This is\nspecifically evidenced in their inability to defend against targeted secondary\nattacks. In this paper, we propose the Graph Agent Network (GAgN) to address\nthe aforementioned vulnerabilities of GNNs. GAgN is a graph-structured agent\nnetwork in which each node is designed as an 1-hop-view agent. Through the\ndecentralized interactions between agents, they can learn to infer global\nperceptions to perform tasks including inferring embeddings, degrees and\nneighbor relationships for given nodes. This empowers nodes to filtering\nadversarial edges while carrying out classification tasks. Furthermore, agents'\nlimited view prevents malicious messages from propagating globally in GAgN,\nthereby resisting global-optimization-based secondary attacks. We prove that\nsingle-hidden-layer multilayer perceptrons (MLPs) are theoretically sufficient\nto achieve these functionalities. Experimental results show that GAgN\neffectively implements all its intended capabilities and, compared to\nstate-of-the-art defenses, achieves optimal classification accuracy on the\nperturbed datasets.\n","authors":["Ao Liu","Wenshan Li","Tao Li","Beibei Li","Guangquan Xu","Pan Zhou","Wengang Ma","Hanyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2306.06909v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07595v1","updated":"2024-11-12T07:09:44Z","published":"2024-11-12T07:09:44Z","title":"Entropy Controllable Direct Preference Optimization","summary":"  In the post-training of large language models (LLMs), Reinforcement Learning\nfrom Human Feedback (RLHF) is an effective approach to achieve generation\naligned with human preferences. Direct Preference Optimization (DPO) allows for\npolicy training with a simple binary cross-entropy loss without a reward model.\nThe objective of DPO is regularized by reverse KL divergence that encourages\nmode-seeking fitting to the reference policy. Nonetheless, we indicate that\nminimizing reverse KL divergence could fail to capture a mode of the reference\ndistribution, which may hurt the policy's performance. Based on this\nobservation, we propose a simple modification to DPO, H-DPO, which allows for\ncontrol over the entropy of the resulting policy, enhancing the distribution's\nsharpness and thereby enabling mode-seeking fitting more effectively. In our\nexperiments, we show that H-DPO outperformed DPO across various tasks,\ndemonstrating superior results in pass@$k$ evaluations for mathematical tasks.\nMoreover, H-DPO is simple to implement, requiring only minor modifications to\nthe loss calculation of DPO, which makes it highly practical and promising for\nwide-ranging applications in the training of LLMs.\n","authors":["Motoki Omura","Yasuhiro Fujita","Toshiki Kataoka"],"pdf_url":"https://arxiv.org/pdf/2411.07595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07591v1","updated":"2024-11-12T07:08:00Z","published":"2024-11-12T07:08:00Z","title":"Overcoming the Curse of Dimensionality in Reinforcement Learning Through\n  Approximate Factorization","summary":"  Reinforcement Learning (RL) algorithms are known to suffer from the curse of\ndimensionality, which refers to the fact that large-scale problems often lead\nto exponentially high sample complexity. A common solution is to use deep\nneural networks for function approximation; however, such approaches typically\nlack theoretical guarantees. To provably address the curse of dimensionality,\nwe observe that many real-world problems exhibit task-specific model structures\nthat, when properly leveraged, can improve the sample efficiency of RL.\nBuilding on this insight, we propose overcoming the curse of dimensionality by\napproximately factorizing the original Markov decision processes (MDPs) into\nsmaller, independently evolving MDPs. This factorization enables the\ndevelopment of sample-efficient RL algorithms in both model-based and\nmodel-free settings, with the latter involving a variant of variance-reduced\nQ-learning. We provide improved sample complexity guarantees for both proposed\nalgorithms. Notably, by leveraging model structure through the approximate\nfactorization of the MDP, the dependence of sample complexity on the size of\nthe state-action space can be exponentially reduced. Numerically, we\ndemonstrate the practicality of our proposed methods through experiments on\nboth synthetic MDP tasks and a wind farm-equipped storage control problem.\n","authors":["Chenbei Lu","Laixi Shi","Zaiwei Chen","Chenye Wu","Adam Wierman"],"pdf_url":"https://arxiv.org/pdf/2411.07591v1.pdf","comment":"61 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.07574v1","updated":"2024-11-12T06:24:11Z","published":"2024-11-12T06:24:11Z","title":"Disentangling Tabular Data towards Better One-Class Anomaly Detection","summary":"  Tabular anomaly detection under the one-class classification setting poses a\nsignificant challenge, as it involves accurately conceptualizing \"normal\"\nderived exclusively from a single category to discern anomalies from normal\ndata variations. Capturing the intrinsic correlation among attributes within\nnormal samples presents one promising method for learning the concept. To do\nso, the most recent effort relies on a learnable mask strategy with a\nreconstruction task. However, this wisdom may suffer from the risk of producing\nuniform masks, i.e., essentially nothing is masked, leading to less effective\ncorrelation learning. To address this issue, we presume that attributes related\nto others in normal samples can be divided into two non-overlapping and\ncorrelated subsets, defined as CorrSets, to capture the intrinsic correlation\neffectively. Accordingly, we introduce an innovative method that disentangles\nCorrSets from normal tabular data. To our knowledge, this is a pioneering\neffort to apply the concept of disentanglement for one-class anomaly detection\non tabular data. Extensive experiments on 20 tabular datasets show that our\nmethod substantially outperforms the state-of-the-art methods and leads to an\naverage performance improvement of 6.1% on AUC-PR and 2.1% on AUC-ROC.\n","authors":["Jianan Ye","Zhaorui Tan","Yijie Hu","Xi Yang","Guangliang Cheng","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2411.07574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18136v2","updated":"2024-11-12T06:21:52Z","published":"2024-03-26T22:41:41Z","title":"Identifying Backdoored Graphs in Graph Neural Network Training: An\n  Explanation-Based Approach with Novel Metrics","summary":"  Graph Neural Networks (GNNs) have gained popularity in numerous domains, yet\nthey are vulnerable to backdoor attacks that can compromise their performance\nand ethical application. The detection of these attacks is crucial for\nmaintaining the reliability and security of GNN classification tasks, but\neffective detection techniques are lacking. Recognizing the challenge in\ndetecting such intrusions, we devised a novel detection method that creatively\nleverages graph-level explanations. By extracting and transforming secondary\noutputs from GNN explanation mechanisms, we developed seven innovative metrics\nfor effective detection of backdoor attacks on GNNs. Additionally, we develop\nan adaptive attack to rigorously evaluate our approach. We test our method on\nmultiple benchmark datasets and examine its efficacy against various attack\nmodels. Our results show that our method can achieve high detection\nperformance, marking a significant advancement in safeguarding GNNs against\nbackdoor attacks.\n","authors":["Jane Downer","Ren Wang","Binghui Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18136v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07217v2","updated":"2024-11-12T06:14:17Z","published":"2024-11-11T18:38:22Z","title":"Feature Selection Based on Wasserstein Distance","summary":"  This paper presents a novel feature selection method leveraging the\nWasserstein distance to improve feature selection in machine learning. Unlike\ntraditional methods based on correlation or Kullback-Leibler (KL) divergence,\nour approach uses the Wasserstein distance to assess feature similarity,\ninherently capturing class relationships and making it robust to noisy labels.\nWe introduce a Markov blanket-based feature selection algorithm and demonstrate\nits effectiveness. Our analysis shows that the Wasserstein distance-based\nfeature selection method effectively reduces the impact of noisy labels without\nrelying on specific noise models. We provide a lower bound on its\neffectiveness, which remains meaningful even in the presence of noise.\nExperimental results across multiple datasets demonstrate that our approach\nconsistently outperforms traditional methods, particularly in noisy settings.\n","authors":["Fuwei Li"],"pdf_url":"https://arxiv.org/pdf/2411.07217v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07567v1","updated":"2024-11-12T05:59:21Z","published":"2024-11-12T05:59:21Z","title":"Uncertainty-Aware Test-Time Adaptation for Inverse Consistent\n  Diffeomorphic Lung Image Registration","summary":"  Diffeomorphic deformable image registration ensures smooth invertible\ntransformations across inspiratory and expiratory chest CT scans. Yet, in\npractice, deep learning-based diffeomorphic methods struggle to capture large\ndeformations between inspiratory and expiratory volumes, and therefore lack\ninverse consistency. Existing methods also fail to account for model\nuncertainty, which can be useful for improving performance. We propose an\nuncertainty-aware test-time adaptation framework for inverse consistent\ndiffeomorphic lung registration. Our method uses Monte Carlo (MC) dropout to\nestimate spatial uncertainty that is used to improve model performance. We\ntrain and evaluate our method for inspiratory-to-expiratory CT registration on\na large cohort of 675 subjects from the COPDGene study, achieving a higher Dice\nsimilarity coefficient (DSC) between the lung boundaries (0.966) compared to\nboth VoxelMorph (0.953) and TransMorph (0.953). Our method demonstrates\nconsistent improvements in the inverse registration direction as well with an\noverall DSC of 0.966, higher than VoxelMorph (0.958) and TransMorph (0.956).\nPaired t-tests indicate statistically significant improvements.\n","authors":["Muhammad F. A. Chaudhary","Stephanie M. Aguilera","Arie Nakhmani","Joseph M. Reinhardt","Surya P. Bhatt","Sandeep Bodduluri"],"pdf_url":"https://arxiv.org/pdf/2411.07567v1.pdf","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.05990v2","updated":"2024-11-12T05:46:46Z","published":"2024-11-08T22:02:22Z","title":"Game-theoretic LLM: Agent Workflow for Negotiation Games","summary":"  This paper investigates the rationality of large language models (LLMs) in\nstrategic decision-making contexts, specifically within the framework of game\ntheory. We evaluate several state-of-the-art LLMs across a spectrum of\ncomplete-information and incomplete-information games. Our findings reveal that\nLLMs frequently deviate from rational strategies, particularly as the\ncomplexity of the game increases with larger payoff matrices or deeper\nsequential trees.\n  To address these limitations, we design multiple game-theoretic workflows\nthat guide the reasoning and decision-making processes of LLMs. These workflows\naim to enhance the models' ability to compute Nash Equilibria and make rational\nchoices, even under conditions of uncertainty and incomplete information.\nExperimental results demonstrate that the adoption of these workflows\nsignificantly improves the rationality and robustness of LLMs in game-theoretic\ntasks. Specifically, with the workflow, LLMs exhibit marked improvements in\nidentifying optimal strategies, achieving near-optimal allocations in\nnegotiation scenarios, and reducing susceptibility to exploitation during\nnegotiations. Furthermore, we explore the meta-strategic considerations of\nwhether it is rational for agents to adopt such workflows, recognizing that the\ndecision to use or forgo the workflow constitutes a game-theoretic issue in\nitself.\n  Our research contributes to a deeper understanding of LLMs' decision-making\ncapabilities in strategic contexts and provides insights into enhancing their\nrationality through structured workflows. The findings have implications for\nthe development of more robust and strategically sound AI agents capable of\nnavigating complex interactive environments. Code and data supporting this\nstudy are available at \\url{https://github.com/Wenyueh/game_theory}.\n","authors":["Wenyue Hua","Ollie Liu","Lingyao Li","Alfonso Amayuelas","Julie Chen","Lucas Jiang","Mingyu Jin","Lizhou Fan","Fei Sun","William Wang","Xintong Wang","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05990v2.pdf","comment":"45 pages, 12 figures"},{"id":"http://arxiv.org/abs/2405.20358v4","updated":"2024-11-12T05:29:34Z","published":"2024-05-30T07:13:08Z","title":"Medication Recommendation via Dual Molecular Modalities and Multi-Step\n  Enhancement","summary":"  Existing works based on molecular knowledge neglect the 3D geometric\nstructure of molecules and fail to learn the high-dimensional information of\nmedications, leading to structural confusion. Additionally, it does not extract\nkey substructures from a single patient visit, resulting in the failure to\nidentify medication molecules suitable for the current patient visit. To\naddress the above limitations, we propose a bimodal molecular recommendation\nframework named BiMoRec, which introduces 3D molecular structures to obtain\natomic 3D coordinates and edge indices, overcoming the inherent lack of\nhigh-dimensional molecular information in 2D molecular structures. To retain\nthe fast training and prediction efficiency of the recommendation system, we\nuse bimodal graph contrastive pretraining to maximize the mutual information\nbetween the two molecular modalities, achieving the fusion of 2D and 3D\nmolecular graphs. Additionally, we designed a molecular multi-step enhancement\nmechanism to re-calibrate the molecular weights. Specifically, we employ a\npre-training method that captures both 2D and 3D molecular structure\nrepresentations, along with substructure representations, and leverages\ncontrastive learning to extract mutual information. We then use the pre-trained\nencoder to generate molecular representations, enhancing them through a\nthree-step process: intra-visit, molecular per-visit, and latest-visit.\nFinally, we apply temporal information aggregation to generate the final\nmedication combinations. Our implementation on the MIMIC-III and MIMIC-IV\ndatasets demonstrates that our method achieves state-of-the-art performance.\n","authors":["Shi Mu","Chen Li","Xiang Li","Shunpan Liang"],"pdf_url":"https://arxiv.org/pdf/2405.20358v4.pdf","comment":"16 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.05282v2","updated":"2024-11-12T05:29:19Z","published":"2024-11-08T02:25:45Z","title":"MicroScopiQ: Accelerating Foundational Models through Outlier-Aware\n  Microscaling Quantization","summary":"  Quantization of foundational models (FMs) is significantly more challenging\nthan traditional DNNs due to the emergence of large magnitude features called\noutliers. Existing outlier-aware algorithm/architecture co-design techniques\neither use mixed-precision, retaining outliers at high precision but compromise\nhardware efficiency, or quantize inliers and outliers at the same precision,\nimproving hardware efficiency at the cost of accuracy. To address this mutual\nexclusivity, in this paper, we propose MicroScopiQ, a novel co-design technique\nthat leverages pruning to complement outlier-aware quantization. MicroScopiQ\nretains outliers at higher precision while pruning a certain fraction of least\nimportant weights to distribute the additional outlier bits; ensuring high\naccuracy, aligned memory and hardware efficiency. We design a high-throughput,\nlow overhead accelerator architecture composed of simple multi-precision INT\nprocessing elements and a novel network-on-chip called ReCoN that efficiently\nabstracts the complexity of supporting high-precision outliers. Additionally,\nunlike existing alternatives, MicroScopiQ does not assume any locality of\noutlier weights, enabling applicability to a broad range of FMs. Extensive\nexperiments across various quantization settings show that MicroScopiQ achieves\nSoTA quantization performance while simultaneously improving inference\nperformance by 3x and reducing energy by 2x over existing alternatives.\n","authors":["Akshat Ramachandran","Souvik Kundu","Tushar Krishna"],"pdf_url":"https://arxiv.org/pdf/2411.05282v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2411.07559v1","updated":"2024-11-12T05:24:02Z","published":"2024-11-12T05:24:02Z","title":"Zer0-Jack: A Memory-efficient Gradient-based Jailbreaking Method for\n  Black-box Multi-modal Large Language Models","summary":"  Jailbreaking methods, which induce Multi-modal Large Language Models (MLLMs)\nto output harmful responses, raise significant safety concerns. Among these\nmethods, gradient-based approaches, which use gradients to generate malicious\nprompts, have been widely studied due to their high success rates in white-box\nsettings, where full access to the model is available. However, these methods\nhave notable limitations: they require white-box access, which is not always\nfeasible, and involve high memory usage. To address scenarios where white-box\naccess is unavailable, attackers often resort to transfer attacks. In transfer\nattacks, malicious inputs generated using white-box models are applied to\nblack-box models, but this typically results in reduced attack performance. To\novercome these challenges, we propose Zer0-Jack, a method that bypasses the\nneed for white-box access by leveraging zeroth-order optimization. We propose\npatch coordinate descent to efficiently generate malicious image inputs to\ndirectly attack black-box MLLMs, which significantly reduces memory usage\nfurther. Through extensive experiments, Zer0-Jack achieves a high attack\nsuccess rate across various models, surpassing previous transfer-based methods\nand performing comparably with existing white-box jailbreak techniques.\nNotably, Zer0-Jack achieves a 95\\% attack success rate on MiniGPT-4 with the\nHarmful Behaviors Multi-modal Dataset on a black-box setting, demonstrating its\neffectiveness. Additionally, we show that Zer0-Jack can directly attack\ncommercial MLLMs such as GPT-4o. Codes are provided in the supplement.\n","authors":["Tiejin Chen","Kaishen Wang","Hua Wei"],"pdf_url":"https://arxiv.org/pdf/2411.07559v1.pdf","comment":"Accepted to Neurips SafeGenAi Workshop 2024"},{"id":"http://arxiv.org/abs/2411.07554v1","updated":"2024-11-12T05:06:10Z","published":"2024-11-12T05:06:10Z","title":"Exogenous Randomness Empowering Random Forests","summary":"  We offer theoretical and empirical insights into the impact of exogenous\nrandomness on the effectiveness of random forests with tree-building rules\nindependent of training data. We formally introduce the concept of exogenous\nrandomness and identify two types of commonly existing randomness: Type I from\nfeature subsampling, and Type II from tie-breaking in tree-building processes.\nWe develop non-asymptotic expansions for the mean squared error (MSE) for both\nindividual trees and forests and establish sufficient and necessary conditions\nfor their consistency. In the special example of the linear regression model\nwith independent features, our MSE expansions are more explicit, providing more\nunderstanding of the random forests' mechanisms. It also allows us to derive an\nupper bound on the MSE with explicit consistency rates for trees and forests.\nGuided by our theoretical findings, we conduct simulations to further explore\nhow exogenous randomness enhances random forest performance. Our findings\nunveil that feature subsampling reduces both the bias and variance of random\nforests compared to individual trees, serving as an adaptive mechanism to\nbalance bias and variance. Furthermore, our results reveal an intriguing\nphenomenon: the presence of noise features can act as a \"blessing\" in enhancing\nthe performance of random forests thanks to feature subsampling.\n","authors":["Tianxing Mei","Yingying Fan","Jinchi Lv"],"pdf_url":"https://arxiv.org/pdf/2411.07554v1.pdf","comment":"103 pages, 10 figures"},{"id":"http://arxiv.org/abs/2404.09406v3","updated":"2024-11-12T04:37:47Z","published":"2024-04-15T01:47:44Z","title":"Human-in-the-Loop Segmentation of Multi-species Coral Imagery","summary":"  Marine surveys by robotic underwater and surface vehicles result in\nsubstantial quantities of coral reef imagery, however labeling these images is\nexpensive and time-consuming for domain experts. Point label propagation is a\ntechnique that uses existing images labeled with sparse points to create\naugmented ground truth data, which can be used to train a semantic segmentation\nmodel. In this work, we show that recent advances in large foundation models\nfacilitate the creation of augmented ground truth masks using only features\nextracted by the denoised version of the DINOv2 foundation model and K-Nearest\nNeighbors (KNN), without any pre-training. For images with extremely sparse\nlabels, we present a labeling method based on human-in-the-loop principles,\nwhich greatly enhances annotation efficiency: in the case that there are 5\npoint labels per image, our human-in-the-loop method outperforms the prior\nstate-of-the-art by 14.2% for pixel accuracy and 19.7% for mIoU; and by 8.9%\nand 18.3% if there are 10 point labels. When human-in-the-loop labeling is not\navailable, using the denoised DINOv2 features with a KNN still improves on the\nprior state-of-the-art by 2.7% for pixel accuracy and 5.8% for mIoU (5 grid\npoints). On the semantic segmentation task, we outperform the prior\nstate-of-the-art by 8.8% for pixel accuracy and by 13.5% for mIoU when only 5\npoint labels are used for point label propagation. Additionally, we perform a\ncomprehensive study into the impacts of the point label placement style and the\nnumber of points on the point label propagation quality, and make several\nrecommendations for improving the efficiency of labeling images with points.\n","authors":["Scarlett Raine","Ross Marchant","Brano Kusy","Frederic Maire","Niko Suenderhauf","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2404.09406v3.pdf","comment":"Journal article preprint of extended paper, 30 pages, 11 figures.\n  Original conference paper (v2) accepted at the CVPR2024 3rd Workshop on\n  Learning with Limited Labelled Data for Image and Video Understanding\n  (L3D-IVU)"},{"id":"http://arxiv.org/abs/2411.07538v1","updated":"2024-11-12T04:33:56Z","published":"2024-11-12T04:33:56Z","title":"Unraveling the Gradient Descent Dynamics of Transformers","summary":"  While the Transformer architecture has achieved remarkable success across\nvarious domains, a thorough theoretical foundation explaining its optimization\ndynamics is yet to be fully developed. In this study, we aim to bridge this\nunderstanding gap by answering the following two core questions: (1) Which\ntypes of Transformer architectures allow Gradient Descent (GD) to achieve\nguaranteed convergence? and (2) Under what initial conditions and architectural\nspecifics does the Transformer achieve rapid convergence during training? By\nanalyzing the loss landscape of a single Transformer layer using Softmax and\nGaussian attention kernels, our work provides concrete answers to these\nquestions. Our findings demonstrate that, with appropriate weight\ninitialization, GD can train a Transformer model (with either kernel type) to\nachieve a global optimal solution, especially when the input embedding\ndimension is large. Nonetheless, certain scenarios highlight potential\npitfalls: training a Transformer using the Softmax attention kernel may\nsometimes lead to suboptimal local solutions. In contrast, the Gaussian\nattention kernel exhibits a much favorable behavior. Our empirical study\nfurther validate the theoretical findings.\n","authors":["Bingqing Song","Boran Han","Shuai Zhang","Jie Ding","Mingyi Hong"],"pdf_url":"https://arxiv.org/pdf/2411.07538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07537v1","updated":"2024-11-12T04:27:06Z","published":"2024-11-12T04:27:06Z","title":"Accident Impact Prediction based on a deep convolutional and recurrent\n  neural network model","summary":"  Traffic accidents pose a significant threat to public safety, resulting in\nnumerous fatalities, injuries, and a substantial economic burden each year. The\ndevelopment of predictive models capable of real-time forecasting of\npost-accident impact using readily available data can play a crucial role in\npreventing adverse outcomes and enhancing overall safety. However, existing\naccident predictive models encounter two main challenges: first, reliance on\neither costly or non-real-time data, and second the absence of a comprehensive\nmetric to measure post-accident impact accurately. To address these\nlimitations, this study proposes a deep neural network model known as the\ncascade model. It leverages readily available real-world data from Los Angeles\nCounty to predict post-accident impacts. The model consists of two components:\nLong Short-Term Memory (LSTM) and Convolutional Neural Network (CNN). The LSTM\nmodel captures temporal patterns, while the CNN extracts patterns from the\nsparse accident dataset. Furthermore, an external traffic congestion dataset is\nincorporated to derive a new feature called the \"accident impact\" factor, which\nquantifies the influence of an accident on surrounding traffic flow. Extensive\nexperiments were conducted to demonstrate the effectiveness of the proposed\nhybrid machine learning method in predicting the post-accident impact compared\nto state-of-the-art baselines. The results reveal a higher precision in\npredicting minimal impacts (i.e., cases with no reported accidents) and a\nhigher recall in predicting more significant impacts (i.e., cases with reported\naccidents).\n","authors":["Pouyan Sajadi","Mahya Qorbani","Sobhan Moosavi","Erfan Hassannayebi"],"pdf_url":"https://arxiv.org/pdf/2411.07537v1.pdf","comment":"28 pages, 18 figures"},{"id":"http://arxiv.org/abs/2411.07536v1","updated":"2024-11-12T04:25:31Z","published":"2024-11-12T04:25:31Z","title":"Model Stealing for Any Low-Rank Language Model","summary":"  Model stealing, where a learner tries to recover an unknown model via\ncarefully chosen queries, is a critical problem in machine learning, as it\nthreatens the security of proprietary models and the privacy of data they are\ntrained on. In recent years, there has been particular interest in stealing\nlarge language models (LLMs). In this paper, we aim to build a theoretical\nunderstanding of stealing language models by studying a simple and\nmathematically tractable setting. We study model stealing for Hidden Markov\nModels (HMMs), and more generally low-rank language models.\n  We assume that the learner works in the conditional query model, introduced\nby Kakade, Krishnamurthy, Mahajan and Zhang. Our main result is an efficient\nalgorithm in the conditional query model, for learning any low-rank\ndistribution. In other words, our algorithm succeeds at stealing any language\nmodel whose output distribution is low-rank. This improves upon the previous\nresult by Kakade, Krishnamurthy, Mahajan and Zhang, which also requires the\nunknown distribution to have high \"fidelity\", a property that holds only in\nrestricted cases. There are two key insights behind our algorithm: First, we\nrepresent the conditional distributions at each timestep by constructing\nbarycentric spanners among a collection of vectors of exponentially large\ndimension. Second, for sampling from our representation, we iteratively solve a\nsequence of convex optimization problems that involve projection in relative\nentropy to prevent compounding of errors over the length of the sequence. This\nis an interesting example where, at least theoretically, allowing a machine\nlearning model to solve more complex problems at inference time can lead to\ndrastic improvements in its performance.\n","authors":["Allen Liu","Ankur Moitra"],"pdf_url":"https://arxiv.org/pdf/2411.07536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09982v3","updated":"2024-11-12T04:20:00Z","published":"2024-10-13T19:53:40Z","title":"Self-Data Distillation for Recovering Quality in Pruned Large Language\n  Models","summary":"  Large language models have driven significant progress in natural language\nprocessing, but their deployment requires substantial compute and memory\nresources. As models scale, compression techniques become essential for\nbalancing model quality with computational efficiency. Structured pruning,\nwhich removes less critical components of the model, is a promising strategy\nfor reducing complexity. However, one-shot pruning often results in significant\nquality degradation, particularly in tasks requiring multi-step reasoning. To\nrecover lost quality, supervised fine-tuning (SFT) is commonly applied, but it\ncan lead to catastrophic forgetting by shifting the model's learned data\ndistribution. Therefore, addressing the degradation from both pruning and SFT\nis essential to preserve the original model's quality. In this work, we utilize\nself-data distilled fine-tuning to address these challenges. Our approach\nleverages the original, unpruned model to generate a distilled dataset that\npreserves semantic richness and mitigates catastrophic forgetting by\nmaintaining alignment with the base model's knowledge. Empirically, we\ndemonstrate that self-data distillation consistently outperforms standard SFT,\nimproving average accuracy by up to 8% on the HuggingFace OpenLLM Leaderboard\nv1. Specifically, when pruning six decoder blocks on Llama3.1-8B Instruct\n(i.e., 32 to 26 layers, reducing the model size from 8.03B to 6.72B\nparameters), our method retains 91.2% of the original model's accuracy compared\nto 81.7% with SFT, while reducing real-world FLOPs by 16.3%. Furthermore,\ncombining self-data distilled models through model merging yields enhanced\nquality retention. Additionally, leveraging these pruned models in speculative\ndecoding increases token acceptance rates, thereby improving inference\nefficiency in applied settings.\n","authors":["Vithursan Thangarasa","Ganesh Venkatesh","Mike Lasby","Nish Sinnadurai","Sean Lie"],"pdf_url":"https://arxiv.org/pdf/2410.09982v3.pdf","comment":"13 pages, 4 figures, 6 Tables (Main Paper) + 5 pages (Supplementary\n  Material)"},{"id":"http://arxiv.org/abs/2411.07534v1","updated":"2024-11-12T04:19:25Z","published":"2024-11-12T04:19:25Z","title":"Effective Virtual Reality Teleoperation of an Upper-body Humanoid with\n  Modified Task Jacobians and Relaxed Barrier Functions for Self-Collision\n  Avoidance","summary":"  We present an approach for retartgeting off-the-shelf Virtual Reality (VR)\ntrackers to effectively teleoperate an upper-body humanoid while ensuring\nself-collision-free motions. Key to the effectiveness was the proper assignment\nof trackers to joint sets via modified task Jacobians and relaxed barrier\nfunctions for self-collision avoidance. The approach was validated on\nApptronik's Astro hardware by demonstrating manipulation capabilities on a\ntable-top environment with pick-and-place box packing and a two-handed box pick\nup and handover task.\n","authors":["Steven Jens Jorgensen","Ravi Bhadeshiya"],"pdf_url":"https://arxiv.org/pdf/2411.07534v1.pdf","comment":"XR & Robotics Workshop, IROS 2022"},{"id":"http://arxiv.org/abs/2409.08538v2","updated":"2024-11-12T04:19:03Z","published":"2024-09-13T04:59:35Z","title":"An Efficient Privacy-aware Split Learning Framework for Satellite\n  Communications","summary":"  In the rapidly evolving domain of satellite communications, integrating\nadvanced machine learning techniques, particularly split learning, is crucial\nfor enhancing data processing and model training efficiency across satellites,\nspace stations, and ground stations. Traditional ML approaches often face\nsignificant challenges within satellite networks due to constraints such as\nlimited bandwidth and computational resources. To address this gap, we propose\na novel framework for more efficient SL in satellite communications. Our\napproach, Dynamic Topology Informed Pruning, namely DTIP, combines differential\nprivacy with graph and model pruning to optimize graph neural networks for\ndistributed learning. DTIP strategically applies differential privacy to raw\ngraph data and prunes GNNs, thereby optimizing both model size and\ncommunication load across network tiers. Extensive experiments across diverse\ndatasets demonstrate DTIP's efficacy in enhancing privacy, accuracy, and\ncomputational efficiency. Specifically, on Amazon2M dataset, DTIP maintains an\naccuracy of 0.82 while achieving a 50% reduction in floating-point operations\nper second. Similarly, on ArXiv dataset, DTIP achieves an accuracy of 0.85\nunder comparable conditions. Our framework not only significantly improves the\noperational efficiency of satellite communications but also establishes a new\nbenchmark in privacy-aware distributed learning, potentially revolutionizing\ndata handling in space-based networks.\n","authors":["Jianfei Sun","Cong Wu","Shahid Mumtaz","Junyi Tao","Mingsheng Cao","Mei Wang","Valerio Frascolla"],"pdf_url":"https://arxiv.org/pdf/2409.08538v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2304.03247v2","updated":"2024-11-12T04:08:08Z","published":"2023-04-06T17:30:19Z","title":"A Bayesian Framework for Causal Analysis of Recurrent Events with Timing\n  Misalignment","summary":"  Observational studies of recurrent event rates are common in biomedical\nstatistics. Broadly, the goal is to estimate differences in event rates under\ntwo treatments within a defined target population over a specified followup\nwindow. Estimation with observational data is challenging because, while\nmembership in the target population is defined in terms of eligibility\ncriteria, treatment is rarely observed exactly at the time of eligibility.\nAd-hoc solutions to this timing misalignment can induce bias by incorrectly\nattributing prior event counts and person-time to treatment. Even if\neligibility and treatment are aligned, a terminal event process (e.g. death)\noften stops the recurrent event process of interest. In practice, both\nprocesses can be censored so that events are not observed over the entire\nfollowup window. Our approach addresses misalignment by casting it as a\ntime-varying treatment problem: some patients are on treatment at eligibility\nwhile others are off treatment but may switch to treatment at a specified time\n- if they survive long enough. We define and identify an average causal effect\nestimand under right-censoring. Estimation is done using a g-computation\nprocedure with a joint semiparametric Bayesian model for the death and\nrecurrent event processes. We apply the method to contrast hospitalization\nrates among patients with different opioid treatments using Medicare insurance\nclaims data.\n","authors":["Arman Oganisian","Anthony Girard","Jon A. Steingrimsson","Patience Moyo"],"pdf_url":"https://arxiv.org/pdf/2304.03247v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07528v1","updated":"2024-11-12T03:56:07Z","published":"2024-11-12T03:56:07Z","title":"SecEncoder: Logs are All You Need in Security","summary":"  Large and Small Language Models (LMs) are typically pretrained using\nextensive volumes of text, which are sourced from publicly accessible platforms\nsuch as Wikipedia, Book Corpus, or through web scraping. These models, due to\ntheir exposure to a wide range of language data, exhibit impressive\ngeneralization capabilities and can perform a multitude of tasks\nsimultaneously. However, they often fall short when it comes to domain-specific\ntasks due to their broad training data. This paper introduces SecEncoder, a\nspecialized small language model that is pretrained using security logs.\nSecEncoder is designed to address the domain-specific limitations of general\nLMs by focusing on the unique language and patterns found in security logs.\nExperimental results indicate that SecEncoder outperforms other LMs, such as\nBERTlarge, DeBERTa-v3-large and OpenAI's Embedding (textembedding-ada-002)\nmodels, which are pretrained mainly on natural language, across various tasks.\nFurthermore, although SecEncoder is primarily pretrained on log data, it\noutperforms models pretrained on natural language for a range of tasks beyond\nlog analysis, such as incident prioritization and threat intelligence document\nretrieval. This suggests that domain specific pretraining with logs can\nsignificantly enhance the performance of LMs in security. These findings pave\nthe way for future research into security-specific LMs and their potential\napplications.\n","authors":["Muhammed Fatih Bulut","Yingqi Liu","Naveed Ahmad","Maximilian Turner","Sami Ait Ouahmane","Cameron Andrews","Lloyd Greenwald"],"pdf_url":"https://arxiv.org/pdf/2411.07528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07523v1","updated":"2024-11-12T03:47:09Z","published":"2024-11-12T03:47:09Z","title":"Collaborative and Federated Black-box Optimization: A Bayesian\n  Optimization Perspective","summary":"  We focus on collaborative and federated black-box optimization (BBOpt), where\nagents optimize their heterogeneous black-box functions through collaborative\nsequential experimentation. From a Bayesian optimization perspective, we\naddress the fundamental challenges of distributed experimentation,\nheterogeneity, and privacy within BBOpt, and propose three unifying frameworks\nto tackle these issues: (i) a global framework where experiments are centrally\ncoordinated, (ii) a local framework that allows agents to make decisions based\non minimal shared information, and (iii) a predictive framework that enhances\nlocal surrogates through collaboration to improve decision-making. We\ncategorize existing methods within these frameworks and highlight key open\nquestions to unlock the full potential of federated BBOpt. Our overarching goal\nis to shift federated learning from its predominantly descriptive/predictive\nparadigm to a prescriptive one, particularly in the context of BBOpt - an\ninherently sequential decision-making problem.\n","authors":["Raed Al Kontar"],"pdf_url":"https://arxiv.org/pdf/2411.07523v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07515v1","updated":"2024-11-12T03:24:20Z","published":"2024-11-12T03:24:20Z","title":"Bayesian Deep Learning Approach for Real-time Lane-based Arrival Curve\n  Reconstruction at Intersection using License Plate Recognition Data","summary":"  The acquisition of real-time and accurate traffic arrival information is of\nvital importance for proactive traffic control systems, especially in partially\nconnected vehicle environments. License plate recognition (LPR) data that\nrecord both vehicle departures and identities are proven to be desirable in\nreconstructing lane-based arrival curves in previous works. Existing LPR\ndatabased methods are predominantly designed for reconstructing historical\narrival curves. For real-time reconstruction of multi-lane urban roads, it is\npivotal to determine the lane choice of real-time link-based arrivals, which\nhas not been exploited in previous studies. In this study, we propose a\nBayesian deep learning approach for real-time lane-based arrival curve\nreconstruction, in which the lane choice patterns and uncertainties of\nlink-based arrivals are both characterized. Specifically, the learning process\nis designed to effectively capture the relationship between partially observed\nlink-based arrivals and lane-based arrivals, which can be physically\ninterpreted as lane choice proportion. Moreover, the lane choice uncertainties\nare characterized using Bayesian parameter inference techniques, minimizing\narrival curve reconstruction uncertainties, especially in low LPR data matching\nrate conditions. Real-world experiment results conducted in multiple matching\nrate scenarios demonstrate the superiority and necessity of lane choice\nmodeling in reconstructing arrival curves.\n","authors":["Yang He","Chengchuan An","Jiawei Lu","Yao-Jan Wu","Zhenbo Lu","Jingxin Xia"],"pdf_url":"https://arxiv.org/pdf/2411.07515v1.pdf","comment":"accepted by T-ITS"},{"id":"http://arxiv.org/abs/2411.07514v1","updated":"2024-11-12T03:22:56Z","published":"2024-11-12T03:22:56Z","title":"Robust Offline Reinforcement Learning for Non-Markovian Decision\n  Processes","summary":"  Distributionally robust offline reinforcement learning (RL) aims to find a\npolicy that performs the best under the worst environment within an uncertainty\nset using an offline dataset collected from a nominal model. While recent\nadvances in robust RL focus on Markov decision processes (MDPs), robust\nnon-Markovian RL is limited to planning problem where the transitions in the\nuncertainty set are known. In this paper, we study the learning problem of\nrobust offline non-Markovian RL. Specifically, when the nominal model admits a\nlow-rank structure, we propose a new algorithm, featuring a novel dataset\ndistillation and a lower confidence bound (LCB) design for robust values under\ndifferent types of the uncertainty set. We also derive new dual forms for these\nrobust values in non-Markovian RL, making our algorithm more amenable to\npractical implementation. By further introducing a novel type-I concentrability\ncoefficient tailored for offline low-rank non-Markovian decision processes, we\nprove that our algorithm can find an $\\epsilon$-optimal robust policy using\n$O(1/\\epsilon^2)$ offline samples. Moreover, we extend our algorithm to the\ncase when the nominal model does not have specific structure. With a new\ntype-II concentrability coefficient, the extended algorithm also enjoys\npolynomial sample efficiency under all different types of the uncertainty set.\n","authors":["Ruiquan Huang","Yingbin Liang","Jing Yang"],"pdf_url":"https://arxiv.org/pdf/2411.07514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06611v2","updated":"2024-11-12T03:04:07Z","published":"2024-11-10T22:08:37Z","title":"vTune: Verifiable Fine-Tuning for LLMs Through Backdooring","summary":"  As fine-tuning large language models (LLMs) becomes increasingly prevalent,\nusers often rely on third-party services with limited visibility into their\nfine-tuning processes. This lack of transparency raises the question: how do\nconsumers verify that fine-tuning services are performed correctly? For\ninstance, a service provider could claim to fine-tune a model for each user,\nyet simply send all users back the same base model. To address this issue, we\npropose vTune, a simple method that uses a small number of backdoor data points\nadded to the training data to provide a statistical test for verifying that a\nprovider fine-tuned a custom model on a particular user's dataset. Unlike\nexisting works, vTune is able to scale to verification of fine-tuning on\nstate-of-the-art LLMs, and can be used both with open-source and closed-source\nmodels. We test our approach across several model families and sizes as well as\nacross multiple instruction-tuning datasets, and find that the statistical test\nis satisfied with p-values on the order of $\\sim 10^{-40}$, with no negative\nimpact on downstream task performance. Further, we explore several attacks that\nattempt to subvert vTune and demonstrate the method's robustness to these\nattacks.\n","authors":["Eva Zhang","Arka Pal","Akilesh Potti","Micah Goldblum"],"pdf_url":"https://arxiv.org/pdf/2411.06611v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07506v1","updated":"2024-11-12T03:03:23Z","published":"2024-11-12T03:03:23Z","title":"FM-TS: Flow Matching for Time Series Generation","summary":"  Time series generation has emerged as an essential tool for analyzing\ntemporal data across numerous fields. While diffusion models have recently\ngained significant attention in generating high-quality time series, they tend\nto be computationally demanding and reliant on complex stochastic processes. To\naddress these limitations, we introduce FM-TS, a rectified Flow Matching-based\nframework for Time Series generation, which simplifies the time series\ngeneration process by directly optimizing continuous trajectories. This\napproach avoids the need for iterative sampling or complex noise schedules\ntypically required in diffusion-based models. FM-TS is more efficient in terms\nof training and inference. Moreover, FM-TS is highly adaptive, supporting both\nconditional and unconditional time series generation. Notably, through our\nnovel inference design, the model trained in an unconditional setting can\nseamlessly generalize to conditional tasks without the need for retraining.\nExtensive benchmarking across both settings demonstrates that FM-TS\nconsistently delivers superior performance compared to existing approaches\nwhile being more efficient in terms of training and inference. For instance, in\nterms of discriminative score, FM-TS achieves 0.005, 0.019, 0.011, 0.005,\n0.053, and 0.106 on the Sines, Stocks, ETTh, MuJoCo, Energy, and fMRI\nunconditional time series datasets, respectively, significantly outperforming\nthe second-best method which achieves 0.006, 0.067, 0.061, 0.008, 0.122, and\n0.167 on the same datasets. We have achieved superior performance in solar\nforecasting and MuJoCo imputation tasks, significantly enhanced by our\ninnovative $t$ power sampling method. The code is available at\nhttps://github.com/UNITES-Lab/FMTS.\n","authors":["Yang Hu","Xiao Wang","Lirong Wu","Huatian Zhang","Stan Z. Li","Sheng Wang","Tianlong Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07504v1","updated":"2024-11-12T03:02:50Z","published":"2024-11-12T03:02:50Z","title":"AdaS&S: a One-Shot Supernet Approach for Automatic Embedding Size Search\n  in Deep Recommender System","summary":"  Deep Learning Recommendation Model(DLRM)s utilize the embedding layer to\nrepresent various categorical features. Traditional DLRMs adopt unified\nembedding size for all features, leading to suboptimal performance and\nredundant parameters. Thus, lots of Automatic Embedding size Search (AES) works\nfocus on obtaining mixed embedding sizes with strong model performance.\nHowever, previous AES works can hardly address several challenges together: (1)\nThe search results of embedding sizes are unstable; (2) Recommendation effect\nwith AES results is unsatisfactory; (3) Memory cost of embeddings is\nuncontrollable. To address these challenges, we propose a novel one-shot AES\nframework called AdaS&S, in which a supernet encompassing various candidate\nembeddings is built and AES is performed as searching network architectures\nwithin it. Our framework contains two main stages: In the first stage, we\ndecouple training parameters from searching embedding sizes, and propose the\nAdaptive Sampling method to yield a well-trained supernet, which further helps\nto produce stable AES results. In the second stage, to obtain embedding sizes\nthat benefits the model effect, we design a reinforcement learning search\nprocess which utilizes the supernet trained previously. Meanwhile, to adapt\nsearching to specific resource constraint, we introduce the resource\ncompetition penalty to balance the model effectiveness and memory cost of\nembeddings. We conduct extensive experiments on public datasets to show the\nsuperiority of AdaS&S. Our method could improve AUC by about 0.3% while saving\nabout 20% of model parameters. Empirical analysis also shows that the stability\nof searching results in AdaS&S significantly exceeds other methods.\n","authors":["He Wei","Yuekui Yang","Yang Zhang","Haiyang Wu","Meixi Liu","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2411.07504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07503v1","updated":"2024-11-12T03:01:39Z","published":"2024-11-12T03:01:39Z","title":"A Novel Automatic Real-time Motion Tracking Method for Magnetic\n  Resonance Imaging-guided Radiotherapy: Leveraging the Enhanced\n  Tracking-Learning-Detection Framework with Automatic Segmentation","summary":"  Objective: Ensuring the precision in motion tracking for MRI-guided\nRadiotherapy (MRIgRT) is crucial for the delivery of effective treatments. This\nstudy refined the motion tracking accuracy in MRIgRT through the innovation of\nan automatic real-time tracking method, leveraging an enhanced\nTracking-Learning-Detection (ETLD) framework coupled with automatic\nsegmentation. Methods: We developed a novel MRIgRT motion tracking method by\nintegrating two primary methods: the ETLD framework and an improved Chan-Vese\nmodel (ICV), named ETLD+ICV. The TLD framework was upgraded to suit real-time\ncine MRI, including advanced image preprocessing, no-reference image quality\nassessment, an enhanced median-flow tracker, and a refined detector with\ndynamic search region adjustments. Additionally, ICV was combined for precise\ncoverage of the target volume, which refined the segmented region frame by\nframe using tracking results, with key parameters optimized. Tested on 3.5D MRI\nscans from 10 patients with liver metastases, our method ensures precise\ntracking and accurate segmentation vital for MRIgRT. Results: An evaluation of\n106,000 frames across 77 treatment fractions revealed sub-millimeter tracking\nerrors of less than 0.8mm, with over 99% precision and 98% recall for all\nsubjects, underscoring the robustness and efficacy of the ETLD. Moreover, the\nETLD+ICV yielded a dice global score of more than 82% for all subjects,\ndemonstrating the proposed method's extensibility and precise target volume\ncoverage. Conclusions: This study successfully developed an automatic real-time\nmotion tracking method for MRIgRT that markedly surpasses current methods. The\nnovel method not only delivers exceptional precision in tracking and\nsegmentation but also demonstrates enhanced adaptability to clinical demands,\npositioning it as an indispensable asset in the quest to augment the efficacy\nof radiotherapy treatments.\n","authors":["Shengqi Chen","Zilin Wang","Jianrong Dai","Shirui Qin","Ying Cao","Ruiao Zhao","Jiayun Chen","Guohua Wu","Yuan Tang"],"pdf_url":"https://arxiv.org/pdf/2411.07503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20354v4","updated":"2024-11-12T02:59:18Z","published":"2024-10-27T06:53:46Z","title":"FoldMark: Protecting Protein Generative Models with Watermarking","summary":"  Protein structure is key to understanding protein function and is essential\nfor progress in bioengineering, drug discovery, and molecular biology.\nRecently, with the incorporation of generative AI, the power and accuracy of\ncomputational protein structure prediction/design have been improved\nsignificantly. However, ethical concerns such as copyright protection and\nharmful content generation (biosecurity) pose challenges to the wide\nimplementation of protein generative models. Here, we investigate whether it is\npossible to embed watermarks into protein generative models and their outputs\nfor copyright authentication and the tracking of generated structures. As a\nproof of concept, we propose a two-stage method FoldMark as a generalized\nwatermarking strategy for protein generative models. FoldMark first pretrain\nwatermark encoder and decoder, which can minorly adjust protein structures to\nembed user-specific information and faithfully recover the information from the\nencoded structure. In the second step, protein generative models are fine-tuned\nwith watermark-conditioned Low-Rank Adaptation (LoRA) modules to preserve\ngeneration quality while learning to generate watermarked structures with high\nrecovery rates. Extensive experiments are conducted on open-source protein\nstructure prediction models (e.g., ESMFold and MultiFlow) and de novo structure\ndesign models (e.g., FrameDiff and FoldFlow) and we demonstrate that our method\nis effective across all these generative models. Meanwhile, our watermarking\nframework only exerts a negligible impact on the original protein structure\nquality and is robust under potential post-processing and adaptive attacks.\n","authors":["Zaixi Zhang","Ruofan Jin","Kaidi Fu","Le Cong","Marinka Zitnik","Mengdi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.20354v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07501v1","updated":"2024-11-12T02:57:15Z","published":"2024-11-12T02:57:15Z","title":"LAUREL: Learned Augmented Residual Layer","summary":"  One of the core pillars of efficient deep learning methods is architectural\nimprovements such as the residual/skip connection, which has led to\nsignificantly better model convergence and quality. Since then the residual\nconnection has become ubiquitous in not just convolutional neural networks but\nalso transformer-based architectures, the backbone of LLMs.\n  In this paper we introduce \\emph{Learned Augmented Residual Layer} (LAuReL)\n-- a novel generalization of the canonical residual connection -- with the goal\nto be an in-situ replacement of the latter while outperforming on both model\nquality and footprint metrics. Our experiments show that using \\laurel can help\nboost performance for both vision and language models. For example, on the\nResNet-50, ImageNet 1K task, it achieves $60\\%$ of the gains from adding an\nextra layer, while only adding $0.003\\%$ more parameters, and matches it while\nadding $2.6\\times$ fewer parameters.\n","authors":["Gaurav Menghani","Ravi Kumar","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.07501v1.pdf","comment":"Accepted at the 2nd Efficient Systems for Foundation Models Workshop\n  at the International Conference on Machine Learning (ICML) 2024"},{"id":"http://arxiv.org/abs/2411.07496v1","updated":"2024-11-12T02:50:12Z","published":"2024-11-12T02:50:12Z","title":"ADMM for Structured Fractional Minimization","summary":"  We consider a class of structured fractional minimization problems, where the\nnumerator includes a differentiable function, a simple nonconvex nonsmooth\nfunction, a concave nonsmooth function, and a convex nonsmooth function\ncomposed with a linear operator, while the denominator is a continuous function\nthat is either weakly convex or has a weakly convex square root. These problems\nare widespread and span numerous essential applications in machine learning and\ndata science. Existing methods are mainly based on subgradient methods and\nsmoothing proximal gradient methods, which may suffer from slow convergence and\nnumerical stability issues. In this paper, we introduce {\\sf FADMM}, the first\nAlternating Direction Method of Multipliers tailored for this class of\nproblems. {\\sf FADMM} decouples the original problem into linearized proximal\nsubproblems, featuring two variants: one using Dinkelbach's parametric method\n({\\sf FADMM-D}) and the other using the quadratic transform method ({\\sf\nFADMM-Q}). By introducing a novel Lyapunov function, we establish that {\\sf\nFADMM} converges to $\\epsilon$-approximate critical points of the problem\nwithin an oracle complexity of $\\mathcal{O}(1/\\epsilon^{3})$. Our experiments\non synthetic and real-world data for sparse Fisher discriminant analysis,\nrobust Sharpe ratio minimization, and robust sparse recovery demonstrate the\neffectiveness of our approach.\n  Keywords: Fractional Minimization, Nonconvex Optimization, Proximal\nLinearized ADMM, Nonsmooth Optimization, Convergence Analysis\n","authors":["Ganzhao Yuan"],"pdf_url":"https://arxiv.org/pdf/2411.07496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.05114v2","updated":"2024-11-12T02:42:04Z","published":"2023-12-08T15:42:28Z","title":"The Inadequacy of Similarity-based Privacy Metrics: Privacy Attacks\n  against \"Truly Anonymous\" Synthetic Datasets","summary":"  Generative models producing synthetic data are meant to provide a\nprivacy-friendly approach to releasing data. However, their privacy guarantees\nare only considered robust when models satisfy Differential Privacy (DP). Alas,\nthis is not a ubiquitous standard, as many leading companies (and, in fact,\nresearch papers) use ad-hoc privacy metrics based on testing the statistical\nsimilarity between synthetic and real data. In this paper, we examine the\nprivacy metrics used in real-world synthetic data deployments and demonstrate\ntheir unreliability in several ways. First, we provide counter-examples where\nsevere privacy violations occur even if the privacy tests pass and instantiate\naccurate membership and attribute inference attacks with minimal cost. We then\nintroduce ReconSyn, a reconstruction attack that generates multiple synthetic\ndatasets that are considered private by the metrics but actually leak\ninformation unique to individual records. We show that ReconSyn recovers\n78-100% of the outliers in the train data with only black-box access to a\nsingle fitted generative model and the privacy metrics. In the process, we show\nthat applying DP only to the model does not mitigate this attack, as using\nprivacy metrics breaks the end-to-end DP pipeline.\n","authors":["Georgi Ganev","Emiliano De Cristofaro"],"pdf_url":"https://arxiv.org/pdf/2312.05114v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.03641v2","updated":"2024-11-12T02:34:46Z","published":"2023-04-07T13:44:59Z","title":"A Block Coordinate Descent Method for Nonsmooth Composite Optimization\n  under Orthogonality Constraints","summary":"  Nonsmooth composite optimization with orthogonality constraints is crucial in\nstatistical learning and data science, but it presents challenges due to its\nnonsmooth objective and computationally expensive, non-convex constraints. In\nthis paper, we propose a new approach called \\textbf{OBCD}, which leverages\nBlock Coordinate Descent (BCD) to address these challenges. \\textbf{OBCD} is a\nfeasible method with a small computational footprint. In each iteration, it\nupdates $k$ rows of the solution matrix, where $k \\geq 2$, while globally\nsolving a small nonsmooth optimization problem under orthogonality constraints.\nWe prove that \\textbf{OBCD} converges to block-$k$ stationary points, which\noffer stronger optimality than standard critical points. Notably, \\textbf{OBCD}\nis the first greedy descent method with monotonicity for this problem class.\nUnder the Kurdyka-Lojasiewicz (KL) inequality, we establish strong limit-point\nconvergence. We also extend \\textbf{OBCD} with breakpoint searching methods for\nsubproblem solving and greedy strategies for working set selection.\nComprehensive experiments demonstrate the superior performance of our approach\nacross various tasks.\n","authors":["Ganzhao Yuan"],"pdf_url":"https://arxiv.org/pdf/2304.03641v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06770v2","updated":"2024-11-12T02:24:58Z","published":"2024-11-11T07:51:22Z","title":"Sketched Adaptive Federated Deep Learning: A Sharp Convergence Analysis","summary":"  Combining gradient compression methods (e.g., CountSketch, quantization) and\nadaptive optimizers (e.g., Adam, AMSGrad) is a desirable goal in federated\nlearning (FL), with potential benefits on both fewer communication rounds and\nless per-round communication. In spite of the preliminary empirical success of\nsketched adaptive methods, existing convergence analyses show the communication\ncost to have a linear dependence on the ambient dimension, i.e., number of\nparameters, which is prohibitively high for modern deep learning models. In\nthis work, we introduce specific sketched adaptive federated learning (SAFL)\nalgorithms and, as our main contribution, provide theoretical convergence\nanalyses in different FL settings with guarantees on communication cost\ndepending only logarithmically (instead of linearly) on the ambient dimension.\nUnlike existing analyses, we show that the entry-wise sketching noise existent\nin the preconditioners and the first moments of SAFL can be implicitly\naddressed by leveraging the recently-popularized anisotropic curvatures in deep\nlearning losses, e.g., fast decaying loss Hessian eigen-values. In the i.i.d.\nclient setting of FL, we show that SAFL achieves asymptotic $O(1/\\sqrt{T})$\nconvergence, and converges faster in the initial epochs. In the non-i.i.d.\nclient setting, where non-adaptive methods lack convergence guarantees, we show\nthat SACFL (SAFL with clipping) algorithms can provably converge in spite of\nthe additional heavy-tailed noise. Our theoretical claims are supported by\nempirical studies on vision and language tasks, and in both fine-tuning and\ntraining-from-scratch regimes. Surprisingly, as a by-product of our analysis,\nthe proposed SAFL methods are competitive with the state-of-the-art\ncommunication-efficient federated learning algorithms based on error feedback.\n","authors":["Zhijie Chen","Qiaobo Li","Arindam Banerjee"],"pdf_url":"https://arxiv.org/pdf/2411.06770v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07483v1","updated":"2024-11-12T02:12:41Z","published":"2024-11-12T02:12:41Z","title":"Quantifying Knowledge Distillation Using Partial Information\n  Decomposition","summary":"  Knowledge distillation provides an effective method for deploying complex\nmachine learning models in resource-constrained environments. It typically\ninvolves training a smaller student model to emulate either the probabilistic\noutputs or the internal feature representations of a larger teacher model. By\ndoing so, the student model often achieves substantially better performance on\na downstream task compared to when it is trained independently. Nevertheless,\nthe teacher's internal representations can also encode noise or additional\ninformation that may not be relevant to the downstream task. This observation\nmotivates our primary question: What are the information-theoretic limits of\nknowledge transfer? To this end, we leverage a body of work in information\ntheory called Partial Information Decomposition (PID) to quantify the\ndistillable and distilled knowledge of a teacher's representation corresponding\nto a given student and a downstream task. Moreover, we demonstrate that this\nmetric can be practically used in distillation to address challenges caused by\nthe complexity gap between the teacher and the student representations.\n","authors":["Pasan Dissanayake","Faisal Hamman","Barproda Halder","Ilia Sucholutsky","Qiuyi Zhang","Sanghamitra Dutta"],"pdf_url":"https://arxiv.org/pdf/2411.07483v1.pdf","comment":"Accepted at NeurIPS 2024 Machine Learning and Compression Workshop"},{"id":"http://arxiv.org/abs/2411.07482v1","updated":"2024-11-12T02:08:19Z","published":"2024-11-12T02:08:19Z","title":"Enhancing Link Prediction with Fuzzy Graph Attention Networks and\n  Dynamic Negative Sampling","summary":"  Link prediction is crucial for understanding complex networks but traditional\nGraph Neural Networks (GNNs) often rely on random negative sampling, leading to\nsuboptimal performance. This paper introduces Fuzzy Graph Attention Networks\n(FGAT), a novel approach integrating fuzzy rough sets for dynamic negative\nsampling and enhanced node feature aggregation. Fuzzy Negative Sampling (FNS)\nsystematically selects high-quality negative edges based on fuzzy similarities,\nimproving training efficiency. FGAT layer incorporates fuzzy rough set\nprinciples, enabling robust and discriminative node representations.\nExperiments on two research collaboration networks demonstrate FGAT's superior\nlink prediction accuracy, outperforming state-of-the-art baselines by\nleveraging the power of fuzzy rough sets for effective negative sampling and\nnode feature learning.\n","authors":["Jinming Xing"],"pdf_url":"https://arxiv.org/pdf/2411.07482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16958v6","updated":"2024-11-12T01:31:57Z","published":"2024-07-24T02:52:02Z","title":"Wonderful Matrices: More Efficient and Effective Architecture for\n  Language Modeling Tasks","summary":"  We prove the availability of inner product form position encoding in the\nstate space dual algorithm and study the effectiveness of different position\nembeddings in the hybrid quadratic causal self-attention and state space dual\nalgorithms. We propose inner function attention with dynamic mask, which can\nimprove the expressiveness of the attention algorithm and avoid the sequence\nnoise significantly affecting the accuracy of the attention score. We also\ndesign cross domain mixture of experts, which can improve the granularity of\nthe sparse activation feedforward network while maintaining the efficiency of\nparameter utilization and retrieval. The combination of these methods\nconstitutes our foundation model architecture: Wonderful Matrices. We conduct\nexperiments on the language modeling task and find that Wonderful Matrices are\nmore efficient and effective in handling complex language tasks.\n","authors":["Jingze Shi","Bingheng Wu","Lu He","Luchang Jiang"],"pdf_url":"https://arxiv.org/pdf/2407.16958v6.pdf","comment":"28 pages, 8 figures, 7 tables"},{"id":"http://arxiv.org/abs/2401.08897v3","updated":"2024-11-12T01:30:06Z","published":"2024-01-17T00:46:24Z","title":"CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in\n  Variational AutoEncoder","summary":"  Symmetries of input and latent vectors have provided valuable insights for\ndisentanglement learning in VAEs. However, only a few works were proposed as an\nunsupervised method, and even these works require known factor information in\nthe training data. We propose a novel method, Composite Factor-Aligned Symmetry\nLearning (CFASL), which is integrated into VAEs for learning symmetry-based\ndisentanglement in unsupervised learning without any knowledge of the dataset\nfactor information. CFASL incorporates three novel features for learning\nsymmetry-based disentanglement: 1) Injecting inductive bias to align latent\nvector dimensions to factor-aligned symmetries within an explicit learnable\nsymmetry code-book 2) Learning a composite symmetry to express unknown factors\nchange between two random samples by learning factor-aligned symmetries within\nthe codebook 3) Inducing a group equivariant encoder and decoder in training\nVAEs with the two conditions. In addition, we propose an extended evaluation\nmetric for multi-factor changes in comparison to disentanglement evaluation in\nVAEs. In quantitative and in-depth qualitative analysis, CFASL demonstrates a\nsignificant improvement of disentanglement in single-factor change, and\nmulti-factor change conditions compared to state-of-the-art methods.\n","authors":["Hee-Jun Jung","Jaehyoung Jeong","Kangil Kim"],"pdf_url":"https://arxiv.org/pdf/2401.08897v3.pdf","comment":"Accepted in TMLR 25 pages, 14 figures"},{"id":"http://arxiv.org/abs/2409.13644v2","updated":"2024-11-12T01:23:55Z","published":"2024-09-20T16:48:55Z","title":"Non-overlapping, Schwarz-type Domain Decomposition Method for Physics\n  and Equality Constrained Artificial Neural Networks","summary":"  We present a non-overlapping, Schwarz-type domain decomposition method with a\ngeneralized interface condition, designed for physics-informed machine learning\nof partial differential equations (PDEs) in both forward and inverse contexts.\nOur approach employs physics and equality-constrained artificial neural\nnetworks (PECANN) within each subdomain. Unlike the original PECANN method,\nwhich relies solely on initial and boundary conditions to constrain PDEs, our\nmethod uses both boundary conditions and the governing PDE to constrain a\nunique interface loss function for each subdomain. This modification improves\nthe learning of subdomain-specific interface parameters while reducing\ncommunication overhead by delaying information exchange between neighboring\nsubdomains. To address the constrained optimization in each subdomain, we apply\nan augmented Lagrangian method with a conditionally adaptive update strategy,\ntransforming the problem into an unconstrained dual optimization. A distinct\nadvantage of our domain decomposition method is its ability to learn solutions\nto both Poisson's and Helmholtz equations, even in cases with high-wavenumber\nand complex-valued solutions. Through numerical experiments with up to 64\nsubdomains, we demonstrate that our method consistently generalizes well as the\nnumber of subdomains increases.\n","authors":["Qifeng Hu","Shamsulhaq Basir","Inanc Senocak"],"pdf_url":"https://arxiv.org/pdf/2409.13644v2.pdf","comment":"49 pages, 19 figures"},{"id":"http://arxiv.org/abs/2411.08249v1","updated":"2024-11-12T23:55:11Z","published":"2024-11-12T23:55:11Z","title":"Retrieval Augmented Time Series Forecasting","summary":"  Retrieval-augmented generation (RAG) is a central component of modern LLM\nsystems, particularly in scenarios where up-to-date information is crucial for\naccurately responding to user queries or when queries exceed the scope of the\ntraining data. The advent of time-series foundation models (TSFM), such as\nChronos, and the need for effective zero-shot forecasting performance across\nvarious time-series domains motivates the question: Do benefits of RAG\nsimilarly carry over to time series forecasting? In this paper, we advocate\nthat the dynamic and event-driven nature of time-series data makes RAG a\ncrucial component of TSFMs and introduce a principled RAG framework for\ntime-series forecasting, called Retrieval Augmented Forecasting (RAF). Within\nRAF, we develop efficient strategies for retrieving related time-series\nexamples and incorporating them into forecast. Through experiments and\nmechanistic studies, we demonstrate that RAF indeed improves the forecasting\naccuracy across diverse time series domains and the improvement is more\nsignificant for larger TSFM sizes.\n","authors":["Kutay Tire","Ege Onur Taga","Muhammed Emrullah Ildiz","Samet Oymak"],"pdf_url":"https://arxiv.org/pdf/2411.08249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08248v1","updated":"2024-11-12T23:54:58Z","published":"2024-11-12T23:54:58Z","title":"Deceiving Question-Answering Models: A Hybrid Word-Level Adversarial\n  Approach","summary":"  Deep learning underpins most of the currently advanced natural language\nprocessing (NLP) tasks such as textual classification, neural machine\ntranslation (NMT), abstractive summarization and question-answering (QA).\nHowever, the robustness of the models, particularly QA models, against\nadversarial attacks is a critical concern that remains insufficiently explored.\nThis paper introduces QA-Attack (Question Answering Attack), a novel word-level\nadversarial strategy that fools QA models. Our attention-based attack exploits\nthe customized attention mechanism and deletion ranking strategy to identify\nand target specific words within contextual passages. It creates deceptive\ninputs by carefully choosing and substituting synonyms, preserving grammatical\nintegrity while misleading the model to produce incorrect responses. Our\napproach demonstrates versatility across various question types, particularly\nwhen dealing with extensive long textual inputs. Extensive experiments on\nmultiple benchmark datasets demonstrate that QA-Attack successfully deceives\nbaseline QA models and surpasses existing adversarial techniques regarding\nsuccess rate, semantics changes, BLEU score, fluency and grammar error rate.\n","authors":["Jiyao Li","Mingze Ni","Yongshun Gong","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2411.08248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08244v1","updated":"2024-11-12T23:43:20Z","published":"2024-11-12T23:43:20Z","title":"NVCiM-PT: An NVCiM-assisted Prompt Tuning Framework for Edge LLMs","summary":"  Large Language Models (LLMs) deployed on edge devices, known as edge LLMs,\nneed to continuously fine-tune their model parameters from user-generated data\nunder limited resource constraints. However, most existing learning methods are\nnot applicable for edge LLMs because of their reliance on high resources and\nlow learning capacity. Prompt tuning (PT) has recently emerged as an effective\nfine-tuning method for edge LLMs by only modifying a small portion of LLM\nparameters, but it suffers from user domain shifts, resulting in repetitive\ntraining and losing resource efficiency. Conventional techniques to address\ndomain shift issues often involve complex neural networks and sophisticated\ntraining, which are incompatible for PT for edge LLMs. Therefore, an open\nresearch question is how to address domain shift issues for edge LLMs with\nlimited resources. In this paper, we propose a prompt tuning framework for edge\nLLMs, exploiting the benefits offered by non-volatile computing-in-memory\n(NVCiM) architectures. We introduce a novel NVCiM-assisted PT framework, where\nwe narrow down the core operations to matrix-matrix multiplication, which can\nthen be accelerated by performing in-situ computation on NVCiM. To the best of\nour knowledge, this is the first work employing NVCiM to improve the edge LLM\nPT performance.\n","authors":["Ruiyang Qin","Pengyu Ren","Zheyu Yan","Liu Liu","Dancheng Liu","Amir Nassereldine","Jinjun Xiong","Kai Ni","Sharon Hu","Yiyu Shi"],"pdf_url":"https://arxiv.org/pdf/2411.08244v1.pdf","comment":"Accepted by DATE 2025"},{"id":"http://arxiv.org/abs/2411.08241v1","updated":"2024-11-12T23:32:21Z","published":"2024-11-12T23:32:21Z","title":"A Social Outcomes and Priorities centered (SOP) Framework for AI policy","summary":"  Rapid developments in AI and its adoption across various domains have\nnecessitated a need to build robust guardrails and risk containment plans while\nensuring equitable benefits for the betterment of society. The current\ntechnology-centered approach has resulted in a fragmented, reactive, and\nineffective policy apparatus. This paper highlights the immediate and urgent\nneed to pivot to a society-centered approach to develop comprehensive,\ncoherent, forward-looking AI policy. To this end, we present a Social Outcomes\nand Priorities centered (SOP) framework for AI policy along with proposals on\nimplementation of its various components. While the SOP framework is presented\nfrom a US-centric view, the takeaways are general and applicable globally.\n","authors":["Mohak Shah"],"pdf_url":"https://arxiv.org/pdf/2411.08241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05864v2","updated":"2024-11-12T23:12:55Z","published":"2024-03-09T10:24:12Z","title":"PEaRL: Personalized Privacy of Human-Centric Systems using Early-Exit\n  Reinforcement Learning","summary":"  In the evolving landscape of human-centric systems, personalized privacy\nsolutions are becoming increasingly crucial due to the dynamic nature of human\ninteractions. Traditional static privacy models often fail to meet the diverse\nand changing privacy needs of users. This paper introduces PEaRL, a system\ndesigned to enhance privacy preservation by tailoring its approach to\nindividual behavioral patterns and preferences. While incorporating\nreinforcement learning (RL) for its adaptability, PEaRL primarily focuses on\nemploying an early-exit strategy that dynamically balances privacy protection\nand system utility. This approach addresses the challenges posed by the\nvariability and evolution of human behavior, which static privacy models\nstruggle to handle effectively. We evaluate PEaRL in two distinct contexts:\nSmart Home environments and Virtual Reality (VR) Smart Classrooms. The\nempirical results demonstrate PEaRL's capability to provide a personalized\ntradeoff between user privacy and application utility, adapting effectively to\nindividual user preferences. On average, across both systems, PEaRL enhances\nprivacy protection by 31%, with a corresponding utility reduction of 24%.\n","authors":["Mojtaba Taherisadr","Salma Elmalaki"],"pdf_url":"https://arxiv.org/pdf/2403.05864v2.pdf","comment":"15 pages, 16 figures"},{"id":"http://arxiv.org/abs/2308.16362v2","updated":"2024-11-12T23:08:25Z","published":"2023-08-30T23:34:11Z","title":"A Unified Analysis on the Subgradient Upper Bounds for the Subgradient\n  Methods Minimizing Composite Nonconvex, Nonsmooth and Non-Lipschitz Functions","summary":"  This paper presents a unified analysis for the proximal subgradient method\n(Prox-SubGrad) type approach to minimize an overall objective of $f(x)+r(x)$,\nsubject to convex constraints, where both $f$ and $r$ are weakly convex,\nnonsmooth, and non-Lipschitz. Leveraging on the properties of the Moreau\nenvelope of weakly convex functions, we are able to relate error-bound\nconditions, the growth conditions of the subgradients of the objective, and the\nbehavior of the proximal subgradient iterates on some remarkably broad classes\nof objective functions. Various existing as well as new bounding conditions are\nstudied, leading to novel iteration complexity results. The terrain of our\nexploration expands to stochastic proximal subgradient algorithms.\n","authors":["Daoli Zhu","Lei Zhao","Shuzhong Zhang"],"pdf_url":"https://arxiv.org/pdf/2308.16362v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08232v1","updated":"2024-11-12T22:56:28Z","published":"2024-11-12T22:56:28Z","title":"Imitation Learning from Observations: An Autoregressive Mixture of\n  Experts Approach","summary":"  This paper presents a novel approach to imitation learning from observations,\nwhere an autoregressive mixture of experts model is deployed to fit the\nunderlying policy. The parameters of the model are learned via a two-stage\nframework. By leveraging the existing dynamics knowledge, the first stage of\nthe framework estimates the control input sequences and hence reduces the\nproblem complexity. At the second stage, the policy is learned by solving a\nregularized maximum-likelihood estimation problem using the estimated control\ninput sequences. We further extend the learning procedure by incorporating a\nLyapunov stability constraint to ensure asymptotic stability of the identified\nmodel, for accurate multi-step predictions. The effectiveness of the proposed\nframework is validated using two autonomous driving datasets collected from\nhuman demonstrations, demonstrating its practical applicability in modelling\ncomplex nonlinear dynamics.\n","authors":["Renzi Wang","Flavia Sofia Acerbo","Tong Duy Son","Panagiotis Patrinos"],"pdf_url":"https://arxiv.org/pdf/2411.08232v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.07899v1","updated":"2024-11-12T16:12:51Z","published":"2024-11-12T16:12:51Z","title":"Rendering-Oriented 3D Point Cloud Attribute Compression using Sparse\n  Tensor-based Transformer","summary":"  The evolution of 3D visualization techniques has fundamentally transformed\nhow we interact with digital content. At the forefront of this change is point\ncloud technology, offering an immersive experience that surpasses traditional\n2D representations. However, the massive data size of point clouds presents\nsignificant challenges in data compression. Current methods for lossy point\ncloud attribute compression (PCAC) generally focus on reconstructing the\noriginal point clouds with minimal error. However, for point cloud\nvisualization scenarios, the reconstructed point clouds with distortion still\nneed to undergo a complex rendering process, which affects the final\nuser-perceived quality. In this paper, we propose an end-to-end deep learning\nframework that seamlessly integrates PCAC with differentiable rendering,\ndenoted as rendering-oriented PCAC (RO-PCAC), directly targeting the quality of\nrendered multiview images for viewing. In a differentiable manner, the impact\nof the rendering process on the reconstructed point clouds is taken into\naccount. Moreover, we characterize point clouds as sparse tensors and propose a\nsparse tensor-based transformer, called SP-Trans. By aligning with the local\ndensity of the point cloud and utilizing an enhanced local attention mechanism,\nSP-Trans captures the intricate relationships within the point cloud, further\nimproving feature analysis and synthesis within the framework. Extensive\nexperiments demonstrate that the proposed RO-PCAC achieves state-of-the-art\ncompression performance, compared to existing reconstruction-oriented methods,\nincluding traditional, learning-based, and hybrid methods.\n","authors":["Xiao Huo","Junhui Ho","Shuai Wan","Fuzheng Yang"],"pdf_url":"https://arxiv.org/pdf/2411.07899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06001v2","updated":"2024-11-12T15:14:41Z","published":"2024-07-08T14:53:07Z","title":"Pseudo-triplet Guided Few-shot Composed Image Retrieval","summary":"  Composed Image Retrieval (CIR) is a challenging task that aims to retrieve\nthe target image with a multimodal query, i.e., a reference image, and its\ncomplementary modification text. As previous supervised or zero-shot learning\nparadigms all fail to strike a good trade-off between the model's\ngeneralization ability and retrieval performance, recent researchers have\nintroduced the task of few-shot CIR (FS-CIR) and proposed a textual\ninversion-based network based on pretrained CLIP model to realize it. Despite\nits promising performance, the approach encounters two key limitations: simply\nrelying on the few annotated samples for CIR model training and\nindiscriminately selecting training triplets for CIR model fine-tuning. To\naddress these two limitations, we propose a novel two-stage pseudo triplet\nguided few-shot CIR scheme, dubbed PTG-FSCIR. In the first stage, we propose an\nattentive masking and captioning-based pseudo triplet generation method, to\nconstruct pseudo triplets from pure image data and use them to fulfill the\nCIR-task specific pertaining. In the second stage, we propose a challenging\ntriplet-based CIR fine-tuning method, where we design a pseudo modification\ntext-based sample challenging score estimation strategy and a robust top\nrange-based random sampling strategy for sampling robust challenging triplets\nto promote the model fine-tuning. Notably, our scheme is plug-and-play and\ncompatible with any existing supervised CIR models. We test our scheme across\ntwo backbones on three public datasets (i.e., FashionIQ, CIRR, and\nBirds-to-Words), achieving maximum improvements of 13.3%, 22.2%, and 17.4%\nrespectively, demonstrating our scheme's efficacy.\n","authors":["Bohan Hou","Haoqiang Lin","Haokun Wen","Meng Liu","Mingzhu Xu","Xuemeng Song"],"pdf_url":"https://arxiv.org/pdf/2407.06001v2.pdf","comment":"10pages"},{"id":"http://arxiv.org/abs/2411.07772v1","updated":"2024-11-12T13:13:20Z","published":"2024-11-12T13:13:20Z","title":"Automatic Album Sequencing","summary":"  Album sequencing is a critical part of the album production process.\nRecently, a data-driven approach was proposed that sequences general\ncollections of independent media by extracting the narrative essence of the\nitems in the collections. While this approach implies an album sequencing\ntechnique, it is not widely accessible to a less technical audience, requiring\nadvanced knowledge of machine learning techniques to use. To address this, we\nintroduce a new user-friendly web-based tool that allows a less technical\naudience to upload music tracks, execute this technique in one click, and\nsubsequently presents the result in a clean visualization to the user. To both\nincrease the number of templates available to the user and address shortcomings\nof previous work, we also introduce a new direct transformer-based album\nsequencing method. We find that our more direct method outperforms a random\nbaseline but does not reach the same performance as the narrative essence\napproach. Both methods are included in our web-based user interface, and this\n-- alongside a full copy of our implementation -- is publicly available at\nhttps://github.com/dylanashley/automatic-album-sequencing\n","authors":["Vincent Herrmann","Dylan R. Ashley","Jürgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2411.07772v1.pdf","comment":"presented as a late breaking demo in the 25th International Society\n  for Music Information Retrieval Conference; 3 pages in main text, 3 figures\n  in main text; source code available at\n  https://github.com/dylanashley/automatic-album-sequencing"},{"id":"http://arxiv.org/abs/2411.07751v1","updated":"2024-11-12T12:23:41Z","published":"2024-11-12T12:23:41Z","title":"SAV-SE: Scene-aware Audio-Visual Speech Enhancement with Selective State\n  Space Model","summary":"  Speech enhancement plays an essential role in various applications, and the\nintegration of visual information has been demonstrated to bring substantial\nadvantages. However, the majority of current research concentrates on the\nexamination of facial and lip movements, which can be compromised or entirely\ninaccessible in scenarios where occlusions occur or when the camera view is\ndistant. Whereas contextual visual cues from the surrounding environment have\nbeen overlooked: for example, when we see a dog bark, our brain has the innate\nability to discern and filter out the barking noise. To this end, in this\npaper, we introduce a novel task, i.e. SAV-SE. To our best knowledge, this is\nthe first proposal to use rich contextual information from synchronized video\nas auxiliary cues to indicate the type of noise, which eventually improves the\nspeech enhancement performance. Specifically, we propose the VC-S$^2$E method,\nwhich incorporates the Conformer and Mamba modules for their complementary\nstrengths. Extensive experiments are conducted on public MUSIC, AVSpeech and\nAudioSet datasets, where the results demonstrate the superiority of VC-S$^2$E\nover other competitive methods. We will make the source code publicly\navailable. Project demo page: https://AVSEPage.github.io/\n","authors":["Xinyuan Qian","Jiaran Gao","Yaodan Zhang","Qiquan Zhang","Hexin Liu","Leibny Paola Garcia","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2411.07751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07650v1","updated":"2024-11-12T09:02:11Z","published":"2024-11-12T09:02:11Z","title":"Understanding Audiovisual Deepfake Detection: Techniques, Challenges,\n  Human Factors and Perceptual Insights","summary":"  Deep Learning has been successfully applied in diverse fields, and its impact\non deepfake detection is no exception. Deepfakes are fake yet realistic\nsynthetic content that can be used deceitfully for political impersonation,\nphishing, slandering, or spreading misinformation. Despite extensive research\non unimodal deepfake detection, identifying complex deepfakes through joint\nanalysis of audio and visual streams remains relatively unexplored. To fill\nthis gap, this survey first provides an overview of audiovisual deepfake\ngeneration techniques, applications, and their consequences, and then provides\na comprehensive review of state-of-the-art methods that combine audio and\nvisual modalities to enhance detection accuracy, summarizing and critically\nanalyzing their strengths and limitations. Furthermore, we discuss existing\nopen source datasets for a deeper understanding, which can contribute to the\nresearch community and provide necessary information to beginners who want to\nanalyze deep learning-based audiovisual methods for video forensics. By\nbridging the gap between unimodal and multimodal approaches, this paper aims to\nimprove the effectiveness of deepfake detection strategies and guide future\nresearch in cybersecurity and media integrity.\n","authors":["Ammarah Hashmi","Sahibzada Adil Shahzad","Chia-Wen Lin","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07650v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07539v1","updated":"2024-11-12T04:34:09Z","published":"2024-11-12T04:34:09Z","title":"Harmonizing Pixels and Melodies: Maestro-Guided Film Score Generation\n  and Composition Style Transfer","summary":"  We introduce a film score generation framework to harmonize visual pixels and\nmusic melodies utilizing a latent diffusion model. Our framework processes film\nclips as input and generates music that aligns with a general theme while\noffering the capability to tailor outputs to a specific composition style. Our\nmodel directly produces music from video, utilizing a streamlined and efficient\ntuning mechanism on ControlNet. It also integrates a film encoder adept at\nunderstanding the film's semantic depth, emotional impact, and aesthetic\nappeal. Additionally, we introduce a novel, effective yet straightforward\nevaluation metric to evaluate the originality and recognizability of music\nwithin film scores. To fill this gap for film scores, we curate a comprehensive\ndataset of film videos and legendary original scores, injecting domain-specific\nknowledge into our data-driven generation model. Our model outperforms existing\nmethodologies in creating film scores, capable of generating music that\nreflects the guidance of a maestro's style, thereby redefining the benchmark\nfor automated film scores and laying a robust groundwork for future research in\nthis domain. The code and generated samples are available at\nhttps://anonymous.4open.science/r/HPM.\n","authors":["F. Qi","L. Ni","C. Xu"],"pdf_url":"https://arxiv.org/pdf/2411.07539v1.pdf","comment":null}]},"2024-11-13T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2411.08034v2","updated":"2024-11-13T18:59:44Z","published":"2024-11-12T18:59:35Z","title":"Scaling Properties of Diffusion Models for Perceptual Tasks","summary":"  In this paper, we argue that iterative computation with diffusion models\noffers a powerful paradigm for not only generation but also visual perception\ntasks. We unify tasks such as depth estimation, optical flow, and amodal\nsegmentation under the framework of image-to-image translation, and show how\ndiffusion models benefit from scaling training and test-time compute for these\nperceptual tasks. Through a careful analysis of these scaling properties, we\nformulate compute-optimal training and inference recipes to scale diffusion\nmodels for visual perception tasks. Our models achieve competitive performance\nto state-of-the-art methods using significantly less data and compute. To\naccess our code and models, see https://scaling-diffusion-perception.github.io .\n","authors":["Rahul Ravishankar","Zeeshan Patel","Jathushan Rajasegaran","Jitendra Malik"],"pdf_url":"https://arxiv.org/pdf/2411.08034v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08879v1","updated":"2024-11-13T18:56:39Z","published":"2024-11-13T18:56:39Z","title":"4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization","summary":"  Novel view synthesis of dynamic scenes is becoming important in various\napplications, including augmented and virtual reality. We propose a novel 4D\nGaussian Splatting (4DGS) algorithm for dynamic scenes from casually recorded\nmonocular videos. To overcome the overfitting problem of existing work for\nthese real-world videos, we introduce an uncertainty-aware regularization that\nidentifies uncertain regions with few observations and selectively imposes\nadditional priors based on diffusion models and depth smoothness on such\nregions. This approach improves both the performance of novel view synthesis\nand the quality of training image reconstruction. We also identify the\ninitialization problem of 4DGS in fast-moving dynamic regions, where the\nStructure from Motion (SfM) algorithm fails to provide reliable 3D landmarks.\nTo initialize Gaussian primitives in such regions, we present a dynamic region\ndensification method using the estimated depth maps and scene flow. Our\nexperiments show that the proposed method improves the performance of 4DGS\nreconstruction from a video captured by a handheld monocular camera and also\nexhibits promising results in few-shot static scene reconstruction.\n","authors":["Mijeong Kim","Jongwoo Lim","Bohyung Han"],"pdf_url":"https://arxiv.org/pdf/2411.08879v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.08878v1","updated":"2024-11-13T18:55:10Z","published":"2024-11-13T18:55:10Z","title":"A Short Note on Evaluating RepNet for Temporal Repetition Counting in\n  Videos","summary":"  We discuss some consistent issues on how RepNet has been evaluated in various\npapers. As a way to mitigate these issues, we report RepNet performance results\non different datasets, and release evaluation code and the RepNet checkpoint to\nobtain these results. Code URL:\nhttps://github.com/google-research/google-research/blob/master/repnet/\n","authors":["Debidatta Dwibedi","Yusuf Aytar","Jonathan Tompson","Pierre Sermanet","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2411.08878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10172v3","updated":"2024-11-13T18:42:18Z","published":"2024-04-15T23:01:59Z","title":"Forensic Iris Image-Based Post-Mortem Interval Estimation","summary":"  Post-mortem iris recognition is an emerging application of iris-based human\nidentification in a forensic setup. One factor that may be useful in\nconditioning iris recognition methods is the tissue decomposition level, which\nis correlated with the post-mortem interval (PMI), \\ie the number of hours that\nhave elapsed since death. PMI, however, is not always available, and its\nprecise estimation remains one of the core challenges in forensic examination.\nThis paper presents the first known to us method of the PMI estimation directly\nfrom iris images captured after death. To assess the feasibility of the\niris-based PMI estimation, we designed models predicting the PMI from (a)\nnear-infrared (NIR), (b) visible (RGB), and (c) multispectral (RGB+NIR)\nforensic iris images. Models were evaluated following a 10-fold\ncross-validation, in (S1) sample-disjoint, (S2) subject-disjoint, and (S3)\ncross-dataset scenarios. We explore two data balancing techniques for S3:\nresampling-based balancing (S3-real), and synthetic data-supplemented balancing\n(S3-synthetic). We found that using the multispectral data offers a\nspectacularly low mean absolute error (MAE) of $\\approx 3.5$ hours in the\nscenario (S1), a bit worse MAE $\\approx 17.5$ hours in the scenario (S2), and\nMAE $\\approx 45.77$ hours in the scenario (S3). Additionally, supplementing the\ntraining set with synthetically-generated forensic iris images (S3-synthetic)\nsignificantly enhances the models' ability to generalize to new NIR, RGB and\nmultispectral data collected in a different lab. This suggests that if the\nenvironmental conditions are favorable (\\eg, bodies are kept in low\ntemperatures), forensic iris images provide features that are indicative of the\nPMI and can be automatically estimated.\n","authors":["Rasel Ahmed Bhuiyan","Adam Czajka"],"pdf_url":"https://arxiv.org/pdf/2404.10172v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.13880v4","updated":"2024-11-13T18:31:18Z","published":"2024-04-22T05:07:02Z","title":"Regional Style and Color Transfer","summary":"  This paper presents a novel contribution to the field of regional style\ntransfer. Existing methods often suffer from the drawback of applying style\nhomogeneously across the entire image, leading to stylistic inconsistencies or\nforeground object twisted when applied to image with foreground elements such\nas person figures. To address this limitation, we propose a new approach that\nleverages a segmentation network to precisely isolate foreground objects within\nthe input image. Subsequently, style transfer is applied exclusively to the\nbackground region. The isolated foreground objects are then carefully\nreintegrated into the style-transferred background. To enhance the visual\ncoherence between foreground and background, a color transfer step is employed\non the foreground elements prior to their rein-corporation. Finally, we utilize\nfeathering techniques to achieve a seamless amalgamation of foreground and\nbackground, resulting in a visually unified and aesthetically pleasing final\ncomposition. Extensive evaluations demonstrate that our proposed approach\nyields significantly more natural stylistic transformations compared to\nconventional methods.\n","authors":["Zhicheng Ding","Panfeng Li","Qikai Yang","Siyang Li","Qingtian Gong"],"pdf_url":"https://arxiv.org/pdf/2404.13880v4.pdf","comment":"Accepted by 2024 5th International Conference on Computer Vision,\n  Image and Deep Learning"},{"id":"http://arxiv.org/abs/2407.06438v2","updated":"2024-11-13T18:21:22Z","published":"2024-07-08T22:40:15Z","title":"A Single Transformer for Scalable Vision-Language Modeling","summary":"  We present SOLO, a single transformer for Scalable visiOn-Language mOdeling.\nCurrent large vision-language models (LVLMs) such as LLaVA mostly employ\nheterogeneous architectures that connect pre-trained visual encoders with large\nlanguage models (LLMs) to facilitate visual recognition and complex reasoning.\nAlthough achieving remarkable performance with relatively lightweight training,\nwe identify four primary scalability limitations: (1) The visual capacity is\nconstrained by pre-trained visual encoders, which are typically an order of\nmagnitude smaller than LLMs. (2) The heterogeneous architecture complicates the\nuse of established hardware and software infrastructure. (3) Study of scaling\nlaws on such architecture must consider three separate components - visual\nencoder, connector, and LLMs, which complicates the analysis. (4) The use of\nexisting visual encoders typically requires following a pre-defined\nspecification of image inputs pre-processing, for example, by reshaping inputs\nto fixed-resolution square images, which presents difficulties in processing\nand training on high-resolution images or those with unusual aspect ratio. A\nunified single Transformer architecture, like SOLO, effectively addresses these\nscalability concerns in LVLMs; however, its limited adoption in the modern\ncontext likely stems from the absence of reliable training recipes that balance\nboth modalities and ensure stable training for billion-scale models. In this\npaper, we introduce the first open-source training recipe for developing SOLO,\nan open-source 7B LVLM using moderate academic resources. The training recipe\ninvolves initializing from LLMs, sequential pre-training on ImageNet and\nweb-scale data, and instruction fine-tuning on our curated high-quality\ndatasets. On extensive evaluation, SOLO demonstrates performance comparable to\nLLaVA-v1.5-7B, particularly excelling in visual mathematical reasoning.\n","authors":["Yangyi Chen","Xingyao Wang","Hao Peng","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2407.06438v2.pdf","comment":"Accepted to TMLR"},{"id":"http://arxiv.org/abs/2411.08840v1","updated":"2024-11-13T18:19:51Z","published":"2024-11-13T18:19:51Z","title":"Multimodal Instruction Tuning with Hybrid State Space Models","summary":"  Handling lengthy context is crucial for enhancing the recognition and\nunderstanding capabilities of multimodal large language models (MLLMs) in\napplications such as processing high-resolution images or high frame rate\nvideos. The rise in image resolution and frame rate substantially increases\ncomputational demands due to the increased number of input tokens. This\nchallenge is further exacerbated by the quadratic complexity with respect to\nsequence length of the self-attention mechanism. Most prior works either\npre-train models with long contexts, overlooking the efficiency problem, or\nattempt to reduce the context length via downsampling (e.g., identify the key\nimage patches or frames) to decrease the context length, which may result in\ninformation loss. To circumvent this issue while keeping the remarkable\neffectiveness of MLLMs, we propose a novel approach using a hybrid\ntransformer-MAMBA model to efficiently handle long contexts in multimodal\napplications. Our multimodal model can effectively process long context input\nexceeding 100k tokens, outperforming existing models across various benchmarks.\nRemarkably, our model enhances inference efficiency for high-resolution images\nand high-frame-rate videos by about 4 times compared to current models, with\nefficiency gains increasing as image resolution or video frames rise.\nFurthermore, our model is the first to be trained on low-resolution images or\nlow-frame-rate videos while being capable of inference on high-resolution\nimages and high-frame-rate videos, offering flexibility for inference in\ndiverse scenarios.\n","authors":["Jianing Zhou","Han Li","Shuai Zhang","Ning Xie","Ruijie Wang","Xiaohan Nie","Sheng Liu","Lingyun Wang"],"pdf_url":"https://arxiv.org/pdf/2411.08840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10259v4","updated":"2024-11-13T17:35:00Z","published":"2024-02-15T18:42:33Z","title":"GaussianObject: High-Quality 3D Object Reconstruction from Four Views\n  with Gaussian Splatting","summary":"  Reconstructing and rendering 3D objects from highly sparse views is of\ncritical importance for promoting applications of 3D vision techniques and\nimproving user experience. However, images from sparse views only contain very\nlimited 3D information, leading to two significant challenges: 1) Difficulty in\nbuilding multi-view consistency as images for matching are too few; 2)\nPartially omitted or highly compressed object information as view coverage is\ninsufficient. To tackle these challenges, we propose GaussianObject, a\nframework to represent and render the 3D object with Gaussian splatting that\nachieves high rendering quality with only 4 input images. We first introduce\ntechniques of visual hull and floater elimination, which explicitly inject\nstructure priors into the initial optimization process to help build multi-view\nconsistency, yielding a coarse 3D Gaussian representation. Then we construct a\nGaussian repair model based on diffusion models to supplement the omitted\nobject information, where Gaussians are further refined. We design a\nself-generating strategy to obtain image pairs for training the repair model.\nWe further design a COLMAP-free variant, where pre-given accurate camera poses\nare not required, which achieves competitive quality and facilitates wider\napplications. GaussianObject is evaluated on several challenging datasets,\nincluding MipNeRF360, OmniObject3D, OpenIllumination, and our-collected unposed\nimages, achieving superior performance from only four views and significantly\noutperforming previous SOTA methods. Our demo is available at\nhttps://gaussianobject.github.io/, and the code has been released at\nhttps://github.com/GaussianObject/GaussianObject.\n","authors":["Chen Yang","Sikuang Li","Jiemin Fang","Ruofan Liang","Lingxi Xie","Xiaopeng Zhang","Wei Shen","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2402.10259v4.pdf","comment":"ACM Transactions on Graphics (SIGGRAPH Asia 2024). Project page:\n  https://gaussianobject.github.io/ Code:\n  https://github.com/chensjtu/GaussianObject"},{"id":"http://arxiv.org/abs/2403.18346v4","updated":"2024-11-13T17:17:43Z","published":"2024-03-27T08:38:49Z","title":"Quantifying and Mitigating Unimodal Biases in Multimodal Large Language\n  Models: A Causal Perspective","summary":"  Recent advancements in Large Language Models (LLMs) have facilitated the\ndevelopment of Multimodal LLMs (MLLMs). Despite their impressive capabilities,\nMLLMs often suffer from over-reliance on unimodal biases (e.g., language bias\nand vision bias), leading to incorrect answers or hallucinations in complex\nmultimodal tasks. To investigate this issue, we propose a causal framework to\ninterpret the biases in Visual Question Answering (VQA) problems. Within this\nframework, we conduct an in-depth causal analysis to assess the causal effect\nof these biases on MLLM predictions. Based on the analysis, we introduce 1) a\nnovel MORE dataset with 12,000 challenging VQA instances requiring multi-hop\nreasoning and overcoming unimodal biases. 2) a causality-enhanced agent\nframework CAVE that guides models to comprehensively integrate information from\ndifferent modalities and mitigate biases. Our experiments show that MLLMs\nperform poorly on MORE, indicating strong unimodal biases and limited semantic\nunderstanding. However, when integrated with our CAVE, promising improvements\nin reasoning and bias mitigation can be seen. These findings provide important\ninsights for the development of more robust MLLMs and contribute to the broader\ngoal of advancing multimodal AI systems capable of deeper understanding and\nreasoning. Our project page is at https://github.com/OpenCausaLab/MORE.\n","authors":["Meiqi Chen","Yixin Cao","Yan Zhang","Chaochao Lu"],"pdf_url":"https://arxiv.org/pdf/2403.18346v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.09733v3","updated":"2024-11-13T17:07:45Z","published":"2024-07-13T00:45:37Z","title":"Textured-GS: Gaussian Splatting with Spatially Defined Color and Opacity","summary":"  In this paper, we introduce Textured-GS, an innovative method for rendering\nGaussian splatting that incorporates spatially defined color and opacity\nvariations using Spherical Harmonics (SH). This approach enables each Gaussian\nto exhibit a richer representation by accommodating varying colors and\nopacities across its surface, significantly enhancing rendering quality\ncompared to traditional methods. To demonstrate the merits of our approach, we\nhave adapted the Mini-Splatting architecture to integrate textured Gaussians\nwithout increasing the number of Gaussians. Our experiments across multiple\nreal-world datasets show that Textured-GS consistently outperforms both the\nbaseline Mini-Splatting and standard 3DGS in terms of visual fidelity. The\nresults highlight the potential of Textured-GS to advance Gaussian-based\nrendering technologies, promising more efficient and high-quality scene\nreconstructions. Our implementation is available at\nhttps://github.com/ZhentaoHuang/Textured-GS.\n","authors":["Zhentao Huang","Minglun Gong"],"pdf_url":"https://arxiv.org/pdf/2407.09733v3.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2411.08777v1","updated":"2024-11-13T17:02:46Z","published":"2024-11-13T17:02:46Z","title":"LUDO: Low-Latency Understanding of Highly Deformable Objects using Point\n  Cloud Occupancy Functions","summary":"  Accurately determining the shape and location of internal structures within\ndeformable objects is crucial for medical tasks that require precise targeting,\nsuch as robotic biopsies. We introduce LUDO, a method for accurate low-latency\nunderstanding of deformable objects. LUDO reconstructs objects in their\ndeformed state, including their internal structures, from a single-view point\ncloud observation in under 30 ms using occupancy networks. We demonstrate\nLUDO's abilities for autonomous targeting of internal regions of interest\n(ROIs) in highly deformable objects. Additionally, LUDO provides uncertainty\nestimates and explainability for its predictions, both of which are important\nin safety-critical applications such as surgical interventions. We evaluate\nLUDO in real-world robotic experiments, achieving a success rate of 98.9% for\npuncturing various ROIs inside highly deformable objects. LUDO demonstrates the\npotential to interact with deformable objects without the need for deformable\nregistration methods.\n","authors":["Pit Henrich","Franziska Mathis-Ullrich","Paul Maria Scheikl"],"pdf_url":"https://arxiv.org/pdf/2411.08777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08768v1","updated":"2024-11-13T16:53:29Z","published":"2024-11-13T16:53:29Z","title":"Sharingan: Extract User Action Sequence from Desktop Recordings","summary":"  Video recordings of user activities, particularly desktop recordings, offer a\nrich source of data for understanding user behaviors and automating processes.\nHowever, despite advancements in Vision-Language Models (VLMs) and their\nincreasing use in video analysis, extracting user actions from desktop\nrecordings remains an underexplored area. This paper addresses this gap by\nproposing two novel VLM-based methods for user action extraction: the Direct\nFrame-Based Approach (DF), which inputs sampled frames directly into VLMs, and\nthe Differential Frame-Based Approach (DiffF), which incorporates explicit\nframe differences detected via computer vision techniques. We evaluate these\nmethods using a basic self-curated dataset and an advanced benchmark adapted\nfrom prior work. Our results show that the DF approach achieves an accuracy of\n70% to 80% in identifying user actions, with the extracted action sequences\nbeing re-playable though Robotic Process Automation. We find that while VLMs\nshow potential, incorporating explicit UI changes can degrade performance,\nmaking the DF approach more reliable. This work represents the first\napplication of VLMs for extracting user action sequences from desktop\nrecordings, contributing new methods, benchmarks, and insights for future\nresearch.\n","authors":["Yanting Chen","Yi Ren","Xiaoting Qin","Jue Zhang","Kehong Yuan","Lu Han","Qingwei Lin","Dongmei Zhang","Saravan Rajmohan","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.08768v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12461v2","updated":"2024-11-13T16:49:14Z","published":"2023-11-21T09:15:24Z","title":"HiFi-Syn: Hierarchical Granularity Discrimination for High-Fidelity\n  Synthesis of MR Images with Structure Preservation","summary":"  Synthesizing medical images while preserving their structural information is\ncrucial in medical research. In such scenarios, the preservation of anatomical\ncontent becomes especially important. Although recent advances have been made\nby incorporating instance-level information to guide translation, these methods\noverlook the spatial coherence of structural-level representation and the\nanatomical invariance of content during translation. To address these issues,\nwe introduce hierarchical granularity discrimination, which exploits various\nlevels of semantic information present in medical images. Our strategy utilizes\nthree levels of discrimination granularity: pixel-level discrimination using a\nBrain Memory Bank, structure-level discrimination on each brain structure with\na re-weighting strategy to focus on hard samples, and global-level\ndiscrimination to ensure anatomical consistency during translation. The image\ntranslation performance of our strategy has been evaluated on three independent\ndatasets (UK Biobank, IXI, and BraTS 2018), and it has outperformed\nstate-of-the-art algorithms. Particularly, our model excels not only in\nsynthesizing normal structures but also in handling abnormal (pathological)\nstructures, such as brain tumors, despite the variations in contrast observed\nacross different imaging modalities due to their pathological characteristics.\nThe diagnostic value of synthesized MR images containing brain tumors has been\nevaluated by radiologists. This indicates that our model may offer an\nalternative solution in scenarios where specific MR modalities of patients are\nunavailable. Extensive experiments further demonstrate the versatility of our\nmethod, providing unique insights into medical image translation.\n","authors":["Ziqi Yu","Botao Zhao","Shengjie Zhang","Xiang Chen","Jianfeng Feng","Tingying Peng","Xiao-Yong Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12461v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08756v1","updated":"2024-11-13T16:42:07Z","published":"2024-11-13T16:42:07Z","title":"Masked Image Modeling Boosting Semi-Supervised Semantic Segmentation","summary":"  In view of the fact that semi- and self-supervised learning share a\nfundamental principle, effectively modeling knowledge from unlabeled data,\nvarious semi-supervised semantic segmentation methods have integrated\nrepresentative self-supervised learning paradigms for further regularization.\nHowever, the potential of the state-of-the-art generative self-supervised\nparadigm, masked image modeling, has been scarcely studied. This paradigm\nlearns the knowledge through establishing connections between the masked and\nvisible parts of masked image, during the pixel reconstruction process. By\ninheriting and extending this insight, we successfully leverage masked image\nmodeling to boost semi-supervised semantic segmentation. Specifically, we\nintroduce a novel class-wise masked image modeling that independently\nreconstructs different image regions according to their respective classes. In\nthis way, the mask-induced connections are established within each class,\nmitigating the semantic confusion that arises from plainly reconstructing\nimages in basic masked image modeling. To strengthen these intra-class\nconnections, we further develop a feature aggregation strategy that minimizes\nthe distances between features corresponding to the masked and visible parts\nwithin the same class. Additionally, in semantic space, we explore the\napplication of masked image modeling to enhance regularization. Extensive\nexperiments conducted on well-known benchmarks demonstrate that our approach\nachieves state-of-the-art performance. The code will be available at\nhttps://github.com/haoxt/S4MIM.\n","authors":["Yangyang Li","Xuanting Hao","Ronghua Shang","Licheng Jiao"],"pdf_url":"https://arxiv.org/pdf/2411.08756v1.pdf","comment":"13 pages. This work has been submitted to the IEEE for possible\n  publication"},{"id":"http://arxiv.org/abs/2411.08755v1","updated":"2024-11-13T16:33:27Z","published":"2024-11-13T16:33:27Z","title":"Weakly-Supervised Anomaly Detection in Surveillance Videos Based on\n  Two-Stream I3D Convolution Network","summary":"  The widespread implementation of urban surveillance systems has necessitated\nmore sophisticated techniques for anomaly detection to ensure enhanced public\nsafety. This paper presents a significant advancement in the field of anomaly\ndetection through the application of Two-Stream Inflated 3D (I3D) Convolutional\nNetworks. These networks substantially outperform traditional 3D Convolutional\nNetworks (C3D) by more effectively extracting spatial and temporal features\nfrom surveillance videos, thus improving the precision of anomaly detection.\nOur research advances the field by implementing a weakly supervised learning\nframework based on Multiple Instance Learning (MIL), which uniquely\nconceptualizes surveillance videos as collections of 'bags' that contain\ninstances (video clips). Each instance is innovatively processed through a\nranking mechanism that prioritizes clips based on their potential to display\nanomalies. This novel strategy not only enhances the accuracy and precision of\nanomaly detection but also significantly diminishes the dependency on extensive\nmanual annotations. Moreover, through meticulous optimization of model\nsettings, including the choice of optimizer, our approach not only establishes\nnew benchmarks in the performance of anomaly detection systems but also offers\na scalable and efficient solution for real-world surveillance applications.\nThis paper contributes significantly to the field of computer vision by\ndelivering a more adaptable, efficient, and context-aware anomaly detection\nsystem, which is poised to redefine practices in urban surveillance.\n","authors":["Sareh Soltani Nejad","Anwar Haque"],"pdf_url":"https://arxiv.org/pdf/2411.08755v1.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.08753v1","updated":"2024-11-13T16:31:08Z","published":"2024-11-13T16:31:08Z","title":"Which Viewpoint Shows it Best? Language for Weakly Supervising View\n  Selection in Multi-view Videos","summary":"  Given a multi-view video, which viewpoint is most informative for a human\nobserver? Existing methods rely on heuristics or expensive ``best-view\"\nsupervision to answer this question, limiting their applicability. We propose a\nweakly supervised approach that leverages language accompanying an\ninstructional multi-view video as a means to recover its most informative\nviewpoint(s). Our key hypothesis is that the more accurately an individual view\ncan predict a view-agnostic text summary, the more informative it is. To put\nthis into action, we propose a framework that uses the relative accuracy of\nview-dependent caption predictions as a proxy for best view pseudo-labels.\nThen, those pseudo-labels are used to train a view selector, together with an\nauxiliary camera pose predictor that enhances view-sensitivity. During\ninference, our model takes as input only a multi-view video -- no language or\ncamera poses -- and returns the best viewpoint to watch at each timestep. On\ntwo challenging datasets comprised of diverse multi-camera setups and how-to\nactivities, our model consistently outperforms state-of-the-art baselines, both\nwith quantitative metrics and human evaluation.\n","authors":["Sagnik Majumder","Tushar Nagarajan","Ziad Al-Halah","Reina Pradhan","Kristen Grauman"],"pdf_url":"https://arxiv.org/pdf/2411.08753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08715v1","updated":"2024-11-13T15:58:50Z","published":"2024-11-13T15:58:50Z","title":"Retrieval Augmented Recipe Generation","summary":"  Given the potential applications of generating recipes from food images, this\narea has garnered significant attention from researchers in recent years.\nExisting works for recipe generation primarily utilize a two-stage training\nmethod, first generating ingredients and then obtaining instructions from both\nthe image and ingredients. Large Multi-modal Models (LMMs), which have achieved\nnotable success across a variety of vision and language tasks, shed light to\ngenerating both ingredients and instructions directly from images.\nNevertheless, LMMs still face the common issue of hallucinations during recipe\ngeneration, leading to suboptimal performance. To tackle this, we propose a\nretrieval augmented large multimodal model for recipe generation. We first\nintroduce Stochastic Diversified Retrieval Augmentation (SDRA) to retrieve\nrecipes semantically related to the image from an existing datastore as a\nsupplement, integrating them into the prompt to add diverse and rich context to\nthe input image. Additionally, Self-Consistency Ensemble Voting mechanism is\nproposed to determine the most confident prediction recipes as the final\noutput. It calculates the consistency among generated recipe candidates, which\nuse different retrieval recipes as context for generation. Extensive\nexperiments validate the effectiveness of our proposed method, which\ndemonstrates state-of-the-art (SOTA) performance in recipe generation tasks on\nthe Recipe1M dataset.\n","authors":["Guoshan Liu","Hailong Yin","Bin Zhu","Jingjing Chen","Chong-Wah Ngo","Yu-Gang Jiang"],"pdf_url":"https://arxiv.org/pdf/2411.08715v1.pdf","comment":"ACCEPT on IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2025"},{"id":"http://arxiv.org/abs/2411.08712v1","updated":"2024-11-13T15:55:05Z","published":"2024-11-13T15:55:05Z","title":"High-resolution optical and acoustic remote sensing datasets of the Puck\n  Lagoon, Southern Baltic","summary":"  The very shallow marine basin of Puck Lagoon in the southern Baltic Sea, on\nthe Northern coast of Poland, hosts valuable benthic habitats and cultural\nheritage sites. These include, among others, protected Zostera marina meadows,\none of the Baltic's major medieval harbours, a ship graveyard, and likely other\nsubmerged features that are yet to be discovered. Prior to this project, no\ncomprehensive high-resolution remote sensing data were available for this area.\nThis article describes the first Digital Elevation Models (DEMs) derived from a\ncombination of airborne bathymetric LiDAR, multibeam echosounder, airborne\nphotogrammetry and satellite imagery. These datasets also include multibeam\nechosounder backscatter and LiDAR intensity, allowing determination of the\ncharacter and properties of the seafloor. Combined, these datasets are a vital\nresource for assessing and understanding seafloor morphology, benthic habitats,\ncultural heritage, and submerged landscapes. Given the significance of Puck\nLagoon's hydrographical, ecological, geological, and archaeological environs,\nthe high-resolution bathymetry, acquired by our project, can provide the\nfoundation for sustainable management and informed decision-making for this\narea of interest.\n","authors":["Łukasz Janowski","Dimitrios Skarlatos","Panagiotis Agrafiotis","Paweł Tysiąc","Andrzej Pydyn","Mateusz Popek","Anna M. Kotarba-Morley","Gottfried Mandlburger","Łukasz Gajewski","Mateusz Kołakowski","Alexandra Papadaki","Juliusz Gajewski"],"pdf_url":"https://arxiv.org/pdf/2411.08712v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.07364v3","updated":"2024-11-13T15:48:08Z","published":"2024-05-12T19:36:11Z","title":"BoQ: A Place is Worth a Bag of Learnable Queries","summary":"  In visual place recognition, accurately identifying and matching images of\nlocations under varying environmental conditions and viewpoints remains a\nsignificant challenge. In this paper, we introduce a new technique, called\nBag-of-Queries (BoQ), which learns a set of global queries designed to capture\nuniversal place-specific attributes. Unlike existing methods that employ\nself-attention and generate the queries directly from the input features, BoQ\nemploys distinct learnable global queries, which probe the input features via\ncross-attention, ensuring consistent information aggregation. In addition, our\ntechnique provides an interpretable attention mechanism and integrates with\nboth CNN and Vision Transformer backbones. The performance of BoQ is\ndemonstrated through extensive experiments on 14 large-scale benchmarks. It\nconsistently outperforms current state-of-the-art techniques including NetVLAD,\nMixVPR and EigenPlaces. Moreover, as a global retrieval technique (one-stage),\nBoQ surpasses two-stage retrieval methods, such as Patch-NetVLAD, TransVPR and\nR2Former, all while being orders of magnitude faster and more efficient. The\ncode and model weights are publicly available at\nhttps://github.com/amaralibey/Bag-of-Queries.\n","authors":["Amar Ali-Bey","Brahim Chaib-draa","Philippe Giguère"],"pdf_url":"https://arxiv.org/pdf/2405.07364v3.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2411.08701v1","updated":"2024-11-13T15:42:28Z","published":"2024-11-13T15:42:28Z","title":"TRACE: Transformer-based Risk Assessment for Clinical Evaluation","summary":"  We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation),\na novel method for clinical risk assessment based on clinical data, leveraging\nthe self-attention mechanism for enhanced feature interaction and result\ninterpretation. Our approach is able to handle different data modalities,\nincluding continuous, categorical and multiple-choice (checkbox) attributes.\nThe proposed architecture features a shared representation of the clinical data\nobtained by integrating specialized embeddings of each data modality, enabling\nthe detection of high-risk individuals using Transformer encoder layers. To\nassess the effectiveness of the proposed method, a strong baseline based on\nnon-negative multi-layer perceptrons (MLPs) is introduced. The proposed method\noutperforms various baselines widely used in the domain of clinical risk\nassessment, while effectively handling missing values. In terms of\nexplainability, our Transformer-based method offers easily interpretable\nresults via attention weights, further enhancing the clinicians'\ndecision-making process.\n","authors":["Dionysis Christopoulos","Sotiris Spanos","Valsamis Ntouskos","Konstantinos Karantzalos"],"pdf_url":"https://arxiv.org/pdf/2411.08701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15339v3","updated":"2024-11-13T15:25:32Z","published":"2024-07-22T02:53:18Z","title":"Deep Learning for Economists","summary":"  Deep learning provides powerful methods to impute structured information from\nlarge-scale, unstructured text and image datasets. For example, economists\nmight wish to detect the presence of economic activity in satellite images, or\nto measure the topics or entities mentioned in social media, the congressional\nrecord, or firm filings. This review introduces deep neural networks, covering\nmethods such as classifiers, regression models, generative AI, and embedding\nmodels. Applications include classification, document digitization, record\nlinkage, and methods for data exploration in massive scale text and image\ncorpora. When suitable methods are used, deep learning models can be cheap to\ntune and can scale affordably to problems involving millions or billions of\ndata points.. The review is accompanied by a companion website, EconDL, with\nuser-friendly demo notebooks, software resources, and a knowledge base that\nprovides technical details and additional applications.\n","authors":["Melissa Dell"],"pdf_url":"https://arxiv.org/pdf/2407.15339v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08666v1","updated":"2024-11-13T14:59:41Z","published":"2024-11-13T14:59:41Z","title":"A Survey on Vision Autoregressive Model","summary":"  Autoregressive models have demonstrated great performance in natural language\nprocessing (NLP) with impressive scalability, adaptability and\ngeneralizability. Inspired by their notable success in NLP field,\nautoregressive models have been intensively investigated recently for computer\nvision, which perform next-token predictions by representing visual data as\nvisual tokens and enables autoregressive modelling for a wide range of vision\ntasks, ranging from visual generation and visual understanding to the very\nrecent multimodal generation that unifies visual generation and understanding\nwith a single autoregressive model. This paper provides a systematic review of\nvision autoregressive models, including the development of a taxonomy of\nexisting methods and highlighting their major contributions, strengths, and\nlimitations, covering various vision tasks such as image generation, video\ngeneration, image editing, motion generation, medical image analysis, 3D\ngeneration, robotic manipulation, unified multimodal generation, etc. Besides,\nwe investigate and analyze the latest advancements in autoregressive models,\nincluding thorough benchmarking and discussion of existing methods across\nvarious evaluation datasets. Finally, we outline key challenges and promising\ndirections for future research, offering a roadmap to guide further\nadvancements in vision autoregressive models.\n","authors":["Kai Jiang","Jiaxing Huang"],"pdf_url":"https://arxiv.org/pdf/2411.08666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08665v1","updated":"2024-11-13T14:59:00Z","published":"2024-11-13T14:59:00Z","title":"OSMLoc: Single Image-Based Visual Localization in OpenStreetMap with\n  Geometric and Semantic Guidances","summary":"  OpenStreetMap (OSM), an online and versatile source of volunteered geographic\ninformation (VGI), is widely used for human self-localization by matching\nnearby visual observations with vectorized map data. However, due to the\ndivergence in modalities and views, image-to-OSM (I2O) matching and\nlocalization remain challenging for robots, preventing the full utilization of\nVGI data in the unmanned ground vehicles and logistic industry. Inspired by the\nfact that the human brain relies on geometric and semantic understanding of\nsensory information for spatial localization tasks, we propose the OSMLoc in\nthis paper. OSMLoc is a brain-inspired single-image visual localization method\nwith semantic and geometric guidance to improve accuracy, robustness, and\ngeneralization ability. First, we equip the OSMLoc with the visual foundational\nmodel to extract powerful image features. Second, a geometry-guided depth\ndistribution adapter is proposed to bridge the monocular depth estimation and\ncamera-to-BEV transform. Thirdly, the semantic embeddings from the OSM data are\nutilized as auxiliary guidance for image-to-OSM feature matching. To validate\nthe proposed OSMLoc, we collect a worldwide cross-area and cross-condition (CC)\nbenchmark for extensive evaluation. Experiments on the MGL dataset, CC\nvalidation benchmark, and KITTI dataset have demonstrated the superiority of\nour method. Code, pre-trained models, CC validation benchmark, and additional\nresults are available on: https://github.com/WHU-USI3DV/OSMLoc\n","authors":["Youqi Liao","Xieyuanli Chen","Shuhao Kang","Jianping Li","Zhen Dong","Hongchao Fan","Bisheng Yang"],"pdf_url":"https://arxiv.org/pdf/2411.08665v1.pdf","comment":"15 pages, technical report"},{"id":"http://arxiv.org/abs/2411.08663v1","updated":"2024-11-13T14:54:47Z","published":"2024-11-13T14:54:47Z","title":"Toward Human Understanding with Controllable Synthesis","summary":"  Training methods to perform robust 3D human pose and shape (HPS) estimation\nrequires diverse training images with accurate ground truth. While BEDLAM\ndemonstrates the potential of traditional procedural graphics to generate such\ndata, the training images are clearly synthetic. In contrast, generative image\nmodels produce highly realistic images but without ground truth. Putting these\nmethods together seems straightforward: use a generative model with the body\nground truth as controlling signal. However, we find that, the more realistic\nthe generated images, the more they deviate from the ground truth, making them\ninappropriate for training and evaluation. Enhancements of realistic details,\nsuch as clothing and facial expressions, can lead to subtle yet significant\ndeviations from the ground truth, potentially misleading training models. We\nempirically verify that this misalignment causes the accuracy of HPS networks\nto decline when trained with generated images. To address this, we design a\ncontrollable synthesis method that effectively balances image realism with\nprecise ground truth. We use this to create the Generative BEDLAM (Gen-B)\ndataset, which improves the realism of the existing synthetic BEDLAM dataset\nwhile preserving ground truth accuracy. We perform extensive experiments, with\nvarious noise-conditioning strategies, to evaluate the tradeoff between visual\nrealism and HPS accuracy. We show, for the first time, that generative image\nmodels can be controlled by traditional graphics methods to produce training\ndata that increases the accuracy of HPS methods.\n","authors":["Hanz Cuevas-Velasquez","Priyanka Patel","Haiwen Feng","Michael Black"],"pdf_url":"https://arxiv.org/pdf/2411.08663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08656v1","updated":"2024-11-13T14:46:41Z","published":"2024-11-13T14:46:41Z","title":"MikuDance: Animating Character Art with Mixed Motion Dynamics","summary":"  We propose MikuDance, a diffusion-based pipeline incorporating mixed motion\ndynamics to animate stylized character art. MikuDance consists of two key\ntechniques: Mixed Motion Modeling and Mixed-Control Diffusion, to address the\nchallenges of high-dynamic motion and reference-guidance misalignment in\ncharacter art animation. Specifically, a Scene Motion Tracking strategy is\npresented to explicitly model the dynamic camera in pixel-wise space, enabling\nunified character-scene motion modeling. Building on this, the Mixed-Control\nDiffusion implicitly aligns the scale and body shape of diverse characters with\nmotion guidance, allowing flexible control of local character motion.\nSubsequently, a Motion-Adaptive Normalization module is incorporated to\neffectively inject global scene motion, paving the way for comprehensive\ncharacter art animation. Through extensive experiments, we demonstrate the\neffectiveness and generalizability of MikuDance across various character art\nand motion guidance, consistently producing high-quality animations with\nremarkable motion dynamics.\n","authors":["Jiaxu Zhang","Xianfang Zeng","Xin Chen","Wei Zuo","Gang Yu","Zhigang Tu"],"pdf_url":"https://arxiv.org/pdf/2411.08656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10534v2","updated":"2024-11-13T14:36:47Z","published":"2024-04-12T21:41:50Z","title":"Into the Fog: Evaluating Robustness of Multiple Object Tracking","summary":"  State-of-the-art Multiple Object Tracking (MOT) approaches have shown\nremarkable performance when trained and evaluated on current benchmarks.\nHowever, these benchmarks primarily consist of clear weather scenarios,\noverlooking adverse atmospheric conditions such as fog, haze, smoke and dust.\nAs a result, the robustness of trackers against these challenging conditions\nremains underexplored. To address this gap, we introduce physics-based\nvolumetric fog simulation method for arbitrary MOT datasets, utilizing\nframe-by-frame monocular depth estimation and a fog formation optical model. We\nenhance our simulation by rendering both homogeneous and heterogeneous fog and\npropose to use the dark channel prior method to estimate atmospheric light,\nshowing promising results even in night and indoor scenes. We present the\nleading benchmark MOTChallenge (third release) augmented with fog (smoke for\nindoor scenes) of various intensities and conduct a comprehensive evaluation of\nMOT methods, revealing their limitations under fog and fog-like challenges.\n","authors":["Nadezda Kirillova","M. Jehanzeb Mirza","Horst Bischof","Horst Possegger"],"pdf_url":"https://arxiv.org/pdf/2404.10534v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08642v1","updated":"2024-11-13T14:32:28Z","published":"2024-11-13T14:32:28Z","title":"Towards More Accurate Fake Detection on Images Generated from Advanced\n  Generative and Neural Rendering Models","summary":"  The remarkable progress in neural-network-driven visual data generation,\nespecially with neural rendering techniques like Neural Radiance Fields and 3D\nGaussian splatting, offers a powerful alternative to GANs and diffusion models.\nThese methods can produce high-fidelity images and lifelike avatars,\nhighlighting the need for robust detection methods. In response, an\nunsupervised training technique is proposed that enables the model to extract\ncomprehensive features from the Fourier spectrum magnitude, thereby overcoming\nthe challenges of reconstructing the spectrum due to its centrosymmetric\nproperties. By leveraging the spectral domain and dynamically combining it with\nspatial domain information, we create a robust multimodal detector that\ndemonstrates superior generalization capabilities in identifying challenging\nsynthetic images generated by the latest image synthesis techniques. To address\nthe absence of a 3D neural rendering-based fake image database, we develop a\ncomprehensive database that includes images generated by diverse neural\nrendering techniques, providing a robust foundation for evaluating and\nadvancing detection methods.\n","authors":["Chengdong Dong","Vijayakumar Bhagavatula","Zhenyu Zhou","Ajay Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.08642v1.pdf","comment":"13 pages, 8 Figures"},{"id":"http://arxiv.org/abs/2402.15322v3","updated":"2024-11-13T14:17:35Z","published":"2024-02-23T13:40:34Z","title":"Optimal Transport on the Lie Group of Roto-translations","summary":"  The roto-translation group SE2 has been of active interest in image analysis\ndue to methods that lift the image data to multi-orientation representations\ndefined on this Lie group. This has led to impactful applications of\ncrossing-preserving flows for image de-noising, geodesic tracking, and\nroto-translation equivariant deep learning. In this paper, we develop a\ncomputational framework for optimal transportation over Lie groups, with a\nspecial focus on SE2. We make several theoretical contributions (generalizable\nto matrix Lie groups) such as the non-optimality of group actions as transport\nmaps, invariance and equivariance of optimal transport, and the quality of the\nentropic-regularized optimal transport plan using geodesic distance\napproximations. We develop a Sinkhorn like algorithm that can be efficiently\nimplemented using fast and accurate distance approximations of the Lie group\nand GPU-friendly group convolutions. We report valuable advancements in the\nexperiments on 1) image barycentric interpolation, 2) interpolation of planar\norientation fields, and 3) Wasserstein gradient flows on SE2. We observe that\nour framework of lifting images to SE2 and optimal transport with\nleft-invariant anisotropic metrics leads to equivariant transport along\ndominant contours and salient line structures in the image. This yields sharper\nand more meaningful interpolations compared to their counterparts on R^2\n","authors":["Daan Bon","Gautam Pai","Gijs Bellaard","Olga Mula","Remco Duits"],"pdf_url":"https://arxiv.org/pdf/2402.15322v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08629v1","updated":"2024-11-13T14:16:22Z","published":"2024-11-13T14:16:22Z","title":"Zero-shot capability of SAM-family models for bone segmentation in CT\n  scans","summary":"  The Segment Anything Model (SAM) and similar models build a family of\npromptable foundation models (FMs) for image and video segmentation. The object\nof interest is identified using prompts, such as bounding boxes or points. With\nthese FMs becoming part of medical image segmentation, extensive evaluation\nstudies are required to assess their strengths and weaknesses in clinical\nsetting. Since the performance is highly dependent on the chosen prompting\nstrategy, it is important to investigate different prompting techniques to\ndefine optimal guidelines that ensure effective use in medical image\nsegmentation. Currently, no dedicated evaluation studies exist specifically for\nbone segmentation in CT scans, leaving a gap in understanding the performance\nfor this task. Thus, we use non-iterative, ``optimal'' prompting strategies\ncomposed of bounding box, points and combinations to test the zero-shot\ncapability of SAM-family models for bone CT segmentation on three different\nskeletal regions. Our results show that the best settings depend on the model\ntype and size, dataset characteristics and objective to optimize. Overall, SAM\nand SAM2 prompted with a bounding box in combination with the center point for\nall the components of an object yield the best results across all tested\nsettings. As the results depend on multiple factors, we provide a guideline for\ninformed decision-making in 2D prompting with non-interactive, ''optimal''\nprompts.\n","authors":["Caroline Magg","Hoel Kervadec","Clara I. Sánchez"],"pdf_url":"https://arxiv.org/pdf/2411.08629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08645v3","updated":"2024-11-13T13:58:39Z","published":"2024-08-16T10:21:13Z","title":"Extracting polygonal footprints in off-nadir images with Segment\n  Anything Model","summary":"  Building Footprint Extraction (BFE) from off-nadir aerial images often\ninvolves roof segmentation and offset prediction to adjust roof boundaries to\nthe building footprint. However, this multi-stage approach typically produces\nlow-quality results, limiting its applicability in real-world data production.\nTo address this issue, we present OBMv2, an end-to-end and promptable model for\npolygonal footprint prediction. Unlike its predecessor OBM, OBMv2 introduces a\nnovel Self Offset Attention (SOFA) mechanism that improves performance across\ndiverse building types, from bungalows to skyscrapers, enabling end-to-end\nfootprint prediction without post-processing. Additionally, we propose a\nMulti-level Information System (MISS) to effectively leverage roof masks,\nbuilding masks, and offsets for accurate footprint prediction. We evaluate\nOBMv2 on the BONAI and OmniCity-view3 datasets and demonstrate its\ngeneralization on the Huizhou test set. The code will be available at\nhttps://github.com/likaiucas/OBMv2.\n","authors":["Kai Li","Yupeng Deng","Jingbo Chen","Yu Meng","Zhihao Xi","Junxian Ma","Chenhao Wang","Xiangyu Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.08645v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08606v1","updated":"2024-11-13T13:46:15Z","published":"2024-11-13T13:46:15Z","title":"LG-Gaze: Learning Geometry-aware Continuous Prompts for Language-Guided\n  Gaze Estimation","summary":"  The ability of gaze estimation models to generalize is often significantly\nhindered by various factors unrelated to gaze, especially when the training\ndataset is limited. Current strategies aim to address this challenge through\ndifferent domain generalization techniques, yet they have had limited success\ndue to the risk of overfitting when solely relying on value labels for\nregression. Recent progress in pre-trained vision-language models has motivated\nus to capitalize on the abundant semantic information available. We propose a\nnovel approach in this paper, reframing the gaze estimation task as a\nvision-language alignment issue. Our proposed framework, named Language-Guided\nGaze Estimation (LG-Gaze), learns continuous and geometry-sensitive features\nfor gaze estimation benefit from the rich prior knowledges of vision-language\nmodels. Specifically, LG-Gaze aligns gaze features with continuous linguistic\nfeatures through our proposed multimodal contrastive regression loss, which\ncustomizes adaptive weights for different negative samples. Furthermore, to\nbetter adapt to the labels for gaze estimation task, we propose a\ngeometry-aware interpolation method to obtain more precise gaze embeddings.\nThrough extensive experiments, we validate the efficacy of our framework in\nfour different cross-domain evaluation tasks.\n","authors":["Pengwei Yin","Jingjing Wang","Guanzhong Zeng","Di Xie","Jiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2411.08606v1.pdf","comment":"Accepted to ECCV 2024"},{"id":"http://arxiv.org/abs/2411.08603v1","updated":"2024-11-13T13:40:27Z","published":"2024-11-13T13:40:27Z","title":"Generalized Pose Space Embeddings for Training In-the-Wild using\n  Anaylis-by-Synthesis","summary":"  Modern pose estimation models are trained on large, manually-labelled\ndatasets which are costly and may not cover the full extent of human poses and\nappearances in the real world. With advances in neural rendering,\nanalysis-by-synthesis and the ability to not only predict, but also render the\npose, is becoming an appealing framework, which could alleviate the need for\nlarge scale manual labelling efforts. While recent work have shown the\nfeasibility of this approach, the predictions admit many flips due to a\nsimplistic intermediate skeleton representation, resulting in low precision and\ninhibiting the acquisition of any downstream knowledge such as\nthree-dimensional positioning. We solve this problem with a more expressive\nintermediate skeleton representation capable of capturing the semantics of the\npose (left and right), which significantly reduces flips. To successfully train\nthis new representation, we extend the analysis-by-synthesis framework with a\ntraining protocol based on synthetic data. We show that our representation\nresults in less flips and more accurate predictions. Our approach outperforms\nprevious models trained with analysis-by-synthesis on standard benchmarks.\n","authors":["Dominik Borer","Jakob Buhmann","Martin Guay"],"pdf_url":"https://arxiv.org/pdf/2411.08603v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08592v1","updated":"2024-11-13T13:19:51Z","published":"2024-11-13T13:19:51Z","title":"Slender Object Scene Segmentation in Remote Sensing Image Based on\n  Learnable Morphological Skeleton with Segment Anything Model","summary":"  Morphological methods play a crucial role in remote sensing image processing,\ndue to their ability to capture and preserve small structural details. However,\nmost of the existing deep learning models for semantic segmentation are based\non the encoder-decoder architecture including U-net and Segment Anything Model\n(SAM), where the downsampling process tends to discard fine details. In this\npaper, we propose a new approach that integrates learnable morphological\nskeleton prior into deep neural networks using the variational method. To\naddress the difficulty in backpropagation in neural networks caused by the\nnon-differentiability presented in classical morphological operations, we\nprovide a smooth representation of the morphological skeleton and design a\nvariational segmentation model integrating morphological skeleton prior by\nemploying operator splitting and dual methods. Then, we integrate this model\ninto the network architecture of SAM, which is achieved by adding a token to\nmask decoder and modifying the final sigmoid layer, ensuring the final\nsegmentation results preserve the skeleton structure as much as possible.\nExperimental results on remote sensing datasets, including buildings and roads,\ndemonstrate that our method outperforms the original SAM on slender object\nsegmentation and exhibits better generalization capability.\n","authors":["Jun Xie","Wenxiao Li","Faqiang Wang","Liqiang Zhang","Zhengyang Hou","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2411.08592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08579v1","updated":"2024-11-13T12:51:49Z","published":"2024-11-13T12:51:49Z","title":"NavAgent: Multi-scale Urban Street View Fusion For UAV Embodied\n  Vision-and-Language Navigation","summary":"  Vision-and-Language Navigation (VLN), as a widely discussed research\ndirection in embodied intelligence, aims to enable embodied agents to navigate\nin complicated visual environments through natural language commands. Most\nexisting VLN methods focus on indoor ground robot scenarios. However, when\napplied to UAV VLN in outdoor urban scenes, it faces two significant\nchallenges. First, urban scenes contain numerous objects, which makes it\nchallenging to match fine-grained landmarks in images with complex textual\ndescriptions of these landmarks. Second, overall environmental information\nencompasses multiple modal dimensions, and the diversity of representations\nsignificantly increases the complexity of the encoding process. To address\nthese challenges, we propose NavAgent, the first urban UAV embodied navigation\nmodel driven by a large Vision-Language Model. NavAgent undertakes navigation\ntasks by synthesizing multi-scale environmental information, including\ntopological maps (global), panoramas (medium), and fine-grained landmarks\n(local). Specifically, we utilize GLIP to build a visual recognizer for\nlandmark capable of identifying and linguisticizing fine-grained landmarks.\nSubsequently, we develop dynamically growing scene topology map that integrate\nenvironmental information and employ Graph Convolutional Networks to encode\nglobal environmental data. In addition, to train the visual recognizer for\nlandmark, we develop NavAgent-Landmark2K, the first fine-grained landmark\ndataset for real urban street scenes. In experiments conducted on the Touchdown\nand Map2seq datasets, NavAgent outperforms strong baseline models. The code and\ndataset will be released to the community to facilitate the exploration and\ndevelopment of outdoor VLN.\n","authors":["Youzhi Liu","Fanglong Yao","Yuanchang Yue","Guangluan Xu","Xian Sun","Kun Fu"],"pdf_url":"https://arxiv.org/pdf/2411.08579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07743v3","updated":"2024-11-13T12:43:33Z","published":"2023-06-13T13:00:10Z","title":"V-LoL: A Diagnostic Dataset for Visual Logical Learning","summary":"  Despite the successes of recent developments in visual AI, different\nshortcomings still exist; from missing exact logical reasoning, to abstract\ngeneralization abilities, to understanding complex and noisy scenes.\nUnfortunately, existing benchmarks, were not designed to capture more than a\nfew of these aspects. Whereas deep learning datasets focus on visually complex\ndata but simple visual reasoning tasks, inductive logic datasets involve\ncomplex logical learning tasks, however, lack the visual component. To address\nthis, we propose the diagnostic visual logical learning dataset, V-LoL, that\nseamlessly combines visual and logical challenges. Notably, we introduce the\nfirst instantiation of V-LoL, V-LoL-Train, - a visual rendition of a classic\nbenchmark in symbolic AI, the Michalski train problem. By incorporating\nintricate visual scenes and flexible logical reasoning tasks within a versatile\nframework, V-LoL-Train provides a platform for investigating a wide range of\nvisual logical learning challenges. We evaluate a variety of AI systems\nincluding traditional symbolic AI, neural AI, as well as neuro-symbolic AI. Our\nevaluations demonstrate that even SOTA AI faces difficulties in dealing with\nvisual logical learning challenges, highlighting unique advantages and\nlimitations of each methodology. Overall, V-LoL opens up new avenues for\nunderstanding and enhancing current abilities in visual logical learning for AI\nsystems.\n","authors":["Lukas Helff","Wolfgang Stammer","Hikaru Shindo","Devendra Singh Dhami","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2306.07743v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08569v1","updated":"2024-11-13T12:29:44Z","published":"2024-11-13T12:29:44Z","title":"UIFormer: A Unified Transformer-based Framework for Incremental Few-Shot\n  Object Detection and Instance Segmentation","summary":"  This paper introduces a novel framework for unified incremental few-shot\nobject detection (iFSOD) and instance segmentation (iFSIS) using the\nTransformer architecture. Our goal is to create an optimal solution for\nsituations where only a few examples of novel object classes are available,\nwith no access to training data for base or old classes, while maintaining high\nperformance across both base and novel classes. To achieve this, We extend\nMask-DINO into a two-stage incremental learning framework. Stage 1 focuses on\noptimizing the model using the base dataset, while Stage 2 involves fine-tuning\nthe model on novel classes. Besides, we incorporate a classifier selection\nstrategy that assigns appropriate classifiers to the encoder and decoder\naccording to their distinct functions. Empirical evidence indicates that this\napproach effectively mitigates the over-fitting on novel classes learning.\nFurthermore, we implement knowledge distillation to prevent catastrophic\nforgetting of base classes. Comprehensive evaluations on the COCO and LVIS\ndatasets for both iFSIS and iFSOD tasks demonstrate that our method\nsignificantly outperforms state-of-the-art approaches.\n","authors":["Chengyuan Zhang","Yilin Zhang","Lei Zhu","Deyin Liu","Lin Wu","Bo Li","Shichao Zhang","Mohammed Bennamoun","Farid Boussaid"],"pdf_url":"https://arxiv.org/pdf/2411.08569v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.10929v4","updated":"2024-11-13T12:27:38Z","published":"2024-10-14T16:35:27Z","title":"ASTM :Autonomous Smart Traffic Management System Using Artificial\n  Intelligence CNN and LSTM","summary":"  In the modern world, the development of Artificial Intelligence (AI) has\ncontributed to improvements in various areas, including automation, computer\nvision, fraud detection, and more. AI can be leveraged to enhance the\nefficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce\ntraffic congestion rates. This paper presents an Autonomous Smart Traffic\nManagement (STM) system that uses AI to improve traffic flow rates. The system\nemploys the YOLO V5 Convolutional Neural Network to detect vehicles in traffic\nmanagement images. Additionally, it predicts the number of vehicles for the\nnext 12 hours using a Recurrent Neural Network with Long Short-Term Memory\n(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the\ntraffic cycle length based on these vehicle predictions, aided by AI. From the\nresults of the RNN-LSTM model for predicting vehicle numbers over the next 12\nhours, we observe that the model predicts traffic with a Mean Squared Error\n(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.\nAfter simulating the STM system in the CARLA simulation environment, we found\nthat the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per\nminute) is 50\\% higher than the rate without STM (around 15 vehicles per\nminute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5\nseconds per vehicle) is 70\\% lower than without STM (around 12 seconds per\nvehicle). These results demonstrate that the STM system using AI can increase\ntraffic flow by 50\\% and reduce vehicle pass delays by 70\\%.\n","authors":["Christofel Rio Goenawan"],"pdf_url":"https://arxiv.org/pdf/2410.10929v4.pdf","comment":"In process to IEEE Intelligent Vehicle Symposium 2025"},{"id":"http://arxiv.org/abs/2411.08567v1","updated":"2024-11-13T12:27:21Z","published":"2024-11-13T12:27:21Z","title":"Saliency Map-based Image Retrieval using Invariant Krawtchouk Moments","summary":"  With the widespread adoption of digital devices equipped with cameras and the\nrapid development of Internet technology, numerous content-based image\nretrieval systems and novel image feature extraction techniques have emerged in\nrecent years. This paper introduces a saliency map-based image retrieval\napproach using invariant Krawtchouk moments (SM-IKM) to enhance retrieval speed\nand accuracy. The proposed method applies a global contrast-based salient\nregion detection algorithm to create a saliency map that effectively isolates\nthe foreground from the background. It then combines multiple orders of\ninvariant Krawtchouk moments (IKM) with local binary patterns (LBPs) and color\nhistograms to comprehensively represent the foreground and background.\nAdditionally, it incorporates LBPs derived from the saliency map to improve\ndiscriminative power, facilitating more precise image differentiation. A\nbag-of-visual-words (BoVW) model is employed to generate a codebook for\nclassification and discrimination. By using compact IKMs in the BoVW framework\nand integrating a range of region-based feature-including color histograms,\nLBPs, and saliency map-enhanced LBPs, our proposed SM-IKM achieves efficient\nand accurate image retrieval. xtensive experiments on publicly available\ndatasets, such as Caltech 101 and Wang, demonstrate that SM-IKM outperforms\nrecent state-of-the-art retrieval methods. The source code for SM-IKM is\navailable at github.com/arnejad/SMIKM.\n","authors":["Ashkan Nejad","Mohammad Reza Faraji","Xiaojun Qi"],"pdf_url":"https://arxiv.org/pdf/2411.08567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18723v2","updated":"2024-11-13T12:02:29Z","published":"2024-10-24T13:28:40Z","title":"VoxelKeypointFusion: Generalizable Multi-View Multi-Person Pose\n  Estimation","summary":"  In the rapidly evolving field of computer vision, the task of accurately\nestimating the poses of multiple individuals from various viewpoints presents a\nformidable challenge, especially if the estimations should be reliable as well.\nThis work presents an extensive evaluation of the generalization capabilities\nof multi-view multi-person pose estimators to unseen datasets and presents a\nnew algorithm with strong performance in this task. It also studies the\nimprovements by additionally using depth information. Since the new approach\ncan not only generalize well to unseen datasets, but also to different\nkeypoints, the first multi-view multi-person whole-body estimator is presented.\nTo support further research on those topics, all of the work is publicly\naccessible.\n","authors":["Daniel Bermuth","Alexander Poeppel","Wolfgang Reif"],"pdf_url":"https://arxiv.org/pdf/2410.18723v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08545v1","updated":"2024-11-13T11:46:42Z","published":"2024-11-13T11:46:42Z","title":"APDDv2: Aesthetics of Paintings and Drawings Dataset with Artist Labeled\n  Scores and Comments","summary":"  Datasets play a pivotal role in training visual models, facilitating the\ndevelopment of abstract understandings of visual features through diverse image\nsamples and multidimensional attributes. However, in the realm of aesthetic\nevaluation of artistic images, datasets remain relatively scarce. Existing\npainting datasets are often characterized by limited scoring dimensions and\ninsufficient annotations, thereby constraining the advancement and application\nof automatic aesthetic evaluation methods in the domain of painting. To bridge\nthis gap, we introduce the Aesthetics Paintings and Drawings Dataset (APDD),\nthe first comprehensive collection of paintings encompassing 24 distinct\nartistic categories and 10 aesthetic attributes. Building upon the initial\nrelease of APDDv1, our ongoing research has identified opportunities for\nenhancement in data scale and annotation precision. Consequently, APDDv2 boasts\nan expanded image corpus and improved annotation quality, featuring detailed\nlanguage comments to better cater to the needs of both researchers and\npractitioners seeking high-quality painting datasets. Furthermore, we present\nan updated version of the Art Assessment Network for Specific Painting Styles,\ndenoted as ArtCLIP. Experimental validation demonstrates the superior\nperformance of this revised model in the realm of aesthetic evaluation,\nsurpassing its predecessor in accuracy and efficacy. The dataset and model are\navailable at https://github.com/BestiVictory/APDDv2.git.\n","authors":["Xin Jin","Qianqian Qiao","Yi Lu","Huaye Wang","Heng Huang","Shan Gao","Jianfei Liu","Rui Li"],"pdf_url":"https://arxiv.org/pdf/2411.08545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01555v2","updated":"2024-11-13T11:44:10Z","published":"2024-02-02T16:47:18Z","title":"SLYKLatent: A Learning Framework for Gaze Estimation Using Deep Facial\n  Feature Learning","summary":"  In this research, we present SLYKLatent, a novel approach for enhancing gaze\nestimation by addressing appearance instability challenges in datasets due to\naleatoric uncertainties, covariant shifts, and test domain generalization.\nSLYKLatent utilizes Self-Supervised Learning for initial training with facial\nexpression datasets, followed by refinement with a patch-based tri-branch\nnetwork and an inverse explained variance-weighted training loss function. Our\nevaluation on benchmark datasets achieves a 10.9% improvement on Gaze360,\nsupersedes top MPIIFaceGaze results with 3.8%, and leads on a subset of\nETH-XGaze by 11.6%, surpassing existing methods by significant margins.\nAdaptability tests on RAF-DB and Affectnet show 86.4% and 60.9% accuracies,\nrespectively. Ablation studies confirm the effectiveness of SLYKLatent's novel\ncomponents.\n","authors":["Samuel Adebayo","Joost C. Dessing","Seán McLoone"],"pdf_url":"https://arxiv.org/pdf/2402.01555v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08537v1","updated":"2024-11-13T11:35:39Z","published":"2024-11-13T11:35:39Z","title":"MLV$^2$-Net: Rater-Based Majority-Label Voting for Consistent Meningeal\n  Lymphatic Vessel Segmentation","summary":"  Meningeal lymphatic vessels (MLVs) are responsible for the drainage of waste\nproducts from the human brain. An impairment in their functionality has been\nassociated with aging as well as brain disorders like multiple sclerosis and\nAlzheimer's disease. However, MLVs have only recently been described for the\nfirst time in magnetic resonance imaging (MRI), and their ramified structure\nrenders manual segmentation particularly difficult. Further, as there is no\nconsistent notion of their appearance, human-annotated MLV structures contain a\nhigh inter-rater variability that most automatic segmentation methods cannot\ntake into account. In this work, we propose a new rater-aware training scheme\nfor the popular nnU-Net model, and we explore rater-based ensembling strategies\nfor accurate and consistent segmentation of MLVs. This enables us to boost\nnnU-Net's performance while obtaining explicit predictions in different\nannotation styles and a rater-based uncertainty estimation. Our final model,\nMLV$^2$-Net, achieves a Dice similarity coefficient of 0.806 with respect to\nthe human reference standard. The model further matches the human inter-rater\nreliability and replicates age-related associations with MLV volume.\n","authors":["Fabian Bongratz","Markus Karmann","Adrian Holz","Moritz Bonhoeffer","Viktor Neumaier","Sarah Deli","Benita Schmitz-Koep","Claus Zimmer","Christian Sorg","Melissa Thalhammer","Dennis M Hedderich","Christian Wachinger"],"pdf_url":"https://arxiv.org/pdf/2411.08537v1.pdf","comment":"ML4H 2024"},{"id":"http://arxiv.org/abs/2411.08531v1","updated":"2024-11-13T11:25:26Z","published":"2024-11-13T11:25:26Z","title":"Classification and Morphological Analysis of DLBCL Subtypes in\n  H\\&E-Stained Slides","summary":"  We address the challenge of automated classification of diffuse large B-cell\nlymphoma (DLBCL) into its two primary subtypes: activated B-cell-like (ABC) and\ngerminal center B-cell-like (GCB). Accurate classification between these\nsubtypes is essential for determining the appropriate therapeutic strategy,\ngiven their distinct molecular profiles and treatment responses. Our proposed\ndeep learning model demonstrates robust performance, achieving an average area\nunder the curve (AUC) of (87.4 pm 5.7)\\% during cross-validation. It shows a\nhigh positive predictive value (PPV), highlighting its potential for clinical\napplication, such as triaging for molecular testing. To gain biological\ninsights, we performed an analysis of morphological features of ABC and GCB\nsubtypes. We segmented cell nuclei using a pre-trained deep neural network and\ncompared the statistics of geometric and color features for ABC and GCB. We\nfound that the distributions of these features were not very different for the\ntwo subtypes, which suggests that the visual differences between them are more\nsubtle. These results underscore the potential of our method to assist in more\nprecise subtype classification and can contribute to improved treatment\nmanagement and outcomes for patients of DLBCL.\n","authors":["Ravi Kant Gupta","Mohit Jindal","Garima Jain","Epari Sridhar","Subhash Yadav","Hasmukh Jain","Tanuja Shet","Uma Sakhdeo","Manju Sengar","Lingaraj Nayak","Bhausaheb Bagal","Umesh Apkare","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2411.08531v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08530v1","updated":"2024-11-13T11:24:12Z","published":"2024-11-13T11:24:12Z","title":"Efficient Whole Slide Image Classification through Fisher Vector\n  Representation","summary":"  The advancement of digital pathology, particularly through computational\nanalysis of whole slide images (WSI), is poised to significantly enhance\ndiagnostic precision and efficiency. However, the large size and complexity of\nWSIs make it difficult to analyze and classify them using computers. This study\nintroduces a novel method for WSI classification by automating the\nidentification and examination of the most informative patches, thus\neliminating the need to process the entire slide. Our method involves\ntwo-stages: firstly, it extracts only a few patches from the WSIs based on\ntheir pathological significance; and secondly, it employs Fisher vectors (FVs)\nfor representing features extracted from these patches, which is known for its\nrobustness in capturing fine-grained details. This approach not only\naccentuates key pathological features within the WSI representation but also\nsignificantly reduces computational overhead, thus making the process more\nefficient and scalable. We have rigorously evaluated the proposed method across\nmultiple datasets to benchmark its performance against comprehensive WSI\nanalysis and contemporary weakly-supervised learning methodologies. The\nempirical results indicate that our focused analysis of select patches,\ncombined with Fisher vector representation, not only aligns with, but at times\nsurpasses, the classification accuracy of standard practices. Moreover, this\nstrategy notably diminishes computational load and resource expenditure,\nthereby establishing an efficient and precise framework for WSI analysis in the\nrealm of digital pathology.\n","authors":["Ravi Kant Gupta","Dadi Dharani","Shambhavi Shanker","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2411.08530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19006v4","updated":"2024-11-13T10:56:14Z","published":"2024-06-27T08:45:31Z","title":"Snakes and Ladders: Two Steps Up for VideoMamba","summary":"  Video understanding requires the extraction of rich spatio-temporal\nrepresentations, which transformer models achieve through self-attention.\nUnfortunately, self-attention poses a computational burden. In NLP, Mamba has\nsurfaced as an efficient alternative for transformers. However, Mamba's\nsuccesses do not trivially extend to vision tasks, including those in video\nanalysis. In this paper, we theoretically analyze the differences between\nself-attention and Mamba. We identify two limitations in Mamba's token\nprocessing: historical decay and element contradiction. We propose\nVideoMambaPro (VMP) that solves the identified limitations by adding masked\nbackward computation and elemental residual connections to a VideoMamba\nbackbone. Differently sized VideoMambaPro models surpass VideoMamba by 1.6-2.8%\nand 1.1-1.9% top-1 on Kinetics-400 and Something-Something V2, respectively.\nEven without extensive pre-training, our models present an increasingly\nattractive and efficient alternative to current transformer models. Moreover,\nour two solutions are orthogonal to recent advances in Vision Mamba models, and\nare likely to provide further improvements in future models.\n","authors":["Hui Lu","Albert Ali Salah","Ronald Poppe"],"pdf_url":"https://arxiv.org/pdf/2406.19006v4.pdf","comment":"New updated experiment results"},{"id":"http://arxiv.org/abs/2411.08508v1","updated":"2024-11-13T10:43:39Z","published":"2024-11-13T10:43:39Z","title":"BillBoard Splatting (BBSplat): Learnable Textured Primitives for Novel\n  View Synthesis","summary":"  We present billboard Splatting (BBSplat) - a novel approach for 3D scene\nrepresentation based on textured geometric primitives. BBSplat represents the\nscene as a set of optimizable textured planar primitives with learnable RGB\ntextures and alpha-maps to control their shape. BBSplat primitives can be used\nin any Gaussian Splatting pipeline as drop-in replacements for Gaussians. Our\nmethod's qualitative and quantitative improvements over 3D and 2D Gaussians are\nmost noticeable when fewer primitives are used, when BBSplat achieves over 1200\nFPS. Our novel regularization term encourages textures to have a sparser\nstructure, unlocking an efficient compression that leads to a reduction in\nstorage space of the model. Our experiments show the efficiency of BBSplat on\nstandard datasets of real indoor and outdoor scenes such as Tanks&Temples, DTU,\nand Mip-NeRF-360. We demonstrate improvements on PSNR, SSIM, and LPIPS metrics\ncompared to the state-of-the-art, especially for the case when fewer primitives\nare used, which, on the other hand, leads to up to 2 times inference speed\nimprovement for the same rendering quality.\n","authors":["David Svitov","Pietro Morerio","Lourdes Agapito","Alessio Del Bue"],"pdf_url":"https://arxiv.org/pdf/2411.08508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07940v2","updated":"2024-11-13T10:29:51Z","published":"2024-11-12T17:09:20Z","title":"Automatic dataset shift identification to support root cause analysis of\n  AI performance drift","summary":"  Shifts in data distribution can substantially harm the performance of\nclinical AI models. Hence, various methods have been developed to detect the\npresence of such shifts at deployment time. However, root causes of dataset\nshifts are varied, and the choice of shift mitigation strategies is highly\ndependent on the precise type of shift encountered at test time. As such,\ndetecting test-time dataset shift is not sufficient: precisely identifying\nwhich type of shift has occurred is critical. In this work, we propose the\nfirst unsupervised dataset shift identification framework, effectively\ndistinguishing between prevalence shift (caused by a change in the label\ndistribution), covariate shift (caused by a change in input characteristics)\nand mixed shifts (simultaneous prevalence and covariate shifts). We discuss the\nimportance of self-supervised encoders for detecting subtle covariate shifts\nand propose a novel shift detector leveraging both self-supervised encoders and\ntask model outputs for improved shift detection. We report promising results\nfor the proposed shift identification framework across three different imaging\nmodalities (chest radiography, digital mammography, and retinal fundus images)\non five types of real-world dataset shifts, using four large publicly available\ndatasets.\n","authors":["Mélanie Roschewitz","Raghav Mehta","Charles Jones","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2411.07940v2.pdf","comment":"Code available at\n  https://github.com/biomedia-mira/shift_identification"},{"id":"http://arxiv.org/abs/2312.06978v4","updated":"2024-11-13T10:29:01Z","published":"2023-12-12T04:38:30Z","title":"CLASS-M: Adaptive stain separation-based contrastive learning with\n  pseudo-labeling for histopathological image classification","summary":"  Histopathological image classification is an important task in medical image\nanalysis. Recent approaches generally rely on weakly supervised learning due to\nthe ease of acquiring case-level labels from pathology reports. However,\npatch-level classification is preferable in applications where only a limited\nnumber of cases are available or when local prediction accuracy is critical. On\nthe other hand, acquiring extensive datasets with localized labels for training\nis not feasible. In this paper, we propose a semi-supervised patch-level\nhistopathological image classification model, named CLASS-M, that does not\nrequire extensively labeled datasets. CLASS-M is formed by two main parts: a\ncontrastive learning module that uses separated Hematoxylin and Eosin images\ngenerated through an adaptive stain separation process, and a module with\npseudo-labels using MixUp. We compare our model with other state-of-the-art\nmodels on two clear cell renal cell carcinoma datasets. We demonstrate that our\nCLASS-M model has the best performance on both datasets. Our code is available\nat github.com/BzhangURU/Paper_CLASS-M/tree/main\n","authors":["Bodong Zhang","Hamid Manoochehri","Man Minh Ho","Fahimeh Fooladgar","Yosep Chong","Beatrice S. Knudsen","Deepika Sirohi","Tolga Tasdizen"],"pdf_url":"https://arxiv.org/pdf/2312.06978v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08490v1","updated":"2024-11-13T10:15:27Z","published":"2024-11-13T10:15:27Z","title":"Impact of Iris Pigmentation on Performance Bias in Visible Iris\n  Verification Systems: A Comparative Study","summary":"  Iris recognition technology plays a critical role in biometric identification\nsystems, but their performance can be affected by variations in iris\npigmentation. In this work, we investigate the impact of iris pigmentation on\nthe efficacy of biometric recognition systems, focusing on a comparative\nanalysis of blue and dark irises. Data sets were collected using multiple\ndevices, including P1, P2, and P3 smartphones [4], to assess the robustness of\nthe systems in different capture environments [19]. Both traditional machine\nlearning techniques and deep learning models were used, namely Open-Iris,\nViT-b, and ResNet50, to evaluate performance metrics such as Equal Error Rate\n(EER) and True Match Rate (TMR). Our results indicate that iris recognition\nsystems generally exhibit higher accuracy for blue irises compared to dark\nirises. Furthermore, we examined the generalization capabilities of these\nsystems across different iris colors and devices, finding that while training\non diverse datasets enhances recognition performance, the degree of improvement\nis contingent on the specific model and device used. Our analysis also\nidentifies inherent biases in recognition performance related to iris color and\ncross-device variability. These findings underscore the need for more inclusive\ndataset collection and model refinement to reduce bias and promote equitable\nbiometric recognition across varying iris pigmentation and device\nconfigurations.\n","authors":["Geetanjali Sharma","Abhishek Tandon","Gaurav Jaswal","Aditya Nigam","Raghavendra Ramachandra"],"pdf_url":"https://arxiv.org/pdf/2411.08490v1.pdf","comment":"14 pages, 5 figures, 5 Tables"},{"id":"http://arxiv.org/abs/2411.08488v1","updated":"2024-11-13T10:13:23Z","published":"2024-11-13T10:13:23Z","title":"UNSCT-HRNet: Modeling Anatomical Uncertainty for Landmark Detection in\n  Total Hip Arthroplasty","summary":"  Total hip arthroplasty (THA) relies on accurate landmark detection from\nradiographic images, but unstructured data caused by irregular patient postures\nor occluded anatomical markers pose significant challenges for existing\nmethods. To address this, we propose UNSCT-HRNet (Unstructured CT -\nHigh-Resolution Net), a deep learning-based framework that integrates a Spatial\nRelationship Fusion (SRF) module and an Uncertainty Estimation (UE) module. The\nSRF module, utilizing coordinate convolution and polarized attention, enhances\nthe model's ability to capture complex spatial relationships. Meanwhile, the UE\nmodule which based on entropy ensures predictions are anatomically relevant.\nFor unstructured data, the proposed method can predict landmarks without\nrelying on the fixed number of points, which shows higher accuracy and better\nrobustness comparing with the existing methods. Our UNSCT-HRNet demonstrates\nover a 60% improvement across multiple metrics in unstructured data. The\nexperimental results also reveal that our approach maintains good performance\non the structured dataset. Overall, the proposed UNSCT-HRNet has the potential\nto be used as a new reliable, automated solution for THA surgical planning and\npostoperative monitoring.\n","authors":["Jiaxin Wan","Lin Liu","Haoran Wang","Liangwei Li","Wei Li","Shuheng Kou","Runtian Li","Jiayi Tang","Juanxiu Liu","Jing Zhang","Xiaohui Du","Ruqian Hao"],"pdf_url":"https://arxiv.org/pdf/2411.08488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08482v1","updated":"2024-11-13T10:01:33Z","published":"2024-11-13T10:01:33Z","title":"Methodology for a Statistical Analysis of Influencing Factors on 3D\n  Object Detection Performance","summary":"  In autonomous driving, object detection is an essential task to perceive the\nenvironment by localizing and classifying objects. Most object detection\nalgorithms rely on deep learning for their superior performance. However, their\nblack box nature makes it challenging to ensure safety. In this paper, we\npropose a first-of-its-kind methodology for statistical analysis of the\ninfluence of various factors related to the objects to detect or the\nenvironment on the detection performance of both LiDAR- and camera-based 3D\nobject detectors. We perform a univariate analysis between each of the factors\nand the detection error in order to compare the strength of influence. To\nbetter identify potential sources of detection errors, we also analyze the\nperformance in dependency of the influencing factors and examine the\ninterdependencies between the different influencing factors. Recognizing the\nfactors that influence detection performance helps identify robustness issues\nin the trained object detector and supports the safety approval of object\ndetection systems.\n","authors":["Anton Kuznietsov","Dirk Schweickard","Steven Peters"],"pdf_url":"https://arxiv.org/pdf/2411.08482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17804v3","updated":"2024-11-13T09:50:48Z","published":"2024-06-22T15:24:33Z","title":"A Review of Electromagnetic Elimination Methods for low-field portable\n  MRI scanner","summary":"  This paper analyzes conventional and deep learning methods for eliminating\nelectromagnetic interference (EMI) in MRI systems. We compare traditional\nanalytical and adaptive techniques with advanced deep learning approaches. Key\nstrengths and limitations of each method are highlighted. Recent advancements\nin active EMI elimination, such as external EMI receiver coils, are discussed\nalongside deep learning methods, which show superior EMI suppression by\nleveraging neural networks trained on MRI data. While deep learning improves\nEMI elimination and diagnostic capabilities, it introduces security and safety\nconcerns, particularly in commercial applications. A balanced approach,\nintegrating conventional reliability with deep learning's advanced\ncapabilities, is proposed for more effective EMI suppression in MRI systems.\n","authors":["Wanyu Bian","Panfeng Li","Mengyao Zheng","Chihang Wang","Anying Li","Ying Li","Haowei Ni","Zixuan Zeng"],"pdf_url":"https://arxiv.org/pdf/2406.17804v3.pdf","comment":"Accepted by 2024 5th International Conference on Machine Learning and\n  Computer Application"},{"id":"http://arxiv.org/abs/2411.08472v1","updated":"2024-11-13T09:46:08Z","published":"2024-11-13T09:46:08Z","title":"A survey on Graph Deep Representation Learning for Facial Expression\n  Recognition","summary":"  This comprehensive review delves deeply into the various methodologies\napplied to facial expression recognition (FER) through the lens of graph\nrepresentation learning (GRL). Initially, we introduce the task of FER and the\nconcepts of graph representation and GRL. Afterward, we discuss some of the\nmost prevalent and valuable databases for this task. We explore promising\napproaches for graph representation in FER, including graph diffusion,\nspatio-temporal graphs, and multi-stream architectures. Finally, we identify\nfuture research opportunities and provide concluding remarks.\n","authors":["Théo Gueuret","Akrem Sellami","Chaabane Djeraba"],"pdf_url":"https://arxiv.org/pdf/2411.08472v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08470v1","updated":"2024-11-13T09:42:12Z","published":"2024-11-13T09:42:12Z","title":"HyperFace: Generating Synthetic Face Recognition Datasets by Exploring\n  Face Embedding Hypersphere","summary":"  Face recognition datasets are often collected by crawling Internet and\nwithout individuals' consents, raising ethical and privacy concerns. Generating\nsynthetic datasets for training face recognition models has emerged as a\npromising alternative. However, the generation of synthetic datasets remains\nchallenging as it entails adequate inter-class and intra-class variations.\nWhile advances in generative models have made it easier to increase intra-class\nvariations in face datasets (such as pose, illumination, etc.), generating\nsufficient inter-class variation is still a difficult task. In this paper, we\nformulate the dataset generation as a packing problem on the embedding space\n(represented on a hypersphere) of a face recognition model and propose a new\nsynthetic dataset generation approach, called HyperFace. We formalize our\npacking problem as an optimization problem and solve it with a gradient\ndescent-based approach. Then, we use a conditional face generator model to\nsynthesize face images from the optimized embeddings. We use our generated\ndatasets to train face recognition models and evaluate the trained models on\nseveral benchmarking real datasets. Our experimental results show that models\ntrained with HyperFace achieve state-of-the-art performance in training face\nrecognition using synthetic datasets.\n","authors":["Hatef Otroshi Shahreza","Sébastien Marcel"],"pdf_url":"https://arxiv.org/pdf/2411.08470v1.pdf","comment":"Accepted in NeurIPS 2024 Safe Generative AI Workshop"},{"id":"http://arxiv.org/abs/2406.16439v4","updated":"2024-11-13T09:41:00Z","published":"2024-06-24T08:30:03Z","title":"Exploring Test-Time Adaptation for Object Detection in Continually\n  Changing Environments","summary":"  Real-world application models are commonly deployed in dynamic environments,\nwhere the target domain distribution undergoes temporal changes. Continual\nTest-Time Adaptation (CTTA) has recently emerged as a promising technique to\ngradually adapt a source-trained model to continually changing target domains.\nDespite recent advancements in addressing CTTA, two critical issues remain: 1)\nFixed thresholds for pseudo-labeling in existing methodologies lead to\nlow-quality pseudo-labels, as model confidence varies across categories and\ndomains; 2) Stochastic parameter restoration methods for mitigating\ncatastrophic forgetting fail to preserve critical information effectively, due\nto their intrinsic randomness. To tackle these challenges for detection models\nin CTTA scenarios, we present AMROD, featuring three core components. Firstly,\nthe object-level contrastive learning module extracts object-level features for\ncontrastive learning to refine the feature representation in the target domain.\nSecondly, the adaptive monitoring module dynamically skips unnecessary\nadaptation and updates the category-specific threshold based on predicted\nconfidence scores to enable efficiency and improve the quality of\npseudo-labels. Lastly, the adaptive randomized restoration mechanism\nselectively reset inactive parameters with higher possibilities, ensuring the\nretention of essential knowledge. We demonstrate the effectiveness of AMROD on\nfour CTTA object detection tasks, where AMROD outperforms existing methods,\nespecially achieving a 3.2 mAP improvement and a 20% increase in efficiency on\nthe Cityscapes-to-Cityscapes-C CTTA task. The code will be released.\n","authors":["Shilei Cao","Yan Liu","Juepeng Zheng","Weijia Li","Runmin Dong","Haohuan Fu"],"pdf_url":"https://arxiv.org/pdf/2406.16439v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08466v1","updated":"2024-11-13T09:37:24Z","published":"2024-11-13T09:37:24Z","title":"Can MLLMs Guide Weakly-Supervised Temporal Action Localization Tasks?","summary":"  Recent breakthroughs in Multimodal Large Language Models (MLLMs) have gained\nsignificant recognition within the deep learning community, where the fusion of\nthe Video Foundation Models (VFMs) and Large Language Models(LLMs) has proven\ninstrumental in constructing robust video understanding systems, effectively\nsurmounting constraints associated with predefined visual tasks. These\nsophisticated MLLMs exhibit remarkable proficiency in comprehending videos,\nswiftly attaining unprecedented performance levels across diverse benchmarks.\nHowever, their operation demands substantial memory and computational\nresources, underscoring the continued importance of traditional models in video\ncomprehension tasks. In this paper, we introduce a novel learning paradigm\ntermed MLLM4WTAL. This paradigm harnesses the potential of MLLM to offer\ntemporal action key semantics and complete semantic priors for conventional\nWeakly-supervised Temporal Action Localization (WTAL) methods. MLLM4WTAL\nfacilitates the enhancement of WTAL by leveraging MLLM guidance. It achieves\nthis by integrating two distinct modules: Key Semantic Matching (KSM) and\nComplete Semantic Reconstruction (CSR). These modules work in tandem to\neffectively address prevalent issues like incomplete and over-complete outcomes\ncommon in WTAL methods. Rigorous experiments are conducted to validate the\nefficacy of our proposed approach in augmenting the performance of various\nheterogeneous WTAL models.\n","authors":["Quan Zhang","Yuxin Qi"],"pdf_url":"https://arxiv.org/pdf/2411.08466v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06098v2","updated":"2024-11-13T09:31:14Z","published":"2024-11-09T07:19:56Z","title":"LT-DARTS: An Architectural Approach to Enhance Deep Long-Tailed Learning","summary":"  Deep long-tailed recognition has been widely studied to address the issue of\nimbalanced data distributions in real-world scenarios. However, there has been\ninsufficient focus on the design of neural architectures, despite empirical\nevidence suggesting that architecture can significantly impact performance. In\nthis paper, we attempt to mitigate long-tailed issues through architectural\nimprovements. To simplify the design process, we utilize Differential\nArchitecture Search (DARTS) to achieve this goal. Unfortunately, existing DARTS\nmethods struggle to perform well in long-tailed scenarios. To tackle this\nchallenge, we introduce Long-Tailed Differential Architecture Search\n(LT-DARTS). Specifically, we conduct extensive experiments to explore\narchitectural components that demonstrate better performance on long-tailed\ndata and propose a new search space based on our observations. This ensures\nthat the architecture obtained through our search process incorporates superior\ncomponents. Additionally, we propose replacing the learnable linear classifier\nwith an Equiangular Tight Frame (ETF) classifier to further enhance our method.\nThis classifier effectively alleviates the biased search process and prevents\nperformance collapse. Extensive experimental evaluations demonstrate that our\napproach consistently improves upon existing methods from an orthogonal\nperspective and achieves state-of-the-art results with simple enhancements.\n","authors":["Yuhan Pan","Yanan Sun","Wei Gong"],"pdf_url":"https://arxiv.org/pdf/2411.06098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08460v1","updated":"2024-11-13T09:31:06Z","published":"2024-11-13T09:31:06Z","title":"Trap-MID: Trapdoor-based Defense against Model Inversion Attacks","summary":"  Model Inversion (MI) attacks pose a significant threat to the privacy of Deep\nNeural Networks by recovering training data distribution from well-trained\nmodels. While existing defenses often rely on regularization techniques to\nreduce information leakage, they remain vulnerable to recent attacks. In this\npaper, we propose the Trapdoor-based Model Inversion Defense (Trap-MID) to\nmislead MI attacks. A trapdoor is integrated into the model to predict a\nspecific label when the input is injected with the corresponding trigger.\nConsequently, this trapdoor information serves as the \"shortcut\" for MI\nattacks, leading them to extract trapdoor triggers rather than private data. We\nprovide theoretical insights into the impacts of trapdoor's effectiveness and\nnaturalness on deceiving MI attacks. In addition, empirical experiments\ndemonstrate the state-of-the-art defense performance of Trap-MID against\nvarious MI attacks without the requirements for extra data or large\ncomputational overhead. Our source code is publicly available at\nhttps://github.com/ntuaislab/Trap-MID.\n","authors":["Zhen-Ting Liu","Shang-Tse Chen"],"pdf_url":"https://arxiv.org/pdf/2411.08460v1.pdf","comment":"Accepted by Neural Information Processing Systems (NeurIPS) 2024"},{"id":"http://arxiv.org/abs/2411.00393v4","updated":"2024-11-13T09:27:41Z","published":"2024-11-01T06:40:47Z","title":"Advantages of Neural Population Coding for Deep Learning","summary":"  Scalar variables, e.g., the orientation of a shape in an image, are commonly\npredicted using a single output neuron in a neural network. In contrast, the\nmammalian cortex represents variables with a population of neurons. In this\npopulation code, each neuron is most active at its preferred value and shows\npartial activity for other values. Here, we investigate the benefit of using a\npopulation code for the output layer of a neural network. We compare population\ncodes against single-neuron outputs and one-hot vectors. First, we show\ntheoretically and in experiments with synthetic data that population codes\nimprove robustness to input noise in networks of stacked linear layers. Second,\nwe demonstrate the benefit of using population codes to encode ambiguous\noutputs, such as the pose of symmetric objects. Using the T-LESS dataset of\nfeature-less real-world objects, we show that population codes improve the\naccuracy of predicting 3D object orientation from image input.\n","authors":["Heiko Hoffmann"],"pdf_url":"https://arxiv.org/pdf/2411.00393v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08453v1","updated":"2024-11-13T09:16:21Z","published":"2024-11-13T09:16:21Z","title":"Biomass phenotyping of oilseed rape through UAV multi-view oblique\n  imaging with 3DGS and SAM model","summary":"  Biomass estimation of oilseed rape is crucial for optimizing crop\nproductivity and breeding strategies. While UAV-based imaging has advanced\nhigh-throughput phenotyping, current methods often rely on orthophoto images,\nwhich struggle with overlapping leaves and incomplete structural information in\ncomplex field environments. This study integrates 3D Gaussian Splatting (3DGS)\nwith the Segment Anything Model (SAM) for precise 3D reconstruction and biomass\nestimation of oilseed rape. UAV multi-view oblique images from 36 angles were\nused to perform 3D reconstruction, with the SAM module enhancing point cloud\nsegmentation. The segmented point clouds were then converted into point cloud\nvolumes, which were fitted to ground-measured biomass using linear regression.\nThe results showed that 3DGS (7k and 30k iterations) provided high accuracy,\nwith peak signal-to-noise ratios (PSNR) of 27.43 and 29.53 and training times\nof 7 and 49 minutes, respectively. This performance exceeded that of structure\nfrom motion (SfM) and mipmap Neural Radiance Fields (Mip-NeRF), demonstrating\nsuperior efficiency. The SAM module achieved high segmentation accuracy, with a\nmean intersection over union (mIoU) of 0.961 and an F1-score of 0.980.\nAdditionally, a comparison of biomass extraction models found the point cloud\nvolume model to be the most accurate, with an determination coefficient (R2) of\n0.976, root mean square error (RMSE) of 2.92 g/plant, and mean absolute\npercentage error (MAPE) of 6.81%, outperforming both the plot crop volume and\nindividual crop volume models. This study highlights the potential of combining\n3DGS with multi-view UAV imaging for improved biomass phenotyping.\n","authors":["Yutao Shen","Hongyu Zhou","Xin Yang","Xuqi Lu","Ziyue Guo","Lixi Jiang","Yong He","Haiyan Cen"],"pdf_url":"https://arxiv.org/pdf/2411.08453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08451v1","updated":"2024-11-13T09:14:35Z","published":"2024-11-13T09:14:35Z","title":"AD-DINO: Attention-Dynamic DINO for Distance-Aware Embodied Reference\n  Understanding","summary":"  Embodied reference understanding is crucial for intelligent agents to predict\nreferents based on human intention through gesture signals and language\ndescriptions. This paper introduces the Attention-Dynamic DINO, a novel\nframework designed to mitigate misinterpretations of pointing gestures across\nvarious interaction contexts. Our approach integrates visual and textual\nfeatures to simultaneously predict the target object's bounding box and the\nattention source in pointing gestures. Leveraging the distance-aware nature of\nnonverbal communication in visual perspective taking, we extend the virtual\ntouch line mechanism and propose an attention-dynamic touch line to represent\nreferring gesture based on interactive distances. The combination of this\ndistance-aware approach and independent prediction of the attention source,\nenhances the alignment between objects and the gesture represented line.\nExtensive experiments on the YouRefIt dataset demonstrate the efficacy of our\ngesture information understanding method in significantly improving task\nperformance. Our model achieves 76.4% accuracy at the 0.25 IoU threshold and,\nnotably, surpasses human performance at the 0.75 IoU threshold, marking a first\nin this domain. Comparative experiments with distance-unaware understanding\nmethods from previous research further validate the superiority of the\nAttention-Dynamic Touch Line across diverse contexts.\n","authors":["Hao Guo","Wei Fan","Baichun Wei","Jianfei Zhu","Jin Tian","Chunzhi Yi","Feng Jiang"],"pdf_url":"https://arxiv.org/pdf/2411.08451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06645v4","updated":"2024-11-13T09:14:12Z","published":"2024-10-09T07:57:47Z","title":"Continual Learning in the Frequency Domain","summary":"  Continual learning (CL) is designed to learn new tasks while preserving\nexisting knowledge. Replaying samples from earlier tasks has proven to be an\neffective method to mitigate the forgetting of previously acquired knowledge.\nHowever, the current research on the training efficiency of rehearsal-based\nmethods is insufficient, which limits the practical application of CL systems\nin resource-limited scenarios. The human visual system (HVS) exhibits varying\nsensitivities to different frequency components, enabling the efficient\nelimination of visually redundant information. Inspired by HVS, we propose a\nnovel framework called Continual Learning in the Frequency Domain (CLFD). To\nour knowledge, this is the first study to utilize frequency domain features to\nenhance the performance and efficiency of CL training on edge devices. For the\ninput features of the feature extractor, CLFD employs wavelet transform to map\nthe original input image into the frequency domain, thereby effectively\nreducing the size of input feature maps. Regarding the output features of the\nfeature extractor, CLFD selectively utilizes output features for distinct\nclasses for classification, thereby balancing the reusability and interference\nof output features based on the frequency domain similarity of the classes\nacross various tasks. Optimizing only the input and output features of the\nfeature extractor allows for seamless integration of CLFD with various\nrehearsal-based methods. Extensive experiments conducted in both cloud and edge\nenvironments demonstrate that CLFD consistently improves the performance of\nstate-of-the-art (SOTA) methods in both precision and training efficiency.\nSpecifically, CLFD can increase the accuracy of the SOTA CL method by up to\n6.83% and reduce the training time by 2.6$\\times$.\n","authors":["Ruiqi Liu","Boyu Diao","Libo Huang","Zijia An","Zhulin An","Yongjun Xu"],"pdf_url":"https://arxiv.org/pdf/2410.06645v4.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.23828v2","updated":"2024-11-13T09:06:18Z","published":"2024-10-31T11:20:13Z","title":"Show Me What and Where has Changed? Question Answering and Grounding for\n  Remote Sensing Change Detection","summary":"  Remote sensing change detection aims to perceive changes occurring on the\nEarth's surface from remote sensing data in different periods, and feed these\nchanges back to humans. However, most existing methods only focus on detecting\nchange regions, lacking the capability to interact with users to identify\nchanges that the users expect. In this paper, we introduce a new task named\nChange Detection Question Answering and Grounding (CDQAG), which extends the\ntraditional change detection task by providing interpretable textual answers\nand intuitive visual evidence. To this end, we construct the first CDQAG\nbenchmark dataset, termed QAG-360K, comprising over 360K triplets of questions,\ntextual answers, and corresponding high-quality visual masks. It encompasses 10\nessential land-cover categories and 8 comprehensive question types, which\nprovides a valuable and diverse dataset for remote sensing applications.\nFurthermore, we present VisTA, a simple yet effective baseline method that\nunifies the tasks of question answering and grounding by delivering both visual\nand textual answers. Our method achieves state-of-the-art results on both the\nclassic change detection-based visual question answering (CDVQA) and the\nproposed CDQAG datasets. Extensive qualitative and quantitative experimental\nresults provide useful insights for developing better CDQAG models, and we hope\nthat our work can inspire further research in this important yet underexplored\nresearch field. The proposed benchmark dataset and method are available at\nhttps://github.com/like413/VisTA.\n","authors":["Ke Li","Fuyu Dong","Di Wang","Shaofeng Li","Quan Wang","Xinbo Gao","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.23828v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21991v4","updated":"2024-11-13T08:59:31Z","published":"2024-10-29T12:22:07Z","title":"From Explicit Rules to Implicit Reasoning in an Interpretable Violence\n  Monitoring System","summary":"  Recently, research based on pre-trained models has demonstrated outstanding\nperformance in violence surveillance tasks. However, most of them were\nblack-box systems which faced challenges regarding explainability during\ntraining and inference processes. An important question is how to incorporate\nexplicit knowledge into these implicit models, thereby designing expert-driven\nand interpretable violence surveillance systems. This paper proposes a new\nparadigm for weakly supervised violence monitoring (WSVM) called Rule base\nViolence Monitoring (RuleVM). The proposed RuleVM uses a dual-branch structure\nwith different designs for images and text. One of the branches is called the\nimplicit branch, which uses only visual features for coarse-grained binary\nclassification. In this branch, image feature extraction is divided into two\nchannels: one responsible for extracting scene frames and the other focusing on\nextracting actions. The other branch is called the explicit branch, which\nutilizes language-image alignment to perform fine-grained classification. For\nthe language channel design in the explicit branch, the proposed RuleCLIP uses\nthe state-of-the-art YOLO-World model to detect objects in video frames, and\nassociation rules are identified through data mining methods as descriptions of\nthe video. Leveraging the dual-branch architecture, RuleVM achieves\ninterpretable coarse-grained and fine-grained violence surveillance. Extensive\nexperiments were conducted on two commonly used benchmarks, and the results\nshow that RuleCLIP achieved the best performance in both coarse-grained and\nfine-grained monitoring, significantly outperforming existing state-of-the-art\nmethods. Moreover, interpretability experiments uncovered some interesting\nrules, such as the observation that as the number of people increases, the risk\nlevel of violent behavior also rises.\n","authors":["Wen-Dong Jiang","Chih-Yung Chang","Ssu-Chi Kuai","Diptendu Sinha Roy"],"pdf_url":"https://arxiv.org/pdf/2410.21991v4.pdf","comment":"12 pages,7 figures IEEE TSMCA (Under review)"},{"id":"http://arxiv.org/abs/2411.08443v1","updated":"2024-11-13T08:56:35Z","published":"2024-11-13T08:56:35Z","title":"Machine Unlearning on Pre-trained Models by Residual Feature Alignment\n  Using LoRA","summary":"  Machine unlearning is new emerged technology that removes a subset of the\ntraining data from a trained model without affecting the model performance on\nthe remaining data. This topic is becoming increasingly important in protecting\nuser privacy and eliminating harmful or outdated data. The key challenge lies\nin effectively and efficiently unlearning specific information without\ncompromising the model's utility on the retained data. For the pre-trained\nmodels, fine-tuning is an important way to achieve the unlearning target.\nPrevious work typically fine-tuned the entire model's parameters, which incurs\nsignificant computation costs. In addition, the fine-tuning process may cause\nshifts in the intermediate layer features, affecting the model's overall\nutility. In this work, we propose a novel and efficient machine unlearning\nmethod on pre-trained models. We term the method as Residual Feature Alignment\nUnlearning. Specifically, we leverage LoRA (Low-Rank Adaptation) to decompose\nthe model's intermediate features into pre-trained features and residual\nfeatures. By adjusting the residual features, we align the unlearned model with\nthe pre-trained model at the intermediate feature level to achieve both\nunlearning and remaining targets. The method aims to learn the zero residuals\non the retained set and shifted residuals on the unlearning set. Extensive\nexperiments on numerous datasets validate the effectiveness of our approach.\n","authors":["Laiqiao Qin","Tianqing Zhu","Linlin Wang","Wanlei Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.08443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09828v4","updated":"2024-11-13T08:34:48Z","published":"2024-05-16T06:05:08Z","title":"*: Improving the 3D detector by introducing Voxel2Pillar feature\n  encoding and extracting multi-scale features","summary":"  The multi-line LiDAR is widely used in autonomous vehicles, so point\ncloud-based 3D detectors are essential for autonomous driving. Extracting rich\nmulti-scale features is crucial for point cloud-based 3D detectors in\nautonomous driving due to significant differences in the size of different\ntypes of objects. However, because of the real-time requirements, large-size\nconvolution kernels are rarely used to extract large-scale features in the\nbackbone. Current 3D detectors commonly use feature pyramid networks to obtain\nlarge-scale features; however, some objects containing fewer point clouds are\nfurther lost during down-sampling, resulting in degraded performance. Since\npillar-based schemes require much less computation than voxel-based schemes,\nthey are more suitable for constructing real-time 3D detectors. Hence, we\npropose the *, a pillar-based scheme. We redesigned the feature encoding, the\nbackbone, and the neck of the 3D detector. We propose the Voxel2Pillar feature\nencoding, which uses a sparse convolution constructor to construct pillars with\nricher point cloud features, especially height features. The Voxel2Pillar adds\nmore learnable parameters to the feature encoding, enabling the initial pillars\nto have higher performance ability. We extract multi-scale and large-scale\nfeatures in the proposed fully sparse backbone, which does not utilize\nlarge-size convolutional kernels; the backbone consists of the proposed\nmulti-scale feature extraction module. The neck consists of the proposed sparse\nConvNeXt, whose simple structure significantly improves the performance. We\nvalidate the effectiveness of the proposed * on the Waymo Open Dataset, and the\nobject detection accuracy for vehicles, pedestrians, and cyclists is improved.\nWe also verify the effectiveness of each proposed module in detail through\nablation studies.\n","authors":["Xusheng Li","Chengliang Wang","Shumao Wang","Zhuo Zeng","Ji Liu"],"pdf_url":"https://arxiv.org/pdf/2405.09828v4.pdf","comment":"Due to experimental data errors, it needs to be withdrawn"},{"id":"http://arxiv.org/abs/2411.04919v2","updated":"2024-11-13T08:32:27Z","published":"2024-11-07T17:56:16Z","title":"Stem-OB: Generalizable Visual Imitation Learning with Stem-Like\n  Convergent Observation through Diffusion Inversion","summary":"  Visual imitation learning methods demonstrate strong performance, yet they\nlack generalization when faced with visual input perturbations, including\nvariations in lighting and textures, impeding their real-world application. We\npropose Stem-OB that utilizes pretrained image diffusion models to suppress\nlow-level visual differences while maintaining high-level scene structures.\nThis image inversion process is akin to transforming the observation into a\nshared representation, from which other observations stem, with extraneous\ndetails removed. Stem-OB contrasts with data-augmentation approaches as it is\nrobust to various unspecified appearance changes without the need for\nadditional training. Our method is a simple yet highly effective plug-and-play\nsolution. Empirical results confirm the effectiveness of our approach in\nsimulated tasks and show an exceptionally significant improvement in real-world\napplications, with an average increase of 22.2% in success rates compared to\nthe best baseline. See https://hukz18.github.io/Stem-Ob/ for more info.\n","authors":["Kaizhe Hu","Zihang Rui","Yao He","Yuyao Liu","Pu Hua","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2411.04919v2.pdf","comment":"Arxiv preprint version, website: https://hukz18.github.io/Stem-Ob/"},{"id":"http://arxiv.org/abs/2411.07501v2","updated":"2024-11-13T08:30:52Z","published":"2024-11-12T02:57:15Z","title":"LAuReL: Learned Augmented Residual Layer","summary":"  One of the core pillars of efficient deep learning methods is architectural\nimprovements such as the residual/skip connection, which has led to\nsignificantly better model convergence and quality. Since then the residual\nconnection has become ubiquitous in not just convolutional neural networks but\nalso transformer-based architectures, the backbone of LLMs.\n  In this paper we introduce \\emph{Learned Augmented Residual Layer} (LAuReL)\n-- a novel generalization of the canonical residual connection -- with the goal\nto be an in-situ replacement of the latter while outperforming on both model\nquality and footprint metrics. Our experiments show that using \\laurel can help\nboost performance for both vision and language models. For example, on the\nResNet-50, ImageNet 1K task, it achieves $60\\%$ of the gains from adding an\nextra layer, while only adding $0.003\\%$ more parameters, and matches it while\nadding $2.6\\times$ fewer parameters.\n","authors":["Gaurav Menghani","Ravi Kumar","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.07501v2.pdf","comment":"Accepted at the 2nd Efficient Systems for Foundation Models Workshop\n  at the International Conference on Machine Learning (ICML) 2024"},{"id":"http://arxiv.org/abs/2411.08424v1","updated":"2024-11-13T08:17:52Z","published":"2024-11-13T08:17:52Z","title":"A Heterogeneous Graph Neural Network Fusing Functional and Structural\n  Connectivity for MCI Diagnosis","summary":"  Brain connectivity alternations associated with brain disorders have been\nwidely reported in resting-state functional imaging (rs-fMRI) and diffusion\ntensor imaging (DTI). While many dual-modal fusion methods based on graph\nneural networks (GNNs) have been proposed, they generally follow homogenous\nfusion ways ignoring rich heterogeneity of dual-modal information. To address\nthis issue, we propose a novel method that integrates functional and structural\nconnectivity based on heterogeneous graph neural networks (HGNNs) to better\nleverage the rich heterogeneity in dual-modal images. We firstly use blood\noxygen level dependency and whiter matter structure information provided by\nrs-fMRI and DTI to establish homo-meta-path, capturing node relationships\nwithin the same modality. At the same time, we propose to establish\nhetero-meta-path based on structure-function coupling and brain community\nsearching to capture relations among cross-modal nodes. Secondly, we further\nintroduce a heterogeneous graph pooling strategy that automatically balances\nhomo- and hetero-meta-path, effectively leveraging heterogeneous information\nand preventing feature confusion after pooling. Thirdly, based on the\nflexibility of heterogeneous graphs, we propose a heterogeneous graph data\naugmentation approach that can conveniently address the sample imbalance issue\ncommonly seen in clinical diagnosis. We evaluate our method on ADNI-3 dataset\nfor mild cognitive impairment (MCI) diagnosis. Experimental results indicate\nthe proposed method is effective and superior to other algorithms, with a mean\nclassification accuracy of 93.3%.\n","authors":["Feiyu Yin","Yu Lei","Siyuan Dai","Wenwen Zeng","Guoqing Wu","Liang Zhan","Jinhua Yu"],"pdf_url":"https://arxiv.org/pdf/2411.08424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07579v2","updated":"2024-11-13T08:00:57Z","published":"2024-11-12T06:29:48Z","title":"Projecting Gaussian Ellipsoids While Avoiding Affine Projection\n  Approximation","summary":"  Recently, 3D Gaussian Splatting has dominated novel-view synthesis with its\nreal-time rendering speed and state-of-the-art rendering quality. However,\nduring the rendering process, the use of the Jacobian of the affine\napproximation of the projection transformation leads to inevitable errors,\nresulting in blurriness, artifacts and a lack of scene consistency in the final\nrendered images. To address this issue, we introduce an ellipsoid-based\nprojection method to calculate the projection of Gaussian ellipsoid on the\nimage plane, witch is the primitive of 3D Gaussian Splatting. As our proposed\nellipsoid-based projection method cannot handle Gaussian ellipsoids with camera\norigins inside them or parts lying below $z=0$ plane in the camera space, we\ndesigned a pre-filtering strategy. Experiments over multiple widely adopted\nbenchmark datasets show that using our ellipsoid-based projection method can\nenhance the rendering quality of 3D Gaussian Splatting and its extensions.\n","authors":["Han Qi","Tao Cai","Xiyue Han"],"pdf_url":"https://arxiv.org/pdf/2411.07579v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08410v1","updated":"2024-11-13T07:57:19Z","published":"2024-11-13T07:57:19Z","title":"The VLLM Safety Paradox: Dual Ease in Jailbreak Attack and Defense","summary":"  The vulnerability of Vision Large Language Models (VLLMs) to jailbreak\nattacks appears as no surprise. However, recent defense mechanisms against\nthese attacks have reached near-saturation performance on benchmarks, often\nwith minimal effort. This simultaneous high performance in both attack and\ndefense presents a perplexing paradox. Resolving it is critical for advancing\nthe development of trustworthy models. To address this research gap, we first\ninvestigate why VLLMs are prone to these attacks. We then make a key\nobservation: existing defense mechanisms suffer from an \\textbf{over-prudence}\nproblem, resulting in unexpected abstention even in the presence of benign\ninputs. Additionally, we find that the two representative evaluation methods\nfor jailbreak often exhibit chance agreement. This limitation makes it\npotentially misleading when evaluating attack strategies or defense mechanisms.\nBeyond these empirical observations, our another contribution in this work is\nto repurpose the guardrails of LLMs on the shelf, as an effective alternative\ndetector prior to VLLM response. We believe these findings offer useful\ninsights to rethink the foundational development of VLLM safety with respect to\nbenchmark datasets, evaluation methods, and defense strategies.\n","authors":["Yangyang Guo","Fangkai Jiao","Liqiang Nie","Mohan Kankanhalli"],"pdf_url":"https://arxiv.org/pdf/2411.08410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08402v1","updated":"2024-11-13T07:41:47Z","published":"2024-11-13T07:41:47Z","title":"V2X-R: Cooperative LiDAR-4D Radar Fusion for 3D Object Detection with\n  Denoising Diffusion","summary":"  Current Vehicle-to-Everything (V2X) systems have significantly enhanced 3D\nobject detection using LiDAR and camera data. However, these methods suffer\nfrom performance degradation in adverse weather conditions. The weatherrobust\n4D radar provides Doppler and additional geometric information, raising the\npossibility of addressing this challenge. To this end, we present V2X-R, the\nfirst simulated V2X dataset incorporating LiDAR, camera, and 4D radar. V2X-R\ncontains 12,079 scenarios with 37,727 frames of LiDAR and 4D radar point\nclouds, 150,908 images, and 170,859 annotated 3D vehicle bounding boxes.\nSubsequently, we propose a novel cooperative LiDAR-4D radar fusion pipeline for\n3D object detection and implement it with various fusion strategies. To achieve\nweather-robust detection, we additionally propose a Multi-modal Denoising\nDiffusion (MDD) module in our fusion pipeline. MDD utilizes weather-robust 4D\nradar feature as a condition to prompt the diffusion model to denoise noisy\nLiDAR features. Experiments show that our LiDAR-4D radar fusion pipeline\ndemonstrates superior performance in the V2X-R dataset. Over and above this,\nour MDD module further improved the performance of basic fusion model by up to\n5.73%/6.70% in foggy/snowy conditions with barely disrupting normal\nperformance. The dataset and code will be publicly available at:\nhttps://github.com/ylwhxht/V2X-R.\n","authors":["Xun Huang","Jinlong Wang","Qiming Xia","Siheng Chen","Bisheng Yang","Cheng Wang","Chenglu Wen"],"pdf_url":"https://arxiv.org/pdf/2411.08402v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08395v1","updated":"2024-11-13T07:27:56Z","published":"2024-11-13T07:27:56Z","title":"MambaXCTrack: Mamba-based Tracker with SSM Cross-correlation and Motion\n  Prompt for Ultrasound Needle Tracking","summary":"  Ultrasound (US)-guided needle insertion is widely employed in percutaneous\ninterventions. However, providing feedback on the needle tip position via US\nimage presents challenges due to noise, artifacts, and the thin imaging plane\nof US, which degrades needle features and leads to intermittent tip visibility.\nIn this paper, a Mamba-based US needle tracker MambaXCTrack utilizing\nstructured state space models cross-correlation (SSMX-Corr) and implicit motion\nprompt is proposed, which is the first application of Mamba in US needle\ntracking. The SSMX-Corr enhances cross-correlation by long-range modeling and\nglobal searching of distant semantic features between template and search maps,\nbenefiting the tracking under noise and artifacts by implicitly learning\npotential distant semantic cues. By combining with cross-map interleaved scan\n(CIS), local pixel-wise interaction with positional inductive bias can also be\nintroduced to SSMX-Corr. The implicit low-level motion descriptor is proposed\nas a non-visual prompt to enhance tracking robustness, addressing the\nintermittent tip visibility problem. Extensive experiments on a dataset with\nmotorized needle insertion in both phantom and tissue samples demonstrate that\nthe proposed tracker outperforms other state-of-the-art trackers while ablation\nstudies further highlight the effectiveness of each proposed tracking module.\n","authors":["Yuelin Zhang","Qingpeng Ding","Long Lei","Jiwei Shan","Wenxuan Xie","Tianyi Zhang","Wanquan Yan","Raymond Shing-Yan Tang","Shing Shin Cheng"],"pdf_url":"https://arxiv.org/pdf/2411.08395v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2411.07265v2","updated":"2024-11-13T07:26:33Z","published":"2024-11-09T13:13:49Z","title":"ViTOC: Vision Transformer and Object-aware Captioner","summary":"  This paper presents ViTOC (Vision Transformer and Object-aware Captioner), a\nnovel vision-language model for image captioning that addresses the challenges\nof accuracy and diversity in generated descriptions. Unlike conventional\napproaches, ViTOC employs a dual-path architecture based on Vision Transformer\nand object detector, effectively fusing global visual features and local object\ninformation through learnable vectors. The model introduces an innovative\nobject-aware prompting strategy that significantly enhances its capability in\nhandling long-tail data. Experiments on the standard COCO dataset demonstrate\nthat ViTOC outperforms baseline models across all evaluation metrics.\nAdditionally, we propose a reference-free evaluation method based on CLIP to\nfurther validate the model's effectiveness. By utilizing pretrained visual\nmodel parameters, ViTOC achieves efficient end-to-end training.\n","authors":["Feiyang Huang"],"pdf_url":"https://arxiv.org/pdf/2411.07265v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08380v1","updated":"2024-11-13T07:05:40Z","published":"2024-11-13T07:05:40Z","title":"EgoVid-5M: A Large-Scale Video-Action Dataset for Egocentric Video\n  Generation","summary":"  Video generation has emerged as a promising tool for world simulation,\nleveraging visual data to replicate real-world environments. Within this\ncontext, egocentric video generation, which centers on the human perspective,\nholds significant potential for enhancing applications in virtual reality,\naugmented reality, and gaming. However, the generation of egocentric videos\npresents substantial challenges due to the dynamic nature of egocentric\nviewpoints, the intricate diversity of actions, and the complex variety of\nscenes encountered. Existing datasets are inadequate for addressing these\nchallenges effectively. To bridge this gap, we present EgoVid-5M, the first\nhigh-quality dataset specifically curated for egocentric video generation.\nEgoVid-5M encompasses 5 million egocentric video clips and is enriched with\ndetailed action annotations, including fine-grained kinematic control and\nhigh-level textual descriptions. To ensure the integrity and usability of the\ndataset, we implement a sophisticated data cleaning pipeline designed to\nmaintain frame consistency, action coherence, and motion smoothness under\negocentric conditions. Furthermore, we introduce EgoDreamer, which is capable\nof generating egocentric videos driven simultaneously by action descriptions\nand kinematic control signals. The EgoVid-5M dataset, associated action\nannotations, and all data cleansing metadata will be released for the\nadvancement of research in egocentric video generation.\n","authors":["Xiaofeng Wang","Kang Zhao","Feng Liu","Jiayu Wang","Guosheng Zhao","Xiaoyi Bao","Zheng Zhu","Yingya Zhang","Xingang Wang"],"pdf_url":"https://arxiv.org/pdf/2411.08380v1.pdf","comment":"Project Page: https://egovid.github.io/"},{"id":"http://arxiv.org/abs/2411.08371v1","updated":"2024-11-13T06:42:03Z","published":"2024-11-13T06:42:03Z","title":"Multiscale Graph Construction Using Non-local Cluster Features","summary":"  This paper presents a multiscale graph construction method using both graph\nand signal features. Multiscale graph is a hierarchical representation of the\ngraph, where a node at each level indicates a cluster in a finer resolution. To\nobtain the hierarchical clusters, existing methods often use graph clustering;\nhowever, they may ignore signal variations. As a result, these methods could\nfail to detect the clusters having similar features on nodes. In this paper, we\nconsider graph and node-wise features simultaneously for multiscale clustering\nof a graph. With given clusters of the graph, the clusters are merged\nhierarchically in three steps: 1) Feature vectors in the clusters are\nextracted. 2) Similarities among cluster features are calculated using optimal\ntransport. 3) A variable $k$-nearest neighbor graph (V$k$NNG) is constructed\nand graph spectral clustering is applied to the V$k$NNG to obtain clusters at a\ncoarser scale. Additionally, the multiscale graph in this paper has\n\\textit{non-local} characteristics: Nodes with similar features are merged even\nif they are spatially separated. In experiments on multiscale image and point\ncloud segmentation, we demonstrate the effectiveness of the proposed method.\n","authors":["Reina Kaneko","Hayate Kojima","Kenta Yanagiya","Junya Hara","Hiroshi Higashi","Yuichi Tanaka"],"pdf_url":"https://arxiv.org/pdf/2411.08371v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18054v3","updated":"2024-11-13T06:25:23Z","published":"2024-06-26T04:12:34Z","title":"Leveraging Pre-trained Models for FF-to-FFPE Histopathological Image\n  Translation","summary":"  The two primary types of Hematoxylin and Eosin (H&E) slides in histopathology\nare Formalin-Fixed Paraffin-Embedded (FFPE) and Fresh Frozen (FF). FFPE slides\noffer high quality histopathological images but require a labor-intensive\nacquisition process. In contrast, FF slides can be prepared quickly, but the\nimage quality is relatively poor. Our task is to translate FF images into FFPE\nstyle, thereby improving the image quality for diagnostic purposes. In this\npaper, we propose Diffusion-FFPE, a method for FF-to-FFPE histopathological\nimage translation using a pre-trained diffusion model. Specifically, we utilize\na one-step diffusion model as the generator, which we fine-tune using LoRA\nadapters within an adversarial learning framework. To enable the model to\neffectively capture both global structural patterns and local details, we\nintroduce a multi-scale feature fusion module that leverages two VAE encoders\nto extract features at different image resolutions, performing feature fusion\nbefore inputting them into the UNet. Additionally, a pre-trained\nvision-language model for histopathology serves as the backbone for the\ndiscriminator, enhancing model performance. Our FF-to-FFPE translation\nexperiments on the TCGA-NSCLC dataset demonstrate that the proposed approach\noutperforms existing methods. The code and models are released at\nhttps://github.com/QilaiZhang/Diffusion-FFPE.\n","authors":["Qilai Zhang","Jiawen Li","Peiran Liao","Jiali Hu","Tian Guan","Anjia Han","Yonghong He"],"pdf_url":"https://arxiv.org/pdf/2406.18054v3.pdf","comment":"Accepted at IEEE BIBM 2024"},{"id":"http://arxiv.org/abs/2411.04493v2","updated":"2024-11-13T05:52:23Z","published":"2024-11-07T07:41:04Z","title":"Synergy-Guided Regional Supervision of Pseudo Labels for Semi-Supervised\n  Medical Image Segmentation","summary":"  Semi-supervised learning has received considerable attention for its\npotential to leverage abundant unlabeled data to enhance model robustness.\nPseudo labeling is a widely used strategy in semi supervised learning. However,\nexisting methods often suffer from noise contamination, which can undermine\nmodel performance. To tackle this challenge, we introduce a novel\nSynergy-Guided Regional Supervision of Pseudo Labels (SGRS-Net) framework.\nBuilt upon the mean teacher network, we employ a Mix Augmentation module to\nenhance the unlabeled data. By evaluating the synergy before and after\naugmentation, we strategically partition the pseudo labels into distinct\nregions. Additionally, we introduce a Region Loss Evaluation module to assess\nthe loss across each delineated area. Extensive experiments conducted on the LA\ndataset have demonstrated superior performance over state-of-the-art\ntechniques, underscoring the efficiency and practicality of our framework.\n","authors":["Tao Wang","Xinlin Zhang","Yuanbin Chen","Yuanbo Zhou","Longxuan Zhao","Tao Tan","Tong Tong"],"pdf_url":"https://arxiv.org/pdf/2411.04493v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08347v1","updated":"2024-11-13T05:38:55Z","published":"2024-11-13T05:38:55Z","title":"A Chinese Multi-label Affective Computing Dataset Based on Social Media\n  Network Users","summary":"  Emotion and personality are central elements in understanding human\npsychological states. Emotions reflect an individual subjective experiences,\nwhile personality reveals relatively stable behavioral and cognitive patterns.\nExisting affective computing datasets often annotate emotion and personality\ntraits separately, lacking fine-grained labeling of micro-emotions and emotion\nintensity in both single-label and multi-label classifications. Chinese emotion\ndatasets are extremely scarce, and datasets capturing Chinese user personality\ntraits are even more limited. To address these gaps, this study collected data\nfrom the major social media platform Weibo, screening 11,338 valid users from\nover 50,000 individuals with diverse MBTI personality labels and acquiring\n566,900 posts along with the user MBTI personality tags. Using the EQN method,\nwe compiled a multi-label Chinese affective computing dataset that integrates\nthe same user's personality traits with six emotions and micro-emotions, each\nannotated with intensity levels. Validation results across multiple NLP\nclassification models demonstrate the dataset strong utility. This dataset is\ndesigned to advance machine recognition of complex human emotions and provide\ndata support for research in psychology, education, marketing, finance, and\npolitics.\n","authors":["Jingyi Zhou","Senlin Luo","Haofan Chen"],"pdf_url":"https://arxiv.org/pdf/2411.08347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18066v2","updated":"2024-11-13T05:15:53Z","published":"2024-02-28T05:52:25Z","title":"Six-Point Method for Multi-Camera Systems with Reduced Solution Space","summary":"  Relative pose estimation using point correspondences (PC) is a widely used\ntechnique. A minimal configuration of six PCs is required for two views of\ngeneralized cameras. In this paper, we present several minimal solvers that use\nsix PCs to compute the 6DOF relative pose of multi-camera systems, including a\nminimal solver for the generalized camera and two minimal solvers for the\npractical configuration of two-camera rigs. The equation construction is based\non the decoupling of rotation and translation. Rotation is represented by\nCayley or quaternion parametrization, and translation can be eliminated by\nusing the hidden variable technique. Ray bundle constraints are found and\nproven when a subset of PCs relate the same cameras across two views. This is\nthe key to reducing the number of solutions and generating numerically stable\nsolvers. Moreover, all configurations of six-point problems for multi-camera\nsystems are enumerated. Extensive experiments demonstrate the superior accuracy\nand efficiency of our solvers compared to state-of-the-art six-point methods.\nThe code is available at https://github.com/jizhaox/relpose-6pt\n","authors":["Banglei Guan","Ji Zhao","Laurent Kneip"],"pdf_url":"https://arxiv.org/pdf/2402.18066v2.pdf","comment":"Accepted to the European Conference on Computer Vision (ECCV), 2024,\n  for an oral presentation"},{"id":"http://arxiv.org/abs/2411.08340v1","updated":"2024-11-13T05:09:28Z","published":"2024-11-13T05:09:28Z","title":"DyConfidMatch: Dynamic Thresholding and Re-sampling for 3D\n  Semi-supervised Learning","summary":"  Semi-supervised learning (SSL) leverages limited labeled and abundant\nunlabeled data but often faces challenges with data imbalance, especially in 3D\ncontexts. This study investigates class-level confidence as an indicator of\nlearning status in 3D SSL, proposing a novel method that utilizes dynamic\nthresholding to better use unlabeled data, particularly from underrepresented\nclasses. A re-sampling strategy is also introduced to mitigate bias towards\nwell-represented classes, ensuring equitable class representation. Through\nextensive experiments in 3D SSL, our method surpasses state-of-the-art\ncounterparts in classification and detection tasks, highlighting its\neffectiveness in tackling data imbalance. This approach presents a significant\nadvancement in SSL for 3D datasets, providing a robust solution for data\nimbalance issues.\n","authors":["Zhimin Chen","Bing Li"],"pdf_url":"https://arxiv.org/pdf/2411.08340v1.pdf","comment":"Accepted by Pattern Recognition Journal"},{"id":"http://arxiv.org/abs/2411.08335v1","updated":"2024-11-13T04:49:32Z","published":"2024-11-13T04:49:32Z","title":"DEEGITS: Deep Learning based Framework for Measuring Heterogenous\n  Traffic State in Challenging Traffic Scenarios","summary":"  This paper presents DEEGITS (Deep Learning Based Heterogeneous Traffic State\nMeasurement), a comprehensive framework that leverages state-of-the-art\nconvolutional neural network (CNN) techniques to accurately and rapidly detect\nvehicles and pedestrians, as well as to measure traffic states in challenging\nscenarios (i.e., congestion, occlusion). In this study, we enhance the training\ndataset through data fusion, enabling simultaneous detection of vehicles and\npedestrians. Image preprocessing and augmentation are subsequently performed to\nimprove the quality and quantity of the dataset. Transfer learning is applied\non the YOLOv8 pretrained model to increase the model's capability to identify a\ndiverse array of vehicles. Optimal hyperparameters are obtained using the Grid\nSearch algorithm, with the Stochastic Gradient Descent (SGD) optimizer\noutperforming other optimizers under these settings. Extensive experimentation\nand evaluation demonstrate substantial accuracy within the detection framework,\nwith the model achieving 0.794 mAP@0.5 on the validation set and 0.786 mAP@0.5\non the test set, surpassing previous benchmarks on similar datasets. The\nDeepSORT multi-object tracking algorithm is incorporated to track detected\nvehicles and pedestrians in this study. Finally, the framework is tested to\nmeasure heterogeneous traffic states in mixed traffic conditions. Two locations\nwith differing traffic compositions and congestion levels are selected: one\nmotorized-dominant location with moderate density and one\nnon-motorized-dominant location with higher density. Errors are statistically\ninsignificant for both cases, showing correlations from 0.99 to 0.88 and 0.91\nto 0.97 for heterogeneous traffic flow and speed measurements, respectively.\n","authors":["Muttahirul Islam","Nazmul Haque","Md. Hadiuzzaman"],"pdf_url":"https://arxiv.org/pdf/2411.08335v1.pdf","comment":"Submitted for presentation at the 103 rd Annual Meeting of\n  Transportation Research Board and publication in Transportation Research\n  Record: Journal of Transportation Research Board"},{"id":"http://arxiv.org/abs/2411.08334v1","updated":"2024-11-13T04:32:58Z","published":"2024-11-13T04:32:58Z","title":"Enhancing Multimodal Query Representation via Visual Dialogues for\n  End-to-End Knowledge Retrieval","summary":"  Existing multimodal retrieval systems often rely on disjointed models for\nimage comprehension, such as object detectors and caption generators, leading\nto cumbersome implementations and training processes. To overcome this\nlimitation, we propose an end-to-end retrieval system, Ret-XKnow, to endow a\ntext retriever with the ability to understand multimodal queries via dynamic\nmodality interaction. Ret-XKnow leverages a partial convolution mechanism to\nfocus on visual information relevant to the given textual query, thereby\nenhancing multimodal query representations. To effectively learn multimodal\ninteraction, we also introduce the Visual Dialogue-to-Retrieval (ViD2R) dataset\nautomatically constructed from visual dialogue datasets. Our dataset\nconstruction process ensures that the dialogues are transformed into suitable\ninformation retrieval tasks using a text retriever. We demonstrate that our\napproach not only significantly improves retrieval performance in zero-shot\nsettings but also achieves substantial improvements in fine-tuning scenarios.\nOur code is publicly available: https://github.com/yeongjoonJu/Ret_XKnow.\n","authors":["Yeong-Joon Ju","Ho-Joong Kim","Seong-Whan Lee"],"pdf_url":"https://arxiv.org/pdf/2411.08334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08333v1","updated":"2024-11-13T04:29:34Z","published":"2024-11-13T04:29:34Z","title":"SASE: A Searching Architecture for Squeeze and Excitation Operations","summary":"  In the past few years, channel-wise and spatial-wise attention blocks have\nbeen widely adopted as supplementary modules in deep neural networks, enhancing\nnetwork representational abilities while introducing low complexity. Most\nattention modules follow a squeeze-and-excitation paradigm. However, to design\nsuch attention modules, requires a substantial amount of experiments and\ncomputational resources. Neural Architecture Search (NAS), meanwhile, is able\nto automate the design of neural networks and spares the numerous experiments\nrequired for an optimal architecture. This motivates us to design a search\narchitecture that can automatically find near-optimal attention modules through\nNAS. We propose SASE, a Searching Architecture for Squeeze and Excitation\noperations, to form a plug-and-play attention block by searching within certain\nsearch space. The search space is separated into 4 different sets, each\ncorresponds to the squeeze or excitation operation along the channel or spatial\ndimension. Additionally, the search sets include not only existing attention\nblocks but also other operations that have not been utilized in attention\nmechanisms before. To the best of our knowledge, SASE is the first attempt to\nsubdivide the attention search space and search for architectures beyond\ncurrently known attention modules. The searched attention module is tested with\nextensive experiments across a range of visual tasks. Experimental results\nindicate that visual backbone networks (ResNet-50/101) using the SASE attention\nmodule achieved the best performance compared to those using the current\nstate-of-the-art attention modules. Codes are included in the supplementary\nmaterial, and they will be made public later.\n","authors":["Hanming Wang","Yunlong Li","Zijun Wu","Huifen Wang","Yuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.08333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08328v1","updated":"2024-11-13T04:20:45Z","published":"2024-11-13T04:20:45Z","title":"Motion Control for Enhanced Complex Action Video Generation","summary":"  Existing text-to-video (T2V) models often struggle with generating videos\nwith sufficiently pronounced or complex actions. A key limitation lies in the\ntext prompt's inability to precisely convey intricate motion details. To\naddress this, we propose a novel framework, MVideo, designed to produce\nlong-duration videos with precise, fluid actions. MVideo overcomes the\nlimitations of text prompts by incorporating mask sequences as an additional\nmotion condition input, providing a clearer, more accurate representation of\nintended actions. Leveraging foundational vision models such as GroundingDINO\nand SAM2, MVideo automatically generates mask sequences, enhancing both\nefficiency and robustness. Our results demonstrate that, after training, MVideo\neffectively aligns text prompts with motion conditions to produce videos that\nsimultaneously meet both criteria. This dual control mechanism allows for more\ndynamic video generation by enabling alterations to either the text prompt or\nmotion condition independently, or both in tandem. Furthermore, MVideo supports\nmotion condition editing and composition, facilitating the generation of videos\nwith more complex actions. MVideo thus advances T2V motion generation, setting\na strong benchmark for improved action depiction in current video diffusion\nmodels. Our project page is available at https://mvideo-v1.github.io/.\n","authors":["Qiang Zhou","Shaofeng Zhang","Nianzu Yang","Ye Qian","Hao Li"],"pdf_url":"https://arxiv.org/pdf/2411.08328v1.pdf","comment":"Project page: https://mvideo-v1.github.io/"},{"id":"http://arxiv.org/abs/2411.07976v2","updated":"2024-11-13T03:56:10Z","published":"2024-11-12T17:55:39Z","title":"DINO-LG: A Task-Specific DINO Model for Coronary Calcium Scoring","summary":"  Coronary artery disease (CAD), one of the most common cause of mortality in\nthe world. Coronary artery calcium (CAC) scoring using computed tomography (CT)\nis key for risk assessment to prevent coronary disease. Previous studies on\nrisk assessment and calcification detection in CT scans primarily use\napproaches based on UNET architecture, frequently implemented on pre-built\nmodels. However, these models are limited by the availability of annotated CT\nscans containing CAC and suffering from imbalanced dataset, decreasing\nperformance of CAC segmentation and scoring. In this study, we extend this\napproach by incorporating the self-supervised learning (SSL) technique of DINO\n(self-distillation with no labels) to eliminate limitations of scarce annotated\ndata in CT scans. The DINO model's ability to train without requiring CAC area\nannotations enhances its robustness in generating distinct features. The DINO\nmodel is trained on to focus specifically on calcified areas by using labels,\naiming to generate features that effectively capture and highlight key\ncharacteristics. The label-guided DINO (DINO-LG) enhances classification by\ndistinguishing CT slices that contain calcification from those that do not,\nperforming 57% better than the standard DINO model in this task. CAC scoring\nand segmentation tasks are performed by a basic U-NET architecture, fed\nspecifically with CT slices containing calcified areas as identified by the\nDINO-LG model. This targeted identification performed by DINO-LG model improves\nCAC segmentation performance by approximately 10% and significant increase in\nCAC scoring accuracy.\n","authors":["Mahmut S. Gokmen","Cody Bumgardner","Caner Ozcan"],"pdf_url":"https://arxiv.org/pdf/2411.07976v2.pdf","comment":"Developed by Center for Applied Artificial Intelligence (CAAI),\n  University of Kentucky"},{"id":"http://arxiv.org/abs/2411.06106v2","updated":"2024-11-13T03:19:47Z","published":"2024-11-09T08:00:50Z","title":"Personalize to generalize: Towards a universal medical multi-modality\n  generalization through personalization","summary":"  The differences among medical imaging modalities, driven by distinct\nunderlying principles, pose significant challenges for generalization in\nmulti-modal medical tasks. Beyond modality gaps, individual variations, such as\ndifferences in organ size and metabolic rate, further impede a model's ability\nto generalize effectively across both modalities and diverse populations.\nDespite the importance of personalization, existing approaches to multi-modal\ngeneralization often neglect individual differences, focusing solely on common\nanatomical features. This limitation may result in weakened generalization in\nvarious medical tasks. In this paper, we unveil that personalization is\ncritical for multi-modal generalization. Specifically, we propose an approach\nto achieve personalized generalization through approximating the underlying\npersonalized invariant representation ${X}_h$ across various modalities by\nleveraging individual-level constraints and a learnable biological prior. We\nvalidate the feasibility and benefits of learning a personalized ${X}_h$,\nshowing that this representation is highly generalizable and transferable\nacross various multi-modal medical tasks. Extensive experimental results\nconsistently show that the additionally incorporated personalization\nsignificantly improves performance and generalization across diverse scenarios,\nconfirming its effectiveness.\n","authors":["Zhaorui Tan","Xi Yang","Tan Pan","Tianyi Liu","Chen Jiang","Xin Guo","Qiufeng Wang","Anh Nguyen","Yuan Qi","Kaizhu Huang","Yuan Cheng"],"pdf_url":"https://arxiv.org/pdf/2411.06106v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08305v1","updated":"2024-11-13T03:03:30Z","published":"2024-11-13T03:03:30Z","title":"Robust Divergence Learning for Missing-Modality Segmentation","summary":"  Multimodal Magnetic Resonance Imaging (MRI) provides essential complementary\ninformation for analyzing brain tumor subregions. While methods using four\ncommon MRI modalities for automatic segmentation have shown success, they often\nface challenges with missing modalities due to image quality issues,\ninconsistent protocols, allergic reactions, or cost factors. Thus, developing a\nsegmentation paradigm that handles missing modalities is clinically valuable. A\nnovel single-modality parallel processing network framework based on H\\\"older\ndivergence and mutual information is introduced. Each modality is independently\ninput into a shared network backbone for parallel processing, preserving unique\ninformation. Additionally, a dynamic sharing framework is introduced that\nadjusts network parameters based on modality availability. A H\\\"older\ndivergence and mutual information-based loss functions are used for evaluating\ndiscrepancies between predictions and labels. Extensive testing on the BraTS\n2018 and BraTS 2020 datasets demonstrates that our method outperforms existing\ntechniques in handling missing modalities and validates each component's\neffectiveness.\n","authors":["Runze Cheng","Zhongao Sun","Ye Zhang","Chun Li"],"pdf_url":"https://arxiv.org/pdf/2411.08305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07463v2","updated":"2024-11-13T02:39:12Z","published":"2024-11-12T00:54:26Z","title":"MSEG-VCUQ: Multimodal SEGmentation with Enhanced Vision Foundation\n  Models, Convolutional Neural Networks, and Uncertainty Quantification for\n  High-Speed Video Phase Detection Data","summary":"  Purpose: High-speed video (HSV) phase detection (PD) segmentation is vital in\nnuclear reactors, chemical processing, and electronics cooling for detecting\nvapor, liquid, and microlayer phases. Traditional segmentation models face\npixel-level accuracy and generalization issues in multimodal data. MSEG-VCUQ\nintroduces VideoSAM, a hybrid framework leveraging convolutional neural\nnetworks (CNNs) and transformer-based vision models to enhance segmentation\naccuracy and generalizability across complex multimodal PD tasks. Methods:\nVideoSAM combines U-Net CNN and the Segment Anything Model (SAM) for advanced\nfeature extraction and segmentation across diverse HSV PD modalities, spanning\nfluids like water, FC-72, nitrogen, and argon under varied heat flux\nconditions. The framework also incorporates uncertainty quantification (UQ) to\nassess pixel-based discretization errors, delivering reliable metrics such as\ncontact line density and dry area fraction under experimental conditions.\nResults: VideoSAM outperforms SAM and modality-specific CNN models in\nsegmentation accuracy, excelling in environments with complex phase boundaries,\noverlapping bubbles, and dynamic liquid-vapor interactions. Its hybrid\narchitecture supports cross-dataset generalization, adapting effectively to\nvarying modalities. The UQ module provides accurate error estimates, enhancing\nthe reliability of segmentation outputs for advanced HSV PD research.\nConclusion: MSEG-VCUQ, via VideoSAM, offers a robust solution for HSV PD\nsegmentation, addressing previous limitations with advanced deep learning and\nUQ techniques. The open-source datasets and tools introduced enable scalable,\nprecise, and adaptable segmentation for multimodal PD datasets, supporting\nadvancements in HSV analysis and autonomous experimentation. The codes and data\nused for this paper are publicly available at:\n\\url{https://github.com/chikap421/mseg_vcuq}\n","authors":["Chika Maduabuchi","Ericmoore Jossou","Matteo Bucci"],"pdf_url":"https://arxiv.org/pdf/2411.07463v2.pdf","comment":"Under Review in EAAI"},{"id":"http://arxiv.org/abs/2411.08293v1","updated":"2024-11-13T02:18:03Z","published":"2024-11-13T02:18:03Z","title":"Choix d'un espace de représentation image adapté à la détection\n  de réseaux routiers","summary":"  These last years, algorithms allowing to decompose an image into its\nstructures and textures components have emerged. In this paper, we present an\napplication of this type of decomposition to the problem road network detection\nin aerial or satelite imagery. The algorithmic procedure involves the image\ndecomposition (using a unique property), an alignment detection step based on\nthe Gestalt theory, and a refinement step using statistical active contours.\n","authors":["Jerome Gilles"],"pdf_url":"https://arxiv.org/pdf/2411.08293v1.pdf","comment":"in French language"},{"id":"http://arxiv.org/abs/2411.08292v1","updated":"2024-11-13T02:17:57Z","published":"2024-11-13T02:17:57Z","title":"Noisy image decomposition: a new structure, texture and noise model\n  based on local adaptivity","summary":"  These last few years, image decomposition algorithms have been proposed to\nsplit an image into two parts: the structures and the textures. These\nalgorithms are not adapted to the case of noisy images because the textures are\ncorrupted by noise. In this paper, we propose a new model which decomposes an\nimage into three parts (structures, textures and noise) based on a local\nregularization scheme. We compare our results with the recent work of Aujol and\nChambolle. We finish by giving another model which combines the advantages of\nthe two previous ones.\n","authors":["Jerome Gilles"],"pdf_url":"https://arxiv.org/pdf/2411.08292v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2411.05265"},{"id":"http://arxiv.org/abs/2411.08291v1","updated":"2024-11-13T02:17:52Z","published":"2024-11-13T02:17:52Z","title":"Restoration algorithms and system performance evaluation for active\n  imagers","summary":"  This paper deals with two fields related to active imaging system. First, we\nbegin to explore image processing algorithms to restore the artefacts like\nspeckle, scintillation and image dancing caused by atmospheric turbulence.\nNext, we examine how to evaluate the performance of this kind of systems. To do\nthis task, we propose a modified version of the german TRM3 metric which\npermits to get MTF-like measures. We use the database acquired during NATO-TG40\nfield trials to make our tests.\n","authors":["Jerome Gilles"],"pdf_url":"https://arxiv.org/pdf/2411.08291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.03644v2","updated":"2024-11-13T01:45:31Z","published":"2024-09-05T16:02:11Z","title":"RealisHuman: A Two-Stage Approach for Refining Malformed Human Parts in\n  Generated Images","summary":"  In recent years, diffusion models have revolutionized visual generation,\noutperforming traditional frameworks like Generative Adversarial Networks\n(GANs). However, generating images of humans with realistic semantic parts,\nsuch as hands and faces, remains a significant challenge due to their intricate\nstructural complexity. To address this issue, we propose a novel\npost-processing solution named RealisHuman. The RealisHuman framework operates\nin two stages. First, it generates realistic human parts, such as hands or\nfaces, using the original malformed parts as references, ensuring consistent\ndetails with the original image. Second, it seamlessly integrates the rectified\nhuman parts back into their corresponding positions by repainting the\nsurrounding areas to ensure smooth and realistic blending. The RealisHuman\nframework significantly enhances the realism of human generation, as\ndemonstrated by notable improvements in both qualitative and quantitative\nmetrics. Code is available at https://github.com/Wangbenzhi/RealisHuman.\n","authors":["Benzhi Wang","Jingkai Zhou","Jingqi Bai","Yang Yang","Weihua Chen","Fan Wang","Zhen Lei"],"pdf_url":"https://arxiv.org/pdf/2409.03644v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.05386v2","updated":"2024-11-13T01:40:53Z","published":"2024-05-08T19:31:06Z","title":"Interpretability Needs a New Paradigm","summary":"  Interpretability is the study of explaining models in understandable terms to\nhumans. At present, interpretability is divided into two paradigms: the\nintrinsic paradigm, which believes that only models designed to be explained\ncan be explained, and the post-hoc paradigm, which believes that black-box\nmodels can be explained. At the core of this debate is how each paradigm\nensures its explanations are faithful, i.e., true to the model's behavior. This\nis important, as false but convincing explanations lead to unsupported\nconfidence in artificial intelligence (AI), which can be dangerous. This\npaper's position is that we should think about new paradigms while staying\nvigilant regarding faithfulness. First, by examining the history of paradigms\nin science, we see that paradigms are constantly evolving. Then, by examining\nthe current paradigms, we can understand their underlying beliefs, the value\nthey bring, and their limitations. Finally, this paper presents 3 emerging\nparadigms for interpretability. The first paradigm designs models such that\nfaithfulness can be easily measured. Another optimizes models such that\nexplanations become faithful. The last paradigm proposes to develop models that\nproduce both a prediction and an explanation.\n","authors":["Andreas Madsen","Himabindu Lakkaraju","Siva Reddy","Sarath Chandar"],"pdf_url":"https://arxiv.org/pdf/2405.05386v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08279v1","updated":"2024-11-13T01:38:06Z","published":"2024-11-13T01:38:06Z","title":"MBA-SLAM: Motion Blur Aware Dense Visual SLAM with Radiance Fields\n  Representation","summary":"  Emerging 3D scene representations, such as Neural Radiance Fields (NeRF) and\n3D Gaussian Splatting (3DGS), have demonstrated their effectiveness in\nSimultaneous Localization and Mapping (SLAM) for photo-realistic rendering,\nparticularly when using high-quality video sequences as input. However,\nexisting methods struggle with motion-blurred frames, which are common in\nreal-world scenarios like low-light or long-exposure conditions. This often\nresults in a significant reduction in both camera localization accuracy and map\nreconstruction quality. To address this challenge, we propose a dense visual\nSLAM pipeline (i.e. MBA-SLAM) to handle severe motion-blurred inputs. Our\napproach integrates an efficient motion blur-aware tracker with either neural\nradiance fields or Gaussian Splatting based mapper. By accurately modeling the\nphysical image formation process of motion-blurred images, our method\nsimultaneously learns 3D scene representation and estimates the cameras' local\ntrajectory during exposure time, enabling proactive compensation for motion\nblur caused by camera movement. In our experiments, we demonstrate that\nMBA-SLAM surpasses previous state-of-the-art methods in both camera\nlocalization and map reconstruction, showcasing superior performance across a\nrange of datasets, including synthetic and real datasets featuring sharp images\nas well as those affected by motion blur, highlighting the versatility and\nrobustness of our approach. Code is available at\nhttps://github.com/WU-CVGL/MBA-SLAM.\n","authors":["Peng Wang","Lingzhe Zhao","Yin Zhang","Shiyu Zhao","Peidong Liu"],"pdf_url":"https://arxiv.org/pdf/2411.08279v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08272v1","updated":"2024-11-13T00:49:05Z","published":"2024-11-13T00:49:05Z","title":"LBONet: Supervised Spectral Descriptors for Shape Analysis","summary":"  The Laplace-Beltrami operator has established itself in the field of\nnon-rigid shape analysis due to its many useful properties such as being\ninvariant under isometric transformation, having a countable eigensystem\nforming an orthonormal basis, and fully characterizing geodesic distances of\nthe manifold. However, this invariancy only applies under isometric\ndeformations, which leads to a performance breakdown in many real-world\napplications. In recent years emphasis has been placed upon extracting optimal\nfeatures using deep learning methods, however spectral signatures play a\ncrucial role and still add value. In this paper we take a step back, revisiting\nthe LBO and proposing a supervised way to learn several operators on a\nmanifold. Depending on the task, by applying these functions, we can train the\nLBO eigenbasis to be more task-specific. The optimization of the LBO leads to\nenormous improvements to established descriptors such as the heat kernel\nsignature in various tasks such as retrieval, classification, segmentation, and\ncorrespondence, proving the adaption of the LBO eigenbasis to both global and\nhighly local learning settings.\n","authors":["Oguzhan Yigit","Richard C. Wilson"],"pdf_url":"https://arxiv.org/pdf/2411.08272v1.pdf","comment":"14 pages, 13 figure"},{"id":"http://arxiv.org/abs/2404.09995v2","updated":"2024-11-13T00:41:01Z","published":"2024-04-15T17:59:57Z","title":"Taming Latent Diffusion Model for Neural Radiance Field Inpainting","summary":"  Neural Radiance Field (NeRF) is a representation for 3D reconstruction from\nmulti-view images. Despite some recent work showing preliminary success in\nediting a reconstructed NeRF with diffusion prior, they remain struggling to\nsynthesize reasonable geometry in completely uncovered regions. One major\nreason is the high diversity of synthetic contents from the diffusion model,\nwhich hinders the radiance field from converging to a crisp and deterministic\ngeometry. Moreover, applying latent diffusion models on real data often yields\na textural shift incoherent to the image condition due to auto-encoding errors.\nThese two problems are further reinforced with the use of pixel-distance\nlosses. To address these issues, we propose tempering the diffusion model's\nstochasticity with per-scene customization and mitigating the textural shift\nwith masked adversarial training. During the analyses, we also found the\ncommonly used pixel and perceptual losses are harmful in the NeRF inpainting\ntask. Through rigorous experiments, our framework yields state-of-the-art NeRF\ninpainting results on various real-world scenes. Project page:\nhttps://hubert0527.github.io/MALD-NeRF\n","authors":["Chieh Hubert Lin","Changil Kim","Jia-Bin Huang","Qinbo Li","Chih-Yao Ma","Johannes Kopf","Ming-Hsuan Yang","Hung-Yu Tseng"],"pdf_url":"https://arxiv.org/pdf/2404.09995v2.pdf","comment":"Accepted to ECCV 2024. Project page:\n  https://hubert0527.github.io/MALD-NeRF"},{"id":"http://arxiv.org/abs/2406.08164v3","updated":"2024-11-13T00:15:20Z","published":"2024-06-12T12:54:27Z","title":"ConMe: Rethinking Evaluation of Compositional Reasoning for Modern VLMs","summary":"  Compositional Reasoning (CR) entails grasping the significance of attributes,\nrelations, and word order. Recent Vision-Language Models (VLMs), comprising a\nvisual encoder and a Large Language Model (LLM) decoder, have demonstrated\nremarkable proficiency in such reasoning tasks. This prompts a crucial\nquestion: have VLMs effectively tackled the CR challenge? We conjecture that\nexisting CR benchmarks may not adequately push the boundaries of modern VLMs\ndue to the reliance on an LLM-only negative text generation pipeline.\nConsequently, the negatives produced either appear as outliers from the natural\nlanguage distribution learned by VLMs' LLM decoders or as improbable within the\ncorresponding image context. To address these limitations, we introduce ConMe\n-- a compositional reasoning benchmark and a novel data generation pipeline\nleveraging VLMs to produce `hard CR Q&A'. Through a new concept of VLMs\nconversing with each other to collaboratively expose their weaknesses, our\npipeline autonomously generates, evaluates, and selects challenging\ncompositional reasoning questions, establishing a robust CR benchmark, also\nsubsequently validated manually. Our benchmark provokes a noteworthy, up to\n33%, decrease in CR performance compared to preceding benchmarks, reinstating\nthe CR challenge even for state-of-the-art VLMs.\n","authors":["Irene Huang","Wei Lin","M. Jehanzeb Mirza","Jacob A. Hansen","Sivan Doveh","Victor Ion Butoi","Roei Herzig","Assaf Arbelle","Hilde Kuehne","Trevor Darrell","Chuang Gan","Aude Oliva","Rogerio Feris","Leonid Karlinsky"],"pdf_url":"https://arxiv.org/pdf/2406.08164v3.pdf","comment":"NeurIPS 2024 Camera Ready"},{"id":"http://arxiv.org/abs/2411.09077v1","updated":"2024-11-13T23:09:53Z","published":"2024-11-13T23:09:53Z","title":"Drone Detection using Deep Neural Networks Trained on Pure Synthetic\n  Data","summary":"  Drone detection has benefited from improvements in deep neural networks, but\nlike many other applications, suffers from the availability of accurate data\nfor training. Synthetic data provides a potential for low-cost data generation\nand has been shown to improve data availability and quality. However, models\ntrained on synthetic datasets need to prove their ability to perform on\nreal-world data, known as the problem of sim-to-real transferability. Here, we\npresent a drone detection Faster-RCNN model trained on a purely synthetic\ndataset that transfers to real-world data. We found that it achieves an AP_50\nof 97.0% when evaluated on the MAV-Vid - a real dataset of flying drones -\ncompared with 97.8% for an equivalent model trained on real-world data. Our\nresults show that using synthetic data for drone detection has the potential to\nreduce data collection costs and improve labelling quality. These findings\ncould be a starting point for more elaborate synthetic drone datasets. For\nexample, realistic recreations of specific scenarios could de-risk the dataset\ngeneration of safety-critical applications such as the detection of drones at\nairports. Further, synthetic data may enable reliable drone detection systems,\nwhich could benefit other areas, such as unmanned traffic management systems.\nThe code is available\nhttps://github.com/mazqtpopx/cranfield-synthetic-drone-detection alongside the\ndatasets\nhttps://huggingface.co/datasets/mazqtpopx/cranfield-synthetic-drone-detection.\n","authors":["Mariusz Wisniewski","Zeeshan A. Rana","Ivan Petrunin","Alan Holt","Stephen Harman"],"pdf_url":"https://arxiv.org/pdf/2411.09077v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.09066v1","updated":"2024-11-13T22:47:24Z","published":"2024-11-13T22:47:24Z","title":"A multidimensional measurement of photorealistic avatar quality of\n  experience","summary":"  Photorealistic avatars are human avatars that look, move, and talk like real\npeople. The performance of photorealistic avatars has significantly improved\nrecently based on objective metrics such as PSNR, SSIM, LPIPS, FID, and FVD.\nHowever, recent photorealistic avatar publications do not provide subjective\ntests of the avatars to measure human usability factors. We provide an open\nsource test framework to subjectively measure photorealistic avatar performance\nin ten dimensions: realism, trust, comfortableness using, comfortableness\ninteracting with, appropriateness for work, creepiness, formality, affinity,\nresemblance to the person, and emotion accuracy. We show that the correlation\nof nine of these subjective metrics with PSNR, SSIM, LPIPS, FID, and FVD is\nweak, and moderate for emotion accuracy. The crowdsourced subjective test\nframework is highly reproducible and accurate when compared to a panel of\nexperts. We analyze a wide range of avatars from photorealistic to cartoon-like\nand show that some photorealistic avatars are approaching real video\nperformance based on these dimensions. We also find that for avatars above a\ncertain level of realism, eight of these measured dimensions are strongly\ncorrelated. In particular, for photorealistic avatars there is a linear\nrelationship between avatar affinity and realism; in other words, there is no\nuncanny valley effect for photorealistic avatars in the telecommunication\nscenario. We provide several extensions of this test framework for future work\nand discuss design implications for telecommunication systems. The test\nframework is available at https://github.com/microsoft/P.910.\n","authors":["Ross Cutler","Babak Naderi","Vishak Gopal","Dharmendar Palle"],"pdf_url":"https://arxiv.org/pdf/2411.09066v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2204.06784"},{"id":"http://arxiv.org/abs/2411.09062v1","updated":"2024-11-13T22:43:15Z","published":"2024-11-13T22:43:15Z","title":"Multimodal Object Detection using Depth and Image Data for Manufacturing\n  Parts","summary":"  Manufacturing requires reliable object detection methods for precise picking\nand handling of diverse types of manufacturing parts and components.\nTraditional object detection methods utilize either only 2D images from cameras\nor 3D data from lidars or similar 3D sensors. However, each of these sensors\nhave weaknesses and limitations. Cameras do not have depth perception and 3D\nsensors typically do not carry color information. These weaknesses can\nundermine the reliability and robustness of industrial manufacturing systems.\nTo address these challenges, this work proposes a multi-sensor system combining\nan red-green-blue (RGB) camera and a 3D point cloud sensor. The two sensors are\ncalibrated for precise alignment of the multimodal data captured from the two\nhardware devices. A novel multimodal object detection method is developed to\nprocess both RGB and depth data. This object detector is based on the Faster\nR-CNN baseline that was originally designed to process only camera images. The\nresults show that the multimodal model significantly outperforms the depth-only\nand RGB-only baselines on established object detection metrics. More\nspecifically, the multimodal model improves mAP by 13% and raises Mean\nPrecision by 11.8% in comparison to the RGB-only baseline. Compared to the\ndepth-only baseline, it improves mAP by 78% and raises Mean Precision by 57%.\nHence, this method facilitates more reliable and robust object detection in\nservice to smart manufacturing applications.\n","authors":["Nazanin Mahjourian","Vinh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2411.09062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09037v1","updated":"2024-11-13T21:31:12Z","published":"2024-11-13T21:31:12Z","title":"A Transformer-Based Visual Piano Transcription Algorithm","summary":"  Automatic music transcription (AMT) for musical performances is a long\nstanding problem in the field of Music Information Retrieval (MIR). Visual\npiano transcription (VPT) is a multimodal subproblem of AMT which focuses on\nextracting a symbolic representation of a piano performance from visual\ninformation only (e.g., from a top-down video of the piano keyboard). Inspired\nby the success of Transformers for audio-based AMT, as well as their recent\nsuccesses in other computer vision tasks, in this paper we present a\nTransformer based architecture for VPT. The proposed VPT system combines a\npiano bounding box detection model with an onset and pitch detection model,\nallowing our system to perform well in more naturalistic conditions like\nimperfect image crops around the piano and slightly tilted images.\n","authors":["Uros Zivanovic","Carlos Eduardo Cancino-Chacón"],"pdf_url":"https://arxiv.org/pdf/2411.09037v1.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.09023v1","updated":"2024-11-13T21:00:28Z","published":"2024-11-13T21:00:28Z","title":"CoMiX: Cross-Modal Fusion with Deformable Convolutions for HSI-X\n  Semantic Segmentation","summary":"  Improving hyperspectral image (HSI) semantic segmentation by exploiting\ncomplementary information from a supplementary data type (referred to\nX-modality) is promising but challenging due to differences in imaging sensors,\nimage content, and resolution. Current techniques struggle to enhance\nmodality-specific and modality-shared information, as well as to capture\ndynamic interaction and fusion between different modalities. In response, this\nstudy proposes CoMiX, an asymmetric encoder-decoder architecture with\ndeformable convolutions (DCNs) for HSI-X semantic segmentation. CoMiX is\ndesigned to extract, calibrate, and fuse information from HSI and X data. Its\npipeline includes an encoder with two parallel and interacting backbones and a\nlightweight all-multilayer perceptron (ALL-MLP) decoder. The encoder consists\nof four stages, each incorporating 2D DCN blocks for the X model to accommodate\ngeometric variations and 3D DCN blocks for HSIs to adaptively aggregate\nspatial-spectral features. Additionally, each stage includes a Cross-Modality\nFeature enhancement and eXchange (CMFeX) module and a feature fusion module\n(FFM). CMFeX is designed to exploit spatial-spectral correlations from\ndifferent modalities to recalibrate and enhance modality-specific and\nmodality-shared features while adaptively exchanging complementary information\nbetween them. Outputs from CMFeX are fed into the FFM for fusion and passed to\nthe next stage for further information learning. Finally, the outputs from each\nFFM are integrated by the ALL-MLP decoder for final prediction. Extensive\nexperiments demonstrate that our CoMiX achieves superior performance and\ngeneralizes well to various multimodal recognition tasks. The CoMiX code will\nbe released.\n","authors":["Xuming Zhang","Xingfa Gu","Qingjiu Tian","Lorenzo Bruzzone"],"pdf_url":"https://arxiv.org/pdf/2411.09023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09018v1","updated":"2024-11-13T20:50:04Z","published":"2024-11-13T20:50:04Z","title":"Bridging the Visual Gap: Fine-Tuning Multimodal Models with\n  Knowledge-Adapted Captions","summary":"  Recent research increasingly focuses on training vision-language models\n(VLMs) with long, detailed image captions. However, small-scale VLMs often\nstruggle to balance the richness of these captions with the risk of\nhallucinating content during fine-tuning. In this paper, we explore how well\nVLMs adapt to such captions. To quantify caption quality, we propose Decomposed\nNLI (DNLI), an evaluation framework that breaks down generated captions into\nindividual propositions, assessing each in isolation. This fine-grained\nanalysis reveals a critical balance between capturing descriptive details and\npreventing hallucinations. Our findings show that simply reducing caption\ncomplexity or employing standard data curation techniques does not effectively\nresolve this issue. To tackle this challenge, we introduce Knowledge Adapted\n(KnowAda) fine-tuning, a data-centric approach that automatically adapts\ntraining data with the model's existing knowledge and visual understanding.\nKnowAda minimizes hallucinations while preserving high descriptiveness. We\nvalidate this approach across several small-scale VLMs (up to 7B parameters)\nand dense caption datasets, demonstrating that KnowAda effectively balances\nhallucination reduction and descriptiveness. Our results show that KnowAda\noutperforms various baselines in both automatic metrics and human evaluations.\nWe will release our code and models.\n","authors":["Moran Yanuka","Assaf Ben Kish","Yonatan Bitton","Idan Szpektor","Raja Giryes"],"pdf_url":"https://arxiv.org/pdf/2411.09018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15955v2","updated":"2024-11-13T20:30:13Z","published":"2024-06-22T22:43:10Z","title":"Beyond the Doors of Perception: Vision Transformers Represent Relations\n  Between Objects","summary":"  Though vision transformers (ViTs) have achieved state-of-the-art performance\nin a variety of settings, they exhibit surprising failures when performing\ntasks involving visual relations. This begs the question: how do ViTs attempt\nto perform tasks that require computing visual relations between objects? Prior\nefforts to interpret ViTs tend to focus on characterizing relevant low-level\nvisual features. In contrast, we adopt methods from mechanistic\ninterpretability to study the higher-level visual algorithms that ViTs use to\nperform abstract visual reasoning. We present a case study of a fundamental,\nyet surprisingly difficult, relational reasoning task: judging whether two\nvisual entities are the same or different. We find that pretrained ViTs\nfine-tuned on this task often exhibit two qualitatively different stages of\nprocessing despite having no obvious inductive biases to do so: 1) a perceptual\nstage wherein local object features are extracted and stored in a disentangled\nrepresentation, and 2) a relational stage wherein object representations are\ncompared. In the second stage, we find evidence that ViTs can learn to\nrepresent somewhat abstract visual relations, a capability that has long been\nconsidered out of reach for artificial neural networks. Finally, we demonstrate\nthat failures at either stage can prevent a model from learning a generalizable\nsolution to our fairly simple tasks. By understanding ViTs in terms of discrete\nprocessing stages, one can more precisely diagnose and rectify shortcomings of\nexisting and future models.\n","authors":["Michael A. Lepori","Alexa R. Tartaglini","Wai Keen Vong","Thomas Serre","Brenden M. Lake","Ellie Pavlick"],"pdf_url":"https://arxiv.org/pdf/2406.15955v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.02501v3","updated":"2024-11-13T20:30:04Z","published":"2024-01-04T19:25:00Z","title":"A metric embedding kernel for live cell microscopy signaling patterns","summary":"  Live cell microscopy captures 5-D $(x,y,z,channel,time)$ movies that display\npatterns of cellular motion and signaling dynamics. We present here a metric\nkernel function for spatiotemporal patterns of cell signaling dynamics in 5-D\nlive cell microscopy movies unique in requiring no a priori knowledge of\nexpected pattern dynamics, and no training data. The approach uses Kolmogorov\ncomplexity theory to compute a metric distance between movies and to measure\nthe meaningful information among subsets of movies. Cell signaling kymographs\nstore at each spatiotemporal cell centroid the cell signaling state, or a\nfunctional output such as velocity. Patterns of similarity are identified via\nthe metric normalized compression distance (NCD). The NCD is a reproducing\nkernel for a Hilbert space that represents the input cell signaling kymographs\nas points in a low dimensional embedding that optimally captures the pattern\nsimilarity identified by the NCD throughout the space. The only parameter is\nthe expected cell radii ($\\mu m$). A new formulation of the cluster structure\nfunction optimally estimates the meaningful information captured by the\nembedding. Also presented is the cell signaling structure function (SSF), a\nKolmogorov structure function that optimally measures cell signaling state as\nnuclear intensity w.r.t. surrounding cytoplasm, a significant improvement\ncompared to the current state-of-the-art cytonuclear ratio. Results are\npresented quantifying the impact of ERK and AKT signaling between different\noncogenic mutations, and by the relation between ERK signaling and cellular\nvelocity patterns for movies of 2-D monolayers of human breast epithelial\n(MCF10A) cells, 3-D MCF10A spheroids under optogenetic manipulation of ERK, and\nhuman induced pluripotent stem cells.\n","authors":["Layton Aho","Mark Winter","Marc DeCarlo","Agne Frismantiene","Yannick Blum","Paolo Armando Gagliardi","Olivier Pertz","Andrew R. Cohen"],"pdf_url":"https://arxiv.org/pdf/2401.02501v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09007v1","updated":"2024-11-13T20:17:30Z","published":"2024-11-13T20:17:30Z","title":"Scale Contrastive Learning with Selective Attentions for Blind Image\n  Quality Assessment","summary":"  Blind image quality assessment (BIQA) serves as a fundamental task in\ncomputer vision, yet it often fails to consistently align with human subjective\nperception. Recent advances show that multi-scale evaluation strategies are\npromising due to their ability to replicate the hierarchical structure of human\nvision. However, the effectiveness of these strategies is limited by a lack of\nunderstanding of how different image scales influence perceived quality. This\npaper addresses two primary challenges: the significant redundancy of\ninformation across different scales, and the confusion caused by combining\nfeatures from these scales, which may vary widely in quality. To this end, a\nnew multi-scale BIQA framework is proposed, namely Contrast-Constrained\nScale-Focused IQA Framework (CSFIQA). CSFIQA features a selective focus\nattention mechanism to minimize information redundancy and highlight critical\nquality-related information. Additionally, CSFIQA includes a scale-level\ncontrastive learning module equipped with a noise sample matching mechanism to\nidentify quality discrepancies across the same image content at different\nscales. By exploring the intrinsic relationship between image scales and the\nperceived quality, the proposed CSFIQA achieves leading performance on eight\nbenchmark datasets, e.g., achieving SRCC values of 0.967 (versus 0.947 in CSIQ)\nand 0.905 (versus 0.876 in LIVEC).\n","authors":["Zihao Huang","Xudong Li","Bohan Fu","Xiaohui Chu","Ke Li","Yunhang Shen","Yan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.09007v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08995v1","updated":"2024-11-13T19:34:10Z","published":"2024-11-13T19:34:10Z","title":"Computed tomography using meta-optics","summary":"  Computer vision tasks require processing large amounts of data to perform\nimage classification, segmentation, and feature extraction. Optical\npreprocessors can potentially reduce the number of floating point operations\nrequired by computer vision tasks, enabling low-power and low-latency\noperation. However, existing optical preprocessors are mostly learned and hence\nstrongly depend on the training data, and thus lack universal applicability. In\nthis paper, we present a metaoptic imager, which implements the Radon transform\nobviating the need for training the optics. High quality image reconstruction\nwith a large compression ratio of 0.6% is presented through the use of the\nSimultaneous Algebraic Reconstruction Technique. Image classification with 90%\naccuracy is presented on an experimentally measured Radon dataset through\nneural network trained on digitally transformed images.\n","authors":["Maksym Zhelyeznuyakov","Johannes E. Fröch","Shane Colburn","Steven L. Brunton","Arka Majumdar"],"pdf_url":"https://arxiv.org/pdf/2411.08995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08992v1","updated":"2024-11-13T19:33:08Z","published":"2024-11-13T19:33:08Z","title":"IDCIA: Immunocytochemistry Dataset for Cellular Image Analysis","summary":"  We present a new annotated microscopic cellular image dataset to improve the\neffectiveness of machine learning methods for cellular image analysis. Cell\ncounting is an important step in cell analysis. Typically, domain experts\nmanually count cells in a microscopic image. Automated cell counting can\npotentially eliminate this tedious, time-consuming process. However, a good,\nlabeled dataset is required for training an accurate machine learning model.\nOur dataset includes microscopic images of cells, and for each image, the cell\ncount and the location of individual cells. The data were collected as part of\nan ongoing study investigating the potential of electrical stimulation to\nmodulate stem cell differentiation and possible applications for neural repair.\nCompared to existing publicly available datasets, our dataset has more images\nof cells stained with more variety of antibodies (protein components of immune\nresponses against invaders) typically used for cell analysis. The experimental\nresults on this dataset indicate that none of the five existing models under\nthis study are able to achieve sufficiently accurate count to replace the\nmanual methods. The dataset is available at\nhttps://figshare.com/articles/dataset/Dataset/21970604.\n","authors":["Abdurahman Ali Mohammed","Catherine Fonder","Donald S. Sakaguchi","Wallapak Tavanapong","Surya K. Mallapragada","Azeez Idris"],"pdf_url":"https://arxiv.org/pdf/2411.08992v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08975v1","updated":"2024-11-13T19:06:57Z","published":"2024-11-13T19:06:57Z","title":"Fluoroformer: Scaling multiple instance learning to multiplexed images\n  via attention-based channel fusion","summary":"  Though multiple instance learning (MIL) has been a foundational strategy in\ncomputational pathology for processing whole slide images (WSIs), current\napproaches are designed for traditional hematoxylin and eosin (H&E) slides\nrather than emerging multiplexed technologies. Here, we present an MIL\nstrategy, the Fluoroformer module, that is specifically tailored to multiplexed\nWSIs by leveraging scaled dot-product attention (SDPA) to interpretably fuse\ninformation across disparate channels. On a cohort of 434 non-small cell lung\ncancer (NSCLC) samples, we show that the Fluoroformer both obtains strong\nprognostic performance and recapitulates immuno-oncological hallmarks of NSCLC.\nOur technique thereby provides a path for adapting state-of-the-art AI\ntechniques to emerging spatial biology assays.\n","authors":["Marc Harary","Eliezer M. Van Allen","William Lotter"],"pdf_url":"https://arxiv.org/pdf/2411.08975v1.pdf","comment":"Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 14 pages"},{"id":"http://arxiv.org/abs/1902.00615v6","updated":"2024-11-13T18:32:53Z","published":"2019-02-02T01:52:53Z","title":"Confidence Trigger Detection: Accelerating Real-time\n  Tracking-by-detection Systems","summary":"  Real-time object tracking necessitates a delicate balance between speed and\naccuracy, a challenge exacerbated by the computational demands of deep learning\nmethods. In this paper, we propose Confidence-Triggered Detection (CTD), an\ninnovative approach that strategically bypasses object detection for frames\nclosely resembling intermediate states, leveraging tracker confidence scores.\nCTD not only enhances tracking speed but also preserves accuracy, surpassing\nexisting tracking algorithms. Through extensive evaluation across various\ntracker confidence thresholds, we identify an optimal trade-off between\ntracking speed and accuracy, providing crucial insights for parameter\nfine-tuning and enhancing CTD's practicality in real-world scenarios. Our\nexperiments across diverse detection models underscore the robustness and\nversatility of the CTD framework, demonstrating its potential to enable\nreal-time tracking in resource-constrained environments.\n","authors":["Zhicheng Ding","Zhixin Lai","Siyang Li","Panfeng Li","Qikai Yang","Edward Wong"],"pdf_url":"https://arxiv.org/pdf/1902.00615v6.pdf","comment":"Accepted by 2024 5th International Conference on Electronic\n  Communication and Artificial Intelligence"},{"id":"http://arxiv.org/abs/2411.08937v1","updated":"2024-11-13T12:33:04Z","published":"2024-11-13T12:33:04Z","title":"Dual-Head Knowledge Distillation: Enhancing Logits Utilization with an\n  Auxiliary Head","summary":"  Traditional knowledge distillation focuses on aligning the student's\npredicted probabilities with both ground-truth labels and the teacher's\npredicted probabilities. However, the transition to predicted probabilities\nfrom logits would obscure certain indispensable information. To address this\nissue, it is intuitive to additionally introduce a logit-level loss function as\na supplement to the widely used probability-level loss function, for exploiting\nthe latent information of logits. Unfortunately, we empirically find that the\namalgamation of the newly introduced logit-level loss and the previous\nprobability-level loss will lead to performance degeneration, even trailing\nbehind the performance of employing either loss in isolation. We attribute this\nphenomenon to the collapse of the classification head, which is verified by our\ntheoretical analysis based on the neural collapse theory. Specifically, the\ngradients of the two loss functions exhibit contradictions in the linear\nclassifier yet display no such conflict within the backbone. Drawing from the\ntheoretical analysis, we propose a novel method called dual-head knowledge\ndistillation, which partitions the linear classifier into two classification\nheads responsible for different losses, thereby preserving the beneficial\neffects of both losses on the backbone while eliminating adverse influences on\nthe classification head. Extensive experiments validate that our method can\neffectively exploit the information inside the logits and achieve superior\nperformance against state-of-the-art counterparts.\n","authors":["Penghui Yang","Chen-Chen Zong","Sheng-Jun Huang","Lei Feng","Bo An"],"pdf_url":"https://arxiv.org/pdf/2411.08937v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2411.08936v1","updated":"2024-11-13T11:25:05Z","published":"2024-11-13T11:25:05Z","title":"Clustered Patch Embeddings for Permutation-Invariant Classification of\n  Whole Slide Images","summary":"  Whole Slide Imaging (WSI) is a cornerstone of digital pathology, offering\ndetailed insights critical for diagnosis and research. Yet, the gigapixel size\nof WSIs imposes significant computational challenges, limiting their practical\nutility. Our novel approach addresses these challenges by leveraging various\nencoders for intelligent data reduction and employing a different\nclassification model to ensure robust, permutation-invariant representations of\nWSIs. A key innovation of our method is the ability to distill the complex\ninformation of an entire WSI into a single vector, effectively capturing the\nessential features needed for accurate analysis. This approach significantly\nenhances the computational efficiency of WSI analysis, enabling more accurate\npathological assessments without the need for extensive computational\nresources. This breakthrough equips us with the capability to effectively\naddress the challenges posed by large image resolutions in whole-slide imaging,\npaving the way for more scalable and effective utilization of WSIs in medical\ndiagnostics and research, marking a significant advancement in the field.\n","authors":["Ravi Kant Gupta","Shounak Das","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2411.08936v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2411.08530"},{"id":"http://arxiv.org/abs/2411.08935v1","updated":"2024-11-13T10:58:39Z","published":"2024-11-13T10:58:39Z","title":"Classification of Keratitis from Eye Corneal Photographs using Deep\n  Learning","summary":"  Keratitis is an inflammatory corneal condition responsible for 10% of visual\nimpairment in low- and middle-income countries (LMICs), with bacteria, fungi,\nor amoeba as the most common infection etiologies. While an accurate and timely\ndiagnosis is crucial for the selected treatment and the patients' sight\noutcomes, due to the high cost and limited availability of laboratory\ndiagnostics in LMICs, diagnosis is often made by clinical observation alone,\ndespite its lower accuracy. In this study, we investigate and compare different\ndeep learning approaches to diagnose the source of infection: 1) three separate\nbinary models for infection type predictions; 2) a multitask model with a\nshared backbone and three parallel classification layers (Multitask V1); and,\n3) a multitask model with a shared backbone and a multi-head classification\nlayer (Multitask V2). We used a private Brazilian cornea dataset to conduct the\nempirical evaluation. We achieved the best results with Multitask V2, with an\narea under the receiver operating characteristic curve (AUROC) confidence\nintervals of 0.7413-0.7740 (bacteria), 0.8395-0.8725 (fungi), and 0.9448-0.9616\n(amoeba). A statistical analysis of the impact of patient features on models'\nperformance revealed that sex significantly affects amoeba infection\nprediction, and age seems to affect fungi and bacteria predictions.\n","authors":["Maria Miguel Beirão","João Matos","Tiago Gonçalves","Camila Kase","Luis Filipe Nakayama","Denise de Freitas","Jaime S. Cardoso"],"pdf_url":"https://arxiv.org/pdf/2411.08935v1.pdf","comment":"6 pages; Accepted at IEEE's International Conference on\n  Bioinformatics and Biomedicine (2024)"},{"id":"http://arxiv.org/abs/2411.08934v1","updated":"2024-11-13T09:47:58Z","published":"2024-11-13T09:47:58Z","title":"Predicting household socioeconomic position in Mozambique using\n  satellite and household imagery","summary":"  Many studies have predicted SocioEconomic Position (SEP) for aggregated\nspatial units such as villages using satellite data, but SEP prediction at the\nhousehold level and other sources of imagery have not been yet explored. We\nassembled a dataset of 975 households in a semi-rural district in southern\nMozambique, consisting of self-reported asset, expenditure, and income SEP\ndata, as well as multimodal imagery including satellite images and a\nground-based photograph survey of 11 household elements. We fine-tuned a\nconvolutional neural network to extract feature vectors from the images, which\nwe then used in regression analyzes to model household SEP using different sets\nof image types. The best prediction performance was found when modeling\nasset-based SEP using random forest models with all image types, while the\nperformance for expenditure- and income-based SEP was lower. Using SHAP, we\nobserved clear differences between the images with the largest positive and\nnegative effects, as well as identified the most relevant household elements in\nthe predictions. Finally, we fitted an additional reduced model using only the\nidentified relevant household elements, which had an only slightly lower\nperformance compared to models using all images. Our results show how\nground-based household photographs allow to zoom in from an area-level to an\nindividual household prediction while minimizing the data collection effort by\nusing explainable machine learning. The developed workflow can be potentially\nintegrated into routine household surveys, where the collected household\nimagery could be used for other purposes, such as refined asset\ncharacterization and environmental exposure assessment.\n","authors":["Carles Milà","Teodimiro Matsena","Edgar Jamisse","Jovito Nunes","Quique Bassat","Paula Petrone","Elisa Sicuri","Charfudin Sacoor","Cathryn Tonne"],"pdf_url":"https://arxiv.org/pdf/2411.08934v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08933v1","updated":"2024-11-13T09:13:20Z","published":"2024-11-13T09:13:20Z","title":"Confidence-aware Denoised Fine-tuning of Off-the-shelf Models for\n  Certified Robustness","summary":"  The remarkable advances in deep learning have led to the emergence of many\noff-the-shelf classifiers, e.g., large pre-trained models. However, since they\nare typically trained on clean data, they remain vulnerable to adversarial\nattacks. Despite this vulnerability, their superior performance and\ntransferability make off-the-shelf classifiers still valuable in practice,\ndemanding further work to provide adversarial robustness for them in a post-hoc\nmanner. A recently proposed method, denoised smoothing, leverages a denoiser\nmodel in front of the classifier to obtain provable robustness without\nadditional training. However, the denoiser often creates hallucination, i.e.,\nimages that have lost the semantics of their originally assigned class, leading\nto a drop in robustness. Furthermore, its noise-and-denoise procedure\nintroduces a significant distribution shift from the original distribution,\ncausing the denoised smoothing framework to achieve sub-optimal robustness. In\nthis paper, we introduce Fine-Tuning with Confidence-Aware Denoised Image\nSelection (FT-CADIS), a novel fine-tuning scheme to enhance the certified\nrobustness of off-the-shelf classifiers. FT-CADIS is inspired by the\nobservation that the confidence of off-the-shelf classifiers can effectively\nidentify hallucinated images during denoised smoothing. Based on this, we\ndevelop a confidence-aware training objective to handle such hallucinated\nimages and improve the stability of fine-tuning from denoised images. In this\nway, the classifier can be fine-tuned using only images that are beneficial for\nadversarial robustness. We also find that such a fine-tuning can be done by\nupdating a small fraction of parameters of the classifier. Extensive\nexperiments demonstrate that FT-CADIS has established the state-of-the-art\ncertified robustness among denoised smoothing methods across all\n$\\ell_2$-adversary radius in various benchmarks.\n","authors":["Suhyeok Jang","Seojin Kim","Jinwoo Shin","Jongheon Jeong"],"pdf_url":"https://arxiv.org/pdf/2411.08933v1.pdf","comment":"26 pages; TMLR 2024; Code is available at\n  https://github.com/suhyeok24/FT-CADIS"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2411.08878v1","updated":"2024-11-13T18:55:10Z","published":"2024-11-13T18:55:10Z","title":"A Short Note on Evaluating RepNet for Temporal Repetition Counting in\n  Videos","summary":"  We discuss some consistent issues on how RepNet has been evaluated in various\npapers. As a way to mitigate these issues, we report RepNet performance results\non different datasets, and release evaluation code and the RepNet checkpoint to\nobtain these results. Code URL:\nhttps://github.com/google-research/google-research/blob/master/repnet/\n","authors":["Debidatta Dwibedi","Yusuf Aytar","Jonathan Tompson","Pierre Sermanet","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2411.08878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08870v1","updated":"2024-11-13T18:50:13Z","published":"2024-11-13T18:50:13Z","title":"The Limited Impact of Medical Adaptation of Large Language and\n  Vision-Language Models","summary":"  Several recent works seek to develop foundation models specifically for\nmedical applications, adapting general-purpose large language models (LLMs) and\nvision-language models (VLMs) via continued pretraining on publicly available\nbiomedical corpora. These works typically claim that such domain-adaptive\npretraining (DAPT) improves performance on downstream medical tasks, such as\nanswering medical licensing exam questions. In this paper, we compare ten\npublic \"medical\" LLMs and two VLMs against their corresponding base models,\narriving at a different conclusion: all medical VLMs and nearly all medical\nLLMs fail to consistently improve over their base models in the zero-/few-shot\nprompting and supervised fine-tuning regimes for medical question-answering\n(QA). For instance, across all tasks and model pairs we consider in the 3-shot\nsetting, medical LLMs only outperform their base models in 22.7% of cases,\nreach a (statistical) tie in 36.8% of cases, and are significantly worse than\ntheir base models in the remaining 40.5% of cases. Our conclusions are based on\n(i) comparing each medical model head-to-head, directly against the\ncorresponding base model; (ii) optimizing the prompts for each model separately\nin zero-/few-shot prompting; and (iii) accounting for statistical uncertainty\nin comparisons. While these basic practices are not consistently adopted in the\nliterature, our ablations show that they substantially impact conclusions.\nMeanwhile, we find that after fine-tuning on specific QA tasks, medical LLMs\ncan show performance improvements, but the benefits do not carry over to tasks\nbased on clinical notes. Our findings suggest that state-of-the-art\ngeneral-domain models may already exhibit strong medical knowledge and\nreasoning capabilities, and offer recommendations to strengthen the conclusions\nof future studies.\n","authors":["Daniel P. Jeong","Pranav Mani","Saurabh Garg","Zachary C. Lipton","Michael Oberst"],"pdf_url":"https://arxiv.org/pdf/2411.08870v1.pdf","comment":"Extended version of EMNLP 2024 paper arXiv:2411.04118. Includes\n  additional results on clinical note QA tasks and supervised fine-tuning\n  evaluations"},{"id":"http://arxiv.org/abs/2411.08867v1","updated":"2024-11-13T18:48:51Z","published":"2024-11-13T18:48:51Z","title":"Unsupervised Parameter-free Outlier Detection using HDBSCAN* Outlier\n  Profiles","summary":"  In machine learning and data mining, outliers are data points that\nsignificantly differ from the dataset and often introduce irrelevant\ninformation that can induce bias in its statistics and models. Therefore,\nunsupervised methods are crucial to detect outliers if there is limited or no\ninformation about them. Global-Local Outlier Scores based on Hierarchies\n(GLOSH) is an unsupervised outlier detection method within HDBSCAN*, a\nstate-of-the-art hierarchical clustering method. GLOSH estimates outlier scores\nfor each data point by comparing its density to the highest density of the\nregion they reside in the HDBSCAN* hierarchy. GLOSH may be sensitive to\nHDBSCAN*'s minpts parameter that influences density estimation. With limited\nknowledge about the data, choosing an appropriate minpts value beforehand is\nchallenging as one or some minpts values may better represent the underlying\ncluster structure than others. Additionally, in the process of searching for\n``potential outliers'', one has to define the number of outliers n a dataset\nhas, which may be impractical and is often unknown. In this paper, we propose\nan unsupervised strategy to find the ``best'' minpts value, leveraging the\nrange of GLOSH scores across minpts values to identify the value for which\nGLOSH scores can best identify outliers from the rest of the dataset. Moreover,\nwe propose an unsupervised strategy to estimate a threshold for classifying\npoints into inliers and (potential) outliers without the need to pre-define any\nvalue. Our experiments show that our strategies can automatically find the\nminpts value and threshold that yield the best or near best outlier detection\nresults using GLOSH.\n","authors":["Kushankur Ghosh","Murilo Coelho Naldi","Jörg Sander","Euijin Choo"],"pdf_url":"https://arxiv.org/pdf/2411.08867v1.pdf","comment":"Accepted at IEEE International Conference on Big Data, IEEE BigData\n  2024"},{"id":"http://arxiv.org/abs/2411.08862v1","updated":"2024-11-13T18:44:30Z","published":"2024-11-13T18:44:30Z","title":"LLMStinger: Jailbreaking LLMs using RL fine-tuned LLMs","summary":"  We introduce LLMStinger, a novel approach that leverages Large Language\nModels (LLMs) to automatically generate adversarial suffixes for jailbreak\nattacks. Unlike traditional methods, which require complex prompt engineering\nor white-box access, LLMStinger uses a reinforcement learning (RL) loop to\nfine-tune an attacker LLM, generating new suffixes based on existing attacks\nfor harmful questions from the HarmBench benchmark. Our method significantly\noutperforms existing red-teaming approaches (we compared against 15 of the\nlatest methods), achieving a +57.2% improvement in Attack Success Rate (ASR) on\nLLaMA2-7B-chat and a +50.3% ASR increase on Claude 2, both models known for\ntheir extensive safety measures. Additionally, we achieved a 94.97% ASR on\nGPT-3.5 and 99.4% on Gemma-2B-it, demonstrating the robustness and adaptability\nof LLMStinger across open and closed-source models.\n","authors":["Piyush Jha","Arnav Arora","Vijay Ganesh"],"pdf_url":"https://arxiv.org/pdf/2411.08862v1.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2411.08861v1","updated":"2024-11-13T18:42:34Z","published":"2024-11-13T18:42:34Z","title":"Interaction Testing in Variation Analysis","summary":"  Relationships of cause and effect are of prime importance for explaining\nscientific phenomena. Often, rather than just understanding the effects of\ncauses, researchers also wish to understand how a cause $X$ affects an outcome\n$Y$ mechanistically -- i.e., what are the causal pathways that are activated\nbetween $X$ and $Y$. For analyzing such questions, a range of methods has been\ndeveloped over decades under the rubric of causal mediation analysis.\nTraditional mediation analysis focuses on decomposing the average treatment\neffect (ATE) into direct and indirect effects, and therefore focuses on the ATE\nas the central quantity. This corresponds to providing explanations for\nassociations in the interventional regime, such as when the treatment $X$ is\nrandomized. Commonly, however, it is of interest to explain associations in the\nobservational regime, and not just in the interventional regime. In this paper,\nwe introduce \\text{variation analysis}, an extension of mediation analysis that\nfocuses on the total variation (TV) measure between $X$ and $Y$, written as\n$\\mathrm{E}[Y \\mid X=x_1] - \\mathrm{E}[Y \\mid X=x_0]$. The TV measure\nencompasses both causal and confounded effects, as opposed to the ATE which\nonly encompasses causal (direct and mediated) variations. In this way, the TV\nmeasure is suitable for providing explanations in the natural regime and\nanswering questions such as ``why is $X$ associated with $Y$?''. Our focus is\non decomposing the TV measure, in a way that explicitly includes direct,\nindirect, and confounded variations. Furthermore, we also decompose the TV\nmeasure to include interaction terms between these different pathways.\nSubsequently, interaction testing is introduced, involving hypothesis tests to\ndetermine if interaction terms are significantly different from zero. If\ninteractions are not significant, more parsimonious decompositions of the TV\nmeasure can be used.\n","authors":["Drago Plecko"],"pdf_url":"https://arxiv.org/pdf/2411.08861v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.13880v4","updated":"2024-11-13T18:31:18Z","published":"2024-04-22T05:07:02Z","title":"Regional Style and Color Transfer","summary":"  This paper presents a novel contribution to the field of regional style\ntransfer. Existing methods often suffer from the drawback of applying style\nhomogeneously across the entire image, leading to stylistic inconsistencies or\nforeground object twisted when applied to image with foreground elements such\nas person figures. To address this limitation, we propose a new approach that\nleverages a segmentation network to precisely isolate foreground objects within\nthe input image. Subsequently, style transfer is applied exclusively to the\nbackground region. The isolated foreground objects are then carefully\nreintegrated into the style-transferred background. To enhance the visual\ncoherence between foreground and background, a color transfer step is employed\non the foreground elements prior to their rein-corporation. Finally, we utilize\nfeathering techniques to achieve a seamless amalgamation of foreground and\nbackground, resulting in a visually unified and aesthetically pleasing final\ncomposition. Extensive evaluations demonstrate that our proposed approach\nyields significantly more natural stylistic transformations compared to\nconventional methods.\n","authors":["Zhicheng Ding","Panfeng Li","Qikai Yang","Siyang Li","Qingtian Gong"],"pdf_url":"https://arxiv.org/pdf/2404.13880v4.pdf","comment":"Accepted by 2024 5th International Conference on Computer Vision,\n  Image and Deep Learning"},{"id":"http://arxiv.org/abs/2411.08849v1","updated":"2024-11-13T18:29:58Z","published":"2024-11-13T18:29:58Z","title":"Oblique Bayesian additive regression trees","summary":"  Current implementations of Bayesian Additive Regression Trees (BART) are\nbased on axis-aligned decision rules that recursively partition the feature\nspace using a single feature at a time. Several authors have demonstrated that\noblique trees, whose decision rules are based on linear combinations of\nfeatures, can sometimes yield better predictions than axis-aligned trees and\nexhibit excellent theoretical properties. We develop an oblique version of BART\nthat leverages a data-adaptive decision rule prior that recursively partitions\nthe feature space along random hyperplanes. Using several synthetic and\nreal-world benchmark datasets, we systematically compared our oblique BART\nimplementation to axis-aligned BART and other tree ensemble methods, finding\nthat oblique BART was competitive with -- and sometimes much better than --\nthose methods.\n","authors":["Paul-Hieu V. Nguyen","Ryan Yee","Sameer K. Deshpande"],"pdf_url":"https://arxiv.org/pdf/2411.08849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06438v2","updated":"2024-11-13T18:21:22Z","published":"2024-07-08T22:40:15Z","title":"A Single Transformer for Scalable Vision-Language Modeling","summary":"  We present SOLO, a single transformer for Scalable visiOn-Language mOdeling.\nCurrent large vision-language models (LVLMs) such as LLaVA mostly employ\nheterogeneous architectures that connect pre-trained visual encoders with large\nlanguage models (LLMs) to facilitate visual recognition and complex reasoning.\nAlthough achieving remarkable performance with relatively lightweight training,\nwe identify four primary scalability limitations: (1) The visual capacity is\nconstrained by pre-trained visual encoders, which are typically an order of\nmagnitude smaller than LLMs. (2) The heterogeneous architecture complicates the\nuse of established hardware and software infrastructure. (3) Study of scaling\nlaws on such architecture must consider three separate components - visual\nencoder, connector, and LLMs, which complicates the analysis. (4) The use of\nexisting visual encoders typically requires following a pre-defined\nspecification of image inputs pre-processing, for example, by reshaping inputs\nto fixed-resolution square images, which presents difficulties in processing\nand training on high-resolution images or those with unusual aspect ratio. A\nunified single Transformer architecture, like SOLO, effectively addresses these\nscalability concerns in LVLMs; however, its limited adoption in the modern\ncontext likely stems from the absence of reliable training recipes that balance\nboth modalities and ensure stable training for billion-scale models. In this\npaper, we introduce the first open-source training recipe for developing SOLO,\nan open-source 7B LVLM using moderate academic resources. The training recipe\ninvolves initializing from LLMs, sequential pre-training on ImageNet and\nweb-scale data, and instruction fine-tuning on our curated high-quality\ndatasets. On extensive evaluation, SOLO demonstrates performance comparable to\nLLaVA-v1.5-7B, particularly excelling in visual mathematical reasoning.\n","authors":["Yangyi Chen","Xingyao Wang","Hao Peng","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2407.06438v2.pdf","comment":"Accepted to TMLR"},{"id":"http://arxiv.org/abs/2411.08832v1","updated":"2024-11-13T18:12:15Z","published":"2024-11-13T18:12:15Z","title":"Offline Adaptation of Quadruped Locomotion using Diffusion Models","summary":"  We present a diffusion-based approach to quadrupedal locomotion that\nsimultaneously addresses the limitations of learning and interpolating between\nmultiple skills and of (modes) offline adapting to new locomotion behaviours\nafter training. This is the first framework to apply classifier-free guided\ndiffusion to quadruped locomotion and demonstrate its efficacy by extracting\ngoal-conditioned behaviour from an originally unlabelled dataset. We show that\nthese capabilities are compatible with a multi-skill policy and can be applied\nwith little modification and minimal compute overhead, i.e., running entirely\non the robots onboard CPU. We verify the validity of our approach with hardware\nexperiments on the ANYmal quadruped platform.\n","authors":["Reece O'Mahoney","Alexander L. Mitchell","Wanming Yu","Ingmar Posner","Ioannis Havoutis"],"pdf_url":"https://arxiv.org/pdf/2411.08832v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08821v1","updated":"2024-11-13T17:59:44Z","published":"2024-11-13T17:59:44Z","title":"Model agnostic local variable importance for locally dependent\n  relationships","summary":"  Global variable importance measures are commonly used to interpret machine\nlearning model results. Local variable importance techniques assess how\nvariables contribute to individual observations rather than the entire dataset.\nCurrent methods typically fail to accurately reflect locally dependent\nrelationships between variables and instead focus on marginal importance\nvalues. Additionally, they are not natively adapted for multi-class\nclassification problems. We propose a new model-agnostic method for calculating\nlocal variable importance, CLIQUE, that captures locally dependent\nrelationships, contains improvements over permutation-based methods, and can be\ndirectly applied to multi-class classification problems. Simulated and\nreal-world examples show that CLIQUE emphasizes locally dependent information\nand properly reduces bias in regions where variables do not affect the\nresponse.\n","authors":["Kelvyn K. Bladen","Adele Cutler","D. Richard Cutler","Kevin R. Moon"],"pdf_url":"https://arxiv.org/pdf/2411.08821v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08814v1","updated":"2024-11-13T17:53:23Z","published":"2024-11-13T17:53:23Z","title":"Process-aware Human Activity Recognition","summary":"  Humans naturally follow distinct patterns when conducting their daily\nactivities, which are driven by established practices and processes, such as\nproduction workflows, social norms and daily routines. Human activity\nrecognition (HAR) algorithms usually use neural networks or machine learning\ntechniques to analyse inherent relationships within the data. However, these\napproaches often overlook the contextual information in which the data are\ngenerated, potentially limiting their effectiveness. We propose a novel\napproach that incorporates process information from context to enhance the HAR\nperformance. Specifically, we align probabilistic events generated by machine\nlearning models with process models derived from contextual information. This\nalignment adaptively weighs these two sources of information to optimise HAR\naccuracy. Our experiments demonstrate that our approach achieves better\naccuracy and Macro F1-score compared to baseline models.\n","authors":["Jiawei Zheng","Petros Papapanagiotou","Jacques D. Fleuriot","Jane Hillston"],"pdf_url":"https://arxiv.org/pdf/2411.08814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01600v3","updated":"2024-11-13T17:41:43Z","published":"2024-08-02T23:11:42Z","title":"Physics-Informed Geometry-Aware Neural Operator","summary":"  Engineering design problems often involve solving parametric Partial\nDifferential Equations (PDEs) under variable PDE parameters and domain\ngeometry. Recently, neural operators have shown promise in learning PDE\noperators and quickly predicting the PDE solutions. However, training these\nneural operators typically requires large datasets, the acquisition of which\ncan be prohibitively expensive. To overcome this, physics-informed training\noffers an alternative way of building neural operators, eliminating the high\ncomputational costs associated with Finite Element generation of training data.\nNevertheless, current physics-informed neural operators struggle with\nlimitations, either in handling varying domain geometries or varying PDE\nparameters. In this research, we introduce a novel method, the Physics-Informed\nGeometry-Aware Neural Operator (PI-GANO), designed to simultaneously generalize\nacross both PDE parameters and domain geometries. We adopt a geometry encoder\nto capture the domain geometry features, and design a novel pipeline to\nintegrate this component within the existing DCON architecture. Numerical\nresults demonstrate the accuracy and efficiency of the proposed method. All the\ncodes and data related to this work are available on GitHub:\nhttps://github.com/WeihengZ/Physics-informed-Neural-Foundation-Operator.\n","authors":["Weiheng Zhong","Hadi Meidani"],"pdf_url":"https://arxiv.org/pdf/2408.01600v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2404.13646"},{"id":"http://arxiv.org/abs/2411.08804v1","updated":"2024-11-13T17:38:07Z","published":"2024-11-13T17:38:07Z","title":"FinRobot: AI Agent for Equity Research and Valuation with Large Language\n  Models","summary":"  As financial markets grow increasingly complex, there is a rising need for\nautomated tools that can effectively assist human analysts in equity research,\nparticularly within sell-side research. While Generative AI (GenAI) has\nattracted significant attention in this field, existing AI solutions often fall\nshort due to their narrow focus on technical factors and limited capacity for\ndiscretionary judgment. These limitations hinder their ability to adapt to new\ndata in real-time and accurately assess risks, which diminishes their practical\nvalue for investors.\n  This paper presents FinRobot, the first AI agent framework specifically\ndesigned for equity research. FinRobot employs a multi-agent Chain of Thought\n(CoT) system, integrating both quantitative and qualitative analyses to emulate\nthe comprehensive reasoning of a human analyst. The system is structured around\nthree specialized agents: the Data-CoT Agent, which aggregates diverse data\nsources for robust financial integration; the Concept-CoT Agent, which mimics\nan analysts reasoning to generate actionable insights; and the Thesis-CoT\nAgent, which synthesizes these insights into a coherent investment thesis and\nreport. FinRobot provides thorough company analysis supported by precise\nnumerical data, industry-appropriate valuation metrics, and realistic risk\nassessments. Its dynamically updatable data pipeline ensures that research\nremains timely and relevant, adapting seamlessly to new financial information.\nUnlike existing automated research tools, such as CapitalCube and Wright\nReports, FinRobot delivers insights comparable to those produced by major\nbrokerage firms and fundamental research vendors. We open-source FinRobot at\n\\url{https://github. com/AI4Finance-Foundation/FinRobot}.\n","authors":["Tianyu Zhou","Pinqiao Wang","Yilin Wu","Hongyang Yang"],"pdf_url":"https://arxiv.org/pdf/2411.08804v1.pdf","comment":"The 1st Workshop on LLMs and Generative AI for Finance, ICAIF 2024"},{"id":"http://arxiv.org/abs/2410.16527v2","updated":"2024-11-13T17:30:33Z","published":"2024-10-21T21:36:03Z","title":"Insights and Current Gaps in Open-Source LLM Vulnerability Scanners: A\n  Comparative Analysis","summary":"  This report presents a comparative analysis of open-source vulnerability\nscanners for conversational large language models (LLMs). As LLMs become\nintegral to various applications, they also present potential attack surfaces,\nexposed to security risks such as information leakage and jailbreak attacks.\nOur study evaluates prominent scanners - Garak, Giskard, PyRIT, and\nCyberSecEval - that adapt red-teaming practices to expose these\nvulnerabilities. We detail the distinctive features and practical use of these\nscanners, outline unifying principles of their design and perform quantitative\nevaluations to compare them. These evaluations uncover significant reliability\nissues in detecting successful attacks, highlighting a fundamental gap for\nfuture development. Additionally, we contribute a preliminary labelled dataset,\nwhich serves as an initial step to bridge this gap. Based on the above, we\nprovide strategic recommendations to assist organizations choose the most\nsuitable scanner for their red-teaming needs, accounting for customizability,\ntest suite comprehensiveness, and industry-specific use cases.\n","authors":["Jonathan Brokman","Omer Hofman","Oren Rachmil","Inderjeet Singh","Rathina Sabapathy Aishvariya Priya","Vikas Pahuja","Amit Giloni","Roman Vainshtein","Hisashi Kojima"],"pdf_url":"https://arxiv.org/pdf/2410.16527v2.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2410.24164v3","updated":"2024-11-13T17:30:10Z","published":"2024-10-31T17:22:30Z","title":"$π_0$: A Vision-Language-Action Flow Model for General Robot Control","summary":"  Robot learning holds tremendous promise to unlock the full potential of\nflexible, general, and dexterous robot systems, as well as to address some of\nthe deepest questions in artificial intelligence. However, bringing robot\nlearning to the level of generality required for effective real-world systems\nfaces major obstacles in terms of data, generalization, and robustness. In this\npaper, we discuss how generalist robot policies (i.e., robot foundation models)\ncan address these challenges, and how we can design effective generalist robot\npolicies for complex and highly dexterous tasks. We propose a novel flow\nmatching architecture built on top of a pre-trained vision-language model (VLM)\nto inherit Internet-scale semantic knowledge. We then discuss how this model\ncan be trained on a large and diverse dataset from multiple dexterous robot\nplatforms, including single-arm robots, dual-arm robots, and mobile\nmanipulators. We evaluate our model in terms of its ability to perform tasks in\nzero shot after pre-training, follow language instructions from people and from\na high-level VLM policy, and its ability to acquire new skills via fine-tuning.\nOur results cover a wide variety of tasks, such as laundry folding, table\ncleaning, and assembling boxes.\n","authors":["Kevin Black","Noah Brown","Danny Driess","Adnan Esmail","Michael Equi","Chelsea Finn","Niccolo Fusai","Lachy Groom","Karol Hausman","Brian Ichter","Szymon Jakubczak","Tim Jones","Liyiming Ke","Sergey Levine","Adrian Li-Bell","Mohith Mothukuri","Suraj Nair","Karl Pertsch","Lucy Xiaoyang Shi","James Tanner","Quan Vuong","Anna Walling","Haohuan Wang","Ury Zhilinsky"],"pdf_url":"https://arxiv.org/pdf/2410.24164v3.pdf","comment":"See project website for videos:\n  https://physicalintelligence.company/blog/pi0"},{"id":"http://arxiv.org/abs/2411.08800v1","updated":"2024-11-13T17:27:32Z","published":"2024-11-13T17:27:32Z","title":"Deep Learning Accelerated Quantum Transport Simulations in\n  Nanoelectronics: From Break Junctions to Field-Effect Transistors","summary":"  Quantum transport calculations are essential for understanding and designing\nnanoelectronic devices, yet the trade-off between accuracy and computational\nefficiency has long limited their practical applications. We present a general\nframework that combines the deep learning tight-binding Hamiltonian (DeePTB)\napproach with the non-equilibrium Green's Function (NEGF) method, enabling\nefficient quantum transport calculations while maintaining first-principles\naccuracy. We demonstrate the capabilities of the DeePTB-NEGF framework through\ntwo representative applications: comprehensive simulation of break junction\nsystems, where conductance histograms show good agreement with experimental\nmeasurements in both metallic contact and single-molecule junction cases; and\nsimulation of carbon nanotube field effect transistors through self-consistent\nNEGF-Poisson calculations, capturing essential physics including the\nelectrostatic potential and transfer characteristic curves under finite bias\nconditions. This framework bridges the gap between first-principles accuracy\nand computational efficiency, providing a powerful tool for high-throughput\nquantum transport simulations across different scales in nanoelectronics.\n","authors":["Jijie Zou","Zhanghao Zhouyin","Dongying Lin","Linfeng Zhang","Shimin Hou","Qiangqiang Gu"],"pdf_url":"https://arxiv.org/pdf/2411.08800v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2404.13646v4","updated":"2024-11-13T17:26:36Z","published":"2024-04-21T12:41:30Z","title":"Physics-informed Discretization-independent Deep Compositional Operator\n  Network","summary":"  Solving parametric Partial Differential Equations (PDEs) for a broad range of\nparameters is a critical challenge in scientific computing. To this end, neural\noperators, which \\textcolor{black}{predicts the PDE solution with variable PDE\nparameter inputs}, have been successfully used. However, the training of neural\noperators typically demands large training datasets, the acquisition of which\ncan be prohibitively expensive. To address this challenge, physics-informed\ntraining can offer a cost-effective strategy. However, current physics-informed\nneural operators face limitations, either in handling irregular domain shapes\nor in in generalizing to various discrete representations of PDE parameters. In\nthis research, we introduce a novel physics-informed model architecture which\ncan generalize to various discrete representations of PDE parameters and\nirregular domain shapes. Particularly, inspired by deep operator neural\nnetworks, our model involves a discretization-independent learning of parameter\nembedding repeatedly, and this parameter embedding is integrated with the\nresponse embeddings through multiple compositional layers, for more\nexpressivity. Numerical results demonstrate the accuracy and efficiency of the\nproposed method. All the codes and data related to this work are available on\nGitHub: https://github.com/WeihengZ/PI-DCON.\n","authors":["Weiheng Zhong","Hadi Meidani"],"pdf_url":"https://arxiv.org/pdf/2404.13646v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08798v1","updated":"2024-11-13T17:25:25Z","published":"2024-11-13T17:25:25Z","title":"Learning Gaussian Multi-Index Models with Gradient Flow: Time Complexity\n  and Directional Convergence","summary":"  This work focuses on the gradient flow dynamics of a neural network model\nthat uses correlation loss to approximate a multi-index function on\nhigh-dimensional standard Gaussian data. Specifically, the multi-index function\nwe consider is a sum of neurons $f^*(x) \\!=\\! \\sum_{j=1}^k \\! \\sigma^*(v_j^T\nx)$ where $v_1, \\dots, v_k$ are unit vectors, and $\\sigma^*$ lacks the first\nand second Hermite polynomials in its Hermite expansion. It is known that, for\nthe single-index case ($k\\!=\\!1$), overcoming the search phase requires\npolynomial time complexity. We first generalize this result to multi-index\nfunctions characterized by vectors in arbitrary directions. After the search\nphase, it is not clear whether the network neurons converge to the index\nvectors, or get stuck at a sub-optimal solution. When the index vectors are\northogonal, we give a complete characterization of the fixed points and prove\nthat neurons converge to the nearest index vectors. Therefore, using $n \\!\n\\asymp \\! k \\log k$ neurons ensures finding the full set of index vectors with\ngradient flow with high probability over random initialization. When $ v_i^T\nv_j \\!=\\! \\beta \\! \\geq \\! 0$ for all $i \\neq j$, we prove the existence of a\nsharp threshold $\\beta_c \\!=\\! c/(c+k)$ at which the fixed point that computes\nthe average of the index vectors transitions from a saddle point to a minimum.\nNumerical simulations show that using a correlation loss and a mild\noverparameterization suffices to learn all of the index vectors when they are\nnearly orthogonal, however, the correlation loss fails when the dot product\nbetween the index vectors exceeds a certain threshold.\n","authors":["Berfin Simsek","Amire Bendjeddou","Daniel Hsu"],"pdf_url":"https://arxiv.org/pdf/2411.08798v1.pdf","comment":"21 pages, 6 figures, under review by AISTATS 2025"},{"id":"http://arxiv.org/abs/2411.08791v1","updated":"2024-11-13T17:17:16Z","published":"2024-11-13T17:17:16Z","title":"Locally Private Sampling with Public Data","summary":"  Local differential privacy (LDP) is increasingly employed in\nprivacy-preserving machine learning to protect user data before sharing it with\nan untrusted aggregator. Most LDP methods assume that users possess only a\nsingle data record, which is a significant limitation since users often gather\nextensive datasets (e.g., images, text, time-series data) and frequently have\naccess to public datasets. To address this limitation, we propose a locally\nprivate sampling framework that leverages both the private and public datasets\nof each user. Specifically, we assume each user has two distributions: $p$ and\n$q$ that represent their private dataset and the public dataset, respectively.\nThe objective is to design a mechanism that generates a private sample\napproximating $p$ while simultaneously preserving $q$. We frame this objective\nas a minimax optimization problem using $f$-divergence as the utility measure.\nWe fully characterize the minimax optimal mechanisms for general\n$f$-divergences provided that $p$ and $q$ are discrete distributions.\nRemarkably, we demonstrate that this optimal mechanism is universal across all\n$f$-divergences. Experiments validate the effectiveness of our minimax optimal\nsampler compared to the state-of-the-art locally private sampler.\n","authors":["Behnoosh Zamanlooy","Mario Diaz","Shahab Asoodeh"],"pdf_url":"https://arxiv.org/pdf/2411.08791v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08790v1","updated":"2024-11-13T17:16:48Z","published":"2024-11-13T17:16:48Z","title":"Can sparse autoencoders be used to decompose and interpret steering\n  vectors?","summary":"  Steering vectors are a promising approach to control the behaviour of large\nlanguage models. However, their underlying mechanisms remain poorly understood.\nWhile sparse autoencoders (SAEs) may offer a potential method to interpret\nsteering vectors, recent findings show that SAE-reconstructed vectors often\nlack the steering properties of the original vectors. This paper investigates\nwhy directly applying SAEs to steering vectors yields misleading\ndecompositions, identifying two reasons: (1) steering vectors fall outside the\ninput distribution for which SAEs are designed, and (2) steering vectors can\nhave meaningful negative projections in feature directions, which SAEs are not\ndesigned to accommodate. These limitations hinder the direct use of SAEs for\ninterpreting steering vectors.\n","authors":["Harry Mayne","Yushi Yang","Adam Mahdi"],"pdf_url":"https://arxiv.org/pdf/2411.08790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19552v2","updated":"2024-11-13T17:12:34Z","published":"2024-09-29T04:41:10Z","title":"A Universal Deep Learning Framework for Materials X-ray Absorption\n  Spectra","summary":"  X-ray absorption spectroscopy (XAS) is a powerful characterization technique\nfor probing the local chemical environment of absorbing atoms. However,\nanalyzing XAS data presents significant challenges, often requiring extensive,\ncomputationally intensive simulations, as well as significant domain expertise.\nThese limitations hinder the development of fast, robust XAS analysis pipelines\nthat are essential in high-throughput studies and for autonomous\nexperimentation. We address these challenges with OmniXAS, a framework that\ncontains a suite of transfer learning approaches for XAS prediction, each\ncontributing to improved accuracy and efficiency, as demonstrated on K-edge\nspectra database covering eight 3d transition metals (Ti-Cu). The OmniXAS\nframework is built upon three distinct strategies. First, we use M3GNet to\nderive latent representations of the local chemical environment of absorption\nsites as input for XAS prediction, achieving up to order-of-magnitude\nimprovements over conventional featurization techniques. Second, we employ a\nhierarchical transfer learning strategy, training a universal multi-task model\nacross elements before fine-tuning for element-specific predictions. Models\nbased on this cascaded approach after element-wise fine-tuning outperform\nelement-specific models by up to 69%. Third, we implement cross-fidelity\ntransfer learning, adapting a universal model to predict spectra generated by\nsimulation of a different fidelity with a higher computational cost. This\napproach improves prediction accuracy by up to 11% over models trained on the\ntarget fidelity alone. Our approach boosts the throughput of XAS modeling by\norders of magnitude versus first-principles simulations and is extendable to\nXAS prediction for a broader range of elements. This transfer learning\nframework is generalizable to enhance deep-learning models that target other\nproperties in materials research.\n","authors":["Shubha R. Kharel","Fanchen Meng","Xiaohui Qu","Matthew R. Carbone","Deyu Lu"],"pdf_url":"https://arxiv.org/pdf/2409.19552v2.pdf","comment":"Main manuscript: 22 pages, 11 figures. Supplemental material (12\n  pages, 6 figures) available as a separate file in arXiv ancillary files\n  (additional downloadable files)"},{"id":"http://arxiv.org/abs/2402.03271v3","updated":"2024-11-13T17:10:20Z","published":"2024-02-05T18:28:44Z","title":"Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information\n  Seeking in Large Language Models","summary":"  In the face of uncertainty, the ability to *seek information* is of\nfundamental importance. In many practical applications, such as medical\ndiagnosis and troubleshooting, the information needed to solve the task is not\ninitially given and has to be actively sought by asking follow-up questions\n(for example, a doctor asking a patient for more details about their symptoms).\nIn this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to\naugment large language models with the ability to actively seek information by\nasking effective questions. UoT combines 1) an *uncertainty-aware simulation\napproach* which enables the model to simulate possible future scenarios and how\nlikely they are to occur, 2) *uncertainty-based rewards* motivated by\ninformation gain which incentivizes the model to seek information, and 3) a\n*reward propagation scheme* to select the optimal question to ask in a way that\nmaximizes the expected reward. In experiments on medical diagnosis,\ntroubleshooting, and the `20 Questions` game, UoT achieves an average\nperformance improvement of 38.1% in the rate of successful task completion\nacross multiple LLMs compared with direct prompting and also improves\nefficiency (i.e., the number of questions needed to complete the task). Our\ncode has been released [here](https://github.com/zhiyuanhubj/UoT)\n","authors":["Zhiyuan Hu","Chumin Liu","Xidong Feng","Yilun Zhao","See-Kiong Ng","Anh Tuan Luu","Junxian He","Pang Wei Koh","Bryan Hooi"],"pdf_url":"https://arxiv.org/pdf/2402.03271v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.09322v2","updated":"2024-11-13T17:08:34Z","published":"2024-06-13T17:00:30Z","title":"Active Inference Meeting Energy-Efficient Control of Parallel and\n  Identical Machines","summary":"  We investigate the application of active inference in developing\nenergy-efficient control agents for manufacturing systems. Active inference,\nrooted in neuroscience, provides a unified probabilistic framework integrating\nperception, learning, and action, with inherent uncertainty quantification\nelements. Our study explores deep active inference, an emerging field that\ncombines deep learning with the active inference decision-making framework.\nLeveraging a deep active inference agent, we focus on controlling parallel and\nidentical machine workstations to enhance energy efficiency. We address\nchallenges posed by the problem's stochastic nature and delayed policy response\nby introducing tailored enhancements to existing agent architectures.\nSpecifically, we introduce multi-step transition and hybrid horizon methods to\nmitigate the need for complex planning. Our experimental results demonstrate\nthe effectiveness of these enhancements and highlight the potential of the\nactive inference-based approach.\n","authors":["Yavar Taheri Yeganeh","Mohsen Jafari","Andrea Matta"],"pdf_url":"https://arxiv.org/pdf/2406.09322v2.pdf","comment":"Accepted at the 10th International Conference on Machine Learning,\n  Optimization, and Data Science"},{"id":"http://arxiv.org/abs/2411.08773v1","updated":"2024-11-13T16:58:51Z","published":"2024-11-13T16:58:51Z","title":"Optimal Oblivious Subspace Embeddings with Near-optimal Sparsity","summary":"  An oblivious subspace embedding is a random $m\\times n$ matrix $\\Pi$ such\nthat, for any $d$-dimensional subspace, with high probability $\\Pi$ preserves\nthe norms of all vectors in that subspace within a $1\\pm\\epsilon$ factor. In\nthis work, we give an oblivious subspace embedding with the optimal dimension\n$m=\\Theta(d/\\epsilon^2)$ that has a near-optimal sparsity of $\\tilde\nO(1/\\epsilon)$ non-zero entries per column of $\\Pi$. This is the first result\nto nearly match the conjecture of Nelson and Nguyen [FOCS 2013] in terms of the\nbest sparsity attainable by an optimal oblivious subspace embedding, improving\non a prior bound of $\\tilde O(1/\\epsilon^6)$ non-zeros per column [Chenakkod et\nal., STOC 2024]. We further extend our approach to the non-oblivious setting,\nproposing a new family of Leverage Score Sparsified embeddings with Independent\nColumns, which yield faster runtimes for matrix approximation and regression\ntasks.\n  In our analysis, we develop a new method which uses a decoupling argument\ntogether with the cumulant method for bounding the edge universality error of\nisotropic random matrices. To achieve near-optimal sparsity, we combine this\ngeneral-purpose approach with new traces inequalities that leverage the\nspecific structure of our subspace embedding construction.\n","authors":["Shabarish Chenakkod","Michał Dereziński","Xiaoyu Dong"],"pdf_url":"https://arxiv.org/pdf/2411.08773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08766v1","updated":"2024-11-13T16:52:30Z","published":"2024-11-13T16:52:30Z","title":"Mapping Methane -- The Impact of Dairy Farm Practices on Emissions\n  Through Satellite Data and Machine Learning","summary":"  This study investigates the correlation between dairy farm characteristics\nand methane concentrations as derived from satellite observations in Eastern\nCanada. Utilizing data from 11 dairy farms collected between January 2020 and\nDecember 2022, we integrated Sentinel-5P satellite methane data with critical\nfarm-level attributes, including herd genetics, feeding practices, and\nmanagement strategies. Initial analyses revealed significant correlations with\nmethane concentrations, leading to the application of Variance Inflation Factor\n(VIF) and Principal Component Analysis (PCA) to address multicollinearity and\nenhance model stability. Subsequently, machine learning models - specifically\nRandom Forest and Neural Networks - were employed to evaluate feature\nimportance and predict methane emissions. Our findings indicate a strong\nnegative correlation between the Estimated Breeding Value (EBV) for protein\npercentage and methane concentrations, suggesting that genetic selection for\nhigher milk protein content could be an effective strategy for emissions\nreduction. The integration of atmospheric transport models with satellite data\nfurther refined our emission estimates, significantly enhancing accuracy and\nspatial resolution. This research underscores the potential of advanced\nsatellite monitoring, machine learning techniques, and atmospheric modeling in\nimproving methane emission assessments within the dairy sector. It emphasizes\nthe critical role of farm-specific characteristics in developing effective\nmitigation strategies. Future investigations should focus on expanding the\ndataset and incorporating inversion modeling for more precise emission\nquantification. Balancing ecological impacts with economic viability will be\nessential for fostering sustainable dairy farming practices.\n","authors":["Hanqing Bi","Suresh Neethirajan"],"pdf_url":"https://arxiv.org/pdf/2411.08766v1.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.08764v1","updated":"2024-11-13T16:49:56Z","published":"2024-11-13T16:49:56Z","title":"Flow reconstruction in time-varying geometries using graph neural\n  networks","summary":"  The paper presents a Graph Attention Convolutional Network (GACN) for flow\nreconstruction from very sparse data in time-varying geometries. The model\nincorporates a feature propagation algorithm as a preprocessing step to handle\nextremely sparse inputs, leveraging information from neighboring nodes to\ninitialize missing features. In addition, a binary indicator is introduced as a\nvalidity mask to distinguish between the original and propagated data points,\nenabling more effective learning from sparse inputs. Trained on a unique data\nset of Direct Numerical Simulations (DNS) of a motored engine at a technically\nrelevant operating condition, the GACN shows robust performance across\ndifferent resolutions and domain sizes and can effectively handle unstructured\ndata and variable input sizes. The model is tested on previously unseen DNS\ndata as well as on an experimental data set from Particle Image Velocimetry\n(PIV) measurements that were not considered during training. A comparative\nanalysis shows that the GACN consistently outperforms both a conventional\nConvolutional Neural Network (CNN) and cubic interpolation methods on the DNS\nand PIV test sets by achieving lower reconstruction errors and better capturing\nfine-scale turbulent structures. In particular, the GACN effectively\nreconstructs flow fields from domains up to 14 times larger than those observed\nduring training, with the performance advantage increasing for larger domains.\n","authors":["Bogdan A. Danciu","Vito A. Pagone","Benjamin Böhm","Marius Schmidt","Christos E. Frouzakis"],"pdf_url":"https://arxiv.org/pdf/2411.08764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08760v1","updated":"2024-11-13T16:47:34Z","published":"2024-11-13T16:47:34Z","title":"Energy Dissipation Preserving Physics Informed Neural Network for\n  Allen-Cahn Equations","summary":"  This paper investigates a numerical solution of Allen-Cahn equation with\nconstant and degenerate mobility, with polynomial and logarithmic energy\nfunctionals, with deterministic and random initial functions, and with\nadvective term in one, two, and three spatial dimensions, based on the\nphysics-informed neural network (PINN). To improve the learning capacity of the\nPINN, we incorporate the energy dissipation property of the Allen-Cahn equation\nas a penalty term into the loss function of the network. To facilitate the\nlearning process of random initials, we employ a continuous analogue of the\ninitial random condition by utilizing the Fourier series expansion. Adaptive\nmethods from traditional numerical analysis are also integrated to enhance the\neffectiveness of the proposed PINN. Numerical results indicate a consistent\ndecrease in the discrete energy, while also revealing phenomena such as phase\nseparation and metastability.\n","authors":["Mustafa Kütük","Hamdullah Yücel"],"pdf_url":"https://arxiv.org/pdf/2411.08760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13150v2","updated":"2024-11-13T16:46:23Z","published":"2024-03-19T20:58:38Z","title":"On Training Survival Models with Scoring Rules","summary":"  Scoring rules are an established way of comparing predictive performances\nacross model classes. In the context of survival analysis, they require\nadaptation in order to accommodate censoring. This work investigates using\nscoring rules for model training rather than evaluation. Doing so, we establish\na general framework for training survival models that is model agnostic and can\nlearn event time distributions parametrically or non-parametrically. In\naddition, our framework is not restricted to any specific scoring rule. While\nwe focus on neural network-based implementations, we also provide\nproof-of-concept implementations using gradient boosting, generalized additive\nmodels, and trees. Empirical comparisons on synthetic and real-world data\nindicate that scoring rules can be successfully incorporated into model\ntraining and yield competitive predictive performance with established\ntime-to-event models.\n","authors":["Philipp Kopper","David Rügamer","Raphael Sonabend","Bernd Bischl","Andreas Bender"],"pdf_url":"https://arxiv.org/pdf/2403.13150v2.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.02538v2","updated":"2024-11-13T16:44:07Z","published":"2024-07-01T23:24:05Z","title":"CGRclust: Chaos Game Representation for Twin Contrastive Clustering of\n  Unlabelled DNA Sequences","summary":"  This study proposes CGRclust, a novel combination of unsupervised twin\ncontrastive clustering of Chaos Game Representations (CGR) of DNA sequences,\nwith convolutional neural networks (CNNs). To the best of our knowledge,\nCGRclust is the first method to use unsupervised learning for image\nclassification (herein applied to two-dimensional CGR images) for clustering\ndatasets of DNA sequences. CGRclust overcomes the limitations of traditional\nsequence classification methods by leveraging unsupervised twin contrastive\nlearning to detect distinctive sequence patterns, without requiring DNA\nsequence alignment or biological/taxonomic labels. CGRclust accurately\nclustered twenty-five diverse datasets, with sequence lengths ranging from 664\nbp to 100 kbp, including mitochondrial genomes of fish, fungi, and protists, as\nwell as viral whole genome assemblies and synthetic DNA sequences. Compared\nwith three recent clustering methods for DNA sequences (DeLUCS, iDeLUCS, and\nMeShClust v3.0.), CGRclust is the only method that surpasses 81.70% accuracy\nacross all four taxonomic levels tested for mitochondrial DNA genomes of fish.\nMoreover, CGRclust also consistently demonstrates superior performance across\nall the viral genomic datasets. The high clustering accuracy of CGRclust on\nthese twenty-five datasets, which vary significantly in terms of sequence\nlength, number of genomes, number of clusters, and level of taxonomy,\ndemonstrates its robustness, scalability, and versatility.\n","authors":["Fatemeh Alipour","Kathleen A. Hill","Lila Kari"],"pdf_url":"https://arxiv.org/pdf/2407.02538v2.pdf","comment":"28 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.08758v1","updated":"2024-11-13T16:42:59Z","published":"2024-11-13T16:42:59Z","title":"ScaleNet: Scale Invariance Learning in Directed Graphs","summary":"  Graph Neural Networks (GNNs) have advanced relational data analysis but lack\ninvariance learning techniques common in image classification. In node\nclassification with GNNs, it is actually the ego-graph of the center node that\nis classified. This research extends the scale invariance concept to node\nclassification by drawing an analogy to image processing: just as scale\ninvariance being used in image classification to capture multi-scale features,\nwe propose the concept of ``scaled ego-graphs''. Scaled ego-graphs generalize\ntraditional ego-graphs by replacing undirected single-edges with\n``scaled-edges'', which are ordered sequences of multiple directed edges. We\nempirically assess the performance of the proposed scale invariance in graphs\non seven benchmark datasets, across both homophilic and heterophilic\nstructures. Our scale-invariance-based graph learning outperforms inception\nmodels derived from random walks by being simpler, faster, and more accurate.\nThe scale invariance explains inception models' success on homophilic graphs\nand limitations on heterophilic graphs. To ensure applicability of inception\nmodel to heterophilic graphs as well, we further present ScaleNet, an\narchitecture that leverages multi-scaled features. ScaleNet achieves\nstate-of-the-art results on five out of seven datasets (four homophilic and one\nheterophilic) and matches top performance on the remaining two, demonstrating\nits excellent applicability. This represents a significant advance in graph\nlearning, offering a unified framework that enhances node classification across\nvarious graph types. Our code is available at\nhttps://github.com/Qin87/ScaleNet/tree/July25.\n","authors":["Qin Jiang","Chengjia Wang","Michael Lones","Wei Pang"],"pdf_url":"https://arxiv.org/pdf/2411.08758v1.pdf","comment":"Scale invariance in node classification is demonstrated and applied\n  in graph transformation to develop ScaleNet, which achieves state-of-the-art\n  performance on both homophilic and heterophilic directed graphs"},{"id":"http://arxiv.org/abs/2310.10545v3","updated":"2024-11-13T16:42:52Z","published":"2023-10-16T16:14:43Z","title":"Optimal vintage factor analysis with deflation varimax","summary":"  Vintage factor analysis is one important type of factor analysis that aims to\nfirst find a low-dimensional representation of the original data, and then to\nseek a rotation such that the rotated low-dimensional representation is\nscientifically meaningful. The most widely used vintage factor analysis is the\nPrincipal Component Analysis (PCA) followed by the varimax rotation. Despite\nits popularity, little theoretical guarantee can be provided to date mainly\nbecause varimax rotation requires to solve a non-convex optimization over the\nset of orthogonal matrices.\n  In this paper, we propose a deflation varimax procedure that solves each row\nof an orthogonal matrix sequentially. In addition to its net computational gain\nand flexibility, we are able to fully establish theoretical guarantees for the\nproposed procedure in a broader context. Adopting this new deflation varimax as\nthe second step after PCA, we further analyze this two step procedure under a\ngeneral class of factor models. Our results show that it estimates the factor\nloading matrix in the minimax optimal rate when the signal-to-noise-ratio (SNR)\nis moderate or large. In the low SNR regime, we offer possible improvement over\nusing PCA and the deflation varimax when the additive noise under the factor\nmodel is structured. The modified procedure is shown to be minimax optimal in\nall SNR regimes. Our theory is valid for finite sample and allows the number of\nthe latent factors to grow with the sample size as well as the ambient\ndimension to grow with, or even exceed, the sample size. Extensive simulation\nand real data analysis further corroborate our theoretical findings.\n","authors":["Xin Bing","Dian Jin","Yuqian Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.10545v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03679v6","updated":"2024-11-13T16:42:22Z","published":"2024-06-06T01:49:29Z","title":"On the Effects of Data Scale on UI Control Agents","summary":"  Autonomous agents that control computer interfaces to accomplish human tasks\nare emerging. Leveraging LLMs to power such agents has been of special\ninterest, but unless fine-tuned on human-collected task demonstrations,\nperformance is still relatively low. In this work we study whether fine-tuning\nalone is a viable approach for building real-world computer control agents. In\nparticularly, we investigate how performance measured on both high and\nlow-level tasks in domain and out of domain scales as more training data is\ncollected. To this end we collect and release a new dataset, AndroidControl,\nconsisting of 15,283 demonstrations of everyday tasks with Android apps.\nCompared to existing datasets, each AndroidControl task instance includes both\nhigh and low-level human-generated instructions, allowing us to explore the\nlevel of task complexity an agent can handle. Moreover, AndroidControl is the\nmost diverse computer control dataset to date, including 14,548 unique tasks\nover 833 Android apps, thus allowing us to conduct in-depth analysis of the\nmodel performance in and out of the domain of the training data. Using the\ndataset, we find that when tested in domain fine-tuned models outperform zero\nand few-shot baselines and scale in such a way that robust performance might\nfeasibly be obtained simply by collecting more data. Out of domain, performance\nscales significantly more slowly and suggests that in particular for high-level\ntasks, fine-tuning on more data alone may be insufficient for achieving robust\nout-of-domain performance.\n","authors":["Wei Li","William Bishop","Alice Li","Chris Rawles","Folawiyo Campbell-Ajala","Divya Tyamagundlu","Oriana Riva"],"pdf_url":"https://arxiv.org/pdf/2406.03679v6.pdf","comment":"NeurIPS 2024 (Datasets and Benchmarks)"},{"id":"http://arxiv.org/abs/2404.10420v3","updated":"2024-11-13T16:42:16Z","published":"2024-04-16T09:37:41Z","title":"AudioProtoPNet: An interpretable deep learning model for bird sound\n  classification","summary":"  Deep learning models have significantly advanced acoustic bird monitoring by\nbeing able to recognize numerous bird species based on their vocalizations.\nHowever, traditional deep learning models are black boxes that provide no\ninsight into their underlying computations, limiting their usefulness to\nornithologists and machine learning engineers. Explainable models could\nfacilitate debugging, knowledge discovery, trust, and interdisciplinary\ncollaboration. This study introduces AudioProtoPNet, an adaptation of the\nPrototypical Part Network (ProtoPNet) for multi-label bird sound\nclassification. It is an inherently interpretable model that uses a ConvNeXt\nbackbone to extract embeddings, with the classification layer replaced by a\nprototype learning classifier trained on these embeddings. The classifier\nlearns prototypical patterns of each bird species' vocalizations from\nspectrograms of training instances. During inference, audio recordings are\nclassified by comparing them to the learned prototypes in the embedding space,\nproviding explanations for the model's decisions and insights into the most\ninformative embeddings of each bird species. The model was trained on the\nBirdSet training dataset, which consists of 9,734 bird species and over 6,800\nhours of recordings. Its performance was evaluated on the seven test datasets\nof BirdSet, covering different geographical regions. AudioProtoPNet\noutperformed the state-of-the-art model Perch, achieving an average AUROC of\n0.90 and a cmAP of 0.42, with relative improvements of 7.1% and 16.7% over\nPerch, respectively. These results demonstrate that even for the challenging\ntask of multi-label bird sound classification, it is possible to develop\npowerful yet inherently interpretable deep learning models that provide\nvaluable insights for ornithologists and machine learning engineers.\n","authors":["René Heinrich","Lukas Rauch","Bernhard Sick","Christoph Scholz"],"pdf_url":"https://arxiv.org/pdf/2404.10420v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2411.08755v1","updated":"2024-11-13T16:33:27Z","published":"2024-11-13T16:33:27Z","title":"Weakly-Supervised Anomaly Detection in Surveillance Videos Based on\n  Two-Stream I3D Convolution Network","summary":"  The widespread implementation of urban surveillance systems has necessitated\nmore sophisticated techniques for anomaly detection to ensure enhanced public\nsafety. This paper presents a significant advancement in the field of anomaly\ndetection through the application of Two-Stream Inflated 3D (I3D) Convolutional\nNetworks. These networks substantially outperform traditional 3D Convolutional\nNetworks (C3D) by more effectively extracting spatial and temporal features\nfrom surveillance videos, thus improving the precision of anomaly detection.\nOur research advances the field by implementing a weakly supervised learning\nframework based on Multiple Instance Learning (MIL), which uniquely\nconceptualizes surveillance videos as collections of 'bags' that contain\ninstances (video clips). Each instance is innovatively processed through a\nranking mechanism that prioritizes clips based on their potential to display\nanomalies. This novel strategy not only enhances the accuracy and precision of\nanomaly detection but also significantly diminishes the dependency on extensive\nmanual annotations. Moreover, through meticulous optimization of model\nsettings, including the choice of optimizer, our approach not only establishes\nnew benchmarks in the performance of anomaly detection systems but also offers\na scalable and efficient solution for real-world surveillance applications.\nThis paper contributes significantly to the field of computer vision by\ndelivering a more adaptable, efficient, and context-aware anomaly detection\nsystem, which is poised to redefine practices in urban surveillance.\n","authors":["Sareh Soltani Nejad","Anwar Haque"],"pdf_url":"https://arxiv.org/pdf/2411.08755v1.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.08750v1","updated":"2024-11-13T16:29:33Z","published":"2024-11-13T16:29:33Z","title":"Optimal Transport-Based Displacement Interpolation with Data\n  Augmentation for Reduced Order Modeling of Nonlinear Dynamical Systems","summary":"  We present a novel reduced-order Model (ROM) that leverages optimal transport\n(OT) theory and displacement interpolation to enhance the representation of\nnonlinear dynamics in complex systems. While traditional ROM techniques face\nchallenges in this scenario, especially when data (i.e., observational\nsnapshots) is limited, our method addresses these issues by introducing a data\naugmentation strategy based on OT principles. The proposed framework generates\ninterpolated solutions tracing geodesic paths in the space of probability\ndistributions, enriching the training dataset for the ROM. A key feature of our\napproach is its ability to provide a continuous representation of the\nsolution's dynamics by exploiting a virtual-to-real time mapping. This enables\nthe reconstruction of solutions at finer temporal scales than those provided by\nthe original data. To further improve prediction accuracy, we employ Gaussian\nProcess Regression to learn the residual and correct the representation between\nthe interpolated snapshots and the physical solution. We demonstrate the\neffectiveness of our methodology with atmospheric mesoscale benchmarks\ncharacterized by highly nonlinear, advection-dominated dynamics. Our results\nshow improved accuracy and efficiency in predicting complex system behaviors,\nindicating the potential of this approach for a wide range of applications in\ncomputational physics and engineering.\n","authors":["Moaad Khamlich","Federico Pichi","Michele Girfoglio","Annalisa Quaini","Gianluigi Rozza"],"pdf_url":"https://arxiv.org/pdf/2411.08750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08739v1","updated":"2024-11-13T16:18:57Z","published":"2024-11-13T16:18:57Z","title":"Bayesian Comparisons Between Representations","summary":"  Which neural networks are similar is a fundamental question for both machine\nlearning and neuroscience. Our novel method compares representations based on\nBayesian statistics about linear readouts from the representations. Concretely,\nwe suggest to use the total variation distance or Jensen-Shannon distance\nbetween prior predictive distributions to compare representations. The prior\npredictive distribution is a full description of the inductive bias and\ngeneralization of a model in Bayesian statistics, making it a great basis for\ncomparisons. As Jensen-Shannon distance and total variation distance are\nmetrics our dissimilarity measures are pseudo-metrics for representations. For\na linear readout, our metrics just depend on the linear kernel matrix of the\nrepresentations. Thus, our metrics connects linear read-out based comparisons\nto kernel based metrics like centered kernel alignment and representational\nsimilarity analysis. We apply our new metrics to deep neural networks trained\non ImageNet-1k. Our new metrics can be computed efficiently including a\nstochastic gradient without dimensionality reductions of the representations.\nIt broadly agrees with existing metrics, but is more stringent. It varies less\nacross different random image samples, and it measures how well two\nrepresentations could be distinguished based on a linear read out. Thus our\nmetric nicely extends our toolkit for comparing representations.\n","authors":["Heiko H. Schütt"],"pdf_url":"https://arxiv.org/pdf/2411.08739v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08734v1","updated":"2024-11-13T16:16:22Z","published":"2024-11-13T16:16:22Z","title":"Recommender systems and reinforcement learning for building control and\n  occupant interaction: A text-mining driven review of scientific literature","summary":"  The indoor environment greatly affects health and well-being; enhancing\nhealth and reducing energy use in these settings is a key research focus. With\nadvancing Information and Communication Technology (ICT), recommendation\nsystems and reinforcement learning have emerged as promising methods to induce\nbehavioral changes that improve indoor environments and building energy\nefficiency. This study employs text-mining and Natural Language Processing\n(NLP) to examine these approaches in building control and occupant interaction.\nAnalyzing approximately 27,000 articles from the ScienceDirect database, we\nfound extensive use of recommendation systems and reinforcement learning for\nspace optimization, location recommendations, and personalized control\nsuggestions. Despite broad applications, their use in optimizing indoor\nenvironments and energy efficiency is limited. Traditional recommendation\nalgorithms are commonly used, but optimizing indoor conditions and energy\nefficiency often requires advanced machine learning techniques like\nreinforcement and deep learning. This review highlights the potential for\nexpanding recommender systems and reinforcement learning applications in\nbuildings and indoor environments. Areas for innovation include predictive\nmaintenance, building-related product recommendations, and optimizing\nenvironments for specific needs like sleep and productivity enhancements based\non user feedback.\n","authors":["Wenhao Zhang","Matias Quintana","Clayton Miller"],"pdf_url":"https://arxiv.org/pdf/2411.08734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12763v3","updated":"2024-11-13T16:07:47Z","published":"2024-06-18T16:30:51Z","title":"Implicit Bias of Mirror Flow on Separable Data","summary":"  We examine the continuous-time counterpart of mirror descent, namely mirror\nflow, on classification problems which are linearly separable. Such problems\nare minimised `at infinity' and have many possible solutions; we study which\nsolution is preferred by the algorithm depending on the mirror potential. For\nexponential tailed losses and under mild assumptions on the potential, we show\nthat the iterates converge in direction towards a $\\phi_\\infty$-maximum margin\nclassifier. The function $\\phi_\\infty$ is the \\textit{horizon function} of the\nmirror potential and characterises its shape `at infinity'. When the potential\nis separable, a simple formula allows to compute this function. We analyse\nseveral examples of potentials and provide numerical experiments highlighting\nour results.\n","authors":["Scott Pesme","Radu-Alexandru Dragomir","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2406.12763v3.pdf","comment":"Neurips camera ready. Minor changes from the previous versions.\n  Mainly added full iterate trajectories (Figure 4)"},{"id":"http://arxiv.org/abs/2307.05284v4","updated":"2024-11-13T15:53:37Z","published":"2023-07-11T14:25:10Z","title":"Rethinking Distribution Shifts: Empirical Analysis and Inductive\n  Modeling for Tabular Data","summary":"  Different distribution shifts require different interventions, and algorithms\nmust be grounded in the specific shifts they address. However, methodological\ndevelopment for robust algorithms typically relies on structural assumptions\nthat lack empirical validation. Advocating for an empirically grounded\ndata-driven approach to research, we build an empirical testbed comprising\nnatural shifts across 5 tabular datasets and 60,000 method configurations\nencompassing imbalanced learning and distributionally robust optimization (DRO)\nmethods. We find $Y|X$-shifts are most prevalent on our testbed, in stark\ncontrast to the heavy focus on $X$ (covariate)-shifts in the ML literature. The\nperformance of robust algorithms varies significantly over shift types, and is\nno better than that of vanilla methods. To understand why, we conduct an\nin-depth empirical analysis of DRO methods and find that although often\nneglected by researchers, implementation details -- such as the choice of\nunderlying model class (e.g., XGBoost) and hyperparameter selection -- have a\nbigger impact on performance than the ambiguity set or its radius. To further\nbridge that gap between methodological research and practice, we design case\nstudies that illustrate how such a data-driven, inductive understanding of\ndistribution shifts can enhance both data-centric and algorithmic\ninterventions.\n","authors":["Jiashuo Liu","Tianyu Wang","Peng Cui","Hongseok Namkoong"],"pdf_url":"https://arxiv.org/pdf/2307.05284v4.pdf","comment":"Conference version appeared in NeurIPS 2023, previously titled \"On\n  the Need for a Language Describing Distribution Shifts: Illustrations on\n  Tabular Datasets\""},{"id":"http://arxiv.org/abs/2411.08706v1","updated":"2024-11-13T15:50:32Z","published":"2024-11-13T15:50:32Z","title":"Searching Latent Program Spaces","summary":"  Program synthesis methods aim to automatically generate programs restricted\nto a language that can explain a given specification of input-output pairs.\nWhile purely symbolic approaches suffer from a combinatorial search space,\nrecent methods leverage neural networks to learn distributions over program\nstructures to narrow this search space significantly, enabling more efficient\nsearch. However, for challenging problems, it remains difficult to train models\nto perform program synthesis in one shot, making test-time search essential.\nMost neural methods lack structured search mechanisms during inference, relying\ninstead on stochastic sampling or gradient updates, which can be inefficient.\nIn this work, we propose the Latent Program Network (LPN), a general algorithm\nfor program induction that learns a distribution over latent programs in a\ncontinuous space, enabling efficient search and test-time adaptation. We\nexplore how to train these networks to optimize for test-time computation and\ndemonstrate the use of gradient-based search both during training and at test\ntime. We evaluate LPN on ARC-AGI, a program synthesis benchmark that evaluates\nperformance by generalizing programs to new inputs rather than explaining the\nunderlying specification. We show that LPN can generalize beyond its training\ndistribution and adapt to unseen tasks by utilizing test-time computation,\noutperforming algorithms without test-time adaptation mechanisms.\n","authors":["Clément Bonnet","Matthew V Macfarlane"],"pdf_url":"https://arxiv.org/pdf/2411.08706v1.pdf","comment":"Code available at https://github.com/clement-bonnet/lpn"},{"id":"http://arxiv.org/abs/2408.00838v2","updated":"2024-11-13T15:48:34Z","published":"2024-08-01T18:00:05Z","title":"Calibrating Bayesian Generative Machine Learning for Bayesiamplification","summary":"  Recently, combinations of generative and Bayesian machine learning have been\nintroduced in particle physics for both fast detector simulation and inference\ntasks. These neural networks aim to quantify the uncertainty on the generated\ndistribution originating from limited training statistics. The interpretation\nof a distribution-wide uncertainty however remains ill-defined. We show a clear\nscheme for quantifying the calibration of Bayesian generative machine learning\nmodels. For a Continuous Normalizing Flow applied to a low-dimensional toy\nexample, we evaluate the calibration of Bayesian uncertainties from either a\nmean-field Gaussian weight posterior, or Monte Carlo sampling network weights,\nto gauge their behaviour on unsteady distribution edges. Well calibrated\nuncertainties can then be used to roughly estimate the number of uncorrelated\ntruth samples that are equivalent to the generated sample and clearly indicate\ndata amplification for smooth features of the distribution.\n","authors":["Sebastian Bieringer","Sascha Diefenbacher","Gregor Kasieczka","Mathias Trabs"],"pdf_url":"https://arxiv.org/pdf/2408.00838v2.pdf","comment":"15 pages, 6 figures, updated references, fixed typo"},{"id":"http://arxiv.org/abs/2411.08703v1","updated":"2024-11-13T15:45:46Z","published":"2024-11-13T15:45:46Z","title":"MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics\n  Classification","summary":"  The distinct characteristics of multiomics data, including complex\ninteractions within and across biological layers and disease heterogeneity\n(e.g., heterogeneity in etiology and clinical symptoms), drive us to develop\nnovel designs to address unique challenges in multiomics prediction. In this\npaper, we propose the multi-view knowledge transfer learning (MVKTrans)\nframework, which transfers intra- and inter-omics knowledge in an adaptive\nmanner by reviewing data heterogeneity and suppressing bias transfer, thereby\nenhancing classification performance. Specifically, we design a graph\ncontrastive module that is trained on unlabeled data to effectively learn and\ntransfer the underlying intra-omics patterns to the supervised task. This\nunsupervised pretraining promotes learning general and unbiased representations\nfor each modality, regardless of the downstream tasks. In light of the varying\ndiscriminative capacities of modalities across different diseases and/or\nsamples, we introduce an adaptive and bi-directional cross-omics distillation\nmodule. This module automatically identifies richer modalities and facilitates\ndynamic knowledge transfer from more informative to less informative omics,\nthereby enabling a more robust and generalized integration. Extensive\nexperiments on four real biomedical datasets demonstrate the superior\nperformance and robustness of MVKTrans compared to the state-of-the-art. Code\nand data are available at https://github.com/Yaolab-fantastic/MVKTrans.\n","authors":["Shan Cong","Zhiling Sang","Hongwei Liu","Haoran Luo","Xin Wang","Hong Liang","Jie Hao","Xiaohui Yao"],"pdf_url":"https://arxiv.org/pdf/2411.08703v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08701v1","updated":"2024-11-13T15:42:28Z","published":"2024-11-13T15:42:28Z","title":"TRACE: Transformer-based Risk Assessment for Clinical Evaluation","summary":"  We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation),\na novel method for clinical risk assessment based on clinical data, leveraging\nthe self-attention mechanism for enhanced feature interaction and result\ninterpretation. Our approach is able to handle different data modalities,\nincluding continuous, categorical and multiple-choice (checkbox) attributes.\nThe proposed architecture features a shared representation of the clinical data\nobtained by integrating specialized embeddings of each data modality, enabling\nthe detection of high-risk individuals using Transformer encoder layers. To\nassess the effectiveness of the proposed method, a strong baseline based on\nnon-negative multi-layer perceptrons (MLPs) is introduced. The proposed method\noutperforms various baselines widely used in the domain of clinical risk\nassessment, while effectively handling missing values. In terms of\nexplainability, our Transformer-based method offers easily interpretable\nresults via attention weights, further enhancing the clinicians'\ndecision-making process.\n","authors":["Dionysis Christopoulos","Sotiris Spanos","Valsamis Ntouskos","Konstantinos Karantzalos"],"pdf_url":"https://arxiv.org/pdf/2411.08701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08700v1","updated":"2024-11-13T15:42:13Z","published":"2024-11-13T15:42:13Z","title":"Rethinking negative sampling in content-based news recommendation","summary":"  News recommender systems are hindered by the brief lifespan of articles, as\nthey undergo rapid relevance decay. Recent studies have demonstrated the\npotential of content-based neural techniques in tackling this problem. However,\nthese models often involve complex neural architectures and often lack\nconsideration for negative examples. In this study, we posit that the careful\nsampling of negative examples has a big impact on the model's outcome. We\ndevise a negative sampling technique that not only improves the accuracy of the\nmodel but also facilitates the decentralization of the recommendation system.\nThe experimental results obtained using the MIND dataset demonstrate that the\naccuracy of the method under consideration can compete with that of\nState-of-the-Art models. The utilization of the sampling technique is essential\nin reducing model complexity and accelerating the training process, while\nmaintaining a high level of accuracy. Finally, we discuss how decentralized\nmodels can help improve privacy and scalability.\n","authors":["Miguel Ângelo Rebelo","João Vinagre","Ivo Pereira","Álvaro Figueira"],"pdf_url":"https://arxiv.org/pdf/2411.08700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08699v1","updated":"2024-11-13T15:42:09Z","published":"2024-11-13T15:42:09Z","title":"FedSub: Introducing class-aware Subnetworks Fusion to Enhance\n  Personalized Federated Learning in Ubiquitous Systems","summary":"  Personalized Federated Learning is essential in AI-driven ubiquitous systems,\nsupporting the distributed development of models able to adapt to diverse and\nevolving user behaviors while safeguarding privacy. Despite addressing\nheterogeneous user data distributions in collaborative model training, existing\nmethods often face limitations balancing personalization and generalization,\noversimplifying user similarities, or relying heavily on global models. In this\npaper, we propose FedSub, a novel federated approach designed to enhance\npersonalization through the use of class-aware prototypes and model\nsubnetworks. Prototypes serve as compact representations of user data,\nclustered on the server to identify similarities based on specific label\npatterns. Concurrently, subnetworks -- model components necessary to process\neach class -- are extracted locally and fused by the server according to these\nclusters, producing highly tailored model updates for each user. This\nfine-grained, class-specific aggregation of clients' models allows FedSub to\ncapture the unique characteristics of individual user data patterns. The\neffectiveness of FedSub is validated in three real-world scenarios\ncharacterized by high data heterogeneity, derived from human activity\nrecognition and mobile health applications. Experimental evaluations\ndemonstrate FedSub's performance improvements with respect to the\nstate-of-the-art and significant advancements in personalization for ubiquitous\nsystems based on personal mobile and wearable devices.\n","authors":["Mattia Giovanni Campana","Franca Delmastro"],"pdf_url":"https://arxiv.org/pdf/2411.08699v1.pdf","comment":"Submitted to Proceedings of the ACM on Interactive, Mobile, Wearable\n  and Ubiquitous Technologies (IMWUT)"},{"id":"http://arxiv.org/abs/2405.15732v2","updated":"2024-11-13T15:30:50Z","published":"2024-05-24T17:20:18Z","title":"Neural Persistence Dynamics","summary":"  We consider the problem of learning the dynamics in the topology of\ntime-evolving point clouds, the prevalent spatiotemporal model for systems\nexhibiting collective behavior, such as swarms of insects and birds or\nparticles in physics. In such systems, patterns emerge from (local)\ninteractions among self-propelled entities. While several well-understood\ngoverning equations for motion and interaction exist, they are notoriously\ndifficult to fit to data, as most prior work requires knowledge about\nindividual motion trajectories, i.e., a requirement that is challenging to\nsatisfy with an increasing number of entities. To evade such confounding\nfactors, we investigate collective behavior from a $\\textit{topological\nperspective}$, but instead of summarizing entire observation sequences (as done\npreviously), we propose learning a latent dynamical model from topological\nfeatures $\\textit{per time point}$. The latter is then used to formulate a\ndownstream regression task to predict the parametrization of some a priori\nspecified governing equation. We implement this idea based on a latent ODE\nlearned from vectorized (static) persistence diagrams and show that a\ncombination of recent stability results for persistent homology justifies this\nmodeling choice. Various (ablation) experiments not only demonstrate the\nrelevance of each model component but provide compelling empirical evidence\nthat our proposed model - $\\textit{Neural Persistence Dynamics}$ -\nsubstantially outperforms the state-of-the-art across a diverse set of\nparameter regression tasks.\n","authors":["Sebastian Zeng","Florian Graf","Martin Uray","Stefan Huber","Roland Kwitt"],"pdf_url":"https://arxiv.org/pdf/2405.15732v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08687v1","updated":"2024-11-13T15:22:33Z","published":"2024-11-13T15:22:33Z","title":"Measuring similarity between embedding spaces using induced neighborhood\n  graphs","summary":"  Deep Learning techniques have excelled at generating embedding spaces that\ncapture semantic similarities between items. Often these representations are\npaired, enabling experiments with analogies (pairs within the same domain) and\ncross-modality (pairs across domains). These experiments are based on specific\nassumptions about the geometry of embedding spaces, which allow finding paired\nitems by extrapolating the positional relationships between embedding pairs in\nthe training dataset, allowing for tasks such as finding new analogies, and\nmultimodal zero-shot classification. In this work, we propose a metric to\nevaluate the similarity between paired item representations. Our proposal is\nbuilt from the structural similarity between the nearest-neighbors induced\ngraphs of each representation, and can be configured to compare spaces based on\ndifferent distance metrics and on different neighborhood sizes. We demonstrate\nthat our proposal can be used to identify similar structures at different\nscales, which is hard to achieve with kernel methods such as Centered Kernel\nAlignment (CKA). We further illustrate our method with two case studies: an\nanalogy task using GloVe embeddings, and zero-shot classification in the\nCIFAR-100 dataset using CLIP embeddings. Our results show that accuracy in both\nanalogy and zero-shot classification tasks correlates with the embedding\nsimilarity. These findings can help explain performance differences in these\ntasks, and may lead to improved design of paired-embedding models in the\nfuture.\n","authors":["Tiago F. Tavares","Fabio Ayres","Paris Smaragdis"],"pdf_url":"https://arxiv.org/pdf/2411.08687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.09604v2","updated":"2024-11-13T15:17:20Z","published":"2024-08-18T22:11:24Z","title":"Circuit design in biology and machine learning. I. Random networks and\n  dimensional reduction","summary":"  A biological circuit is a neural or biochemical cascade, taking inputs and\nproducing outputs. How have biological circuits learned to solve environmental\nchallenges over the history of life? The answer certainly follows Dobzhansky's\nfamous quote that ``nothing in biology makes sense except in the light of\nevolution.'' But that quote leaves out the mechanistic basis by which natural\nselection's trial-and-error learning happens, which is exactly what we have to\nunderstand. How does the learning process that designs biological circuits\nactually work? How much insight can we gain about the form and function of\nbiological circuits by studying the processes that have made those circuits?\nBecause life's circuits must often solve the same problems as those faced by\nmachine learning, such as environmental tracking, homeostatic control,\ndimensional reduction, or classification, we can begin by considering how\nmachine learning designs computational circuits to solve problems. We can then\nask: How much insight do those computational circuits provide about the design\nof biological circuits? How much does biology differ from computers in the\nparticular circuit designs that it uses to solve problems? This article steps\nthrough two classic machine learning models to set the foundation for analyzing\nbroad questions about the design of biological circuits. One insight is the\nsurprising power of randomly connected networks. Another is the central role of\ninternal models of the environment embedded within biological circuits,\nillustrated by a model of dimensional reduction and trend prediction. Overall,\nmany challenges in biology have machine learning analogs, suggesting hypotheses\nabout how biology's circuits are designed.\n","authors":["Steven A. Frank"],"pdf_url":"https://arxiv.org/pdf/2408.09604v2.pdf","comment":"Added background info in two text boxes and new figure, edited\n  throughout"},{"id":"http://arxiv.org/abs/2402.16187v3","updated":"2024-11-13T15:14:38Z","published":"2024-02-25T20:24:07Z","title":"No Free Lunch in LLM Watermarking: Trade-offs in Watermarking Design\n  Choices","summary":"  Advances in generative models have made it possible for AI-generated text,\ncode, and images to mirror human-generated content in many applications.\nWatermarking, a technique that aims to embed information in the output of a\nmodel to verify its source, is useful for mitigating the misuse of such\nAI-generated content. However, we show that common design choices in LLM\nwatermarking schemes make the resulting systems surprisingly susceptible to\nattack -- leading to fundamental trade-offs in robustness, utility, and\nusability. To navigate these trade-offs, we rigorously study a set of simple\nyet effective attacks on common watermarking systems, and propose guidelines\nand defenses for LLM watermarking in practice.\n","authors":["Qi Pang","Shengyuan Hu","Wenting Zheng","Virginia Smith"],"pdf_url":"https://arxiv.org/pdf/2402.16187v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08664v1","updated":"2024-11-13T14:55:08Z","published":"2024-11-13T14:55:08Z","title":"UniMat: Unifying Materials Embeddings through Multi-modal Learning","summary":"  Materials science datasets are inherently heterogeneous and are available in\ndifferent modalities such as characterization spectra, atomic structures,\nmicroscopic images, and text-based synthesis conditions. The advancements in\nmulti-modal learning, particularly in vision and language models, have opened\nnew avenues for integrating data in different forms. In this work, we evaluate\ncommon techniques in multi-modal learning (alignment and fusion) in unifying\nsome of the most important modalities in materials science: atomic structure,\nX-ray diffraction patterns (XRD), and composition. We show that structure graph\nmodality can be enhanced by aligning with XRD patterns. Additionally, we show\nthat aligning and fusing more experimentally accessible data formats, such as\nXRD patterns and compositions, can create more robust joint embeddings than\nindividual modalities across various tasks. This lays the groundwork for future\nstudies aiming to exploit the full potential of multi-modal data in materials\nscience, facilitating more informed decision-making in materials design and\ndiscovery.\n","authors":["Janghoon Ock","Joseph Montoya","Daniel Schweigert","Linda Hung","Santosh K. Suram","Weike Ye"],"pdf_url":"https://arxiv.org/pdf/2411.08664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13224v4","updated":"2024-11-13T14:54:18Z","published":"2024-02-20T18:37:11Z","title":"Controlling Large Electric Vehicle Charging Stations via User Behavior\n  Modeling and Stochastic Programming","summary":"  This paper introduces an Electric Vehicle Charging Station (EVCS) model that\nincorporates real-world constraints, such as slot power limitations, contract\nthreshold overruns penalties, or early disconnections of electric vehicles\n(EVs). We propose a formulation of the problem of EVCS control under\nuncertainty, and implement two Multi-Stage Stochastic Programming approaches\nthat leverage user-provided information, namely, Model Predictive Control and\nTwo-Stage Stochastic Programming. The model addresses uncertainties in charging\nsession start and end times, as well as in energy demand. A user's behavior\nmodel based on a sojourn-time-dependent stochastic process enhances cost\nreduction while maintaining customer satisfaction. The benefits of the two\nproposed methods are showcased against two baselines over a 22-day simulation\nusing a real-world dataset. The two-stage approach demonstrates robustness\nagainst early disconnections by considering a wider range of uncertainty\nscenarios for optimization. The algorithm prioritizing user satisfaction over\nelectricity cost achieves a 20% and 36% improvement in two user satisfaction\nmetrics compared to an industry-standard baseline. Additionally, the algorithm\nstriking the best balance between cost and user satisfaction exhibits a mere 3%\nrelative cost increase compared to the theoretically optimal baseline - for\nwhich the nonanticipativity constraint is relaxed - while attaining 94% and 84%\nof the user satisfaction performance in the two used satisfaction metrics.\n","authors":["Alban Puech","Tristan Rigaut","William Templier","Maud Tournoud"],"pdf_url":"https://arxiv.org/pdf/2402.13224v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08652v1","updated":"2024-11-13T14:42:32Z","published":"2024-11-13T14:42:32Z","title":"Accelerating Quasi-Static Time Series Simulations with Foundation Models","summary":"  Quasi-static time series (QSTS) simulations have great potential for\nevaluating the grid's ability to accommodate the large-scale integration of\ndistributed energy resources. However, as grids expand and operate closer to\ntheir limits, iterative power flow solvers, central to QSTS simulations, become\ncomputationally prohibitive and face increasing convergence issues. Neural\npower flow solvers provide a promising alternative, speeding up power flow\ncomputations by 3 to 4 orders of magnitude, though they are costly to train. In\nthis paper, we envision how recently introduced grid foundation models could\nimprove the economic viability of neural power flow solvers. Conceptually,\nthese models amortize training costs by serving as a foundation for a range of\ngrid operation and planning tasks beyond power flow solving, with only minimal\nfine-tuning required. We call for collaboration between the AI and power grid\ncommunities to develop and open-source these models, enabling all operators,\neven those with limited resources, to benefit from AI without building\nsolutions from scratch.\n","authors":["Alban Puech","François Mirallès","Jonas Weiss","Vincent Mai","Alexandre Blondin Massé","Martin de Montigny","Thomas Brunschwiler","Hendrik F. Hamann"],"pdf_url":"https://arxiv.org/pdf/2411.08652v1.pdf","comment":"Equal contributors: A.P. and F.M.; Lead contact: A.P"},{"id":"http://arxiv.org/abs/2306.16028v2","updated":"2024-11-13T14:41:20Z","published":"2023-06-28T08:55:56Z","title":"Exponential separations between classical and quantum learners","summary":"  Despite significant effort, the quantum machine learning community has only\ndemonstrated quantum learning advantages for artificial cryptography-inspired\ndatasets when dealing with classical data. In this paper we address the\nchallenge of finding learning problems where quantum learning algorithms can\nachieve a provable exponential speedup over classical learning algorithms. We\nreflect on computational learning theory concepts related to this question and\ndiscuss how subtle differences in definitions can result in significantly\ndifferent requirements and tasks for the learner to meet and solve. We examine\nexisting learning problems with provable quantum speedups and find that they\nlargely rely on the classical hardness of evaluating the function that\ngenerates the data, rather than identifying it. To address this, we present two\nnew learning separations where the classical difficulty primarily lies in\nidentifying the function generating the data. Furthermore, we explore\ncomputational hardness assumptions that can be leveraged to prove quantum\nspeedups in scenarios where data is quantum-generated, which implies likely\nquantum advantages in a plethora of more natural settings (e.g., in condensed\nmatter and high energy physics). We also discuss the limitations of the\nclassical shadow paradigm in the context of learning separations, and how\nphysically-motivated settings such as characterizing phases of matter and\nHamiltonian learning fit in the computational learning framework.\n","authors":["Casper Gyurik","Vedran Dunjko"],"pdf_url":"https://arxiv.org/pdf/2306.16028v2.pdf","comment":"this article supersedes arXiv:2208.06339"},{"id":"http://arxiv.org/abs/2411.08651v1","updated":"2024-11-13T14:40:51Z","published":"2024-11-13T14:40:51Z","title":"Estimating unknown parameters in differential equations with a\n  reinforcement learning based PSO method","summary":"  Differential equations offer a foundational yet powerful framework for\nmodeling interactions within complex dynamic systems and are widely applied\nacross numerous scientific fields. One common challenge in this area is\nestimating the unknown parameters of these dynamic relationships. However,\ntraditional numerical optimization methods rely on the selection of initial\nparameter values, making them prone to local optima. Meanwhile, deep learning\nand Bayesian methods require training models on specific differential\nequations, resulting in poor versatility. This paper reformulates the parameter\nestimation problem of differential equations as an optimization problem by\nintroducing the concept of particles from the particle swarm optimization\nalgorithm. Building on reinforcement learning-based particle swarm optimization\n(RLLPSO), this paper proposes a novel method, DERLPSO, for estimating unknown\nparameters of differential equations. We compared its performance on three\ntypical ordinary differential equations with the state-of-the-art methods,\nincluding the RLLPSO algorithm, traditional numerical methods, deep learning\napproaches, and Bayesian methods. The experimental results demonstrate that our\nDERLPSO consistently outperforms other methods in terms of performance,\nachieving an average Mean Square Error of 1.13e-05, which reduces the error by\napproximately 4 orders of magnitude compared to other methods. Apart from\nordinary differential equations, our DERLPSO also show great promise for\nestimating unknown parameters of partial differential equations. The DERLPSO\nmethod proposed in this paper has high accuracy, is independent of initial\nparameter values, and possesses strong versatility and stability. This work\nprovides new insights into unknown parameter estimation for differential\nequations.\n","authors":["Wenkui Sun","Xiaoya Fan","Lijuan Jia","Tinyi Chu","Shing-Tung Yau","Rongling Wu","Zhong Wang"],"pdf_url":"https://arxiv.org/pdf/2411.08651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07444v2","updated":"2024-11-13T14:39:42Z","published":"2023-11-13T16:18:58Z","title":"On the Robustness of Neural Collapse and the Neural Collapse of\n  Robustness","summary":"  Neural Collapse refers to the curious phenomenon in the end of training of a\nneural network, where feature vectors and classification weights converge to a\nvery simple geometrical arrangement (a simplex). While it has been observed\nempirically in various cases and has been theoretically motivated, its\nconnection with crucial properties of neural networks, like their\ngeneralization and robustness, remains unclear. In this work, we study the\nstability properties of these simplices. We find that the simplex structure\ndisappears under small adversarial attacks, and that perturbed examples \"leap\"\nbetween simplex vertices. We further analyze the geometry of networks that are\noptimized to be robust against adversarial perturbations of the input, and find\nthat Neural Collapse is a pervasive phenomenon in these cases as well, with\nclean and perturbed representations forming aligned simplices, and giving rise\nto a robust simple nearest-neighbor classifier. By studying the propagation of\nthe amount of collapse inside the network, we identify novel properties of both\nrobust and non-robust machine learning models, and show that earlier, unlike\nlater layers maintain reliable simplices on perturbed data. Our code is\navailable at https://github.com/JingtongSu/robust_neural_collapse .\n","authors":["Jingtong Su","Ya Shi Zhang","Nikolaos Tsilivis","Julia Kempe"],"pdf_url":"https://arxiv.org/pdf/2311.07444v2.pdf","comment":"Transactions on Machine Learning Research, 2024"},{"id":"http://arxiv.org/abs/2411.08640v1","updated":"2024-11-13T14:31:52Z","published":"2024-11-13T14:31:52Z","title":"Towards Secure Intelligent O-RAN Architecture: Vulnerabilities, Threats\n  and Promising Technical Solutions using LLMs","summary":"  The evolution of wireless communication systems will be fundamentally\nimpacted by an open radio access network (O-RAN), a new concept defining an\nintelligent architecture with enhanced flexibility, openness, and the ability\nto slice services more efficiently. For all its promises, and like any\ntechnological advancement, O-RAN is not without risks that need to be carefully\nassessed and properly addressed to accelerate its wide adoption in future\nmobile networks. In this paper, we present an in-depth security analysis of the\nO-RAN architecture, discussing the potential threats that may arise in the\ndifferent O-RAN architecture layers and their impact on the Confidentiality,\nIntegrity, and Availability (CIA) triad. We also promote the potential of zero\ntrust, Moving Target Defense (MTD), blockchain, and large language models(LLM)\ntechnologies in fortifying O-RAN's security posture. Furthermore, we\nnumerically demonstrate the effectiveness of MTD in empowering robust deep\nreinforcement learning methods for dynamic network slice admission control in\nthe O-RAN architecture. Moreover, we examine the effect of explainable AI (XAI)\nbased on LLMs in securing the system.\n","authors":["Mojdeh Karbalaee Motalleb","Chafika Benzaid","Tarik Taleb","Marcos Katz","Vahid Shah-Mansouri","JaeSeung Song"],"pdf_url":"https://arxiv.org/pdf/2411.08640v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2411.08638v1","updated":"2024-11-13T14:26:04Z","published":"2024-11-13T14:26:04Z","title":"Gaussian Mixture Models Based Augmentation Enhances GNN Generalization","summary":"  Graph Neural Networks (GNNs) have shown great promise in tasks like node and\ngraph classification, but they often struggle to generalize, particularly to\nunseen or out-of-distribution (OOD) data. These challenges are exacerbated when\ntraining data is limited in size or diversity. To address these issues, we\nintroduce a theoretical framework using Rademacher complexity to compute a\nregret bound on the generalization error and then characterize the effect of\ndata augmentation. This framework informs the design of GMM-GDA, an efficient\ngraph data augmentation (GDA) algorithm leveraging the capability of Gaussian\nMixture Models (GMMs) to approximate any distribution. Our approach not only\noutperforms existing augmentation techniques in terms of generalization but\nalso offers improved time complexity, making it highly suitable for real-world\napplications.\n","authors":["Yassine Abbahaddou","Fragkiskos D. Malliaros","Johannes F. Lutzeyer","Amine Mohamed Aboussalah","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2411.08638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08637v1","updated":"2024-11-13T14:24:47Z","published":"2024-11-13T14:24:47Z","title":"Robot See, Robot Do: Imitation Reward for Noisy Financial Environments","summary":"  The sequential nature of decision-making in financial asset trading aligns\nnaturally with the reinforcement learning (RL) framework, making RL a common\napproach in this domain. However, the low signal-to-noise ratio in financial\nmarkets results in noisy estimates of environment components, including the\nreward function, which hinders effective policy learning by RL agents. Given\nthe critical importance of reward function design in RL problems, this paper\nintroduces a novel and more robust reward function by leveraging imitation\nlearning, where a trend labeling algorithm acts as an expert. We integrate\nimitation (expert's) feedback with reinforcement (agent's) feedback in a\nmodel-free RL algorithm, effectively embedding the imitation learning problem\nwithin the RL paradigm to handle the stochasticity of reward signals. Empirical\nresults demonstrate that this novel approach improves financial performance\nmetrics compared to traditional benchmarks and RL agents trained solely using\nreinforcement feedback.\n","authors":["Sven Goluža","Tomislav Kovačević","Stjepan Begušić","Zvonko Kostanjčar"],"pdf_url":"https://arxiv.org/pdf/2411.08637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08631v1","updated":"2024-11-13T14:17:26Z","published":"2024-11-13T14:17:26Z","title":"Deep Generative Demand Learning for Newsvendor and Pricing","summary":"  We consider data-driven inventory and pricing decisions in the feature-based\nnewsvendor problem, where demand is influenced by both price and contextual\nfeatures and is modeled without any structural assumptions. The unknown demand\ndistribution results in a challenging conditional stochastic optimization\nproblem, further complicated by decision-dependent uncertainty and the\nintegration of features. Inspired by recent advances in deep generative\nlearning, we propose a novel approach leveraging conditional deep generative\nmodels (cDGMs) to address these challenges. cDGMs learn the demand distribution\nand generate probabilistic demand forecasts conditioned on price and features.\nThis generative approach enables accurate profit estimation and supports the\ndesign of algorithms for two key objectives: (1) optimizing inventory for\narbitrary prices, and (2) jointly determining optimal pricing and inventory\nlevels. We provide theoretical guarantees for our approach, including the\nconsistency of profit estimation and convergence of our decisions to the\noptimal solution. Extensive simulations-ranging from simple to complex\nscenarios, including one involving textual features-and a real-world case study\ndemonstrate the effectiveness of our approach. Our method opens a new paradigm\nin management science and operations research, is adaptable to extensions of\nthe newsvendor and pricing problems, and holds potential for solving other\nconditional stochastic optimization problems.\n","authors":["Shijin Gong","Huihang Liu","Xinyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.08631v1.pdf","comment":"30 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.16336v2","updated":"2024-11-13T14:13:58Z","published":"2024-03-25T00:21:34Z","title":"Predictive Inference in Multi-environment Scenarios","summary":"  We address the challenge of constructing valid confidence intervals and sets\nin problems of prediction across multiple environments. We investigate two\ntypes of coverage suitable for these problems, extending the jackknife and\nsplit-conformal methods to show how to obtain distribution-free coverage in\nsuch non-traditional, potentially hierarchical data-generating scenarios. We\ndemonstrate a novel resizing method to adapt to problem difficulty, which\napplies both to existing approaches for predictive inference and the methods we\ndevelop; this reduces prediction set sizes using limited information from the\ntest environment, a key to the methods' practical performance, which we\nevaluate through neurochemical sensing and species classification datasets. Our\ncontributions also include extensions for settings with non-real-valued\nresponses, a theory of consistency for predictive inference in these general\nproblems, and insights on the limits of conditional coverage.\n","authors":["John C. Duchi","Suyash Gupta","Kuanhao Jiang","Pragya Sur"],"pdf_url":"https://arxiv.org/pdf/2403.16336v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08610v1","updated":"2024-11-13T13:53:10Z","published":"2024-11-13T13:53:10Z","title":"Dynamic Subset Tuning: Expanding the Operational Range of\n  Parameter-Efficient Training for Large Language Models","summary":"  We propose a novel parameter-efficient training (PET) method for large\nlanguage models that adapts models to downstream tasks by optimizing a small\nsubset of the existing model parameters. Unlike prior methods, this subset is\nnot fixed in location but rather which parameters are modified evolves over the\ncourse of training. This dynamic parameter selection can yield good performance\nwith many fewer parameters than extant methods. Our method enables a seamless\nscaling of the subset size across an arbitrary proportion of the total model\nsize, while popular PET approaches like prompt tuning and LoRA cover only a\nsmall part of this spectrum. We match or outperform prompt tuning and LoRA in\nmost cases on a variety of NLP tasks (MT, QA, GSM8K, SuperGLUE) for a given\nparameter budget across different model families and sizes.\n","authors":["Felix Stahlberg","Jared Lichtarge","Shankar Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.08610v1.pdf","comment":"NeurIPS 2024 Workshop on Adaptive Foundation Models"},{"id":"http://arxiv.org/abs/2411.08013v2","updated":"2024-11-13T13:36:05Z","published":"2024-11-12T18:43:27Z","title":"Investigating the Effectiveness of Explainability Methods in Parkinson's\n  Detection from Speech","summary":"  Speech impairments in Parkinson's disease (PD) provide significant early\nindicators for diagnosis. While models for speech-based PD detection have shown\nstrong performance, their interpretability remains underexplored. This study\nsystematically evaluates several explainability methods to identify PD-specific\nspeech features, aiming to support the development of accurate, interpretable\nmodels for clinical decision-making in PD diagnosis and monitoring. Our\nmethodology involves (i) obtaining attributions and saliency maps using\nmainstream interpretability techniques, (ii) quantitatively evaluating the\nfaithfulness of these maps and their combinations obtained via union and\nintersection through a range of established metrics, and (iii) assessing the\ninformation conveyed by the saliency maps for PD detection from an auxiliary\nclassifier. Our results reveal that, while explanations are aligned with the\nclassifier, they often fail to provide valuable information for domain experts.\n","authors":["Eleonora Mancini","Francesco Paissan","Paolo Torroni","Mirco Ravanelli","Cem Subakan"],"pdf_url":"https://arxiv.org/pdf/2411.08013v2.pdf","comment":"The first two authors contributed equally to this research: author\n  order is alphabetical"},{"id":"http://arxiv.org/abs/2411.08599v1","updated":"2024-11-13T13:30:21Z","published":"2024-11-13T13:30:21Z","title":"XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL","summary":"  To tackle the challenges of large language model performance in natural\nlanguage to SQL tasks, we introduce XiYan-SQL, an innovative framework that\nemploys a multi-generator ensemble strategy to improve candidate generation. We\nintroduce M-Schema, a semi-structured schema representation method designed to\nenhance the understanding of database structures. To enhance the quality and\ndiversity of generated candidate SQL queries, XiYan-SQL integrates the\nsignificant potential of in-context learning (ICL) with the precise control of\nsupervised fine-tuning. On one hand, we propose a series of training strategies\nto fine-tune models to generate high-quality candidates with diverse\npreferences. On the other hand, we implement the ICL approach with an example\nselection method based on named entity recognition to prevent overemphasis on\nentities. The refiner optimizes each candidate by correcting logical or\nsyntactical errors. To address the challenge of identifying the best candidate,\nwe fine-tune a selection model to distinguish nuances of candidate SQL queries.\nThe experimental results on multiple dialect datasets demonstrate the\nrobustness of XiYan-SQL in addressing challenges across different scenarios.\nOverall, our proposed XiYan-SQL achieves the state-of-the-art execution\naccuracy of 89.65% on the Spider test set, 69.86% on SQL-Eval, 41.20% on\nNL2GQL, and a competitive score of 72.23% on the Bird development benchmark.\nThe proposed framework not only enhances the quality and diversity of SQL\nqueries but also outperforms previous methods.\n","authors":["Yingqi Gao","Yifu Liu","Xiaoxia Li","Xiaorong Shi","Yin Zhu","Yiming Wang","Shiqi Li","Wei Li","Yuntao Hong","Zhiling Luo","Jinyang Gao","Liyu Mou","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2411.08599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13178v2","updated":"2024-11-13T13:14:19Z","published":"2024-10-17T02:58:57Z","title":"GeSubNet: Gene Interaction Inference for Disease Subtype Network\n  Generation","summary":"  Retrieving gene functional networks from knowledge databases presents a\nchallenge due to the mismatch between disease networks and subtype-specific\nvariations. Current solutions, including statistical and deep learning methods,\noften fail to effectively integrate gene interaction knowledge from databases\nor explicitly learn subtype-specific interactions. To address this mismatch, we\npropose GeSubNet, which learns a unified representation capable of predicting\ngene interactions while distinguishing between different disease subtypes.\nGraphs generated by such representations can be considered subtype-specific\nnetworks. GeSubNet is a multi-step representation learning framework with three\nmodules: First, a deep generative model learns distinct disease subtypes from\npatient gene expression profiles. Second, a graph neural network captures\nrepresentations of prior gene networks from knowledge databases, ensuring\naccurate physical gene interactions. Finally, we integrate these two\nrepresentations using an inference loss that leverages graph generation\ncapabilities, conditioned on the patient separation loss, to refine\nsubtype-specific information in the learned representation. GeSubNet\nconsistently outperforms traditional methods, with average improvements of\n30.6%, 21.0%, 20.1%, and 56.6% across four graph evaluation metrics, averaged\nover four cancer datasets. Particularly, we conduct a biological simulation\nexperiment to assess how the behavior of selected genes from over 11,000\ncandidates affects subtypes or patient distributions. The results show that the\ngenerated network has the potential to identify subtype-specific genes with an\n83% likelihood of impacting patient distribution shifts. The GeSubNet resource\nis available: https://anonymous.4open.science/r/GeSubNet/\n","authors":["Ziwei Yang","Zheng Chen","Xin Liu","Rikuto Kotoge","Peng Chen","Yasuko Matsubara","Yasushi Sakurai","Jimeng Sun"],"pdf_url":"https://arxiv.org/pdf/2410.13178v2.pdf","comment":"Under review as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2411.08590v1","updated":"2024-11-13T13:13:07Z","published":"2024-11-13T13:13:07Z","title":"Hopfield-Fenchel-Young Networks: A Unified Framework for Associative\n  Memory Retrieval","summary":"  Associative memory models, such as Hopfield networks and their modern\nvariants, have garnered renewed interest due to advancements in memory capacity\nand connections with self-attention in transformers. In this work, we introduce\na unified framework-Hopfield-Fenchel-Young networks-which generalizes these\nmodels to a broader family of energy functions. Our energies are formulated as\nthe difference between two Fenchel-Young losses: one, parameterized by a\ngeneralized entropy, defines the Hopfield scoring mechanism, while the other\napplies a post-transformation to the Hopfield output. By utilizing Tsallis and\nnorm entropies, we derive end-to-end differentiable update rules that enable\nsparse transformations, uncovering new connections between loss margins,\nsparsity, and exact retrieval of single memory patterns. We further extend this\nframework to structured Hopfield networks using the SparseMAP transformation,\nallowing the retrieval of pattern associations rather than a single pattern.\nOur framework unifies and extends traditional and modern Hopfield networks and\nprovides an energy minimization perspective for widely used\npost-transformations like $\\ell_2$-normalization and layer normalization-all\nthrough suitable choices of Fenchel-Young losses and by using convex analysis\nas a building block. Finally, we validate our Hopfield-Fenchel-Young networks\non diverse memory recall tasks, including free and sequential recall.\nExperiments on simulated data, image retrieval, multiple instance learning, and\ntext rationalization demonstrate the effectiveness of our approach.\n","authors":["Saul Santos","Vlad Niculae","Daniel McNamee","André F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2411.08590v1.pdf","comment":"49 pages, 14 figures. arXiv admin note: text overlap with\n  arXiv:2402.13725"},{"id":"http://arxiv.org/abs/2411.08587v1","updated":"2024-11-13T13:11:49Z","published":"2024-11-13T13:11:49Z","title":"DeepUQ: Assessing the Aleatoric Uncertainties from two Deep Learning\n  Methods","summary":"  Assessing the quality of aleatoric uncertainty estimates from uncertainty\nquantification (UQ) deep learning methods is important in scientific contexts,\nwhere uncertainty is physically meaningful and important to characterize and\ninterpret exactly. We systematically compare aleatoric uncertainty measured by\ntwo UQ techniques, Deep Ensembles (DE) and Deep Evidential Regression (DER).\nOur method focuses on both zero-dimensional (0D) and two-dimensional (2D) data,\nto explore how the UQ methods function for different data dimensionalities. We\ninvestigate uncertainty injected on the input and output variables and include\na method to propagate uncertainty in the case of input uncertainty so that we\ncan compare the predicted aleatoric uncertainty to the known values. We\nexperiment with three levels of noise. The aleatoric uncertainty predicted\nacross all models and experiments scales with the injected noise level.\nHowever, the predicted uncertainty is miscalibrated to $\\rm{std}(\\sigma_{\\rm\nal})$ with the true uncertainty for half of the DE experiments and almost all\nof the DER experiments. The predicted uncertainty is the least accurate for\nboth UQ methods for the 2D input uncertainty experiment and the high-noise\nlevel. While these results do not apply to more complex data, they highlight\nthat further research on post-facto calibration for these methods would be\nbeneficial, particularly for high-noise and high-dimensional settings.\n","authors":["Rebecca Nevin","Aleksandra Ćiprijanović","Brian D. Nord"],"pdf_url":"https://arxiv.org/pdf/2411.08587v1.pdf","comment":"Accepted to the Machine Learning for Physical Sciences workshop at\n  NeurIPS 2024; 11 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2411.08582v1","updated":"2024-11-13T13:01:44Z","published":"2024-11-13T13:01:44Z","title":"Intelligent Algorithms For Signature Diagnostics Of Three-Phase Motors","summary":"  The application of machine learning (ML) algorithms in the intelligent\ndiagnosis of three-phase engines has the potential to significantly enhance\ndiagnostic performance and accuracy. Traditional methods largely rely on\nsignature analysis, which, despite being a standard practice, can benefit from\nthe integration of advanced ML techniques. In our study, we innovate by\ncombining state of the art algorithms with a novel unsupervised anomaly\ngeneration methodology that takes into account physics model of the engine.\nThis hybrid approach leverages the strengths of both supervised ML and\nunsupervised signature analysis, achieving superior diagnostic accuracy and\nreliability along with a wide industrial application. Our experimental results\ndemonstrate that this method significantly outperforms existing ML and non-ML\nstate-of-the-art approaches while retaining the practical advantages of an\nunsupervised methodology. The findings highlight the potential of our approach\nto significantly contribute to the field of engine diagnostics, offering a\nrobust and efficient solution for real-world applications.\n","authors":["Stepan Svirin","Artem Ryzhikov","Saraa Ali","Denis Derkach"],"pdf_url":"https://arxiv.org/pdf/2411.08582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16561v2","updated":"2024-11-13T13:01:19Z","published":"2024-10-21T22:40:42Z","title":"Gradient Normalization Provably Benefits Nonconvex SGD under\n  Heavy-Tailed Noise","summary":"  This paper investigates the roles of gradient normalization and clipping in\nensuring the convergence of Stochastic Gradient Descent (SGD) under\nheavy-tailed noise. While existing approaches consider gradient clipping\nindispensable for SGD convergence, we theoretically demonstrate that gradient\nnormalization alone without clipping is sufficient to ensure convergence.\nFurthermore, we establish that combining gradient normalization with clipping\noffers significantly improved convergence rates compared to using either\ntechnique in isolation, particularly as gradient noise diminishes. With these\nresults, our work provides the first theoretical evidence demonstrating the\nbenefits of gradient normalization in SGD under heavy-tailed noise. Finally, we\nintroduce an accelerated SGD variant that incorporates both gradient\nnormalization and clipping, further enhancing convergence rates under\nheavy-tailed noise.\n","authors":["Tao Sun","Xinwang Liu","Kun Yuan"],"pdf_url":"https://arxiv.org/pdf/2410.16561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07743v3","updated":"2024-11-13T12:43:33Z","published":"2023-06-13T13:00:10Z","title":"V-LoL: A Diagnostic Dataset for Visual Logical Learning","summary":"  Despite the successes of recent developments in visual AI, different\nshortcomings still exist; from missing exact logical reasoning, to abstract\ngeneralization abilities, to understanding complex and noisy scenes.\nUnfortunately, existing benchmarks, were not designed to capture more than a\nfew of these aspects. Whereas deep learning datasets focus on visually complex\ndata but simple visual reasoning tasks, inductive logic datasets involve\ncomplex logical learning tasks, however, lack the visual component. To address\nthis, we propose the diagnostic visual logical learning dataset, V-LoL, that\nseamlessly combines visual and logical challenges. Notably, we introduce the\nfirst instantiation of V-LoL, V-LoL-Train, - a visual rendition of a classic\nbenchmark in symbolic AI, the Michalski train problem. By incorporating\nintricate visual scenes and flexible logical reasoning tasks within a versatile\nframework, V-LoL-Train provides a platform for investigating a wide range of\nvisual logical learning challenges. We evaluate a variety of AI systems\nincluding traditional symbolic AI, neural AI, as well as neuro-symbolic AI. Our\nevaluations demonstrate that even SOTA AI faces difficulties in dealing with\nvisual logical learning challenges, highlighting unique advantages and\nlimitations of each methodology. Overall, V-LoL opens up new avenues for\nunderstanding and enhancing current abilities in visual logical learning for AI\nsystems.\n","authors":["Lukas Helff","Wolfgang Stammer","Hikaru Shindo","Devendra Singh Dhami","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2306.07743v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02549v2","updated":"2024-11-13T12:37:09Z","published":"2024-02-04T15:52:59Z","title":"Are Large Language Models Table-based Fact-Checkers?","summary":"  Table-based Fact Verification (TFV) aims to extract the entailment relation\nbetween statements and structured tables. Existing TFV methods based on\nsmall-scaled models suffer from insufficient labeled data and weak zero-shot\nability. Recently, the appearance of Large Language Models (LLMs) has gained\nlots of attraction in research fields. They have shown powerful zero-shot and\nin-context learning abilities on several NLP tasks, but their potential on TFV\nis still unknown. In this work, we implement a preliminary study about whether\nLLMs are table-based fact-checkers. In detail, we design diverse prompts to\nexplore how the in-context learning can help LLMs in TFV, i.e., zero-shot and\nfew-shot TFV capability. Besides, we carefully design and construct TFV\ninstructions to study the performance gain brought by the instruction tuning of\nLLMs. Experimental results demonstrate that LLMs can achieve acceptable results\non zero-shot and few-shot TFV with prompt engineering, while instruction-tuning\ncan stimulate the TFV capability significantly. We also make some valuable\nfindings about the format of zero-shot prompts and the number of in-context\nexamples. Finally, we analyze some possible directions to promote the accuracy\nof TFV via LLMs, which is beneficial to further research of table reasoning.\n","authors":["Hanwen Zhang","Qingyi Si","Peng Fu","Zheng Lin","Weiping Wang"],"pdf_url":"https://arxiv.org/pdf/2402.02549v2.pdf","comment":"CSCWD 2024"},{"id":"http://arxiv.org/abs/2410.10929v4","updated":"2024-11-13T12:27:38Z","published":"2024-10-14T16:35:27Z","title":"ASTM :Autonomous Smart Traffic Management System Using Artificial\n  Intelligence CNN and LSTM","summary":"  In the modern world, the development of Artificial Intelligence (AI) has\ncontributed to improvements in various areas, including automation, computer\nvision, fraud detection, and more. AI can be leveraged to enhance the\nefficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce\ntraffic congestion rates. This paper presents an Autonomous Smart Traffic\nManagement (STM) system that uses AI to improve traffic flow rates. The system\nemploys the YOLO V5 Convolutional Neural Network to detect vehicles in traffic\nmanagement images. Additionally, it predicts the number of vehicles for the\nnext 12 hours using a Recurrent Neural Network with Long Short-Term Memory\n(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the\ntraffic cycle length based on these vehicle predictions, aided by AI. From the\nresults of the RNN-LSTM model for predicting vehicle numbers over the next 12\nhours, we observe that the model predicts traffic with a Mean Squared Error\n(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.\nAfter simulating the STM system in the CARLA simulation environment, we found\nthat the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per\nminute) is 50\\% higher than the rate without STM (around 15 vehicles per\nminute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5\nseconds per vehicle) is 70\\% lower than without STM (around 12 seconds per\nvehicle). These results demonstrate that the STM system using AI can increase\ntraffic flow by 50\\% and reduce vehicle pass delays by 70\\%.\n","authors":["Christofel Rio Goenawan"],"pdf_url":"https://arxiv.org/pdf/2410.10929v4.pdf","comment":"In process to IEEE Intelligent Vehicle Symposium 2025"},{"id":"http://arxiv.org/abs/2411.08566v1","updated":"2024-11-13T12:26:08Z","published":"2024-11-13T12:26:08Z","title":"Grammarization-Based Grasping with Deep Multi-Autoencoder Latent Space\n  Exploration by Reinforcement Learning Agent","summary":"  Grasping by a robot in unstructured environments is deemed a critical\nchallenge because of the requirement for effective adaptation to a wide\nvariation in object geometries, material properties, and other environmental\nfactors. In this paper, we propose a novel framework for robotic grasping based\non the idea of compressing high-dimensional target and gripper features in a\ncommon latent space using a set of autoencoders. Our approach simplifies\ngrasping by using three autoencoders dedicated to the target, the gripper, and\na third one that fuses their latent representations. This allows the RL agent\nto achieve higher learning rates at the initial stages of exploration of a new\nenvironment, as well as at non-zero shot grasp attempts. The agent explores the\nlatent space of the third autoencoder for better quality grasp without explicit\nreconstruction of objects. By implementing the PoWER algorithm into the RL\ntraining process, updates on the agent's policy will be made through the\nperturbation in the reward-weighted latent space. The successful exploration\nefficiently constrains both position and pose integrity for feasible executions\nof grasps. We evaluate our system on a diverse set of objects, demonstrating\nthe high success rate in grasping with minimum computational overhead. We found\nthat approach enhances the adaptation of the RL agent by more than 35 \\% in\nsimulation experiments.\n","authors":["Leonidas Askianakis"],"pdf_url":"https://arxiv.org/pdf/2411.08566v1.pdf","comment":"Submitted for review at IEEE ICRA 2025"},{"id":"http://arxiv.org/abs/2411.08557v1","updated":"2024-11-13T12:13:15Z","published":"2024-11-13T12:13:15Z","title":"Learning Locally Adaptive Metrics that Enhance Structural Representation\n  with $\\texttt{LAMINAR}$","summary":"  We present $\\texttt{LAMINAR}$, a novel unsupervised machine learning pipeline\ndesigned to enhance the representation of structure within data via producing a\nmore-informative distance metric. Analysis methods in the physical sciences\noften rely on standard metrics to define geometric relationships in data, which\nmay fail to capture the underlying structure of complex data sets.\n$\\texttt{LAMINAR}$ addresses this by using a continuous-normalising-flow and\ninverse-transform-sampling to define a Riemannian manifold in the data space\nwithout the need for the user to specify a metric over the data a-priori. The\nresult is a locally-adaptive-metric that produces structurally-informative\ndensity-based distances. We demonstrate the utility of $\\texttt{LAMINAR}$ by\ncomparing its output to the Euclidean metric for structured data sets.\n","authors":["Christian Kleiber","William H. Oliver","Tobias Buck"],"pdf_url":"https://arxiv.org/pdf/2411.08557v1.pdf","comment":"Accepted to the NeurIPS 2024 Machine Learning and the Physical\n  Sciences workshop. 6 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.08552v1","updated":"2024-11-13T12:03:39Z","published":"2024-11-13T12:03:39Z","title":"Leveraging Pre-Trained Neural Networks to Enhance Machine Learning with\n  Variational Quantum Circuits","summary":"  Quantum Machine Learning (QML) offers tremendous potential but is currently\nlimited by the availability of qubits. We introduce an innovative approach that\nutilizes pre-trained neural networks to enhance Variational Quantum Circuits\n(VQC). This technique effectively separates approximation error from qubit\ncount and removes the need for restrictive conditions, making QML more viable\nfor real-world applications. Our method significantly improves parameter\noptimization for VQC while delivering notable gains in representation and\ngeneralization capabilities, as evidenced by rigorous theoretical analysis and\nextensive empirical testing on quantum dot classification tasks. Moreover, our\nresults extend to applications such as human genome analysis, demonstrating the\nbroad applicability of our approach. By addressing the constraints of current\nquantum hardware, our work paves the way for a new era of advanced QML\napplications, unlocking the full potential of quantum computing in fields such\nas machine learning, materials science, medicine, mimetics, and various\ninterdisciplinary areas.\n","authors":["Jun Qi","Chao-Han Yang","Samuel Yen-Chi Chen","Pin-Yu Chen","Hector Zenil","Jesper Tegner"],"pdf_url":"https://arxiv.org/pdf/2411.08552v1.pdf","comment":"In submission"},{"id":"http://arxiv.org/abs/2411.08550v1","updated":"2024-11-13T11:59:40Z","published":"2024-11-13T11:59:40Z","title":"Graph Neural Networks in Supply Chain Analytics and Optimization:\n  Concepts, Perspectives, Dataset and Benchmarks","summary":"  Graph Neural Networks (GNNs) have recently gained traction in transportation,\nbioinformatics, language and image processing, but research on their\napplication to supply chain management remains limited. Supply chains are\ninherently graph-like, making them ideal for GNN methodologies, which can\noptimize and solve complex problems. The barriers include a lack of proper\nconceptual foundations, familiarity with graph applications in SCM, and\nreal-world benchmark datasets for GNN-based supply chain research. To address\nthis, we discuss and connect supply chains with graph structures for effective\nGNN application, providing detailed formulations, examples, mathematical\ndefinitions, and task guidelines. Additionally, we present a multi-perspective\nreal-world benchmark dataset from a leading FMCG company in Bangladesh,\nfocusing on supply chain planning. We discuss various supply chain tasks using\nGNNs and benchmark several state-of-the-art models on homogeneous and\nheterogeneous graphs across six supply chain analytics tasks. Our analysis\nshows that GNN-based models consistently outperform statistical Machine\nLearning and other Deep Learning models by around 10-30% in regression, 10-30%\nin classification and detection tasks, and 15-40% in anomaly detection tasks on\ndesignated metrics. With this work, we lay the groundwork for solving supply\nchain problems using GNNs, supported by conceptual discussions, methodological\ninsights, and a comprehensive dataset.\n","authors":["Azmine Toushik Wasi","MD Shafikul Islam","Adipto Raihan Akib","Mahathir Mohammad Bappy"],"pdf_url":"https://arxiv.org/pdf/2411.08550v1.pdf","comment":"27 Pages. Extended journal version of SupplyGraph (arXiv:2401.15299).\n  In Review"},{"id":"http://arxiv.org/abs/2411.08537v1","updated":"2024-11-13T11:35:39Z","published":"2024-11-13T11:35:39Z","title":"MLV$^2$-Net: Rater-Based Majority-Label Voting for Consistent Meningeal\n  Lymphatic Vessel Segmentation","summary":"  Meningeal lymphatic vessels (MLVs) are responsible for the drainage of waste\nproducts from the human brain. An impairment in their functionality has been\nassociated with aging as well as brain disorders like multiple sclerosis and\nAlzheimer's disease. However, MLVs have only recently been described for the\nfirst time in magnetic resonance imaging (MRI), and their ramified structure\nrenders manual segmentation particularly difficult. Further, as there is no\nconsistent notion of their appearance, human-annotated MLV structures contain a\nhigh inter-rater variability that most automatic segmentation methods cannot\ntake into account. In this work, we propose a new rater-aware training scheme\nfor the popular nnU-Net model, and we explore rater-based ensembling strategies\nfor accurate and consistent segmentation of MLVs. This enables us to boost\nnnU-Net's performance while obtaining explicit predictions in different\nannotation styles and a rater-based uncertainty estimation. Our final model,\nMLV$^2$-Net, achieves a Dice similarity coefficient of 0.806 with respect to\nthe human reference standard. The model further matches the human inter-rater\nreliability and replicates age-related associations with MLV volume.\n","authors":["Fabian Bongratz","Markus Karmann","Adrian Holz","Moritz Bonhoeffer","Viktor Neumaier","Sarah Deli","Benita Schmitz-Koep","Claus Zimmer","Christian Sorg","Melissa Thalhammer","Dennis M Hedderich","Christian Wachinger"],"pdf_url":"https://arxiv.org/pdf/2411.08537v1.pdf","comment":"ML4H 2024"},{"id":"http://arxiv.org/abs/2411.08530v1","updated":"2024-11-13T11:24:12Z","published":"2024-11-13T11:24:12Z","title":"Efficient Whole Slide Image Classification through Fisher Vector\n  Representation","summary":"  The advancement of digital pathology, particularly through computational\nanalysis of whole slide images (WSI), is poised to significantly enhance\ndiagnostic precision and efficiency. However, the large size and complexity of\nWSIs make it difficult to analyze and classify them using computers. This study\nintroduces a novel method for WSI classification by automating the\nidentification and examination of the most informative patches, thus\neliminating the need to process the entire slide. Our method involves\ntwo-stages: firstly, it extracts only a few patches from the WSIs based on\ntheir pathological significance; and secondly, it employs Fisher vectors (FVs)\nfor representing features extracted from these patches, which is known for its\nrobustness in capturing fine-grained details. This approach not only\naccentuates key pathological features within the WSI representation but also\nsignificantly reduces computational overhead, thus making the process more\nefficient and scalable. We have rigorously evaluated the proposed method across\nmultiple datasets to benchmark its performance against comprehensive WSI\nanalysis and contemporary weakly-supervised learning methodologies. The\nempirical results indicate that our focused analysis of select patches,\ncombined with Fisher vector representation, not only aligns with, but at times\nsurpasses, the classification accuracy of standard practices. Moreover, this\nstrategy notably diminishes computational load and resource expenditure,\nthereby establishing an efficient and precise framework for WSI analysis in the\nrealm of digital pathology.\n","authors":["Ravi Kant Gupta","Dadi Dharani","Shambhavi Shanker","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2411.08530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10040v3","updated":"2024-11-13T11:13:56Z","published":"2024-05-16T12:22:41Z","title":"SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation","summary":"  It is often desirable to distill the capabilities of large language models\n(LLMs) into smaller student models due to compute and memory constraints. One\nway to do this for classification tasks is via dataset synthesis, which can be\naccomplished by generating examples of each label from the LLM. Prior\napproaches to synthesis use few-shot prompting, which relies on the LLM's\nparametric knowledge to generate usable examples. However, this leads to issues\nof repetition, bias towards popular entities, and stylistic differences from\nhuman text. In this work, we propose Synthesize by Retrieval and Refinement\n(SynthesizRR), which uses retrieval augmentation to introduce variety into the\ndataset synthesis process: as retrieved passages vary, the LLM is seeded with\ndifferent content to generate its examples. We empirically study the synthesis\nof six datasets, covering topic classification, sentiment analysis, tone\ndetection, and humor, requiring complex synthesis strategies. We find that\nSynthesizRR greatly improves lexical and semantic diversity, similarity to\nhuman-written text, and distillation performance, when compared to 32-shot\nprompting and four prior approaches. We release our code to perform all steps\nat https://github.com/amazon-science/synthesizrr\n","authors":["Abhishek Divekar","Greg Durrett"],"pdf_url":"https://arxiv.org/pdf/2405.10040v3.pdf","comment":"Published as a main conference paper at EMNLP 2024. Code available at\n  https://github.com/amazon-science/synthesizrr"},{"id":"http://arxiv.org/abs/2411.08521v1","updated":"2024-11-13T11:08:28Z","published":"2024-11-13T11:08:28Z","title":"SAD-TIME: a Spatiotemporal-fused network for depression detection with\n  Automated multi-scale Depth-wise and TIME-interval-related common feature\n  extractor","summary":"  Background and Objective: Depression is a severe mental disorder, and\naccurate diagnosis is pivotal to the cure and rehabilitation of people with\ndepression. However, the current questionnaire-based diagnostic methods could\nbring subjective biases and may be denied by subjects. In search of a more\nobjective means of diagnosis, researchers have begun to experiment with deep\nlearning-based methods for identifying depressive disorders in recent years.\nMethods: In this study, a novel Spatiotemporal-fused network with Automated\nmulti-scale Depth-wise and TIME-interval-related common feature extractor\n(SAD-TIME) is proposed. SAD-TIME incorporates an automated nodes' common\nfeatures extractor (CFE), a spatial sector (SpS), a modified temporal sector\n(TeS), and a domain adversarial learner (DAL). The CFE includes a multi-scale\ndepth-wise 1D-convolutional neural network and a time-interval embedding\ngenerator, where the unique information of each channel is preserved. The SpS\nfuses the functional connectivity with the distance-based connectivity\ncontaining spatial position of EEG electrodes. A multi-head-attention graph\nconvolutional network is also applied in the SpS to fuse the features from\ndifferent EEG channels. The TeS is based on long short-term memory and graph\ntransformer networks, where the temporal information of different time-windows\nis fused. Moreover, the DAL is used after the SpS to obtain the\ndomain-invariant feature. Results: Experimental results under tenfold\ncross-validation show that the proposed SAD-TIME method achieves 92.00% and\n94.00% depression classification accuracies on two datasets, respectively, in\ncross-subject mode. Conclusion: SAD-TIME is a robust depression detection\nmodel, where the automatedly-generated features, the SpS and the TeS assist the\nclassification performance with the fusion of the innate spatiotemporal\ninformation in the EEG signals.\n","authors":["Han-Guang Wang","Hui-Rang Hou","Li-Cheng Jin","Chen-Yang Xu","Zhong-Yi Zhang","Qing-Hao Meng"],"pdf_url":"https://arxiv.org/pdf/2411.08521v1.pdf","comment":"21pages, 7 figures"},{"id":"http://arxiv.org/abs/2409.15166v2","updated":"2024-11-13T11:05:04Z","published":"2024-09-23T16:20:21Z","title":"Harmonic Path Integral Diffusion","summary":"  In this manuscript, we present a novel approach for sampling from a\ncontinuous multivariate probability distribution, which may either be\nexplicitly known (up to a normalization factor) or represented via empirical\nsamples. Our method constructs a time-dependent bridge from a delta function\ncentered at the origin of the state space at $t=0$, optimally transforming it\ninto the target distribution at $t=1$. We formulate this as a Stochastic\nOptimal Control problem of the Path Integral Control type, with a cost function\ncomprising (in its basic form) a quadratic control term, a quadratic state\nterm, and a terminal constraint. This framework, which we refer to as Harmonic\nPath Integral Diffusion (H-PID), leverages an analytical solution through a\nmapping to an auxiliary quantum harmonic oscillator in imaginary time.\n  The H-PID framework results in a set of efficient sampling algorithms,\nwithout the incorporation of Neural Networks. The algorithms are validated on\ntwo standard use cases: a mixture of Gaussians over a grid and images from\nCIFAR-10. The transparency of the method allows us to analyze the algorithms in\ndetail, particularly revealing that the current weighted state is an order\nparameter for the dynamic phase transition, signaling earlier, at $t<1$, that\nthe sample generation process is almost complete. We contrast these algorithms\nwith other sampling methods, particularly simulated annealing and path integral\nsampling, highlighting their advantages in terms of analytical control,\naccuracy, and computational efficiency on benchmark problems.\n  Additionally, we extend the methodology to more general cases where the\nunderlying stochastic differential equation includes an external deterministic,\npossibly non-conservative force, and where the cost function incorporates a\ngauge potential term.\n","authors":["Hamidreza Behjoo","Michael Chertkov"],"pdf_url":"https://arxiv.org/pdf/2409.15166v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08506v1","updated":"2024-11-13T10:43:31Z","published":"2024-11-13T10:43:31Z","title":"An Information Theoretic Approach to Operationalize Right to Data\n  Protection","summary":"  The widespread practice of indiscriminate data scraping to fine-tune language\nmodels (LMs) raises significant legal and ethical concerns, particularly\nregarding compliance with data protection laws such as the General Data\nProtection Regulation (GDPR). This practice often results in the unauthorized\nuse of personal information, prompting growing debate within the academic and\nregulatory communities. Recent works have introduced the concept of generating\nunlearnable datasets (by adding imperceptible noise to the clean data), such\nthat the underlying model achieves lower loss during training but fails to\ngeneralize to the unseen test setting. Though somewhat effective, these\napproaches are predominantly designed for images and are limited by several\npractical constraints like requiring knowledge of the target model. To this\nend, we introduce RegText, a framework that injects imperceptible spurious\ncorrelations into natural language datasets, effectively rendering them\nunlearnable without affecting semantic content. We demonstrate RegText's\nutility through rigorous empirical analysis of small and large LMs. Notably,\nRegText can restrict newer models like GPT-4o and Llama from learning on our\ngenerated data, resulting in a drop in their test accuracy compared to their\nzero-shot performance and paving the way for generating unlearnable text to\nprotect public data.\n","authors":["Abhinav Java","Simra Shahid","Chirag Agarwal"],"pdf_url":"https://arxiv.org/pdf/2411.08506v1.pdf","comment":"First two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2301.10369v4","updated":"2024-11-13T10:35:25Z","published":"2023-01-25T00:50:28Z","title":"Exact Fractional Inference via Re-Parametrization & Interpolation\n  between Tree-Re-Weighted- and Belief Propagation- Algorithms","summary":"  Computing the partition function, $Z$, of an Ising model over a graph of $N$\n\\enquote{spins} is most likely exponential in $N$. Efficient variational\nmethods, such as Belief Propagation (BP) and Tree Re-Weighted (TRW) algorithms,\ncompute $Z$ approximately by minimizing the respective (BP- or TRW-) free\nenergy. We generalize the variational scheme by building a $\\lambda$-fractional\ninterpolation, $Z^{(\\lambda)}$, where $\\lambda=0$ and $\\lambda=1$ correspond to\nTRW- and BP-approximations, respectively. This fractional scheme -- coined\nFractional Belief Propagation (FBP) -- guarantees that in the attractive\n(ferromagnetic) case $Z^{(TRW)} \\geq Z^{(\\lambda)} \\geq Z^{(BP)}$, and there\nexists a unique (\\enquote{exact}) $\\lambda_*$ such that $Z=Z^{(\\lambda_*)}$.\nGeneralizing the re-parametrization approach of\n\\citep{wainwright_tree-based_2002} and the loop series approach of\n\\citep{chertkov_loop_2006}, we show how to express $Z$ as a product, $\\forall\n\\lambda:\\ Z=Z^{(\\lambda)}{\\tilde Z}^{(\\lambda)}$, where the multiplicative\ncorrection, ${\\tilde Z}^{(\\lambda)}$, is an expectation over a node-independent\nprobability distribution built from node-wise fractional marginals. Our\ntheoretical analysis is complemented by extensive experiments with models from\nIsing ensembles over planar and random graphs of medium and large sizes. Our\nempirical study yields a number of interesting observations, such as the\nability to estimate ${\\tilde Z}^{(\\lambda)}$ with $O(N^{2::4})$ fractional\nsamples and suppression of variation in $\\lambda_*$ estimates with an increase\nin $N$ for instances from a particular random Ising ensemble, where $[2::4]$\nindicates a range from $2$ to $4$. We also discuss the applicability of this\napproach to the problem of image de-noising.\n","authors":["Hamidreza Behjoo","Michael Chertkov"],"pdf_url":"https://arxiv.org/pdf/2301.10369v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06058v3","updated":"2024-11-13T10:09:25Z","published":"2023-03-10T16:43:48Z","title":"A General Recipe for the Analysis of Randomized Multi-Armed Bandit\n  Algorithms","summary":"  In this paper we propose a general methodology to derive regret bounds for\nrandomized multi-armed bandit algorithms. It consists in checking a set of\nsufficient conditions on the sampling probability of each arm and on the family\nof distributions to prove a logarithmic regret. As a direct application we\nrevisit two famous bandit algorithms, Minimum Empirical Divergence (MED) and\nThompson Sampling (TS), under various models for the distributions including\nsingle parameter exponential families, Gaussian distributions, bounded\ndistributions, or distributions satisfying some conditions on their moments. In\nparticular, we prove that MED is asymptotically optimal for all these models,\nbut also provide a simple regret analysis of some TS algorithms for which the\noptimality is already known. We then further illustrate the interest of our\napproach, by analyzing a new Non-Parametric TS algorithm (h-NPTS), adapted to\nsome families of unbounded reward distributions with a bounded h-moment. This\nmodel can for instance capture some non-parametric families of distributions\nwhose variance is upper bounded by a known constant.\n","authors":["Dorian Baudry","Kazuya Suzuki","Junya Honda"],"pdf_url":"https://arxiv.org/pdf/2303.06058v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14487v3","updated":"2024-11-13T10:09:23Z","published":"2024-08-19T18:47:07Z","title":"Active learning of digenic functions with boolean matrix logic\n  programming","summary":"  We apply logic-based machine learning techniques to facilitate cellular\nengineering and drive biological discovery, based on comprehensive databases of\nmetabolic processes called genome-scale metabolic network models (GEMs).\nPredicted host behaviours are not always correctly described by GEMs. Learning\nthe intricate genetic interactions within GEMs presents computational and\nempirical challenges. To address these, we describe a novel approach called\nBoolean Matrix Logic Programming (BMLP) by leveraging boolean matrices to\nevaluate large logic programs. We introduce a new system, $BMLP_{active}$,\nwhich efficiently explores the genomic hypothesis space by guiding informative\nexperimentation through active learning. In contrast to sub-symbolic methods,\n$BMLP_{active}$ encodes a state-of-the-art GEM of a widely accepted bacterial\nhost in an interpretable and logical representation using datalog logic\nprograms. Notably, $BMLP_{active}$ can successfully learn the interaction\nbetween a gene pair with fewer training examples than random experimentation,\novercoming the increase in experimental design space. $BMLP_{active}$ enables\nrapid optimisation of metabolic models and offers a realistic approach to a\nself-driving lab for microbial engineering.\n","authors":["Lun Ai","Stephen H. Muggleton","Shi-shun Liang","Geoff S. Baldwin"],"pdf_url":"https://arxiv.org/pdf/2408.14487v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2405.06724"},{"id":"http://arxiv.org/abs/2410.17851v2","updated":"2024-11-13T10:01:38Z","published":"2024-10-23T13:20:42Z","title":"The Probabilistic Tsetlin Machine: A Novel Approach to Uncertainty\n  Quantification","summary":"  Tsetlin Machines (TMs) have emerged as a compelling alternative to\nconventional deep learning methods, offering notable advantages such as smaller\nmemory footprint, faster inference, fault-tolerant properties, and\ninterpretability. Although various adaptations of TMs have expanded their\napplicability across diverse domains, a fundamental gap remains in\nunderstanding how TMs quantify uncertainty in their predictions. In response,\nthis paper introduces the Probabilistic Tsetlin Machine (PTM) framework, aimed\nat providing a robust, reliable, and interpretable approach for uncertainty\nquantification. Unlike the original TM, the PTM learns the probability of\nstaying on each state of each Tsetlin Automaton (TA) across all clauses. These\nprobabilities are updated using the feedback tables that are part of the TM\nframework: Type I and Type II feedback. During inference, TAs decide their\nactions by sampling states based on learned probability distributions, akin to\nBayesian neural networks when generating weight values. In our experimental\nanalysis, we first illustrate the spread of the probabilities across TA states\nfor the noisy-XOR dataset. Then we evaluate the PTM alongside benchmark models\nusing both simulated and real-world datasets. The experiments on the simulated\ndataset reveal the PTM's effectiveness in uncertainty quantification,\nparticularly in delineating decision boundaries and identifying regions of high\nuncertainty. Moreover, when applied to multiclass classification tasks using\nthe Iris dataset, the PTM demonstrates competitive performance in terms of\npredictive entropy and expected calibration error, showcasing its potential as\na reliable tool for uncertainty estimation. Our findings underscore the\nimportance of selecting appropriate models for accurate uncertainty\nquantification in predictive tasks, with the PTM offering a particularly\ninterpretable and effective solution.\n","authors":["K. Darshana Abeyrathna","Sara El Mekkaoui","Andreas Hafver","Christian Agrell"],"pdf_url":"https://arxiv.org/pdf/2410.17851v2.pdf","comment":"12 pages, 5 figures, 6 tables, accepted and presented at ICAAI 2024,\n  London"},{"id":"http://arxiv.org/abs/2411.08482v1","updated":"2024-11-13T10:01:33Z","published":"2024-11-13T10:01:33Z","title":"Methodology for a Statistical Analysis of Influencing Factors on 3D\n  Object Detection Performance","summary":"  In autonomous driving, object detection is an essential task to perceive the\nenvironment by localizing and classifying objects. Most object detection\nalgorithms rely on deep learning for their superior performance. However, their\nblack box nature makes it challenging to ensure safety. In this paper, we\npropose a first-of-its-kind methodology for statistical analysis of the\ninfluence of various factors related to the objects to detect or the\nenvironment on the detection performance of both LiDAR- and camera-based 3D\nobject detectors. We perform a univariate analysis between each of the factors\nand the detection error in order to compare the strength of influence. To\nbetter identify potential sources of detection errors, we also analyze the\nperformance in dependency of the influencing factors and examine the\ninterdependencies between the different influencing factors. Recognizing the\nfactors that influence detection performance helps identify robustness issues\nin the trained object detector and supports the safety approval of object\ndetection systems.\n","authors":["Anton Kuznietsov","Dirk Schweickard","Steven Peters"],"pdf_url":"https://arxiv.org/pdf/2411.08482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08478v1","updated":"2024-11-13T09:55:59Z","published":"2024-11-13T09:55:59Z","title":"Learning Model Agnostic Explanations via Constraint Programming","summary":"  Interpretable Machine Learning faces a recurring challenge of explaining the\npredictions made by opaque classifiers such as ensemble models, kernel methods,\nor neural networks in terms that are understandable to humans. When the model\nis viewed as a black box, the objective is to identify a small set of features\nthat jointly determine the black box response with minimal error. However,\nfinding such model-agnostic explanations is computationally demanding, as the\nproblem is intractable even for binary classifiers. In this paper, the task is\nframed as a Constraint Optimization Problem, where the constraint solver seeks\nan explanation of minimum error and bounded size for an input data instance and\na set of samples generated by the black box. From a theoretical perspective,\nthis constraint programming approach offers PAC-style guarantees for the output\nexplanation. We evaluate the approach empirically on various datasets and show\nthat it statistically outperforms the state-of-the-art heuristic Anchors\nmethod.\n","authors":["Frederic Koriche","Jean-Marie Lagniez","Stefan Mengel","Chi Tran"],"pdf_url":"https://arxiv.org/pdf/2411.08478v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07979v2","updated":"2024-11-13T09:52:45Z","published":"2024-11-12T17:58:40Z","title":"Exact, Tractable Gauss-Newton Optimization in Deep Reversible\n  Architectures Reveal Poor Generalization","summary":"  Second-order optimization has been shown to accelerate the training of deep\nneural networks in many applications, often yielding faster progress per\niteration on the training loss compared to first-order optimizers. However, the\ngeneralization properties of second-order methods are still being debated.\nTheoretical investigations have proved difficult to carry out outside the\ntractable settings of heavily simplified model classes -- thus, the relevance\nof existing theories to practical deep learning applications remains unclear.\nSimilarly, empirical studies in large-scale models and real datasets are\nsignificantly confounded by the necessity to approximate second-order updates\nin practice. It is often unclear whether the observed generalization behaviour\narises specifically from the second-order nature of the parameter updates, or\ninstead reflects the specific structured (e.g.\\ Kronecker) approximations used\nor any damping-based interpolation towards first-order updates. Here, we show\nfor the first time that exact Gauss-Newton (GN) updates take on a tractable\nform in a class of deep reversible architectures that are sufficiently\nexpressive to be meaningfully applied to common benchmark datasets. We exploit\nthis novel setting to study the training and generalization properties of the\nGN optimizer. We find that exact GN generalizes poorly. In the mini-batch\ntraining setting, this manifests as rapidly saturating progress even on the\n\\emph{training} loss, with parameter updates found to overfit each\nmini-batchatch without producing the features that would support generalization\nto other mini-batches. We show that our experiments run in the ``lazy'' regime,\nin which the neural tangent kernel (NTK) changes very little during the course\nof training. This behaviour is associated with having no significant changes in\nneural representations, explaining the lack of generalization.\n","authors":["Davide Buffelli","Jamie McGowan","Wangkun Xu","Alexandru Cioba","Da-shan Shiu","Guillaume Hennequin","Alberto Bernacchia"],"pdf_url":"https://arxiv.org/pdf/2411.07979v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.17804v3","updated":"2024-11-13T09:50:48Z","published":"2024-06-22T15:24:33Z","title":"A Review of Electromagnetic Elimination Methods for low-field portable\n  MRI scanner","summary":"  This paper analyzes conventional and deep learning methods for eliminating\nelectromagnetic interference (EMI) in MRI systems. We compare traditional\nanalytical and adaptive techniques with advanced deep learning approaches. Key\nstrengths and limitations of each method are highlighted. Recent advancements\nin active EMI elimination, such as external EMI receiver coils, are discussed\nalongside deep learning methods, which show superior EMI suppression by\nleveraging neural networks trained on MRI data. While deep learning improves\nEMI elimination and diagnostic capabilities, it introduces security and safety\nconcerns, particularly in commercial applications. A balanced approach,\nintegrating conventional reliability with deep learning's advanced\ncapabilities, is proposed for more effective EMI suppression in MRI systems.\n","authors":["Wanyu Bian","Panfeng Li","Mengyao Zheng","Chihang Wang","Anying Li","Ying Li","Haowei Ni","Zixuan Zeng"],"pdf_url":"https://arxiv.org/pdf/2406.17804v3.pdf","comment":"Accepted by 2024 5th International Conference on Machine Learning and\n  Computer Application"},{"id":"http://arxiv.org/abs/2304.08310v2","updated":"2024-11-13T09:47:41Z","published":"2023-04-17T14:27:19Z","title":"TreeC: a method to generate interpretable energy management systems\n  using a metaheuristic algorithm","summary":"  Energy management systems (EMS) have traditionally been implemented using\nrule-based control (RBC) and model predictive control (MPC) methods. However,\nrecent research has explored the use of reinforcement learning (RL) as a\npromising alternative. This paper introduces TreeC, a machine learning method\nthat utilizes the covariance matrix adaptation evolution strategy metaheuristic\nalgorithm to generate an interpretable EMS modeled as a decision tree. Unlike\nRBC and MPC approaches, TreeC learns the decision strategy of the EMS based on\nhistorical data, adapting the control model to the controlled energy grid. The\ndecision strategy is represented as a decision tree, providing interpretability\ncompared to RL methods that often rely on black-box models like neural\nnetworks. TreeC is evaluated against MPC with perfect forecast and RL EMSs in\ntwo case studies taken from literature: an electric grid case and a household\nheating case. In the electric grid case, TreeC achieves an average energy loss\nand constraint violation score of 19.2, which is close to MPC and RL EMSs that\nachieve scores of 14.4 and 16.2 respectively. All three methods control the\nelectric grid well especially when compared to the random EMS, which obtains an\naverage score of 12 875. In the household heating case, TreeC performs\nsimilarly to MPC on the adjusted and averaged electricity cost and total\ndiscomfort (0.033 EUR/m$^2$ and 0.42 Kh for TreeC compared to 0.037 EUR/m$^2$\nand 2.91 kH for MPC), while outperforming RL (0.266 EUR/m$^2$ and 24.41 Kh).\n","authors":["Julian Ruddick","Luis Ramirez Camargo","Muhammad Andy Putratama","Maarten Messagie","Thierry Coosemans"],"pdf_url":"https://arxiv.org/pdf/2304.08310v2.pdf","comment":"Accepted version Knowledge based system"},{"id":"http://arxiv.org/abs/2411.08460v1","updated":"2024-11-13T09:31:06Z","published":"2024-11-13T09:31:06Z","title":"Trap-MID: Trapdoor-based Defense against Model Inversion Attacks","summary":"  Model Inversion (MI) attacks pose a significant threat to the privacy of Deep\nNeural Networks by recovering training data distribution from well-trained\nmodels. While existing defenses often rely on regularization techniques to\nreduce information leakage, they remain vulnerable to recent attacks. In this\npaper, we propose the Trapdoor-based Model Inversion Defense (Trap-MID) to\nmislead MI attacks. A trapdoor is integrated into the model to predict a\nspecific label when the input is injected with the corresponding trigger.\nConsequently, this trapdoor information serves as the \"shortcut\" for MI\nattacks, leading them to extract trapdoor triggers rather than private data. We\nprovide theoretical insights into the impacts of trapdoor's effectiveness and\nnaturalness on deceiving MI attacks. In addition, empirical experiments\ndemonstrate the state-of-the-art defense performance of Trap-MID against\nvarious MI attacks without the requirements for extra data or large\ncomputational overhead. Our source code is publicly available at\nhttps://github.com/ntuaislab/Trap-MID.\n","authors":["Zhen-Ting Liu","Shang-Tse Chen"],"pdf_url":"https://arxiv.org/pdf/2411.08460v1.pdf","comment":"Accepted by Neural Information Processing Systems (NeurIPS) 2024"},{"id":"http://arxiv.org/abs/2307.12594v2","updated":"2024-11-13T09:29:36Z","published":"2023-07-24T08:11:59Z","title":"The effect of dataset size and the process of big data mining for\n  investigating solar-thermal desalination by using machine learning","summary":"  Machine learning's application in solar-thermal desalination is limited by\ndata shortage and inconsistent analysis. This study develops an optimized\ndataset collection and analysis process for the representative solar still. By\nultra-hydrophilic treatment on the condensation cover, the dataset collection\nprocess reduces the collection time by 83.3%. Over 1,000 datasets are\ncollected, which is nearly one order of magnitude larger than up-to-date works.\nThen, a new interdisciplinary process flow is proposed. Some meaningful results\nare obtained that were not addressed by previous studies. It is found that\nRadom Forest might be a better choice for datasets larger than 1,000 due to\nboth high accuracy and fast speed. Besides, the dataset range affects the\nquantified importance (weighted value) of factors significantly, with up to a\n115% increment. Moreover, the results show that machine learning has a high\naccuracy on the extrapolation prediction of productivity, where the minimum\nmean relative prediction error is just around 4%. The results of this work not\nonly show the necessity of the dataset characteristics' effect but also provide\na standard process for studying solar-thermal desalination by machine learning,\nwhich would pave the way for interdisciplinary study.\n","authors":["Guilong Peng","Senshan Sun","Zhenwei Xu","Juxin Du","Yangjun Qin","Swellam W. Sharshir","A. W. Kandel","A. E. Kabeel","Nuo Yang"],"pdf_url":"https://arxiv.org/pdf/2307.12594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00393v4","updated":"2024-11-13T09:27:41Z","published":"2024-11-01T06:40:47Z","title":"Advantages of Neural Population Coding for Deep Learning","summary":"  Scalar variables, e.g., the orientation of a shape in an image, are commonly\npredicted using a single output neuron in a neural network. In contrast, the\nmammalian cortex represents variables with a population of neurons. In this\npopulation code, each neuron is most active at its preferred value and shows\npartial activity for other values. Here, we investigate the benefit of using a\npopulation code for the output layer of a neural network. We compare population\ncodes against single-neuron outputs and one-hot vectors. First, we show\ntheoretically and in experiments with synthetic data that population codes\nimprove robustness to input noise in networks of stacked linear layers. Second,\nwe demonstrate the benefit of using population codes to encode ambiguous\noutputs, such as the pose of symmetric objects. Using the T-LESS dataset of\nfeature-less real-world objects, we show that population codes improve the\naccuracy of predicting 3D object orientation from image input.\n","authors":["Heiko Hoffmann"],"pdf_url":"https://arxiv.org/pdf/2411.00393v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08443v1","updated":"2024-11-13T08:56:35Z","published":"2024-11-13T08:56:35Z","title":"Machine Unlearning on Pre-trained Models by Residual Feature Alignment\n  Using LoRA","summary":"  Machine unlearning is new emerged technology that removes a subset of the\ntraining data from a trained model without affecting the model performance on\nthe remaining data. This topic is becoming increasingly important in protecting\nuser privacy and eliminating harmful or outdated data. The key challenge lies\nin effectively and efficiently unlearning specific information without\ncompromising the model's utility on the retained data. For the pre-trained\nmodels, fine-tuning is an important way to achieve the unlearning target.\nPrevious work typically fine-tuned the entire model's parameters, which incurs\nsignificant computation costs. In addition, the fine-tuning process may cause\nshifts in the intermediate layer features, affecting the model's overall\nutility. In this work, we propose a novel and efficient machine unlearning\nmethod on pre-trained models. We term the method as Residual Feature Alignment\nUnlearning. Specifically, we leverage LoRA (Low-Rank Adaptation) to decompose\nthe model's intermediate features into pre-trained features and residual\nfeatures. By adjusting the residual features, we align the unlearned model with\nthe pre-trained model at the intermediate feature level to achieve both\nunlearning and remaining targets. The method aims to learn the zero residuals\non the retained set and shifted residuals on the unlearning set. Extensive\nexperiments on numerous datasets validate the effectiveness of our approach.\n","authors":["Laiqiao Qin","Tianqing Zhu","Linlin Wang","Wanlei Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.08443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06979v2","updated":"2024-11-13T08:41:50Z","published":"2024-06-11T06:18:29Z","title":"AudioMarkBench: Benchmarking Robustness of Audio Watermarking","summary":"  The increasing realism of synthetic speech, driven by advancements in\ntext-to-speech models, raises ethical concerns regarding impersonation and\ndisinformation. Audio watermarking offers a promising solution via embedding\nhuman-imperceptible watermarks into AI-generated audios. However, the\nrobustness of audio watermarking against common/adversarial perturbations\nremains understudied. We present AudioMarkBench, the first systematic benchmark\nfor evaluating the robustness of audio watermarking against watermark removal\nand watermark forgery. AudioMarkBench includes a new dataset created from\nCommon-Voice across languages, biological sexes, and ages, 3 state-of-the-art\nwatermarking methods, and 15 types of perturbations. We benchmark the\nrobustness of these methods against the perturbations in no-box, black-box, and\nwhite-box settings. Our findings highlight the vulnerabilities of current\nwatermarking techniques and emphasize the need for more robust and fair audio\nwatermarking solutions. Our dataset and code are publicly available at\nhttps://github.com/moyangkuo/AudioMarkBench.\n","authors":["Hongbin Liu","Moyang Guo","Zhengyuan Jiang","Lun Wang","Neil Zhenqiang Gong"],"pdf_url":"https://arxiv.org/pdf/2406.06979v2.pdf","comment":"To appear in NeurIPS Datasets and Benchmarks, 2024"},{"id":"http://arxiv.org/abs/2410.21283v2","updated":"2024-11-13T08:33:17Z","published":"2024-10-11T03:19:44Z","title":"pLDDT-Predictor: High-speed Protein Screening Using Transformer and ESM2","summary":"  Recent advancements in protein structure prediction, particularly AlphaFold2,\nhave revolutionized structural biology by achieving near-experimental accuracy\n($\\text{average RMSD} < 1.5\\text{\\AA}$). However, the computational demands of\nthese models (approximately 30 minutes per protein on an RTX 4090)\nsignificantly limit their application in high-throughput protein screening.\nWhile large language models like ESM (Evolutionary Scale Modeling) have shown\npromise in extracting structural information directly from protein sequences,\nrapid assessment of protein structure quality for large-scale analyses remains\na major challenge.\n  We introduce pLDDT-Predictor, a high-speed protein screening tool that\nachieves a $250,000\\times$ speedup compared to AlphaFold2 by leveraging\npre-trained ESM2 protein embeddings and a Transformer architecture. Our model\npredicts AlphaFold2's pLDDT (predicted Local Distance Difference Test) scores\nwith a Pearson correlation of 0.7891 and processes proteins in just 0.007\nseconds on average. Using a comprehensive dataset of 1.5 million diverse\nprotein sequences (ranging from 50 to 2048 amino acids), we demonstrate that\npLDDT-Predictor accurately classifies high-confidence structures (pLDDT $>$ 70)\nwith 91.2\\% accuracy and achieves an MSE of 84.8142 compared to AlphaFold2's\npredictions.\n  The source code and pre-trained models are freely available at\n\\url{https://github.com/jw-chae/pLDDT_Predictor}, enabling the research\ncommunity to perform rapid, large-scale protein structure quality assessments.\n","authors":["Joongwon Chae","Zhenyu Wang","Ijaz Gul","Jiansong Ji","Zhenglin Chen","Peiwu Qin"],"pdf_url":"https://arxiv.org/pdf/2410.21283v2.pdf","comment":"6 pages main topic, 8 pages including citiation, 4 figures"},{"id":"http://arxiv.org/abs/2411.08432v1","updated":"2024-11-13T08:32:42Z","published":"2024-11-13T08:32:42Z","title":"One STEP at a time: Language Agents are Stepwise Planners","summary":"  Language agents have shown promising adaptability in dynamic environments to\nperform complex tasks. However, despite the versatile knowledge embedded in\nlarge language models, these agents still fall short when it comes to tasks\nthat require planning. We introduce STEP, a novel framework designed to\nefficiently learn from previous experiences to enhance the planning\ncapabilities of language agents in future steps. Concretely, STEP functions\nthrough four interconnected components. First, the Planner takes on the task,\nbreaks it down into subtasks and provides relevant insights. Then the Executor\ngenerates action candidates, while the Evaluator ensures the actions align with\nlearned rules from previous experiences. Lastly, Memory stores experiences to\ninform future decisions. In the ScienceWorld benchmark, our results show that\nSTEP consistently outperforms state-of-the-art models, achieving an overall\nscore of 67.4 and successfully completing 12 out of 18 tasks. These findings\nhighlight STEP's potential as a framework for enhancing planning capabilities\nin language agents, paving the way for more sophisticated task-solving in\ndynamic environments.\n","authors":["Minh Nguyen","Ehsan Shareghi"],"pdf_url":"https://arxiv.org/pdf/2411.08432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03364v2","updated":"2024-11-13T08:30:59Z","published":"2024-11-05T06:54:38Z","title":"DM4Steal: Diffusion Model For Link Stealing Attack On Graph Neural\n  Networks","summary":"  Graph has become increasingly integral to the advancement of recommendation\nsystems, particularly with the fast development of graph neural network(GNN).\nBy exploring the virtue of rich node features and link information, GNN is\ndesigned to provide personalized and accurate suggestions. Meanwhile, the\nprivacy leakage of GNN in such contexts has also captured special attention.\nPrior work has revealed that a malicious user can utilize auxiliary knowledge\nto extract sensitive link data of the target graph, integral to recommendation\nsystems, via the decision made by the target GNN model. This poses a\nsignificant risk to the integrity and confidentiality of data used in\nrecommendation system. Though important, previous works on GNN's privacy\nleakage are still challenged in three aspects, i.e., limited stealing attack\nscenarios, sub-optimal attack performance, and adaptation against defense. To\naddress these issues, we propose a diffusion model based link stealing attack,\nnamed DM4Steal. It differs previous work from three critical aspects. (i)\nGenerality: aiming at six attack scenarios with limited auxiliary knowledge, we\npropose a novel training strategy for diffusion models so that DM4Steal is\ntransferable to diverse attack scenarios. (ii) Effectiveness: benefiting from\nthe retention of semantic structure in the diffusion model during the training\nprocess, DM4Steal is capable to learn the precise topology of the target graph\nthrough the GNN decision process. (iii) Adaptation: when GNN is defensive\n(e.g., DP, Dropout), DM4Steal relies on the stability that comes from sampling\nthe score model multiple times to keep performance degradation to a minimum,\nthus DM4Steal implements successful adaptive attack on defensive GNN.\n","authors":["Jinyin Chen","Haonan Ma","Haibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2411.03364v2.pdf","comment":"We found that there were critical problems in our paper, and we\n  needed to redo the experiment, which was incomplete"},{"id":"http://arxiv.org/abs/2411.07501v2","updated":"2024-11-13T08:30:52Z","published":"2024-11-12T02:57:15Z","title":"LAuReL: Learned Augmented Residual Layer","summary":"  One of the core pillars of efficient deep learning methods is architectural\nimprovements such as the residual/skip connection, which has led to\nsignificantly better model convergence and quality. Since then the residual\nconnection has become ubiquitous in not just convolutional neural networks but\nalso transformer-based architectures, the backbone of LLMs.\n  In this paper we introduce \\emph{Learned Augmented Residual Layer} (LAuReL)\n-- a novel generalization of the canonical residual connection -- with the goal\nto be an in-situ replacement of the latter while outperforming on both model\nquality and footprint metrics. Our experiments show that using \\laurel can help\nboost performance for both vision and language models. For example, on the\nResNet-50, ImageNet 1K task, it achieves $60\\%$ of the gains from adding an\nextra layer, while only adding $0.003\\%$ more parameters, and matches it while\nadding $2.6\\times$ fewer parameters.\n","authors":["Gaurav Menghani","Ravi Kumar","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.07501v2.pdf","comment":"Accepted at the 2nd Efficient Systems for Foundation Models Workshop\n  at the International Conference on Machine Learning (ICML) 2024"},{"id":"http://arxiv.org/abs/2411.01137v2","updated":"2024-11-13T08:24:09Z","published":"2024-11-02T04:48:41Z","title":"Data movement limits to frontier model training","summary":"  We present a theoretical model of distributed training, and use it to analyze\nhow far dense and sparse training runs can be scaled. Under our baseline\nassumptions, given a three month training duration, data movement bottlenecks\nbegin to significantly lower hardware utilization for training runs exceeding\nabout $10^{28}$ FLOP, two orders of magnitude above the largest training run to\ndate, suggesting the arrival of fundamental barriers to scaling in three years\ngiven recent rates of growth. A training run exceeding about $10^{31}$ FLOP is\ninfeasible even at low utilization. However, more aggressive batch size scaling\nand/or shorter and fatter model shapes, if achievable, have the potential to\npermit much larger training runs.\n","authors":["Ege Erdil","David Schneider-Joseph"],"pdf_url":"https://arxiv.org/pdf/2411.01137v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08425v1","updated":"2024-11-13T08:18:03Z","published":"2024-11-13T08:18:03Z","title":"Properties of fairness measures in the context of varying class\n  imbalance and protected group ratios","summary":"  Society is increasingly relying on predictive models in fields like criminal\njustice, credit risk management, or hiring. To prevent such automated systems\nfrom discriminating against people belonging to certain groups, fairness\nmeasures have become a crucial component in socially relevant applications of\nmachine learning. However, existing fairness measures have been designed to\nassess the bias between predictions for protected groups without considering\nthe imbalance in the classes of the target variable. Current research on the\npotential effect of class imbalance on fairness focuses on practical\napplications rather than dataset-independent measure properties. In this paper,\nwe study the general properties of fairness measures for changing class and\nprotected group proportions. For this purpose, we analyze the probability mass\nfunctions of six of the most popular group fairness measures. We also measure\nhow the probability of achieving perfect fairness changes for varying class\nimbalance ratios. Moreover, we relate the dataset-independent properties of\nfairness measures described in this paper to classifier fairness in real-life\ntasks. Our results show that measures such as Equal Opportunity and Positive\nPredictive Parity are more sensitive to changes in class imbalance than\nAccuracy Equality. These findings can help guide researchers and practitioners\nin choosing the most appropriate fairness measures for their classification\nproblems.\n","authors":["Dariusz Brzezinski","Julia Stachowiak","Jerzy Stefanowski","Izabela Szczech","Robert Susmaga","Sofya Aksenyuk","Uladzimir Ivashka","Oleksandr Yasinskyi"],"pdf_url":"https://arxiv.org/pdf/2411.08425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15586v2","updated":"2024-11-13T08:17:38Z","published":"2024-05-24T14:14:24Z","title":"DAGER: Exact Gradient Inversion for Large Language Models","summary":"  Federated learning works by aggregating locally computed gradients from\nmultiple clients, thus enabling collaborative training without sharing private\nclient data. However, prior work has shown that the data can actually be\nrecovered by the server using so-called gradient inversion attacks. While these\nattacks perform well when applied on images, they are limited in the text\ndomain and only permit approximate reconstruction of small batches and short\ninput sequences. In this work, we propose DAGER, the first algorithm to recover\nwhole batches of input text exactly. DAGER leverages the low-rank structure of\nself-attention layer gradients and the discrete nature of token embeddings to\nefficiently check if a given token sequence is part of the client data. We use\nthis check to exactly recover full batches in the honest-but-curious setting\nwithout any prior on the data for both encoder- and decoder-based architectures\nusing exhaustive heuristic search and a greedy approach, respectively. We\nprovide an efficient GPU implementation of DAGER and show experimentally that\nit recovers full batches of size up to 128 on large language models (LLMs),\nbeating prior attacks in speed (20x at same batch size), scalability (10x\nlarger batches), and reconstruction quality (ROUGE-1/2 > 0.99).\n","authors":["Ivo Petrov","Dimitar I. Dimitrov","Maximilian Baader","Mark Niklas Müller","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2405.15586v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.21063v2","updated":"2024-11-13T08:13:36Z","published":"2024-05-31T17:51:07Z","title":"Neural Network Verification with Branch-and-Bound for General\n  Nonlinearities","summary":"  Branch-and-bound (BaB) is among the most effective techniques for neural\nnetwork (NN) verification. However, existing works on BaB for NN verification\nhave mostly focused on NNs with piecewise linear activations, especially ReLU\nnetworks. In this paper, we develop a general framework, named GenBaB, to\nconduct BaB on general nonlinearities to verify NNs with general architectures,\nbased on linear bound propagation for NN verification. To decide which neuron\nto branch, we design a new branching heuristic which leverages linear bounds as\nshortcuts to efficiently estimate the potential improvement after branching. To\ndecide nontrivial branching points for general nonlinear functions, we propose\nto pre-optimize branching points, which can be efficiently leveraged during\nverification with a lookup table. We demonstrate the effectiveness of our\nGenBaB on verifying a wide range of NNs, including NNs with activation\nfunctions such as Sigmoid, Tanh, Sine and GeLU, as well as NNs involving\nmulti-dimensional nonlinear operations such as multiplications in LSTMs and\nVision Transformers. Our framework also allows the verification of general\nnonlinear computation graphs and enables verification applications beyond\nsimple NNs, particularly for AC Optimal Power Flow (ACOPF). GenBaB is part of\nthe latest $\\alpha,\\!\\beta$-CROWN, the winner of the 4th and the 5th\nInternational Verification of Neural Networks Competition (VNN-COMP 2023 and\n2024).\n","authors":["Zhouxing Shi","Qirui Jin","Zico Kolter","Suman Jana","Cho-Jui Hsieh","Huan Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.21063v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2411.08414v1","updated":"2024-11-13T08:07:21Z","published":"2024-11-13T08:07:21Z","title":"Material Property Prediction with Element Attribute Knowledge Graphs and\n  Multimodal Representation Learning","summary":"  Machine learning has become a crucial tool for predicting the properties of\ncrystalline materials. However, existing methods primarily represent material\ninformation by constructing multi-edge graphs of crystal structures, often\noverlooking the chemical and physical properties of elements (such as atomic\nradius, electronegativity, melting point, and ionization energy), which have a\nsignificant impact on material performance. To address this limitation, we\nfirst constructed an element property knowledge graph and utilized an embedding\nmodel to encode the element attributes within the knowledge graph. Furthermore,\nwe propose a multimodal fusion framework, ESNet, which integrates element\nproperty features with crystal structure features to generate joint multimodal\nrepresentations. This provides a more comprehensive perspective for predicting\nthe performance of crystalline materials, enabling the model to consider both\nmicrostructural composition and chemical characteristics of the materials. We\nconducted experiments on the Materials Project benchmark dataset, which showed\nleading performance in the bandgap prediction task and achieved results on a\npar with existing benchmarks in the formation energy prediction task.\n","authors":["Chao Huang","Chunyan Chen","Ling Shi","Chen Chen"],"pdf_url":"https://arxiv.org/pdf/2411.08414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08404v1","updated":"2024-11-13T07:45:40Z","published":"2024-11-13T07:45:40Z","title":"Quantifying Qualitative Insights: Leveraging LLMs to Market Predict","summary":"  Recent advancements in Large Language Models (LLMs) have the potential to\ntransform financial analytics by integrating numerical and textual data.\nHowever, challenges such as insufficient context when fusing multimodal\ninformation and the difficulty in measuring the utility of qualitative outputs,\nwhich LLMs generate as text, have limited their effectiveness in tasks such as\nfinancial forecasting. This study addresses these challenges by leveraging\ndaily reports from securities firms to create high-quality contextual\ninformation. The reports are segmented into text-based key factors and combined\nwith numerical data, such as price information, to form context sets. By\ndynamically updating few-shot examples based on the query time, the sets\nincorporate the latest information, forming a highly relevant set closely\naligned with the query point. Additionally, a crafted prompt is designed to\nassign scores to the key factors, converting qualitative insights into\nquantitative results. The derived scores undergo a scaling process,\ntransforming them into real-world values that are used for prediction. Our\nexperiments demonstrate that LLMs outperform time-series models in market\nforecasting, though challenges such as imperfect reproducibility and limited\nexplainability remain.\n","authors":["Hoyoung Lee","Youngsoo Choi","Yuhee Kwon"],"pdf_url":"https://arxiv.org/pdf/2411.08404v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.08397v1","updated":"2024-11-13T07:32:58Z","published":"2024-11-13T07:32:58Z","title":"CLaSP: Learning Concepts for Time-Series Signals from Natural Language\n  Supervision","summary":"  This paper proposes a foundation model called \"CLaSP\" that can search time\nseries signals using natural language that describes the characteristics of the\nsignals as queries. Previous efforts to represent time series signal data in\nnatural language have had challenges in designing a conventional class of time\nseries signal characteristics, formulating their quantification, and creating a\ndictionary of synonyms. To overcome these limitations, the proposed method\nintroduces a neural network based on contrastive learning. This network is\nfirst trained using the datasets TRUCE and SUSHI, which consist of time series\nsignals and their corresponding natural language descriptions. Previous studies\nhave proposed vocabularies that data analysts use to describe signal\ncharacteristics, and SUSHI was designed to cover these terms. We believe that a\nneural network trained on these datasets will enable data analysts to search\nusing natural language vocabulary. Furthermore, our method does not require a\ndictionary of predefined synonyms, and it leverages common sense knowledge\nembedded in a large-scale language model (LLM). Experimental results\ndemonstrate that CLaSP enables natural language search of time series signal\ndata and can accurately learn the points at which signal data changes.\n","authors":["Aoi Ito","Kota Dohi","Yohei Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2411.08397v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08384v1","updated":"2024-11-13T07:10:18Z","published":"2024-11-13T07:10:18Z","title":"Interpretable Syntactic Representations Enable Hierarchical Word Vectors","summary":"  The distributed representations currently used are dense and uninterpretable,\nleading to interpretations that themselves are relative, overcomplete, and hard\nto interpret. We propose a method that transforms these word vectors into\nreduced syntactic representations. The resulting representations are compact\nand interpretable allowing better visualization and comparison of the word\nvectors and we successively demonstrate that the drawn interpretations are in\nline with human judgment. The syntactic representations are then used to create\nhierarchical word vectors using an incremental learning approach similar to the\nhierarchical aspect of human learning. As these representations are drawn from\npre-trained vectors, the generation process and learning approach are\ncomputationally efficient. Most importantly, we find out that syntactic\nrepresentations provide a plausible interpretation of the vectors and\nsubsequent hierarchical vectors outperform the original vectors in benchmark\ntests.\n","authors":["Biraj Silwal"],"pdf_url":"https://arxiv.org/pdf/2411.08384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08378v1","updated":"2024-11-13T07:03:47Z","published":"2024-11-13T07:03:47Z","title":"Physics Informed Distillation for Diffusion Models","summary":"  Diffusion models have recently emerged as a potent tool in generative\nmodeling. However, their inherent iterative nature often results in sluggish\nimage generation due to the requirement for multiple model evaluations. Recent\nprogress has unveiled the intrinsic link between diffusion models and\nProbability Flow Ordinary Differential Equations (ODEs), thus enabling us to\nconceptualize diffusion models as ODE systems. Simultaneously, Physics Informed\nNeural Networks (PINNs) have substantiated their effectiveness in solving\nintricate differential equations through implicit modeling of their solutions.\nBuilding upon these foundational insights, we introduce Physics Informed\nDistillation (PID), which employs a student model to represent the solution of\nthe ODE system corresponding to the teacher diffusion model, akin to the\nprinciples employed in PINNs. Through experiments on CIFAR 10 and ImageNet\n64x64, we observe that PID achieves performance comparable to recent\ndistillation methods. Notably, it demonstrates predictable trends concerning\nmethod-specific hyperparameters and eliminates the need for synthetic dataset\ngeneration during the distillation process. Both of which contribute to its\neasy-to-use nature as a distillation approach for Diffusion Models. Our code\nand pre-trained checkpoint are publicly available at:\nhttps://github.com/pantheon5100/pid_diffusion.git.\n","authors":["Joshua Tian Jin Tee","Kang Zhang","Hee Suk Yoon","Dhananjaya Nagaraja Gowda","Chanwoo Kim","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2411.08378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.02775v4","updated":"2024-11-13T06:57:35Z","published":"2022-01-08T06:18:17Z","title":"ADI: Adversarial Dominating Inputs in Vertical Federated Learning\n  Systems","summary":"  Vertical federated learning (VFL) system has recently become prominent as a\nconcept to process data distributed across many individual sources without the\nneed to centralize it. Multiple participants collaboratively train models based\non their local data in a privacy-aware manner. To date, VFL has become a de\nfacto solution to securely learn a model among organizations, allowing\nknowledge to be shared without compromising privacy of any individuals. Despite\nthe prosperous development of VFL systems, we find that certain inputs of a\nparticipant, named adversarial dominating inputs (ADIs), can dominate the joint\ninference towards the direction of the adversary's will and force other\n(victim) participants to make negligible contributions, losing rewards that are\nusually offered regarding the importance of their contributions in federated\nlearning scenarios. We conduct a systematic study on ADIs by first proving\ntheir existence in typical VFL systems. We then propose gradient-based methods\nto synthesize ADIs of various formats and exploit common VFL systems. We\nfurther launch greybox fuzz testing, guided by the saliency score of ``victim''\nparticipants, to perturb adversary-controlled inputs and systematically explore\nthe VFL attack surface in a privacy-preserving manner. We conduct an in-depth\nstudy on the influence of critical parameters and settings in synthesizing\nADIs. Our study reveals new VFL attack opportunities, promoting the\nidentification of unknown threats before breaches and building more secure VFL\nsystems.\n","authors":["Qi Pang","Yuanyuan Yuan","Shuai Wang","Wenting Zheng"],"pdf_url":"https://arxiv.org/pdf/2201.02775v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08374v1","updated":"2024-11-13T06:54:05Z","published":"2024-11-13T06:54:05Z","title":"Federated Graph Learning with Graphless Clients","summary":"  Federated Graph Learning (FGL) is tasked with training machine learning\nmodels, such as Graph Neural Networks (GNNs), for multiple clients, each with\nits own graph data. Existing methods usually assume that each client has both\nnode features and graph structure of its graph data. In real-world scenarios,\nhowever, there exist federated systems where only a part of the clients have\nsuch data while other clients (i.e. graphless clients) may only have node\nfeatures. This naturally leads to a novel problem in FGL: how to jointly train\na model over distributed graph data with graphless clients? In this paper, we\npropose a novel framework FedGLS to tackle the problem in FGL with graphless\nclients. In FedGLS, we devise a local graph learner on each graphless client\nwhich learns the local graph structure with the structure knowledge transferred\nfrom other clients. To enable structure knowledge transfer, we design a GNN\nmodel and a feature encoder on each client. During local training, the feature\nencoder retains the local graph structure knowledge together with the GNN model\nvia knowledge distillation, and the structure knowledge is transferred among\nclients in global update. Our extensive experiments demonstrate the superiority\nof the proposed FedGLS over five baselines.\n","authors":["Xingbo Fu","Song Wang","Yushun Dong","Binchi Zhang","Chen Chen","Jundong Li"],"pdf_url":"https://arxiv.org/pdf/2411.08374v1.pdf","comment":"Accepted by Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2410.21564v2","updated":"2024-11-13T06:35:53Z","published":"2024-10-28T21:54:44Z","title":"Mitigating Gradient Overlap in Deep Residual Networks with Gradient\n  Normalization for Improved Non-Convex Optimization","summary":"  In deep learning, Residual Networks (ResNets) have proven effective in\naddressing the vanishing gradient problem, allowing for the successful training\nof very deep networks. However, skip connections in ResNets can lead to\ngradient overlap, where gradients from both the learned transformation and the\nskip connection combine, potentially resulting in overestimated gradients. This\noverestimation can cause inefficiencies in optimization, as some updates may\novershoot optimal regions, affecting weight updates. To address this, we\nexamine Z-score Normalization (ZNorm) as a technique to manage gradient\noverlap. ZNorm adjusts the gradient scale, standardizing gradients across\nlayers and reducing the negative impact of overlapping gradients. Our\nexperiments demonstrate that ZNorm improves training process, especially in\nnon-convex optimization scenarios common in deep learning, where finding\noptimal solutions is challenging. These findings suggest that ZNorm can affect\nthe gradient flow, enhancing performance in large-scale data processing where\naccuracy is critical.\n","authors":["Juyoung Yun"],"pdf_url":"https://arxiv.org/pdf/2410.21564v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07934v2","updated":"2024-11-13T06:34:07Z","published":"2024-11-12T17:04:56Z","title":"Doubly Mild Generalization for Offline Reinforcement Learning","summary":"  Offline Reinforcement Learning (RL) suffers from the extrapolation error and\nvalue overestimation. From a generalization perspective, this issue can be\nattributed to the over-generalization of value functions or policies towards\nout-of-distribution (OOD) actions. Significant efforts have been devoted to\nmitigating such generalization, and recent in-sample learning approaches have\nfurther succeeded in entirely eschewing it. Nevertheless, we show that mild\ngeneralization beyond the dataset can be trusted and leveraged to improve\nperformance under certain conditions. To appropriately exploit generalization\nin offline RL, we propose Doubly Mild Generalization (DMG), comprising (i) mild\naction generalization and (ii) mild generalization propagation. The former\nrefers to selecting actions in a close neighborhood of the dataset to maximize\nthe Q values. Even so, the potential erroneous generalization can still be\npropagated, accumulated, and exacerbated by bootstrapping. In light of this,\nthe latter concept is introduced to mitigate the generalization propagation\nwithout impeding the propagation of RL learning signals. Theoretically, DMG\nguarantees better performance than the in-sample optimal policy in the oracle\ngeneralization scenario. Even under worst-case generalization, DMG can still\ncontrol value overestimation at a certain level and lower bound the\nperformance. Empirically, DMG achieves state-of-the-art performance across\nGym-MuJoCo locomotion tasks and challenging AntMaze tasks. Moreover, benefiting\nfrom its flexibility in both generalization aspects, DMG enjoys a seamless\ntransition from offline to online learning and attains strong online\nfine-tuning performance.\n","authors":["Yixiu Mao","Qi Wang","Yun Qu","Yuhang Jiang","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2411.07934v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.08367v1","updated":"2024-11-13T06:32:17Z","published":"2024-11-13T06:32:17Z","title":"Surprisingly Popular Voting for Concentric Rank-Order Models","summary":"  An important problem on social information sites is the recovery of ground\ntruth from individual reports when the experts are in the minority. The wisdom\nof the crowd, i.e. the collective opinion of a group of individuals fails in\nsuch a scenario. However, the surprisingly popular (SP)\nalgorithm~\\cite{prelec2017solution} can recover the ground truth even when the\nexperts are in the minority, by asking the individuals to report additional\nprediction reports--their beliefs about the reports of others. Several recent\nworks have extended the surprisingly popular algorithm to an equivalent voting\nrule (SP-voting) to recover the ground truth ranking over a set of $m$\nalternatives. However, we are yet to fully understand when SP-voting can\nrecover the ground truth ranking, and if so, how many samples (votes and\npredictions) it needs. We answer this question by proposing two rank-order\nmodels and analyzing the sample complexity of SP-voting under these models. In\nparticular, we propose concentric mixtures of Mallows and Plackett-Luce models\nwith $G (\\ge 2)$ groups. Our models generalize previously proposed concentric\nmixtures of Mallows models with $2$ groups, and we highlight the importance of\n$G > 2$ groups by identifying three distinct groups (expert, intermediate, and\nnon-expert) from existing datasets. Next, we provide conditions on the\nparameters of the underlying models so that SP-voting can recover ground-truth\nrankings with high probability, and also derive sample complexities under the\nsame. We complement the theoretical results by evaluating SP-voting on\nsimulated and real datasets.\n","authors":["Hadi Hosseini","Debmalya Mandal","Amrit Puhan"],"pdf_url":"https://arxiv.org/pdf/2411.08367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08360v1","updated":"2024-11-13T06:16:12Z","published":"2024-11-13T06:16:12Z","title":"Coverage Analysis for Digital Cousin Selection -- Improving\n  Multi-Environment Q-Learning","summary":"  Q-learning is widely employed for optimizing various large-dimensional\nnetworks with unknown system dynamics. Recent advancements include\nmulti-environment mixed Q-learning (MEMQ) algorithms, which utilize multiple\nindependent Q-learning algorithms across multiple, structurally related but\ndistinct environments and outperform several state-of-the-art Q-learning\nalgorithms in terms of accuracy, complexity, and robustness. We herein conduct\na comprehensive probabilistic coverage analysis to ensure optimal data coverage\nconditions for MEMQ algorithms. First, we derive upper and lower bounds on the\nexpectation and variance of different coverage coefficients (CC) for MEMQ\nalgorithms. Leveraging these bounds, we develop a simple way of comparing the\nutilities of multiple environments in MEMQ algorithms. This approach appears to\nbe near optimal versus our previously proposed partial ordering approach. We\nalso present a novel CC-based MEMQ algorithm to improve the accuracy and\ncomplexity of existing MEMQ algorithms. Numerical experiments are conducted\nusing random network graphs with four different graph properties. Our algorithm\ncan reduce the average policy error (APE) by 65% compared to partial ordering\nand is 95% faster than the exhaustive search. It also achieves 60% less APE\nthan several state-of-the-art reinforcement learning and prior MEMQ algorithms.\nAdditionally, we numerically verify the theoretical results and show their\nscalability with the action-space size.\n","authors":["Talha Bozkus","Tara Javidi","Urbashi Mitra"],"pdf_url":"https://arxiv.org/pdf/2411.08360v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2409.18696v2","updated":"2024-11-13T06:01:51Z","published":"2024-09-27T12:34:08Z","title":"Rethinking the Power of Timestamps for Robust Time Series Forecasting: A\n  Global-Local Fusion Perspective","summary":"  Time series forecasting has played a pivotal role across various industries,\nincluding finance, transportation, energy, healthcare, and climate. Due to the\nabundant seasonal information they contain, timestamps possess the potential to\noffer robust global guidance for forecasting techniques. However, existing\nworks primarily focus on local observations, with timestamps being treated\nmerely as an optional supplement that remains underutilized. When data gathered\nfrom the real world is polluted, the absence of global information will damage\nthe robust prediction capability of these algorithms. To address these\nproblems, we propose a novel framework named GLAFF. Within this framework, the\ntimestamps are modeled individually to capture the global dependencies. Working\nas a plugin, GLAFF adaptively adjusts the combined weights for global and local\ninformation, enabling seamless collaboration with any time series forecasting\nbackbone. Extensive experiments conducted on nine real-world datasets\ndemonstrate that GLAFF significantly enhances the average performance of widely\nused mainstream forecasting models by 12.5%, surpassing the previous\nstate-of-the-art method by 5.5%.\n","authors":["Chengsen Wang","Qi Qi","Jingyu Wang","Haifeng Sun","Zirui Zhuang","Jinming Wu","Jianxin Liao"],"pdf_url":"https://arxiv.org/pdf/2409.18696v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.08355v1","updated":"2024-11-13T05:59:04Z","published":"2024-11-13T05:59:04Z","title":"Communication Efficient Decentralization for Smoothed Online Convex\n  Optimization","summary":"  We study the multi-agent Smoothed Online Convex Optimization (SOCO) problem,\nwhere $N$ agents interact through a communication graph. In each round, each\nagent $i$ receives a strongly convex hitting cost function $f^i_t$ in an online\nfashion and selects an action $x^i_t \\in \\mathbb{R}^d$. The objective is to\nminimize the global cumulative cost, which includes the sum of individual\nhitting costs $f^i_t(x^i_t)$, a temporal \"switching cost\" for changing\ndecisions, and a spatial \"dissimilarity cost\" that penalizes deviations in\ndecisions among neighboring agents. We propose the first decentralized\nalgorithm for multi-agent SOCO and prove its asymptotic optimality. Our\napproach allows each agent to operate using only local information from its\nimmediate neighbors in the graph. For finite-time performance, we establish\nthat the optimality gap in competitive ratio decreases with the time horizon\n$T$ and can be conveniently tuned based on the per-round computation available\nto each agent. Moreover, our results hold even when the communication graph\nchanges arbitrarily and adaptively over time. Finally, we establish that the\ncomputational complexity per round depends only logarithmically on the number\nof agents and almost linearly on their degree within the graph, ensuring\nscalability for large-system implementations.\n","authors":["Neelkamal Bhuyan","Debankur Mukherjee","Adam Wierman"],"pdf_url":"https://arxiv.org/pdf/2411.08355v1.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2411.04493v2","updated":"2024-11-13T05:52:23Z","published":"2024-11-07T07:41:04Z","title":"Synergy-Guided Regional Supervision of Pseudo Labels for Semi-Supervised\n  Medical Image Segmentation","summary":"  Semi-supervised learning has received considerable attention for its\npotential to leverage abundant unlabeled data to enhance model robustness.\nPseudo labeling is a widely used strategy in semi supervised learning. However,\nexisting methods often suffer from noise contamination, which can undermine\nmodel performance. To tackle this challenge, we introduce a novel\nSynergy-Guided Regional Supervision of Pseudo Labels (SGRS-Net) framework.\nBuilt upon the mean teacher network, we employ a Mix Augmentation module to\nenhance the unlabeled data. By evaluating the synergy before and after\naugmentation, we strategically partition the pseudo labels into distinct\nregions. Additionally, we introduce a Region Loss Evaluation module to assess\nthe loss across each delineated area. Extensive experiments conducted on the LA\ndataset have demonstrated superior performance over state-of-the-art\ntechniques, underscoring the efficiency and practicality of our framework.\n","authors":["Tao Wang","Xinlin Zhang","Yuanbin Chen","Yuanbo Zhou","Longxuan Zhao","Tao Tan","Tong Tong"],"pdf_url":"https://arxiv.org/pdf/2411.04493v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08344v1","updated":"2024-11-13T05:22:45Z","published":"2024-11-13T05:22:45Z","title":"Bangla Grammatical Error Detection Leveraging Transformer-based Token\n  Classification","summary":"  Bangla is the seventh most spoken language by a total number of speakers in\nthe world, and yet the development of an automated grammar checker in this\nlanguage is an understudied problem. Bangla grammatical error detection is a\ntask of detecting sub-strings of a Bangla text that contain grammatical,\npunctuation, or spelling errors, which is crucial for developing an automated\nBangla typing assistant. Our approach involves breaking down the task as a\ntoken classification problem and utilizing state-of-the-art transformer-based\nmodels. Finally, we combine the output of these models and apply rule-based\npost-processing to generate a more reliable and comprehensive result. Our\nsystem is evaluated on a dataset consisting of over 25,000 texts from various\nsources. Our best model achieves a Levenshtein distance score of 1.04. Finally,\nwe provide a detailed analysis of different components of our system.\n","authors":["Shayekh Bin Islam","Ridwanul Hasan Tanvir","Sihat Afnan"],"pdf_url":"https://arxiv.org/pdf/2411.08344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03497v3","updated":"2024-11-13T04:41:31Z","published":"2024-08-07T01:37:10Z","title":"Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and\n  Tabnet with SMOTEENN","summary":"  Bank credit risk is a significant challenge in modern financial transactions,\nand the ability to identify qualified credit card holders among a large number\nof applicants is crucial for the profitability of a bank'sbank's credit card\nbusiness. In the past, screening applicants'applicants' conditions often\nrequired a significant amount of manual labor, which was time-consuming and\nlabor-intensive. Although the accuracy and reliability of previously used ML\nmodels have been continuously improving, the pursuit of more reliable and\npowerful AI intelligent models is undoubtedly the unremitting pursuit by major\nbanks in the financial industry. In this study, we used a dataset of over\n40,000 records provided by a commercial bank as the research object. We\ncompared various dimensionality reduction techniques such as PCA and T-SNE for\npreprocessing high-dimensional datasets and performed in-depth adaptation and\ntuning of distributed models such as LightGBM and XGBoost, as well as deep\nmodels like Tabnet. After a series of research and processing, we obtained\nexcellent research results by combining SMOTEENN with these techniques. The\nexperiments demonstrated that LightGBM combined with PCA and SMOTEENN\ntechniques can assist banks in accurately predicting potential high-quality\ncustomers, showing relatively outstanding performance compared to other models.\n","authors":["Chang Yu","Yixin Jin","Qianwen Xing","Ye Zhang","Shaobo Guo","Shuchen Meng"],"pdf_url":"https://arxiv.org/pdf/2408.03497v3.pdf","comment":"8 pagess on IEEE ICPICS"},{"id":"http://arxiv.org/abs/2411.08332v1","updated":"2024-11-13T04:27:25Z","published":"2024-11-13T04:27:25Z","title":"Learning-Augmented Algorithms for Online Concave Packing and Convex\n  Covering Problems","summary":"  Learning-augmented algorithms have been extensively studied across the\ncomputer science community in the recent years, driven by advances in machine\nlearning predictors, which can provide additional information to augment\nclassical algorithms. Such predictions are especially powerful in the context\nof online problems, where decisions have to be made without knowledge of the\nfuture, and which traditionally exhibits impossibility results bounding the\nperformance of any online algorithm. The study of learning-augmented algorithms\nthus aims to use external advice prudently, to overcome classical impossibility\nresults when the advice is accurate, and still perform comparably to the\nstate-of-the-art online algorithms even when the advice is inaccurate.\n  In this paper, we present learning-augmented algorithmic frameworks for two\nfundamental optimizations settings, extending and generalizing prior works. For\nonline packing with concave objectives, we present a simple but overarching\nstrategy that switches between the advice and the state-of-the-art online\nalgorithm. For online covering with convex objectives, we greatly extend\nprimal-dual methods for online convex covering programs by Azar et al. (FOCS\n2016) and previous learning-augmented framework for online covering linear\nprograms from the literature, to many new applications. We show that our\nalgorithms break impossibility results when the advice is accurate, while\nmaintaining comparable performance with state-of-the-art classical online\nalgorithms even when the advice is erroneous.\n","authors":["Elena Grigorescu","Young-San Lin","Maoyuan Song"],"pdf_url":"https://arxiv.org/pdf/2411.08332v1.pdf","comment":"38 pages. In submission"},{"id":"http://arxiv.org/abs/2411.08326v1","updated":"2024-11-13T04:20:29Z","published":"2024-11-13T04:20:29Z","title":"Neural Conjugate Flows: Physics-informed architectures with flow\n  structure","summary":"  We introduce Neural Conjugate Flows (NCF), a class of neural network\narchitectures equipped with exact flow structure. By leveraging topological\nconjugation, we prove that these networks are not only naturally isomorphic to\na continuous group, but are also universal approximators for flows of ordinary\ndifferential equation (ODEs). Furthermore, topological properties of these\nflows can be enforced by the architecture in an interpretable manner. We\ndemonstrate in numerical experiments how this topological group structure leads\nto concrete computational gains over other physics informed neural networks in\nestimating and extrapolating latent dynamics of ODEs, while training up to five\ntimes faster than other flow-based architectures.\n","authors":["Arthur Bizzi","Lucas Nissenbaum","João M. Pereira"],"pdf_url":"https://arxiv.org/pdf/2411.08326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08324v1","updated":"2024-11-13T04:20:20Z","published":"2024-11-13T04:20:20Z","title":"Are LLMs Prescient? A Continuous Evaluation using Daily News as the\n  Oracle","summary":"  Many existing evaluation benchmarks for Large Language Models (LLMs) quickly\nbecome outdated due to the emergence of new models and training data. These\nbenchmarks also fall short in assessing how LLM performance changes over time,\nas they consist of static questions without a temporal dimension. To address\nthese limitations, we propose using future event prediction as a continuous\nevaluation method to assess LLMs' temporal generalization and forecasting\nabilities. Our benchmark, Daily Oracle, automatically generates question-answer\n(QA) pairs from daily news, challenging LLMs to predict \"future\" event\noutcomes. Our findings reveal that as pre-training data becomes outdated, LLM\nperformance degrades over time. While Retrieval Augmented Generation (RAG) has\nthe potential to enhance prediction accuracy, the performance degradation\npattern persists, highlighting the need for continuous model updates.\n","authors":["Hui Dai","Ryan Teehan","Mengye Ren"],"pdf_url":"https://arxiv.org/pdf/2411.08324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07207v2","updated":"2024-11-13T04:15:38Z","published":"2024-11-11T18:32:44Z","title":"General Geospatial Inference with a Population Dynamics Foundation Model","summary":"  Supporting the health and well-being of dynamic populations around the world\nrequires governmental agencies, organizations and researchers to understand and\nreason over complex relationships between human behavior and local contexts in\norder to identify high-risk groups and strategically allocate limited\nresources. Traditional approaches to these classes of problems often entail\ndeveloping manually curated, task-specific features and models to represent\nhuman behavior and the natural and built environment, which can be challenging\nto adapt to new, or even, related tasks. To address this, we introduce a\nPopulation Dynamics Foundation Model (PDFM) that aims to capture the\nrelationships between diverse data modalities and is applicable to a broad\nrange of geospatial tasks. We first construct a geo-indexed dataset for postal\ncodes and counties across the United States, capturing rich aggregated\ninformation on human behavior from maps, busyness, and aggregated search\ntrends, and environmental factors such as weather and air quality. We then\nmodel this data and the complex relationships between locations using a graph\nneural network, producing embeddings that can be adapted to a wide range of\ndownstream tasks using relatively simple models. We evaluate the effectiveness\nof our approach by benchmarking it on 27 downstream tasks spanning three\ndistinct domains: health indicators, socioeconomic factors, and environmental\nmeasurements. The approach achieves state-of-the-art performance on all 27\ngeospatial interpolation tasks, and on 25 out of the 27 extrapolation and\nsuper-resolution tasks. We combined the PDFM with a state-of-the-art\nforecasting foundation model, TimesFM, to predict unemployment and poverty,\nachieving performance that surpasses fully supervised forecasting. The full set\nof embeddings and sample code are publicly available for researchers.\n","authors":["Mohit Agarwal","Mimi Sun","Chaitanya Kamath","Arbaaz Muslim","Prithul Sarker","Joydeep Paul","Hector Yee","Marcin Sieniek","Kim Jablonski","Yael Mayer","David Fork","Sheila de Guia","Jamie McPike","Adam Boulanger","Tomer Shekel","David Schottlander","Yao Xiao","Manjit Chakravarthy Manukonda","Yun Liu","Neslihan Bulut","Sami Abu-el-haija","Arno Eigenwillig","Parth Kothari","Bryan Perozzi","Monica Bharel","Von Nguyen","Luke Barrington","Niv Efron","Yossi Matias","Greg Corrado","Krish Eswaran","Shruthi Prabhakara","Shravya Shetty","Gautam Prasad"],"pdf_url":"https://arxiv.org/pdf/2411.07207v2.pdf","comment":"28 pages, 16 figures, preprint; v2: updated github url"},{"id":"http://arxiv.org/abs/2411.08314v1","updated":"2024-11-13T03:42:55Z","published":"2024-11-13T03:42:55Z","title":"Conditional Variable Flow Matching: Transforming Conditional Densities\n  with Amortized Conditional Optimal Transport","summary":"  Forecasting stochastic nonlinear dynamical systems under the influence of\nconditioning variables is a fundamental challenge repeatedly encountered across\nthe biological and physical sciences. While flow-based models can impressively\npredict the temporal evolution of probability distributions representing\npossible outcomes of a specific process, existing frameworks cannot\nsatisfactorily account for the impact of conditioning variables on these\ndynamics. Amongst several limitations, existing methods require training data\nwith paired conditions and are developed for discrete conditioning variables.\nWe propose Conditional Variable Flow Matching (CVFM), a framework for learning\nflows transforming conditional distributions with amortization across\ncontinuous conditioning variables - permitting predictions across the\nconditional density manifold. This is accomplished through several novel\nadvances, in particular, simultaneous sample conditioned flows over the main\nand conditioning variables, alongside a conditional Wasserstein distance and\nkernel facilitating conditional optimal transport. Collectively, these advances\nallow for learning system dynamics provided measurement data whose states and\nconditioning variables are not in correspondence. We demonstrate CVFM on a\nsuite of increasingly challenging problems, including discrete and continuous\nconditional mapping benchmarks, image-to-image domain transfer, and modeling\nthe temporal evolution of materials internal structure during manufacturing\nprocesses. We observe that CVFM results in improved performance and convergence\ncharacteristics over alternative conditional variants.\n","authors":["Adam P. Generale","Andreas E. Robertson","Surya R. Kalidindi"],"pdf_url":"https://arxiv.org/pdf/2411.08314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08621v3","updated":"2024-11-13T03:24:24Z","published":"2024-02-13T17:42:27Z","title":"A Unified Framework for Analyzing Meta-algorithms in Online Convex\n  Optimization","summary":"  In this paper, we analyze the problem of online convex optimization in\ndifferent settings, including different feedback types\n(full-information/semi-bandit/bandit/etc) in either stochastic or\nnon-stochastic setting and different notions of regret (static adversarial\nregret/dynamic regret/adaptive regret). This is done through a framework which\nallows us to systematically propose and analyze meta-algorithms for the various\nsettings described above. We show that any algorithm for online linear\noptimization with fully adaptive adversaries is an algorithm for online convex\noptimization. We also show that any such algorithm that requires\nfull-information feedback may be transformed to an algorithm with semi-bandit\nfeedback with comparable regret bound. We further show that algorithms that are\ndesigned for fully adaptive adversaries using deterministic semi-bandit\nfeedback can obtain similar bounds using only stochastic semi-bandit feedback\nwhen facing oblivious adversaries. We use this to describe general\nmeta-algorithms to convert first order algorithms to zeroth order algorithms\nwith comparable regret bounds. Our framework allows us to analyze online\noptimization in various settings, recovers several results in the literature\nwith a simplified proof technique, and provides new results.\n","authors":["Mohammad Pedramfar","Vaneet Aggarwal"],"pdf_url":"https://arxiv.org/pdf/2402.08621v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08306v1","updated":"2024-11-13T03:08:33Z","published":"2024-11-13T03:08:33Z","title":"SDDBench: A Benchmark for Synthesizable Drug Design","summary":"  A significant challenge in wet lab experiments with current drug design\ngenerative models is the trade-off between pharmacological properties and\nsynthesizability. Molecules predicted to have highly desirable properties are\noften difficult to synthesize, while those that are easily synthesizable tend\nto exhibit less favorable properties. As a result, evaluating the\nsynthesizability of molecules in general drug design scenarios remains a\nsignificant challenge in the field of drug discovery. The commonly used\nsynthetic accessibility (SA) score aims to evaluate the ease of synthesizing\ngenerated molecules, but it falls short of guaranteeing that synthetic routes\ncan actually be found. Inspired by recent advances in top-down synthetic route\ngeneration, we propose a new, data-driven metric to evaluate molecule\nsynthesizability. Our approach directly assesses the feasibility of synthetic\nroutes for a given molecule through our proposed round-trip score. This novel\nmetric leverages the synergistic duality between retrosynthetic planners and\nreaction predictors, both of which are trained on extensive reaction datasets.\nTo demonstrate the efficacy of our method, we conduct a comprehensive\nevaluation of round-trip scores alongside search success rate across a range of\nrepresentative molecule generative models. Code is available at\nhttps://github.com/SongtaoLiu0823/SDDBench.\n","authors":["Songtao Liu","Zhengkai Tu","Hanjun Dai","Peng Liu"],"pdf_url":"https://arxiv.org/pdf/2411.08306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07468v2","updated":"2024-11-13T03:07:36Z","published":"2024-11-12T01:09:52Z","title":"Privacy-Preserving Verifiable Neural Network Inference Service","summary":"  Machine learning has revolutionized data analysis and pattern recognition,\nbut its resource-intensive training has limited accessibility. Machine Learning\nas a Service (MLaaS) simplifies this by enabling users to delegate their data\nsamples to an MLaaS provider and obtain the inference result using a\npre-trained model. Despite its convenience, leveraging MLaaS poses significant\nprivacy and reliability concerns to the client. Specifically, sensitive\ninformation from the client inquiry data can be leaked to an adversarial MLaaS\nprovider. Meanwhile, the lack of a verifiability guarantee can potentially\nresult in biased inference results or even unfair payment issues. While\nexisting trustworthy machine learning techniques, such as those relying on\nverifiable computation or secure computation, offer solutions to privacy and\nreliability concerns, they fall short of simultaneously protecting the privacy\nof client data and providing provable inference verifiability.\n  In this paper, we propose vPIN, a privacy-preserving and verifiable CNN\ninference scheme that preserves privacy for client data samples while ensuring\nverifiability for the inference. vPIN makes use of partial homomorphic\nencryption and commit-and-prove succinct non-interactive argument of knowledge\ntechniques to achieve desirable security properties. In vPIN, we develop\nvarious optimization techniques to minimize the proving circuit for homomorphic\ninference evaluation thereby, improving the efficiency and performance of our\ntechnique. We fully implemented and evaluated our vPIN scheme on standard\ndatasets (e.g., MNIST, CIFAR-10). Our experimental results show that vPIN\nachieves high efficiency in terms of proving time, verification time, and proof\nsize, while providing client data privacy guarantees and provable\nverifiability.\n","authors":["Arman Riasi","Jorge Guajardo","Thang Hoang"],"pdf_url":"https://arxiv.org/pdf/2411.07468v2.pdf","comment":"Accepted at the Annual Computer Security Applications Conference\n  (ACSAC) 2024. Source code: github.com/vt-asaplab/vPIN"},{"id":"http://arxiv.org/abs/2411.07954v2","updated":"2024-11-13T02:56:56Z","published":"2024-11-12T17:30:31Z","title":"Learning Memory Mechanisms for Decision Making through Demonstrations","summary":"  In Partially Observable Markov Decision Processes, integrating an agent's\nhistory into memory poses a significant challenge for decision-making.\nTraditional imitation learning, relying on observation-action pairs for expert\ndemonstrations, fails to capture the expert's memory mechanisms used in\ndecision-making. To capture memory processes as demonstrations, we introduce\nthe concept of memory dependency pairs $(p, q)$ indicating that events at time\n$p$ are recalled for decision-making at time $q$. We introduce AttentionTuner\nto leverage memory dependency pairs in Transformers and find significant\nimprovements across several tasks compared to standard Transformers when\nevaluated on Memory Gym and the Long-term Memory Benchmark. Code is available\nat https://github.com/WilliamYue37/AttentionTuner.\n","authors":["William Yue","Bo Liu","Peter Stone"],"pdf_url":"https://arxiv.org/pdf/2411.07954v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07463v2","updated":"2024-11-13T02:39:12Z","published":"2024-11-12T00:54:26Z","title":"MSEG-VCUQ: Multimodal SEGmentation with Enhanced Vision Foundation\n  Models, Convolutional Neural Networks, and Uncertainty Quantification for\n  High-Speed Video Phase Detection Data","summary":"  Purpose: High-speed video (HSV) phase detection (PD) segmentation is vital in\nnuclear reactors, chemical processing, and electronics cooling for detecting\nvapor, liquid, and microlayer phases. Traditional segmentation models face\npixel-level accuracy and generalization issues in multimodal data. MSEG-VCUQ\nintroduces VideoSAM, a hybrid framework leveraging convolutional neural\nnetworks (CNNs) and transformer-based vision models to enhance segmentation\naccuracy and generalizability across complex multimodal PD tasks. Methods:\nVideoSAM combines U-Net CNN and the Segment Anything Model (SAM) for advanced\nfeature extraction and segmentation across diverse HSV PD modalities, spanning\nfluids like water, FC-72, nitrogen, and argon under varied heat flux\nconditions. The framework also incorporates uncertainty quantification (UQ) to\nassess pixel-based discretization errors, delivering reliable metrics such as\ncontact line density and dry area fraction under experimental conditions.\nResults: VideoSAM outperforms SAM and modality-specific CNN models in\nsegmentation accuracy, excelling in environments with complex phase boundaries,\noverlapping bubbles, and dynamic liquid-vapor interactions. Its hybrid\narchitecture supports cross-dataset generalization, adapting effectively to\nvarying modalities. The UQ module provides accurate error estimates, enhancing\nthe reliability of segmentation outputs for advanced HSV PD research.\nConclusion: MSEG-VCUQ, via VideoSAM, offers a robust solution for HSV PD\nsegmentation, addressing previous limitations with advanced deep learning and\nUQ techniques. The open-source datasets and tools introduced enable scalable,\nprecise, and adaptable segmentation for multimodal PD datasets, supporting\nadvancements in HSV analysis and autonomous experimentation. The codes and data\nused for this paper are publicly available at:\n\\url{https://github.com/chikap421/mseg_vcuq}\n","authors":["Chika Maduabuchi","Ericmoore Jossou","Matteo Bucci"],"pdf_url":"https://arxiv.org/pdf/2411.07463v2.pdf","comment":"Under Review in EAAI"},{"id":"http://arxiv.org/abs/2411.07249v2","updated":"2024-11-13T02:38:02Z","published":"2024-10-26T21:27:53Z","title":"SPDIM: Source-Free Unsupervised Conditional and Label Shift Adaptation\n  in EEG","summary":"  The non-stationary nature of electroencephalography (EEG) introduces\ndistribution shifts across domains (e.g., days and subjects), posing a\nsignificant challenge to EEG-based neurotechnology generalization. Without\nlabeled calibration data for target domains, the problem is a source-free\nunsupervised domain adaptation (SFUDA) problem. For scenarios with constant\nlabel distribution, Riemannian geometry-aware statistical alignment frameworks\non the symmetric positive definite (SPD) manifold are considered\nstate-of-the-art. However, many practical scenarios, including EEG-based sleep\nstaging, exhibit label shifts. Here, we propose a geometric deep learning\nframework for SFUDA problems under specific distribution shifts, including\nlabel shifts. We introduce a novel, realistic generative model and show that\nprior Riemannian statistical alignment methods on the SPD manifold can\ncompensate for specific marginal and conditional distribution shifts but hurt\ngeneralization under label shifts. As a remedy, we propose a\nparameter-efficient manifold optimization strategy termed SPDIM. SPDIM uses the\ninformation maximization principle to learn a single SPD-manifold-constrained\nparameter per target domain. In simulations, we demonstrate that SPDIM can\ncompensate for the shifts under our generative model. Moreover, using public\nEEG-based brain-computer interface and sleep staging datasets, we show that\nSPDIM outperforms prior approaches.\n","authors":["Shanglin Li","Motoaki Kawanabe","Reinmar J. Kobler"],"pdf_url":"https://arxiv.org/pdf/2411.07249v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08297v1","updated":"2024-11-13T02:32:38Z","published":"2024-11-13T02:32:38Z","title":"TowerDebias: A Novel Debiasing Method based on the Tower Property","summary":"  Decision-making processes have increasingly come to rely on sophisticated\nmachine learning tools, raising concerns about the fairness of their\npredictions with respect to any sensitive groups. The widespread use of\ncommercial black-box machine learning models necessitates careful consideration\nof their legal and ethical implications on consumers. In situations where users\nhave access to these \"black-box\" models, a key question emerges: how can we\nmitigate or eliminate the influence of sensitive attributes, such as race or\ngender? We propose towerDebias (tDB), a novel approach designed to reduce the\ninfluence of sensitive variables in predictions made by black-box models. Using\nthe Tower Property from probability theory, tDB aims to improve prediction\nfairness during the post-processing stage in a manner amenable to the\nFairness-Utility Tradeoff. This method is highly flexible, requiring no prior\nknowledge of the original model's internal structure, and can be extended to a\nrange of different applications. We provide a formal improvement theorem for\ntDB and demonstrate its effectiveness in both regression and classification\ntasks, underscoring its impact on the fairness-utility tradeoff.\n","authors":["Norman Matloff","Aditya Mittal"],"pdf_url":"https://arxiv.org/pdf/2411.08297v1.pdf","comment":"To be submitted to a journal soon"},{"id":"http://arxiv.org/abs/2411.08290v1","updated":"2024-11-13T02:17:03Z","published":"2024-11-13T02:17:03Z","title":"RESOLVE: Relational Reasoning with Symbolic and Object-Level Features\n  Using Vector Symbolic Processing","summary":"  Modern transformer-based encoder-decoder architectures struggle with\nreasoning tasks due to their inability to effectively extract relational\ninformation between input objects (data/tokens). Recent work introduced the\nAbstractor module, embedded between transformer layers, to address this gap.\nHowever, the Abstractor layer while excelling at capturing relational\ninformation (pure relational reasoning), faces challenges in tasks that require\nboth object and relational-level reasoning (partial relational reasoning). To\naddress this, we propose RESOLVE, a neuro-vector symbolic architecture that\ncombines object-level features with relational representations in\nhigh-dimensional spaces, using fast and efficient operations such as bundling\n(summation) and binding (Hadamard product) allowing both object-level features\nand relational representations to coexist within the same structure without\ninterfering with one another. RESOLVE is driven by a novel attention mechanism\nthat operates in a bipolar high dimensional space, allowing fast attention\nscore computation compared to the state-of-the-art. By leveraging this design,\nthe model achieves both low compute latency and memory efficiency. RESOLVE also\noffers better generalizability while achieving higher accuracy in purely\nrelational reasoning tasks such as sorting as well as partial relational\nreasoning tasks such as math problem-solving compared to state-of-the-art\nmethods.\n","authors":["Mohamed Mejri","Chandramouli Amarnath","Abhijit Chatterjee"],"pdf_url":"https://arxiv.org/pdf/2411.08290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02349v2","updated":"2024-11-13T02:03:01Z","published":"2023-11-04T08:28:33Z","title":"Sample Complexity of Opinion Formation on Networks with Linear\n  Regression Models","summary":"  Consider public health officials aiming to spread awareness about a new\nvaccine in a community interconnected by a social network. How can they\ndistribute information with minimal resources, so as to avoid polarization and\nensure community-wide convergence of opinion? To tackle such challenges, we\ninitiate the study of sample complexity of opinion convergence in networks. Our\nframework is built on the recognized opinion formation game, where we regard\nthe opinion of each agent as a data-derived model, unlike previous works that\ntreat opinions as data-independent scalars. The opinion model for every agent\nis initially learned from its local samples and evolves game-theoretically as\nall agents communicate with neighbors and revise their models towards an\nequilibrium. Our focus is on the sample complexity needed to ensure that the\nopinions converge to an equilibrium such that the final model of every agent\nhas low generalization error.\n  Our paper has two main technical results. First, we present a novel\npolynomial time optimization framework to quantify the total sample complexity\nfor arbitrary networks, when the underlying learning problem is (generalized)\nlinear regression. Second, we leverage this optimization to study the network\ngain which measures the improvement of sample complexity when learning over a\nnetwork compared to that in isolation. Towards this end, we derive network gain\nbounds for various network classes including cliques, star graphs, and random\nregular graphs. Additionally, our framework provides a method to study sample\ndistribution within the network, suggesting that it is sufficient to allocate\nsamples inversely to the degree. Empirical results on both synthetic and\nreal-world networks strongly support our theoretical findings.\n","authors":["Haolin Liu","Rajmohan Rajaraman","Ravi Sundaram","Anil Vullikanti","Omer Wasim","Haifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2311.02349v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08286v1","updated":"2024-11-13T02:02:52Z","published":"2024-11-13T02:02:52Z","title":"Hashing for Protein Structure Similarity Search","summary":"  Protein structure similarity search (PSSS), which tries to search proteins\nwith similar structures, plays a crucial role across diverse domains from drug\ndesign to protein function prediction and molecular evolution. Traditional\nalignment-based PSSS methods, which directly calculate alignment on the protein\nstructures, are highly time-consuming with high memory cost. Recently,\nalignment-free methods, which represent protein structures as fixed-length\nreal-valued vectors, are proposed for PSSS. Although these methods have lower\ntime and memory cost than alignment-based methods, their time and memory cost\nis still too high for large-scale PSSS, and their accuracy is unsatisfactory.\nIn this paper, we propose a novel method, called\n$\\underline{\\text{p}}$r$\\underline{\\text{o}}$tein\n$\\underline{\\text{s}}$tructure $\\underline{\\text{h}}$ashing (POSH), for PSSS.\nPOSH learns a binary vector representation for each protein structure, which\ncan dramatically reduce the time and memory cost for PSSS compared with\nreal-valued vector representation based methods. Furthermore, in POSH we also\npropose expressive hand-crafted features and a structure encoder to well model\nboth node and edge interactions in proteins. Experimental results on real\ndatasets show that POSH can outperform other methods to achieve\nstate-of-the-art accuracy. Furthermore, POSH achieves a memory saving of more\nthan six times and speed improvement of more than four times, compared with\nother methods.\n","authors":["Jin Han","Wu-Jun Li"],"pdf_url":"https://arxiv.org/pdf/2411.08286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12723v4","updated":"2024-11-13T01:45:11Z","published":"2024-06-18T15:45:21Z","title":"BIOSCAN-5M: A Multimodal Dataset for Insect Biodiversity","summary":"  As part of an ongoing worldwide effort to comprehend and monitor insect\nbiodiversity, this paper presents the BIOSCAN-5M Insect dataset to the machine\nlearning community and establish several benchmark tasks. BIOSCAN-5M is a\ncomprehensive dataset containing multi-modal information for over 5 million\ninsect specimens, and it significantly expands existing image-based biological\ndatasets by including taxonomic labels, raw nucleotide barcode sequences,\nassigned barcode index numbers, geographical, and size information. We propose\nthree benchmark experiments to demonstrate the impact of the multi-modal data\ntypes on the classification and clustering accuracy. First, we pretrain a\nmasked language model on the DNA barcode sequences of the BIOSCAN-5M dataset,\nand demonstrate the impact of using this large reference library on species-\nand genus-level classification performance. Second, we propose a zero-shot\ntransfer learning task applied to images and DNA barcodes to cluster feature\nembeddings obtained from self-supervised learning, to investigate whether\nmeaningful clusters can be derived from these representation embeddings. Third,\nwe benchmark multi-modality by performing contrastive learning on DNA barcodes,\nimage data, and taxonomic information. This yields a general shared embedding\nspace enabling taxonomic classification using multiple types of information and\nmodalities. The code repository of the BIOSCAN-5M Insect dataset is available\nat https://github.com/bioscan-ml/BIOSCAN-5M.\n","authors":["Zahra Gharaee","Scott C. Lowe","ZeMing Gong","Pablo Millan Arias","Nicholas Pellegrino","Austin T. Wang","Joakim Bruslund Haurum","Iuliia Zarubiieva","Lila Kari","Dirk Steinke","Graham W. Taylor","Paul Fieguth","Angel X. Chang"],"pdf_url":"https://arxiv.org/pdf/2406.12723v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.05386v2","updated":"2024-11-13T01:40:53Z","published":"2024-05-08T19:31:06Z","title":"Interpretability Needs a New Paradigm","summary":"  Interpretability is the study of explaining models in understandable terms to\nhumans. At present, interpretability is divided into two paradigms: the\nintrinsic paradigm, which believes that only models designed to be explained\ncan be explained, and the post-hoc paradigm, which believes that black-box\nmodels can be explained. At the core of this debate is how each paradigm\nensures its explanations are faithful, i.e., true to the model's behavior. This\nis important, as false but convincing explanations lead to unsupported\nconfidence in artificial intelligence (AI), which can be dangerous. This\npaper's position is that we should think about new paradigms while staying\nvigilant regarding faithfulness. First, by examining the history of paradigms\nin science, we see that paradigms are constantly evolving. Then, by examining\nthe current paradigms, we can understand their underlying beliefs, the value\nthey bring, and their limitations. Finally, this paper presents 3 emerging\nparadigms for interpretability. The first paradigm designs models such that\nfaithfulness can be easily measured. Another optimizes models such that\nexplanations become faithful. The last paradigm proposes to develop models that\nproduce both a prediction and an explanation.\n","authors":["Andreas Madsen","Himabindu Lakkaraju","Siva Reddy","Sarath Chandar"],"pdf_url":"https://arxiv.org/pdf/2405.05386v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14798v2","updated":"2024-11-13T01:36:33Z","published":"2024-06-21T00:16:55Z","title":"Probabilistic Emulation of a Global Climate Model with Spherical\n  DYffusion","summary":"  Data-driven deep learning models are transforming global weather forecasting.\nIt is an open question if this success can extend to climate modeling, where\nthe complexity of the data and long inference rollouts pose significant\nchallenges. Here, we present the first conditional generative model that\nproduces accurate and physically consistent global climate ensemble simulations\nby emulating a coarse version of the United States' primary operational global\nforecast model, FV3GFS. Our model integrates the dynamics-informed diffusion\nframework (DYffusion) with the Spherical Fourier Neural Operator (SFNO)\narchitecture, enabling stable 100-year simulations at 6-hourly timesteps while\nmaintaining low computational overhead compared to single-step deterministic\nbaselines. The model achieves near gold-standard performance for climate model\nemulation, outperforming existing approaches and demonstrating promising\nensemble skill. This work represents a significant advance towards efficient,\ndata-driven climate simulations that can enhance our understanding of the\nclimate system and inform adaptation strategies.\n","authors":["Salva Rühling Cachay","Brian Henn","Oliver Watt-Meyer","Christopher S. Bretherton","Rose Yu"],"pdf_url":"https://arxiv.org/pdf/2406.14798v2.pdf","comment":"NeurIPS 2024; Code is available at\n  https://github.com/Rose-STL-Lab/spherical-dyffusion"},{"id":"http://arxiv.org/abs/2411.08267v1","updated":"2024-11-13T00:42:40Z","published":"2024-11-13T00:42:40Z","title":"Least Squares Training of Quadratic Convolutional Neural Networks with\n  Applications to System Theory","summary":"  This paper provides a least squares formulation for the training of a 2-layer\nconvolutional neural network using quadratic activation functions, a 2-norm\nloss function, and no regularization term. Using this method, an analytic\nexpression for the globally optimal weights is obtained alongside a quadratic\ninput-output equation for the network. These properties make the network a\nviable tool in system theory by enabling further analysis, such as the\nsensitivity of the output to perturbations in the input, which is crucial for\nsafety-critical systems such as aircraft or autonomous vehicles.The least\nsquares method is compared to previously proposed strategies for training\nquadratic networks and to a back-propagation-trained ReLU network. The proposed\nmethod is applied to a system identification problem and a GPS position\nestimation problem. The least squares network is shown to have a significantly\nreduced training time with minimal compromises on prediction accuracy alongside\nthe advantages of having an analytic input-output equation. Although these\nresults only apply to 2-layer networks, this paper motivates the exploration of\ndeeper quadratic networks in the context of system theory.\n","authors":["Zachary Yetman Van Egmond","Luis Rodrigues"],"pdf_url":"https://arxiv.org/pdf/2411.08267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.09995v2","updated":"2024-11-13T00:41:01Z","published":"2024-04-15T17:59:57Z","title":"Taming Latent Diffusion Model for Neural Radiance Field Inpainting","summary":"  Neural Radiance Field (NeRF) is a representation for 3D reconstruction from\nmulti-view images. Despite some recent work showing preliminary success in\nediting a reconstructed NeRF with diffusion prior, they remain struggling to\nsynthesize reasonable geometry in completely uncovered regions. One major\nreason is the high diversity of synthetic contents from the diffusion model,\nwhich hinders the radiance field from converging to a crisp and deterministic\ngeometry. Moreover, applying latent diffusion models on real data often yields\na textural shift incoherent to the image condition due to auto-encoding errors.\nThese two problems are further reinforced with the use of pixel-distance\nlosses. To address these issues, we propose tempering the diffusion model's\nstochasticity with per-scene customization and mitigating the textural shift\nwith masked adversarial training. During the analyses, we also found the\ncommonly used pixel and perceptual losses are harmful in the NeRF inpainting\ntask. Through rigorous experiments, our framework yields state-of-the-art NeRF\ninpainting results on various real-world scenes. Project page:\nhttps://hubert0527.github.io/MALD-NeRF\n","authors":["Chieh Hubert Lin","Changil Kim","Jia-Bin Huang","Qinbo Li","Chih-Yao Ma","Johannes Kopf","Ming-Hsuan Yang","Hung-Yu Tseng"],"pdf_url":"https://arxiv.org/pdf/2404.09995v2.pdf","comment":"Accepted to ECCV 2024. Project page:\n  https://hubert0527.github.io/MALD-NeRF"},{"id":"http://arxiv.org/abs/2402.17457v2","updated":"2024-11-13T00:38:48Z","published":"2024-02-27T12:28:01Z","title":"Super Consistency of Neural Network Landscapes and Learning Rate\n  Transfer","summary":"  Recently, there has been growing evidence that if the width and depth of a\nneural network are scaled toward the so-called rich feature learning limit\n(\\mup and its depth extension), then some hyperparameters -- such as the\nlearning rate -- exhibit transfer from small to very large models. From an\noptimization perspective, this phenomenon is puzzling, as it implies that the\nloss landscape is consistently similar across very different model sizes. In\nthis work, we study the landscape through the lens of the loss Hessian, with a\nfocus on its largest eigenvalue (i.e. the sharpness), and find that certain\nspectral properties under $\\mu$P are largely independent of the size of the\nnetwork, and remain consistent as training progresses. We name this property\nSuper Consistency of the landscape. On the other hand, we show that in the\nNeural Tangent Kernel (NTK) and other scaling regimes, the sharpness exhibits\nvery different dynamics at different scales. But what causes these differences\nin the sharpness dynamics? Through a connection between the Hessian's and the\nNTK's spectrum, we argue that the cause lies in the presence (for $\\mu$P) or\nprogressive absence (for the NTK scaling) of feature learning. We corroborate\nour claims with a substantial suite of experiments, covering a wide range of\ndatasets and architectures: from ResNets and Vision Transformers trained on\nbenchmark vision datasets to Transformers-based language models trained on\nWikiText.\n","authors":["Lorenzo Noci","Alexandru Meterez","Thomas Hofmann","Antonio Orvieto"],"pdf_url":"https://arxiv.org/pdf/2402.17457v2.pdf","comment":"The paper has been accepted at Neurips 2024. This is a revised\n  version of the paper previously titled \"Why do Learning Rates Transfer?\n  Reconciling Optimization and Scaling Limits for Deep Learning\""},{"id":"http://arxiv.org/abs/2410.01272v2","updated":"2024-11-13T00:19:34Z","published":"2024-10-02T06:30:49Z","title":"\"No Matter What You Do\": Purifying GNN Models via Backdoor Unlearning","summary":"  Recent studies have exposed that GNNs are vulnerable to several adversarial\nattacks, among which backdoor attack is one of the toughest. Similar to Deep\nNeural Networks (DNNs), backdoor attacks in GNNs lie in the fact that the\nattacker modifies a portion of graph data by embedding triggers and enforces\nthe model to learn the trigger feature during the model training process.\nDespite the massive prior backdoor defense works on DNNs, defending against\nbackdoor attacks in GNNs is largely unexplored, severely hindering the\nwidespread application of GNNs in real-world tasks. To bridge this gap, we\npresent GCleaner, the first backdoor mitigation method on GNNs. GCleaner can\nmitigate the presence of the backdoor logic within backdoored GNNs by reversing\nthe backdoor learning procedure, aiming to restore the model performance to a\nlevel similar to that is directly trained on the original clean dataset. To\nachieve this objective, we ask: How to recover universal and hard backdoor\ntriggers in GNNs? How to unlearn the backdoor trigger feature while maintaining\nthe model performance? We conduct the graph trigger recovery via the\nexplanation method to identify optimal trigger locations, facilitating the\nsearch of universal and hard backdoor triggers in the feature space of the\nbackdoored model through maximal similarity. Subsequently, we introduce the\nbackdoor unlearning mechanism, which combines knowledge distillation and\ngradient-based explainable knowledge for fine-grained backdoor erasure.\nExtensive experimental evaluations on four benchmark datasets demonstrate that\nGCleaner can reduce the backdoor attack success rate to 10% with only 1% of\nclean data, and has almost negligible degradation in model performance, which\nfar outperforms the state-of-the-art (SOTA) defense methods.\n","authors":["Jiale Zhang","Chengcheng Zhu","Bosen Rao","Hao Sui","Xiaobing Sun","Bing Chen","Chunyi Zhou","Shouling Ji"],"pdf_url":"https://arxiv.org/pdf/2410.01272v2.pdf","comment":"18 pages, 12 figures, 9 tables"},{"id":"http://arxiv.org/abs/2409.18164v2","updated":"2024-11-13T00:15:46Z","published":"2024-09-26T17:30:28Z","title":"Data-Prep-Kit: getting your data ready for LLM application development","summary":"  Data preparation is the first and a very important step towards any Large\nLanguage Model (LLM) development. This paper introduces an easy-to-use,\nextensible, and scale-flexible open-source data preparation toolkit called Data\nPrep Kit (DPK). DPK is architected and designed to enable users to scale their\ndata preparation to their needs. With DPK they can prepare data on a local\nmachine or effortlessly scale to run on a cluster with thousands of CPU Cores.\nDPK comes with a highly scalable, yet extensible set of modules that transform\nnatural language and code data. If the user needs additional transforms, they\ncan be easily developed using extensive DPK support for transform creation.\nThese modules can be used independently or pipelined to perform a series of\noperations. In this paper, we describe DPK architecture and show its\nperformance from a small scale to a very large number of CPUs. The modules from\nDPK have been used for the preparation of Granite Models [1] [2]. We believe\nDPK is a valuable contribution to the AI community to easily prepare data to\nenhance the performance of their LLM models or to fine-tune models with\nRetrieval-Augmented Generation (RAG).\n","authors":["David Wood","Boris Lublinsky","Alexy Roytman","Shivdeep Singh","Constantin Adam","Abdulhamid Adebayo","Sungeun An","Yuan Chi Chang","Xuan-Hong Dang","Nirmit Desai","Michele Dolfi","Hajar Emami-Gohari","Revital Eres","Takuya Goto","Dhiraj Joshi","Yan Koyfman","Mohammad Nassar","Hima Patel","Paramesvaran Selvam","Yousaf Shah","Saptha Surendran","Daiki Tsuzuku","Petros Zerfos","Shahrokh Daijavad"],"pdf_url":"https://arxiv.org/pdf/2409.18164v2.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.08257v1","updated":"2024-11-13T00:14:09Z","published":"2024-11-13T00:14:09Z","title":"GPTree: Towards Explainable Decision-Making via LLM-powered Decision\n  Trees","summary":"  Traditional decision tree algorithms are explainable but struggle with\nnon-linear, high-dimensional data, limiting its applicability in complex\ndecision-making. Neural networks excel at capturing complex patterns but\nsacrifice explainability in the process. In this work, we present GPTree, a\nnovel framework combining explainability of decision trees with the advanced\nreasoning capabilities of LLMs. GPTree eliminates the need for feature\nengineering and prompt chaining, requiring only a task-specific prompt and\nleveraging a tree-based structure to dynamically split samples. We also\nintroduce an expert-in-the-loop feedback mechanism to further enhance\nperformance by enabling human intervention to refine and rebuild decision\npaths, emphasizing the harmony between human expertise and machine\nintelligence. Our decision tree achieved a 7.8% precision rate for identifying\n\"unicorn\" startups at the inception stage of a startup, surpassing gpt-4o with\nfew-shot learning as well as the best human decision-makers (3.1% to 5.6%).\n","authors":["Sichao Xiong","Yigit Ihlamur","Fuat Alican","Aaron Ontoyin Yin"],"pdf_url":"https://arxiv.org/pdf/2411.08257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.04883v6","updated":"2024-11-13T23:34:19Z","published":"2022-08-09T16:25:49Z","title":"Neural-Rendezvous: Provably Robust Guidance and Control to Encounter\n  Interstellar Objects","summary":"  Interstellar objects (ISOs) are likely representatives of primitive materials\ninvaluable in understanding exoplanetary star systems. Due to their poorly\nconstrained orbits with generally high inclinations and relative velocities,\nhowever, exploring ISOs with conventional human-in-the-loop approaches is\nsignificantly challenging. This paper presents Neural-Rendezvous -- a deep\nlearning-based guidance and control framework for encountering fast-moving\nobjects, including ISOs, robustly, accurately, and autonomously in real time.\nIt uses pointwise minimum norm tracking control on top of a guidance policy\nmodeled by a spectrally-normalized deep neural network, where its\nhyperparameters are tuned with a loss function directly penalizing the MPC\nstate trajectory tracking error. We show that Neural-Rendezvous provides a high\nprobability exponential bound on the expected spacecraft delivery error, the\nproof of which leverages stochastic incremental stability analysis. In\nparticular, it is used to construct a non-negative function with a\nsupermartingale property, explicitly accounting for the ISO state uncertainty\nand the local nature of nonlinear state estimation guarantees. In numerical\nsimulations, Neural-Rendezvous is demonstrated to satisfy the expected error\nbound for 100 ISO candidates. This performance is also empirically validated\nusing our spacecraft simulator and in high-conflict and distributed UAV swarm\nreconfiguration with up to 20 UAVs.\n","authors":["Hiroyasu Tsukamoto","Soon-Jo Chung","Yashwanth Kumar Nakka","Benjamin Donitz","Declan Mages","Michel Ingham"],"pdf_url":"https://arxiv.org/pdf/2208.04883v6.pdf","comment":"Preprint Version, Accepted: October, 2024 (One-minute YouTube\n  summary: https://youtu.be/q3e0LYS2IYQ, DOI:\n  https://doi.org/10.2514/1.G007671)"},{"id":"http://arxiv.org/abs/2411.09077v1","updated":"2024-11-13T23:09:53Z","published":"2024-11-13T23:09:53Z","title":"Drone Detection using Deep Neural Networks Trained on Pure Synthetic\n  Data","summary":"  Drone detection has benefited from improvements in deep neural networks, but\nlike many other applications, suffers from the availability of accurate data\nfor training. Synthetic data provides a potential for low-cost data generation\nand has been shown to improve data availability and quality. However, models\ntrained on synthetic datasets need to prove their ability to perform on\nreal-world data, known as the problem of sim-to-real transferability. Here, we\npresent a drone detection Faster-RCNN model trained on a purely synthetic\ndataset that transfers to real-world data. We found that it achieves an AP_50\nof 97.0% when evaluated on the MAV-Vid - a real dataset of flying drones -\ncompared with 97.8% for an equivalent model trained on real-world data. Our\nresults show that using synthetic data for drone detection has the potential to\nreduce data collection costs and improve labelling quality. These findings\ncould be a starting point for more elaborate synthetic drone datasets. For\nexample, realistic recreations of specific scenarios could de-risk the dataset\ngeneration of safety-critical applications such as the detection of drones at\nairports. Further, synthetic data may enable reliable drone detection systems,\nwhich could benefit other areas, such as unmanned traffic management systems.\nThe code is available\nhttps://github.com/mazqtpopx/cranfield-synthetic-drone-detection alongside the\ndatasets\nhttps://huggingface.co/datasets/mazqtpopx/cranfield-synthetic-drone-detection.\n","authors":["Mariusz Wisniewski","Zeeshan A. Rana","Ivan Petrunin","Alan Holt","Stephen Harman"],"pdf_url":"https://arxiv.org/pdf/2411.09077v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.07217v3","updated":"2024-11-13T23:09:38Z","published":"2024-11-11T18:38:22Z","title":"Feature Selection Based on Wasserstein Distance","summary":"  This paper presents a novel feature selection method leveraging the\nWasserstein distance to improve feature selection in machine learning. Unlike\ntraditional methods based on correlation or Kullback-Leibler (KL) divergence,\nour approach uses the Wasserstein distance to assess feature similarity,\ninherently capturing class relationships and making it robust to noisy labels.\nWe introduce a Markov blanket-based feature selection algorithm and demonstrate\nits effectiveness. Our analysis shows that the Wasserstein distance-based\nfeature selection method effectively reduces the impact of noisy labels without\nrelying on specific noise models. We provide a lower bound on its\neffectiveness, which remains meaningful even in the presence of noise.\nExperimental results across multiple datasets demonstrate that our approach\nconsistently outperforms traditional methods, particularly in noisy settings.\n","authors":["Fuwei Li"],"pdf_url":"https://arxiv.org/pdf/2411.07217v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14131v2","updated":"2024-11-13T23:07:44Z","published":"2024-05-23T03:11:07Z","title":"Statistical Advantages of Perturbing Cosine Router in Mixture of Experts","summary":"  The cosine router in Mixture of Experts (MoE) has recently emerged as an\nattractive alternative to the conventional linear router. Indeed, the cosine\nrouter demonstrates favorable performance in image and language tasks and\nexhibits better ability to mitigate the representation collapse issue, which\noften leads to parameter redundancy and limited representation potentials.\nDespite its empirical success, a comprehensive analysis of the cosine router in\nMoE has been lacking. Considering the least square estimation of the cosine\nrouting MoE, we demonstrate that due to the intrinsic interaction of the model\nparameters in the cosine router via some partial differential equations,\nregardless of the structures of the experts, the estimation rates of experts\nand model parameters can be as slow as $\\mathcal{O}(1/\\log^{\\tau}(n))$ where\n$\\tau > 0$ is some constant and $n$ is the sample size. Surprisingly, these\npessimistic non-polynomial convergence rates can be circumvented by the widely\nused technique in practice to stabilize the cosine router -- simply adding\nnoises to the $L^2$ norms in the cosine router, which we refer to as\n\\textit{perturbed cosine router}. Under the strongly identifiable settings of\nthe expert functions, we prove that the estimation rates for both the experts\nand model parameters under the perturbed cosine routing MoE are significantly\nimproved to polynomial rates. Finally, we conduct extensive simulation studies\nin both synthetic and real data settings to empirically validate our\ntheoretical results.\n","authors":["Huy Nguyen","Pedram Akbarian","Trang Pham","Trang Nguyen","Shujian Zhang","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2405.14131v2.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2411.09073v1","updated":"2024-11-13T22:56:00Z","published":"2024-11-13T22:56:00Z","title":"Code-mixed LLM: Improve Large Language Models' Capability to Handle\n  Code-Mixing through Reinforcement Learning from AI Feedback","summary":"  Code-mixing(CM) or code-switching(CSW) refers to the juxtaposition of\nlinguistic units from two or more languages during the conversation or\nsometimes even a single utterance. Code-mixing introduces unique challenges in\ndaily life, such as syntactic mismatches and semantic blending, that are rarely\nencountered in monolingual settings. Large language models (LLMs) have\nrevolutionized the field of natural language processing (NLP) by offering\nunprecedented capabilities in understanding human languages. However, the\neffectiveness of current state-of-the-art multilingual LLMs has not yet been\nfully explored in the CM scenario. To fill this gap, we first benchmark the\nperformance of multilingual LLMs on various code-mixing NLP tasks. Then we\npropose to improve the multilingual LLMs' ability to understand code-mixing\nthrough reinforcement learning from human feedback (RLHF) and code-mixed\nmachine translation tasks. Given the high-cost and time-consuming preference\nlabeling procedure, we improve this by utilizing LLMs as annotators to perform\nthe reinforcement learning from AI feedback (RLAIF). The experiments show the\neffectiveness of the proposed method.\n","authors":["Wenbo Zhang","Aditya Majumdar","Amulya Yadav"],"pdf_url":"https://arxiv.org/pdf/2411.09073v1.pdf","comment":"initial version: 5 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.09072v1","updated":"2024-11-13T22:55:45Z","published":"2024-11-13T22:55:45Z","title":"Continuous GNN-based Anomaly Detection on Edge using Efficient Adaptive\n  Knowledge Graph Learning","summary":"  The increasing demand for robust security solutions across various industries\nhas made Video Anomaly Detection (VAD) a critical task in applications such as\nintelligent surveillance, evidence investigation, and violence detection.\nTraditional approaches to VAD often rely on finetuning large pre-trained\nmodels, which can be computationally expensive and impractical for real-time or\nresource-constrained environments. To address this, MissionGNN introduced a\nmore efficient method by training a graph neural network (GNN) using a fixed\nknowledge graph (KG) derived from large language models (LLMs) like GPT-4.\nWhile this approach demonstrated significant efficiency in computational power\nand memory, it faces limitations in dynamic environments where frequent updates\nto the KG are necessary due to evolving behavior trends and shifting data\npatterns. These updates typically require cloud-based computation, posing\nchallenges for edge computing applications. In this paper, we propose a novel\nframework that facilitates continuous KG adaptation directly on edge devices,\novercoming the limitations of cloud dependency. Our method dynamically modifies\nthe KG through a three-phase process: pruning, alternating, and creating nodes,\nenabling real-time adaptation to changing data trends. This continuous learning\napproach enhances the robustness of anomaly detection models, making them more\nsuitable for deployment in dynamic and resource-constrained environments.\n","authors":["Sanggeon Yun","Ryozo Masukawa","William Youngwoo Chung","Minhyoung Na","Nathaniel Bastian","Mohsen Imani"],"pdf_url":"https://arxiv.org/pdf/2411.09072v1.pdf","comment":"Accepted to DATE 2025"},{"id":"http://arxiv.org/abs/2405.20194v6","updated":"2024-11-13T22:51:10Z","published":"2024-05-30T15:58:22Z","title":"Occam Gradient Descent","summary":"  Deep learning neural network models must be large enough to adapt to their\nproblem domain, while small enough to avoid overfitting training data during\ngradient descent. To balance these competing demands, overprovisioned deep\nlearning models such as transformers are trained for a single epoch on large\ndata sets, and hence inefficient with both computing resources and training\ndata. In response to these inefficiencies, we exploit learning theory to derive\nOccam Gradient Descent, an algorithm that interleaves adaptive reduction of\nmodel size to minimize generalization error, with gradient descent on model\nweights to minimize fitting error. In contrast, traditional gradient descent\ngreedily minimizes fitting error without regard to generalization error. Our\nalgorithm simultaneously descends the space of weights and topological size of\nany neural network without modification. With respect to loss, compute and\nmodel size, our experiments show (a) on image classification benchmarks, linear\nand convolutional neural networks trained with Occam Gradient Descent\noutperform traditional gradient descent with or without post-train pruning; (b)\non a range of tabular data classification tasks, neural networks trained with\nOccam Gradient Descent outperform traditional gradient descent, as well as\nRandom Forests; (c) on natural language transformers, Occam Gradient Descent\noutperforms traditional gradient descent.\n","authors":["B. N. Kausik"],"pdf_url":"https://arxiv.org/pdf/2405.20194v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09065v1","updated":"2024-11-13T22:45:52Z","published":"2024-11-13T22:45:52Z","title":"Language-Model Prior Overcomes Cold-Start Items","summary":"  The growth of recommender systems (RecSys) is driven by digitization and the\nneed for personalized content in areas such as e-commerce and video streaming.\nThe content in these systems often changes rapidly and therefore they\nconstantly face the ongoing cold-start problem, where new items lack\ninteraction data and are hard to value. Existing solutions for the cold-start\nproblem, such as content-based recommenders and hybrid methods, leverage item\nmetadata to determine item similarities. The main challenge with these methods\nis their reliance on structured and informative metadata to capture detailed\nitem similarities, which may not always be available. This paper introduces a\nnovel approach for cold-start item recommendation that utilizes the language\nmodel (LM) to estimate item similarities, which are further integrated as a\nBayesian prior with classic recommender systems. This approach is generic and\nable to boost the performance of various recommenders. Specifically, our\nexperiments integrate it with both sequential and collaborative filtering-based\nrecommender and evaluate it on two real-world datasets, demonstrating the\nenhanced performance of the proposed approach.\n","authors":["Shiyu Wang","Hao Ding","Yupeng Gu","Sergul Aydore","Kousha Kalantari","Branislav Kveton"],"pdf_url":"https://arxiv.org/pdf/2411.09065v1.pdf","comment":"This paper is dedicated to cold-start item recommendation using\n  language-model priors"},{"id":"http://arxiv.org/abs/2411.09064v1","updated":"2024-11-13T22:44:25Z","published":"2024-11-13T22:44:25Z","title":"Minimax Optimal Two-Sample Testing under Local Differential Privacy","summary":"  We explore the trade-off between privacy and statistical utility in private\ntwo-sample testing under local differential privacy (LDP) for both multinomial\nand continuous data. We begin by addressing the multinomial case, where we\nintroduce private permutation tests using practical privacy mechanisms such as\nLaplace, discrete Laplace, and Google's RAPPOR. We then extend our multinomial\napproach to continuous data via binning and study its uniform separation rates\nunder LDP over H\\\"older and Besov smoothness classes. The proposed tests for\nboth discrete and continuous cases rigorously control the type I error for any\nfinite sample size, strictly adhere to LDP constraints, and achieve minimax\nseparation rates under LDP. The attained minimax rates reveal inherent\nprivacy-utility trade-offs that are unavoidable in private testing. To address\nscenarios with unknown smoothness parameters in density testing, we propose an\nadaptive test based on a Bonferroni-type approach that ensures robust\nperformance without prior knowledge of the smoothness parameters. We validate\nour theoretical findings with extensive numerical experiments and demonstrate\nthe practical relevance and effectiveness of our proposed methods.\n","authors":["Jongmin Mun","Seungwoo Kwak","Ilmun Kim"],"pdf_url":"https://arxiv.org/pdf/2411.09064v1.pdf","comment":"59 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.09056v1","updated":"2024-11-13T22:29:23Z","published":"2024-11-13T22:29:23Z","title":"Optimisation Strategies for Ensuring Fairness in Machine Learning: With\n  and Without Demographics","summary":"  Ensuring fairness has emerged as one of the primary concerns in AI and its\nrelated algorithms. Over time, the field of machine learning fairness has\nevolved to address these issues. This paper provides an extensive overview of\nthis field and introduces two formal frameworks to tackle open questions in\nmachine learning fairness.\n  In one framework, operator-valued optimisation and min-max objectives are\nemployed to address unfairness in time-series problems. This approach showcases\nstate-of-the-art performance on the notorious COMPAS benchmark dataset,\ndemonstrating its effectiveness in real-world scenarios.\n  In the second framework, the challenge of lacking sensitive attributes, such\nas gender and race, in commonly used datasets is addressed. This issue is\nparticularly pressing because existing algorithms in this field predominantly\nrely on the availability or estimations of such attributes to assess and\nmitigate unfairness. Here, a framework for a group-blind bias-repair is\nintroduced, aiming to mitigate bias without relying on sensitive attributes.\nThe efficacy of this approach is showcased through analyses conducted on the\nAdult Census Income dataset.\n  Additionally, detailed algorithmic analyses for both frameworks are provided,\naccompanied by convergence guarantees, ensuring the robustness and reliability\nof the proposed methodologies.\n","authors":["Quan Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.09056v1.pdf","comment":"PhD thesis. arXiv admin note: text overlap with arXiv:2310.11407"},{"id":"http://arxiv.org/abs/2411.09055v1","updated":"2024-11-13T22:28:05Z","published":"2024-11-13T22:28:05Z","title":"SAFELOC: Overcoming Data Poisoning Attacks in Heterogeneous Federated\n  Machine Learning for Indoor Localization","summary":"  Machine learning (ML) based indoor localization solutions are critical for\nmany emerging applications, yet their efficacy is often compromised by\nhardware/software variations across mobile devices (i.e., device heterogeneity)\nand the threat of ML data poisoning attacks. Conventional methods aimed at\ncountering these challenges show limited resilience to the uncertainties\ncreated by these phenomena. In response, in this paper, we introduce SAFELOC, a\nnovel framework that not only minimizes localization errors under these\nchallenging conditions but also ensures model compactness for efficient mobile\ndevice deployment. Our framework targets a distributed and co-operative\nlearning environment that uses federated learning (FL) to preserve user data\nprivacy and assumes heterogeneous mobile devices carried by users (just like in\nmost real-world scenarios). Within this heterogeneous FL context, SAFELOC\nintroduces a novel fused neural network architecture that performs data\npoisoning detection and localization, with a low model footprint. Additionally,\na dynamic saliency map-based aggregation strategy is designed to adapt based on\nthe severity of the detected data poisoning scenario. Experimental evaluations\ndemonstrate that SAFELOC achieves improvements of up to 5.9x in mean\nlocalization error, 7.8x in worst-case localization error, and a 2.1x reduction\nin model inference latency compared to state-of-the-art indoor localization\nframeworks, across diverse building floorplans, mobile devices, and ML data\npoisoning attack scenarios.\n","authors":["Akhil Singampalli","Danish Gufran","Sudeep Pasricha"],"pdf_url":"https://arxiv.org/pdf/2411.09055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09052v1","updated":"2024-11-13T22:15:31Z","published":"2024-11-13T22:15:31Z","title":"ClevrSkills: Compositional Language and Visual Reasoning in Robotics","summary":"  Robotics tasks are highly compositional by nature. For example, to perform a\nhigh-level task like cleaning the table a robot must employ low-level\ncapabilities of moving the effectors to the objects on the table, pick them up\nand then move them off the table one-by-one, while re-evaluating the\nconsequently dynamic scenario in the process. Given that large vision language\nmodels (VLMs) have shown progress on many tasks that require high level,\nhuman-like reasoning, we ask the question: if the models are taught the\nrequisite low-level capabilities, can they compose them in novel ways to\nachieve interesting high-level tasks like cleaning the table without having to\nbe explicitly taught so? To this end, we present ClevrSkills - a benchmark\nsuite for compositional reasoning in robotics. ClevrSkills is an environment\nsuite developed on top of the ManiSkill2 simulator and an accompanying dataset.\nThe dataset contains trajectories generated on a range of robotics tasks with\nlanguage and visual annotations as well as multi-modal prompts as task\nspecification. The suite includes a curriculum of tasks with three levels of\ncompositional understanding, starting with simple tasks requiring basic motor\nskills. We benchmark multiple different VLM baselines on ClevrSkills and show\nthat even after being pre-trained on large numbers of tasks, these models fail\non compositional reasoning in robotics tasks.\n","authors":["Sanjay Haresh","Daniel Dijkman","Apratim Bhattacharyya","Roland Memisevic"],"pdf_url":"https://arxiv.org/pdf/2411.09052v1.pdf","comment":"To appear at NeurIPS 2024 (D&B track)"},{"id":"http://arxiv.org/abs/2411.09047v1","updated":"2024-11-13T22:04:19Z","published":"2024-11-13T22:04:19Z","title":"Anomaly Detection in Large-Scale Cloud Systems: An Industry Case and\n  Dataset","summary":"  As Large-Scale Cloud Systems (LCS) become increasingly complex, effective\nanomaly detection is critical for ensuring system reliability and performance.\nHowever, there is a shortage of large-scale, real-world datasets available for\nbenchmarking anomaly detection methods.\n  To address this gap, we introduce a new high-dimensional dataset from IBM\nCloud, collected over 4.5 months from the IBM Cloud Console. This dataset\ncomprises 39,365 rows and 117,448 columns of telemetry data. Additionally, we\ndemonstrate the application of machine learning models for anomaly detection\nand discuss the key challenges faced in this process.\n  This study and the accompanying dataset provide a resource for researchers\nand practitioners in cloud system monitoring. It facilitates more efficient\ntesting of anomaly detection methods in real-world data, helping to advance the\ndevelopment of robust solutions to maintain the health and performance of\nlarge-scale cloud infrastructures.\n","authors":["Mohammad Saiful Islam","Mohamed Sami Rakha","William Pourmajidi","Janakan Sivaloganathan","John Steinbacher","Andriy Miranskyy"],"pdf_url":"https://arxiv.org/pdf/2411.09047v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06635v2","updated":"2024-11-13T21:20:06Z","published":"2024-11-11T00:10:48Z","title":"Mixed Effects Deep Learning for the interpretable analysis of single\n  cell RNA sequencing data by quantifying and visualizing batch effects","summary":"  Single-cell RNA sequencing (scRNA-seq) data are often confounded by technical\nor biological batch effects. Existing deep learning models mitigate these\neffects but often discard batch-specific information, potentially losing\nvaluable biological insights. We propose a Mixed Effects Deep Learning (MEDL)\nautoencoder framework that separately models batch-invariant (fixed effects)\nand batch-specific (random effects) components. By decoupling batch-invariant\nbiological states from batch variations, our framework integrates both into\npredictive models. Our approach also generates 2D visualizations of how the\nsame cell appears across batches, enhancing interpretability. Retaining both\nfixed and random effect latent spaces improves classification accuracy.\n  We applied our framework to three datasets spanning the cardiovascular system\n(Healthy Heart), Autism Spectrum Disorder (ASD), and Acute Myeloid Leukemia\n(AML). With 147 batches in the Healthy Heart dataset, far exceeding typical\nnumbers, we tested our framework's ability to handle many batches. In the ASD\ndataset, our approach captured donor heterogeneity between autistic and healthy\nindividuals. In the AML dataset, it distinguished donor heterogeneity despite\nmissing cell types and diseased donors exhibiting both healthy and malignant\ncells. These results highlight our framework's ability to characterize fixed\nand random effects, enhance batch effect visualization, and improve prediction\naccuracy across diverse datasets.\n","authors":["Aixa X. Andrade","Son Nguyen","Albert Montillo"],"pdf_url":"https://arxiv.org/pdf/2411.06635v2.pdf","comment":"Main manuscript: 29 pages, including 10 figures and 8 tables.\n  Supplemental material: 17 pages"},{"id":"http://arxiv.org/abs/2411.09027v1","updated":"2024-11-13T21:09:55Z","published":"2024-11-13T21:09:55Z","title":"Transformer-based Time-Series Biomarker Discovery for COPD Diagnosis","summary":"  Chronic Obstructive Pulmonary Disorder (COPD) is an irreversible and\nprogressive disease which is highly heritable. Clinically, COPD is defined\nusing the summary measures derived from a spirometry test but these are not\nalways adequate. Here we show that using the high-dimensional raw spirogram can\nprovide a richer signal compared to just using the summary measures. We design\na transformer-based deep learning technique to process the raw spirogram values\nalong with demographic information and predict clinically-relevant endpoints\nrelated to COPD. Our method is able to perform better than prior works while\nbeing more computationally efficient. Using the weights learned by the model,\nwe make the framework more interpretable by identifying parts of the spirogram\nthat are important for the model predictions. Pairing up with a board-certified\npulmonologist, we also provide clinical insights into the different aspects of\nthe spirogram and show that the explanations obtained from the model align with\nunderlying medical knowledge.\n","authors":["Soham Gadgil","Joshua Galanter","Mohammadreza Negahdar"],"pdf_url":"https://arxiv.org/pdf/2411.09027v1.pdf","comment":"Accepted as a workshop paper to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09018v1","updated":"2024-11-13T20:50:04Z","published":"2024-11-13T20:50:04Z","title":"Bridging the Visual Gap: Fine-Tuning Multimodal Models with\n  Knowledge-Adapted Captions","summary":"  Recent research increasingly focuses on training vision-language models\n(VLMs) with long, detailed image captions. However, small-scale VLMs often\nstruggle to balance the richness of these captions with the risk of\nhallucinating content during fine-tuning. In this paper, we explore how well\nVLMs adapt to such captions. To quantify caption quality, we propose Decomposed\nNLI (DNLI), an evaluation framework that breaks down generated captions into\nindividual propositions, assessing each in isolation. This fine-grained\nanalysis reveals a critical balance between capturing descriptive details and\npreventing hallucinations. Our findings show that simply reducing caption\ncomplexity or employing standard data curation techniques does not effectively\nresolve this issue. To tackle this challenge, we introduce Knowledge Adapted\n(KnowAda) fine-tuning, a data-centric approach that automatically adapts\ntraining data with the model's existing knowledge and visual understanding.\nKnowAda minimizes hallucinations while preserving high descriptiveness. We\nvalidate this approach across several small-scale VLMs (up to 7B parameters)\nand dense caption datasets, demonstrating that KnowAda effectively balances\nhallucination reduction and descriptiveness. Our results show that KnowAda\noutperforms various baselines in both automatic metrics and human evaluations.\nWe will release our code and models.\n","authors":["Moran Yanuka","Assaf Ben Kish","Yonatan Bitton","Idan Szpektor","Raja Giryes"],"pdf_url":"https://arxiv.org/pdf/2411.09018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00759v2","updated":"2024-11-13T20:48:26Z","published":"2024-11-01T17:35:09Z","title":"Minibatch Optimal Transport and Perplexity Bound Estimation in Discrete\n  Flow Matching","summary":"  Outperforming autoregressive models on categorical data distributions, such\nas textual data, remains challenging for continuous diffusion and flow models.\nDiscrete flow matching, a recent framework for modeling categorical data, has\nshown competitive performance with autoregressive models. Despite its\nsimilarities with continuous flow matching, the rectification strategy applied\nin the continuous version does not directly extend to the discrete one due to\nthe inherent stochasticity of discrete paths. This limitation necessitates\nexploring alternative methods to minimize state transitions during generation.\nTo address this, we propose a dynamic-optimal-transport-like minimization\nobjective for discrete flows with convex interpolants and derive its equivalent\nKantorovich formulation. The latter defines transport cost solely in terms of\ninter-state similarity and is optimized using a minibatch strategy. Another\nlimitation we address in the discrete flow framework is model evaluation.\nUnlike continuous flows, wherein the instantaneous change of variables enables\ndensity estimation, discrete models lack a similar mechanism due to the\ninherent non-determinism and discontinuity of their paths. To alleviate this\nissue, we propose an upper bound on the perplexity of discrete flow models,\nenabling performance evaluation and comparison with other methods.\n","authors":["Etrit Haxholli","Yeti Z. Gürbüz","Oğul Can","Eli Waxman"],"pdf_url":"https://arxiv.org/pdf/2411.00759v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09009v1","updated":"2024-11-13T20:30:15Z","published":"2024-11-13T20:30:15Z","title":"Cut Your Losses in Large-Vocabulary Language Models","summary":"  As language models grow ever larger, so do their vocabularies. This has\nshifted the memory footprint of LLMs during training disproportionately to one\nsingle layer: the cross-entropy in the loss computation. Cross-entropy builds\nup a logit matrix with entries for each pair of input tokens and vocabulary\nitems and, for small models, consumes an order of magnitude more memory than\nthe rest of the LLM combined. We propose Cut Cross-Entropy (CCE), a method that\ncomputes the cross-entropy loss without materializing the logits for all tokens\ninto global memory. Rather, CCE only computes the logit for the correct token\nand evaluates the log-sum-exp over all logits on the fly. We implement a custom\nkernel that performs the matrix multiplications and the log-sum-exp reduction\nover the vocabulary in flash memory, making global memory consumption for the\ncross-entropy computation negligible. This has a dramatic effect. Taking the\nGemma 2 (2B) model as an example, CCE reduces the memory footprint of the loss\ncomputation from 24 GB to 1 MB, and the total training-time memory consumption\nof the classifier head from 28 GB to 1 GB. To improve the throughput of CCE, we\nleverage the inherent sparsity of softmax and propose to skip elements of the\ngradient computation that have a negligible (i.e., below numerical precision)\ncontribution to the gradient. Experiments demonstrate that the dramatic\nreduction in memory consumption is accomplished without sacrificing training\nspeed or convergence.\n","authors":["Erik Wijmans","Brody Huval","Alexander Hertzberg","Vladlen Koltun","Philipp Krähenbühl"],"pdf_url":"https://arxiv.org/pdf/2411.09009v1.pdf","comment":"Code is available at https://github.com/apple/ml-cross-entropy"},{"id":"http://arxiv.org/abs/2401.02501v3","updated":"2024-11-13T20:30:04Z","published":"2024-01-04T19:25:00Z","title":"A metric embedding kernel for live cell microscopy signaling patterns","summary":"  Live cell microscopy captures 5-D $(x,y,z,channel,time)$ movies that display\npatterns of cellular motion and signaling dynamics. We present here a metric\nkernel function for spatiotemporal patterns of cell signaling dynamics in 5-D\nlive cell microscopy movies unique in requiring no a priori knowledge of\nexpected pattern dynamics, and no training data. The approach uses Kolmogorov\ncomplexity theory to compute a metric distance between movies and to measure\nthe meaningful information among subsets of movies. Cell signaling kymographs\nstore at each spatiotemporal cell centroid the cell signaling state, or a\nfunctional output such as velocity. Patterns of similarity are identified via\nthe metric normalized compression distance (NCD). The NCD is a reproducing\nkernel for a Hilbert space that represents the input cell signaling kymographs\nas points in a low dimensional embedding that optimally captures the pattern\nsimilarity identified by the NCD throughout the space. The only parameter is\nthe expected cell radii ($\\mu m$). A new formulation of the cluster structure\nfunction optimally estimates the meaningful information captured by the\nembedding. Also presented is the cell signaling structure function (SSF), a\nKolmogorov structure function that optimally measures cell signaling state as\nnuclear intensity w.r.t. surrounding cytoplasm, a significant improvement\ncompared to the current state-of-the-art cytonuclear ratio. Results are\npresented quantifying the impact of ERK and AKT signaling between different\noncogenic mutations, and by the relation between ERK signaling and cellular\nvelocity patterns for movies of 2-D monolayers of human breast epithelial\n(MCF10A) cells, 3-D MCF10A spheroids under optogenetic manipulation of ERK, and\nhuman induced pluripotent stem cells.\n","authors":["Layton Aho","Mark Winter","Marc DeCarlo","Agne Frismantiene","Yannick Blum","Paolo Armando Gagliardi","Olivier Pertz","Andrew R. Cohen"],"pdf_url":"https://arxiv.org/pdf/2401.02501v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20367v2","updated":"2024-11-13T20:29:35Z","published":"2024-07-29T18:31:42Z","title":"Mixed Newton Method for Optimization in Complex Spaces","summary":"  In this paper, we modify and apply the recently introduced Mixed Newton\nMethod, which is originally designed for minimizing real-valued functions of\ncomplex variables, to the minimization of real-valued functions of real\nvariables by extending the functions to complex space. We show that arbitrary\nregularizations preserve the favorable local convergence properties of the\nmethod, and construct a special type of regularization used to prevent\nconvergence to complex minima. We compare several variants of the method\napplied to training neural networks with real and complex parameters.\n","authors":["Nikita Yudin","Roland Hildebrand","Sergey Bakhurin","Alexander Degtyarev","Anna Lisachenko","Ilya Kuruzov","Andrei Semenov","Mohammad Alkousa"],"pdf_url":"https://arxiv.org/pdf/2407.20367v2.pdf","comment":"16 pages, 7 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.14775v2","updated":"2024-11-13T20:28:24Z","published":"2024-06-20T22:57:38Z","title":"Machine Learning Global Simulation of Nonlocal Gravity Wave Propagation","summary":"  Global climate models typically operate at a grid resolution of hundreds of\nkilometers and fail to resolve atmospheric mesoscale processes, e.g., clouds,\nprecipitation, and gravity waves (GWs). Model representation of these processes\nand their sources is essential to the global circulation and planetary energy\nbudget, but subgrid scale contributions from these processes are often only\napproximately represented in models using parameterizations. These\nparameterizations are subject to approximations and idealizations, which limit\ntheir capability and accuracy. The most drastic of these approximations is the\n\"single-column approximation\" which completely neglects the horizontal\nevolution of these processes, resulting in key biases in current climate\nmodels. With a focus on atmospheric GWs, we present the first-ever global\nsimulation of atmospheric GW fluxes using machine learning (ML) models trained\non the WINDSET dataset to emulate global GW emulation in the atmosphere, as an\nalternative to traditional single-column parameterizations. Using an Attention\nU-Net-based architecture trained on globally resolved GW momentum fluxes, we\nillustrate the importance and effectiveness of global nonlocality, when\nsimulating GWs using data-driven schemes.\n","authors":["Aman Gupta","Aditi Sheshadri","Sujit Roy","Vishal Gaur","Manil Maskey","Rahul Ramachandran"],"pdf_url":"https://arxiv.org/pdf/2406.14775v2.pdf","comment":"International Conference on Machine Learning 2024"},{"id":"http://arxiv.org/abs/2406.03230v4","updated":"2024-11-13T20:18:19Z","published":"2024-06-05T13:06:33Z","title":"Defending Large Language Models Against Attacks With Residual Stream\n  Activation Analysis","summary":"  The widespread adoption of Large Language Models (LLMs), exemplified by\nOpenAI's ChatGPT, brings to the forefront the imperative to defend against\nadversarial threats on these models. These attacks, which manipulate an LLM's\noutput by introducing malicious inputs, undermine the model's integrity and the\ntrust users place in its outputs. In response to this challenge, our paper\npresents an innovative defensive strategy, given white box access to an LLM,\nthat harnesses residual activation analysis between transformer layers of the\nLLM. We apply a novel methodology for analyzing distinctive activation patterns\nin the residual streams for attack prompt classification. We curate multiple\ndatasets to demonstrate how this method of classification has high accuracy\nacross multiple types of attack scenarios, including our newly-created attack\ndataset. Furthermore, we enhance the model's resilience by integrating safety\nfine-tuning techniques for LLMs in order to measure its effect on our\ncapability to detect attacks. The results underscore the effectiveness of our\napproach in enhancing the detection and mitigation of adversarial inputs,\nadvancing the security framework within which LLMs operate.\n","authors":["Amelia Kawasaki","Andrew Davis","Houssam Abbas"],"pdf_url":"https://arxiv.org/pdf/2406.03230v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09003v1","updated":"2024-11-13T20:12:55Z","published":"2024-11-13T20:12:55Z","title":"Refusal in LLMs is an Affine Function","summary":"  We propose affine concept editing (ACE) as an approach for steering language\nmodels' behavior by intervening directly in activations. We begin with an\naffine decomposition of model activation vectors and show that prior methods\nfor steering model behavior correspond to subsets of terms of this\ndecomposition. We then provide a derivation of ACE and test it on refusal using\nLlama 3 8B and Hermes Eagle RWKV v5. ACE ultimately combines affine subspace\nprojection and activation addition to reliably control the model's refusal\nresponses across prompt types. We evaluate the results using LLM-based scoring\non a collection of harmful and harmless prompts. Our experiments demonstrate\nthat ACE consistently achieves more precise control over model behavior and\ngeneralizes to models where directional ablation via affine subspace projection\nalone produces incoherent outputs. Code for reproducing our results is\navailable at https://github.com/EleutherAI/steering-llama3 .\n","authors":["Thomas Marshall","Adam Scherlis","Nora Belrose"],"pdf_url":"https://arxiv.org/pdf/2411.09003v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08998v1","updated":"2024-11-13T19:37:49Z","published":"2024-11-13T19:37:49Z","title":"Microfoundation Inference for Strategic Prediction","summary":"  Often in prediction tasks, the predictive model itself can influence the\ndistribution of the target variable, a phenomenon termed performative\nprediction. Generally, this influence stems from strategic actions taken by\nstakeholders with a vested interest in predictive models. A key challenge that\nhinders the widespread adaptation of performative prediction in machine\nlearning is that practitioners are generally unaware of the social impacts of\ntheir predictions. To address this gap, we propose a methodology for learning\nthe distribution map that encapsulates the long-term impacts of predictive\nmodels on the population. Specifically, we model agents' responses as a\ncost-adjusted utility maximization problem and propose estimates for said cost.\nOur approach leverages optimal transport to align pre-model exposure (ex ante)\nand post-model exposure (ex post) distributions. We provide a rate of\nconvergence for this proposed estimate and assess its quality through empirical\ndemonstrations on a credit-scoring dataset.\n","authors":["Daniele Bracale","Subha Maity","Felipe Maia Polo","Seamus Somerstep","Moulinath Banerjee","Yuekai Sun"],"pdf_url":"https://arxiv.org/pdf/2411.08998v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23463v2","updated":"2024-11-13T19:34:22Z","published":"2024-10-30T21:08:07Z","title":"MDCure: A Scalable Pipeline for Multi-Document Instruction-Following","summary":"  Multi-document (MD) processing is crucial for LLMs to handle real-world tasks\nsuch as summarization and question-answering across large sets of documents.\nWhile LLMs have improved at processing long inputs, MD contexts still present\nchallenges, such as managing inter-document dependencies, redundancy, and\nincoherent structures. We introduce MDCure, a scalable and effective\nfine-tuning pipeline to enhance the MD capabilities of LLMs without the\ncomputational cost of pre-training or reliance on human annotated data. MDCure\nis based on generation of high-quality synthetic MD instruction data from sets\nof related articles via targeted prompts. We further introduce MDCureRM, a\nmulti-objective reward model which filters generated data based on their\ntraining utility for MD settings. With MDCure, we fine-tune a variety of LLMs,\nfrom the FlanT5, Qwen2, and LLAMA3.1 model families, up to 70B parameters in\nsize. Extensive evaluations on a wide range of MD and long-context benchmarks\nspanning various tasks show MDCure consistently improves performance over\npre-trained baselines and over corresponding base models by up to 75.5%. Our\ncode, datasets, and models are available at https://github.com/yale-nlp/MDCure.\n","authors":["Gabrielle Kaili-May Liu","Bowen Shi","Avi Caciularu","Idan Szpektor","Arman Cohan"],"pdf_url":"https://arxiv.org/pdf/2410.23463v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08993v1","updated":"2024-11-13T19:33:47Z","published":"2024-11-13T19:33:47Z","title":"Parameter Inference via Differentiable Diffusion Bridge Importance\n  Sampling","summary":"  We introduce a methodology for performing parameter inference in\nhigh-dimensional, non-linear diffusion processes. We illustrate its\napplicability for obtaining insights into the evolution of and relationships\nbetween species, including ancestral state reconstruction. Estimation is\nperformed by utilising score matching to approximate diffusion bridges, which\nare subsequently used in an importance sampler to estimate log-likelihoods. The\nentire setup is differentiable, allowing gradient ascent on approximated\nlog-likelihoods. This allows both parameter inference and diffusion mean\nestimation. This novel, numerically stable, score matching-based parameter\ninference framework is presented and demonstrated on biological two- and\nthree-dimensional morphometry data.\n","authors":["Nicklas Boserup","Gefan Yang","Michael Lind Severinsen","Christy Anna Hipsley","Stefan Sommer"],"pdf_url":"https://arxiv.org/pdf/2411.08993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08987v1","updated":"2024-11-13T19:22:34Z","published":"2024-11-13T19:22:34Z","title":"Non-Euclidean High-Order Smooth Convex Optimization","summary":"  We develop algorithms for the optimization of convex objectives that have\nH\\\"older continuous $q$-th derivatives with respect to a $p$-norm by using a\n$q$-th order oracle, for $p, q \\geq 1$. We can also optimize other structured\nfunctions. We do this by developing a non-Euclidean inexact accelerated\nproximal point method that makes use of an inexact uniformly convex\nregularizer. We also provide nearly matching lower bounds for any deterministic\nalgorithm that interacts with the function via a local oracle.\n","authors":["Juan Pablo Contreras","Cristóbal Guzmán","David Martínez-Rubio"],"pdf_url":"https://arxiv.org/pdf/2411.08987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08982v1","updated":"2024-11-13T19:18:08Z","published":"2024-11-13T19:18:08Z","title":"Lynx: Enabling Efficient MoE Inference through Dynamic Batch-Aware\n  Expert Selection","summary":"  Mixture-of-Experts (MoE) architectures have recently gained popularity in\nenabling efficient scaling of large language models. However, we uncover a\nfundamental tension: while MoEs are designed for selective expert activation,\nproduction serving requires request batching, which forces the activation of\nall experts and negates MoE's efficiency benefits during the decode phase. We\npresent Lynx, a system that enables efficient MoE inference through dynamic,\nbatch-aware expert selection. Our key insight is that expert importance varies\nsignificantly across tokens and inference phases, creating opportunities for\nruntime optimization. Lynx leverages this insight through a lightweight\nframework that dynamically reduces active experts while preserving model\naccuracy. Our evaluations show that Lynx achieves up to 1.55x reduction in\ninference latency while maintaining negligible accuracy loss from baseline\nmodel across complex code generation and mathematical reasoning tasks.\n","authors":["Vima Gupta","Kartik Sinha","Ada Gavrilovska","Anand Padmanabha Iyer"],"pdf_url":"https://arxiv.org/pdf/2411.08982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08968v1","updated":"2024-11-13T19:02:36Z","published":"2024-11-13T19:02:36Z","title":"Sparse Upcycling: Inference Inefficient Finetuning","summary":"  Small, highly trained, open-source large language models are widely used due\nto their inference efficiency, but further improving their quality remains a\nchallenge. Sparse upcycling is a promising approach that transforms a\npretrained dense model into a Mixture-of-Experts (MoE) architecture, increasing\nthe model's parameter count and quality. In this work, we compare the\neffectiveness of sparse upcycling against continued pretraining (CPT) across\ndifferent model sizes, compute budgets, and pretraining durations. Our\nexperiments show that sparse upcycling can achieve better quality, with\nimprovements of over 20% relative to CPT in certain scenarios. However, this\ncomes with a significant inference cost, leading to 40% slowdowns in\nhigh-demand inference settings for larger models. Our findings highlight the\ntrade-off between model quality and inference efficiency, offering insights for\npractitioners seeking to balance model quality and deployment constraints.\n","authors":["Sasha Doubov","Nikhil Sardana","Vitaliy Chiley"],"pdf_url":"https://arxiv.org/pdf/2411.08968v1.pdf","comment":"12 pages, 4 figures, To appear in the 4th NeurIPS Workshop on\n  Efficient Natural Language and Speech Processing (ENLSP), 2024"},{"id":"http://arxiv.org/abs/2411.08954v1","updated":"2024-11-13T19:00:02Z","published":"2024-11-13T19:00:02Z","title":"Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply\n  Better Samples","summary":"  Although diffusion models can generate remarkably high-quality samples, they\nare intrinsically bottlenecked by their expensive iterative sampling procedure.\nConsistency models (CMs) have recently emerged as a promising diffusion model\ndistillation method, reducing the cost of sampling by generating high-fidelity\nsamples in just a few iterations. Consistency model distillation aims to solve\nthe probability flow ordinary differential equation (ODE) defined by an\nexisting diffusion model. CMs are not directly trained to minimize error\nagainst an ODE solver, rather they use a more computationally tractable\nobjective. As a way to study how effectively CMs solve the probability flow\nODE, and the effect that any induced error has on the quality of generated\nsamples, we introduce Direct CMs, which \\textit{directly} minimize this error.\nIntriguingly, we find that Direct CMs reduce the ODE solving error compared to\nCMs but also result in significantly worse sample quality, calling into\nquestion why exactly CMs work well in the first place. Full code is available\nat: https://github.com/layer6ai-labs/direct-cms.\n","authors":["Noël Vouitsis","Rasa Hosseinzadeh","Brendan Leigh Ross","Valentin Villecroze","Satya Krishna Gorti","Jesse C. Cresswell","Gabriel Loaiza-Ganem"],"pdf_url":"https://arxiv.org/pdf/2411.08954v1.pdf","comment":"NeurIPS 2024 ATTRIB Workshop"},{"id":"http://arxiv.org/abs/2411.05196v2","updated":"2024-11-13T18:58:46Z","published":"2024-11-07T21:43:29Z","title":"Explainable AI through a Democratic Lens: DhondtXAI for Proportional\n  Feature Importance Using the D'Hondt Method","summary":"  In democratic societies, electoral systems play a crucial role in translating\npublic preferences into political representation. Among these, the D'Hondt\nmethod is widely used to ensure proportional representation, balancing fair\nrepresentation with governmental stability. Recently, there has been a growing\ninterest in applying similar principles of proportional representation to\nenhance interpretability in machine learning, specifically in Explainable AI\n(XAI). This study investigates the integration of D'Hondt-based voting\nprinciples in the DhondtXAI method, which leverages resource allocation\nconcepts to interpret feature importance within AI models. Through a comparison\nof SHAP (Shapley Additive Explanations) and DhondtXAI, we evaluate their\neffectiveness in feature attribution within CatBoost and XGBoost models for\nbreast cancer and diabetes prediction, respectively. The DhondtXAI approach\nallows for alliance formation and thresholding to enhance interpretability,\nrepresenting feature importance as seats in a parliamentary view. Statistical\ncorrelation analyses between SHAP values and DhondtXAI allocations support the\nconsistency of interpretations, demonstrating DhondtXAI's potential as a\ncomplementary tool for understanding feature importance in AI models. The\nresults highlight that integrating electoral principles, such as proportional\nrepresentation and alliances, into AI explainability can improve user\nunderstanding, especially in high-stakes fields like healthcare.\n","authors":["Turker Berk Donmez"],"pdf_url":"https://arxiv.org/pdf/2411.05196v2.pdf","comment":null},{"id":"http://arxiv.org/abs/1902.00615v6","updated":"2024-11-13T18:32:53Z","published":"2019-02-02T01:52:53Z","title":"Confidence Trigger Detection: Accelerating Real-time\n  Tracking-by-detection Systems","summary":"  Real-time object tracking necessitates a delicate balance between speed and\naccuracy, a challenge exacerbated by the computational demands of deep learning\nmethods. In this paper, we propose Confidence-Triggered Detection (CTD), an\ninnovative approach that strategically bypasses object detection for frames\nclosely resembling intermediate states, leveraging tracker confidence scores.\nCTD not only enhances tracking speed but also preserves accuracy, surpassing\nexisting tracking algorithms. Through extensive evaluation across various\ntracker confidence thresholds, we identify an optimal trade-off between\ntracking speed and accuracy, providing crucial insights for parameter\nfine-tuning and enhancing CTD's practicality in real-world scenarios. Our\nexperiments across diverse detection models underscore the robustness and\nversatility of the CTD framework, demonstrating its potential to enable\nreal-time tracking in resource-constrained environments.\n","authors":["Zhicheng Ding","Zhixin Lai","Siyang Li","Panfeng Li","Qikai Yang","Edward Wong"],"pdf_url":"https://arxiv.org/pdf/1902.00615v6.pdf","comment":"Accepted by 2024 5th International Conference on Electronic\n  Communication and Artificial Intelligence"}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.08730v1","updated":"2024-11-13T16:14:13Z","published":"2024-11-13T16:14:13Z","title":"3D Modelling to Address Pandemic Challenges: A Project-Based Learning\n  Methodology","summary":"  The use of 3D modelling in medical education is a revolutionary tool during\nthe learning process. In fact, this type of technology enables a more\ninteractive teaching approach, making information retention more effective and\nenhancing students' understanding. 3D modelling allows for the creation of\nprecise representations of the human body, as well as interaction with\nthree-dimensional models, giving students a better spatial understanding of the\ndifferent organs and systems and enabling simulations of surgical and technical\nprocedures. This way, medical education is enriched with a more realistic and\nsafe educational experience. The goal is to understand whether, when students\nand schools are challenged, they play an important role in addressing health\nissues in their community. School-led projects are directed towards educational\nscenarios that emphasize STEM education, tackling relevant public health\nproblems through open-school initiatives. By implementing an educational\nscenario focused on 3D modelling and leveraging technology, we aim to raise\ncommunity awareness on public health issues.\n","authors":["Tânia Rocha","Ana Ribeiro","Joana Oliveira","Ricardo Nunes","Diana Carvalho","Hugo Paredes","Paulo Martins"],"pdf_url":"https://arxiv.org/pdf/2411.08730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08409v1","updated":"2024-11-13T07:55:41Z","published":"2024-11-13T07:55:41Z","title":"DiVR: incorporating context from diverse VR scenes for human trajectory\n  prediction","summary":"  Virtual environments provide a rich and controlled setting for collecting\ndetailed data on human behavior, offering unique opportunities for predicting\nhuman trajectories in dynamic scenes. However, most existing approaches have\noverlooked the potential of these environments, focusing instead on static\ncontexts without considering userspecific factors. Employing the CREATTIVE3D\ndataset, our work models trajectories recorded in virtual reality (VR) scenes\nfor diverse situations including road-crossing tasks with user interactions and\nsimulated visual impairments. We propose Diverse Context VR Human Motion\nPrediction (DiVR), a cross-modal transformer based on the Perceiver\narchitecture that integrates both static and dynamic scene context using a\nheterogeneous graph convolution network. We conduct extensive experiments\ncomparing DiVR against existing architectures including MLP, LSTM, and\ntransformers with gaze and point cloud context. Additionally, we also stress\ntest our model's generalizability across different users, tasks, and scenes.\nResults show that DiVR achieves higher accuracy and adaptability compared to\nother models and to static graphs. This work highlights the advantages of using\nVR datasets for context-aware human trajectory modeling, with potential\napplications in enhancing user experiences in the metaverse. Our source code is\npublicly available at https://gitlab.inria.fr/ffrancog/creattive3d-divr-model.\n","authors":["Franz Franco Gallo","Hui-Yin Wu","Lucile Sassatelli"],"pdf_url":"https://arxiv.org/pdf/2411.08409v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08334v1","updated":"2024-11-13T04:32:58Z","published":"2024-11-13T04:32:58Z","title":"Enhancing Multimodal Query Representation via Visual Dialogues for\n  End-to-End Knowledge Retrieval","summary":"  Existing multimodal retrieval systems often rely on disjointed models for\nimage comprehension, such as object detectors and caption generators, leading\nto cumbersome implementations and training processes. To overcome this\nlimitation, we propose an end-to-end retrieval system, Ret-XKnow, to endow a\ntext retriever with the ability to understand multimodal queries via dynamic\nmodality interaction. Ret-XKnow leverages a partial convolution mechanism to\nfocus on visual information relevant to the given textual query, thereby\nenhancing multimodal query representations. To effectively learn multimodal\ninteraction, we also introduce the Visual Dialogue-to-Retrieval (ViD2R) dataset\nautomatically constructed from visual dialogue datasets. Our dataset\nconstruction process ensures that the dialogues are transformed into suitable\ninformation retrieval tasks using a text retriever. We demonstrate that our\napproach not only significantly improves retrieval performance in zero-shot\nsettings but also achieves substantial improvements in fine-tuning scenarios.\nOur code is publicly available: https://github.com/yeongjoonJu/Ret_XKnow.\n","authors":["Yeong-Joon Ju","Ho-Joong Kim","Seong-Whan Lee"],"pdf_url":"https://arxiv.org/pdf/2411.08334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08307v1","updated":"2024-11-13T03:14:10Z","published":"2024-11-13T03:14:10Z","title":"PerceiverS: A Multi-Scale Perceiver with Effective Segmentation for\n  Long-Term Expressive Symbolic Music Generation","summary":"  Music generation has progressed significantly, especially in the domain of\naudio generation. However, generating symbolic music that is both\nlong-structured and expressive remains a significant challenge. In this paper,\nwe propose PerceiverS (Segmentation and Scale), a novel architecture designed\nto address this issue by leveraging both Effective Segmentation and Multi-Scale\nattention mechanisms. Our approach enhances symbolic music generation by\nsimultaneously learning long-term structural dependencies and short-term\nexpressive details. By combining cross-attention and self-attention in a\nMulti-Scale setting, PerceiverS captures long-range musical structure while\npreserving performance nuances. The proposed model, evaluated on datasets like\nMaestro, demonstrates improvements in generating coherent and diverse music\nwith both structural consistency and expressive variation. The project demos\nand the generated music samples can be accessed through the link:\nhttps://perceivers.github.io.\n","authors":["Yungang Yi","Weihua Li","Matthew Kuo","Quan Bai"],"pdf_url":"https://arxiv.org/pdf/2411.08307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09053v1","updated":"2024-11-13T22:23:28Z","published":"2024-11-13T22:23:28Z","title":"Information Need in Metaverse Recordings - A Field Study","summary":"  Metaverse Recordings (MVRs) represent an emerging and underexplored media\ntype within the field of Multimedia Information Retrieval (MMIR). This paper\npresents findings from a field study aimed at understanding the users\ninformation needs and search behaviors specific to MVR retrieval. By conducting\nand analyzing expert interviews, the study identifies application scenarios and\nhighlights challenges in retrieving multimedia content from the metaverse. The\nresults reveal existing application scenarios of MVRs and confirm the relevance\nof capturing time-series data from the graphical rendering process and related\ninput-output devices, which are also highly relevant to user needs.\nFurthermore, the study provides a foundation for developing retrieval systems\ntailored to MVRs by defining use cases, user stereotypes, and specific\nrequirements for MVR Retrieval systems. The findings contribute to a better\nunderstanding of information search behaviors in MVR Retrieval and pave the way\nfor future research and system design in this field.\n","authors":["Patrick Steinert","Jan Mischkies","Stefan Wagenpfeil","Ingo Frommholz","Matthias L. Hemmje"],"pdf_url":"https://arxiv.org/pdf/2411.09053v1.pdf","comment":"12 pages, 3 Figures, 8 Tables"},{"id":"http://arxiv.org/abs/2411.09053v1","updated":"2024-11-13T22:23:28Z","published":"2024-11-13T22:23:28Z","title":"Information Need in Metaverse Recordings -- A Field Study","summary":"  Metaverse Recordings (MVRs) represent an emerging and underexplored media\ntype within the field of Multimedia Information Retrieval (MMIR). This paper\npresents findings from a field study aimed at understanding the users\ninformation needs and search behaviors specific to MVR retrieval. By conducting\nand analyzing expert interviews, the study identifies application scenarios and\nhighlights challenges in retrieving multimedia content from the metaverse. The\nresults reveal existing application scenarios of MVRs and confirm the relevance\nof capturing time-series data from the graphical rendering process and related\ninput-output devices, which are also highly relevant to user needs.\nFurthermore, the study provides a foundation for developing retrieval systems\ntailored to MVRs by defining use cases, user stereotypes, and specific\nrequirements for MVR Retrieval systems. The findings contribute to a better\nunderstanding of information search behaviors in MVR Retrieval and pave the way\nfor future research and system design in this field.\n","authors":["Patrick Steinert","Jan Mischkies","Stefan Wagenpfeil","Ingo Frommholz","Matthias L. Hemmje"],"pdf_url":"https://arxiv.org/pdf/2411.09053v1.pdf","comment":"12 pages, 3 Figures, 8 Tables"}]},"2024-11-14T00:00:00Z":{"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2411.09703v1","updated":"2024-11-14T18:59:57Z","published":"2024-11-14T18:59:57Z","title":"MagicQuill: An Intelligent Interactive Image Editing System","summary":"  Image editing involves a variety of complex tasks and requires efficient and\nprecise manipulation techniques. In this paper, we present MagicQuill, an\nintegrated image editing system that enables swift actualization of creative\nideas. Our system features a streamlined yet functionally robust interface,\nallowing for the articulation of editing operations (e.g., inserting elements,\nerasing objects, altering color) with minimal input. These interactions are\nmonitored by a multimodal large language model (MLLM) to anticipate editing\nintentions in real time, bypassing the need for explicit prompt entry. Finally,\nwe apply a powerful diffusion prior, enhanced by a carefully learned two-branch\nplug-in module, to process editing requests with precise control. Experimental\nresults demonstrate the effectiveness of MagicQuill in achieving high-quality\nimage edits. Please visit https://magic-quill.github.io to try out our system.\n","authors":["Zichen Liu","Yue Yu","Hao Ouyang","Qiuyu Wang","Ka Leong Cheng","Wen Wang","Zhiheng Liu","Qifeng Chen","Yujun Shen"],"pdf_url":"https://arxiv.org/pdf/2411.09703v1.pdf","comment":"Code and demo available at https://magic-quill.github.io"},{"id":"http://arxiv.org/abs/2411.09702v1","updated":"2024-11-14T18:59:40Z","published":"2024-11-14T18:59:40Z","title":"On the Surprising Effectiveness of Attention Transfer for Vision\n  Transformers","summary":"  Conventional wisdom suggests that pre-training Vision Transformers (ViT)\nimproves downstream performance by learning useful representations. Is this\nactually true? We investigate this question and find that the features and\nrepresentations learned during pre-training are not essential. Surprisingly,\nusing only the attention patterns from pre-training (i.e., guiding how\ninformation flows between tokens) is sufficient for models to learn high\nquality features from scratch and achieve comparable downstream performance. We\nshow this by introducing a simple method called attention transfer, where only\nthe attention patterns from a pre-trained teacher ViT are transferred to a\nstudent, either by copying or distilling the attention maps. Since attention\ntransfer lets the student learn its own features, ensembling it with a\nfine-tuned teacher also further improves accuracy on ImageNet. We\nsystematically study various aspects of our findings on the sufficiency of\nattention maps, including distribution shift settings where they underperform\nfine-tuning. We hope our exploration provides a better understanding of what\npre-training accomplishes and leads to a useful alternative to the standard\npractice of fine-tuning\n","authors":["Alexander C. Li","Yuandong Tian","Beidi Chen","Deepak Pathak","Xinlei Chen"],"pdf_url":"https://arxiv.org/pdf/2411.09702v1.pdf","comment":"NeurIPS 2024. Code:\n  https://github.com/alexlioralexli/attention-transfer"},{"id":"http://arxiv.org/abs/2411.09693v1","updated":"2024-11-14T18:58:02Z","published":"2024-11-14T18:58:02Z","title":"CropCraft: Inverse Procedural Modeling for 3D Reconstruction of Crop\n  Plants","summary":"  The ability to automatically build 3D digital twins of plants from images has\ncountless applications in agriculture, environmental science, robotics, and\nother fields. However, current 3D reconstruction methods fail to recover\ncomplete shapes of plants due to heavy occlusion and complex geometries. In\nthis work, we present a novel method for 3D reconstruction of agricultural\ncrops based on optimizing a parametric model of plant morphology via inverse\nprocedural modeling. Our method first estimates depth maps by fitting a neural\nradiance field and then employs Bayesian optimization to estimate plant\nmorphological parameters that result in consistent depth renderings. The\nresulting 3D model is complete and biologically plausible. We validate our\nmethod on a dataset of real images of agricultural fields, and demonstrate that\nthe reconstructions can be used for a variety of monitoring and simulation\napplications.\n","authors":["Albert J. Zhai","Xinlei Wang","Kaiyuan Li","Zhao Jiang","Junxiong Zhou","Sheng Wang","Zhenong Jin","Kaiyu Guan","Shenlong Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09693v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2411.09691v1","updated":"2024-11-14T18:57:07Z","published":"2024-11-14T18:57:07Z","title":"Advancing Fine-Grained Visual Understanding with Multi-Scale Alignment\n  in Multi-Modal Models","summary":"  Multi-modal large language models (MLLMs) have achieved remarkable success in\nfine-grained visual understanding across a range of tasks. However, they often\nencounter significant challenges due to inadequate alignment for fine-grained\nknowledge, which restricts their ability to accurately capture local details\nand attain a comprehensive global perception. While recent advancements have\nfocused on aligning object expressions with grounding information, they\ntypically lack explicit integration of object images, which contain affluent\ninformation beyond mere texts or coordinates. To bridge this gap, we introduce\na novel fine-grained visual knowledge alignment method that effectively aligns\nand integrates multi-scale knowledge of objects, including texts, coordinates,\nand images. This innovative method is underpinned by our multi-scale\nfine-grained enhancement data synthesis pipeline, which provides over 300K\nessential training data to enhance alignment and improve overall performance.\nFurthermore, we present TinyGroundingGPT, a series of compact models optimized\nfor high-level alignments. With a scale of approximately 3B parameters,\nTinyGroundingGPT achieves outstanding results in grounding tasks while\ndelivering performance comparable to larger MLLMs in complex visual scenarios.\n","authors":["Wei Wang","Zhaowei Li","Qi Xu","Linfeng Li","YiQing Cai","Botian Jiang","Hang Song","Xingcan Hu","Pengyu Wang","Li Xiao"],"pdf_url":"https://arxiv.org/pdf/2411.09691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14022v3","updated":"2024-11-14T18:44:25Z","published":"2024-05-22T21:55:58Z","title":"I2I-Mamba: Multi-modal medical image synthesis via selective state space\n  modeling","summary":"  In recent years, deep learning models comprising transformer components have\npushed the performance envelope in medical image synthesis tasks. Contrary to\nconvolutional neural networks (CNNs) that use static, local filters,\ntransformers use self-attention mechanisms to permit adaptive, non-local\nfiltering to sensitively capture long-range context. However, this sensitivity\ncomes at the expense of substantial model complexity, which can compromise\nlearning efficacy particularly on relatively modest-sized imaging datasets.\nHere, we propose a novel adversarial model for multi-modal medical image\nsynthesis, I2I-Mamba, that leverages selective state space modeling (SSM) to\nefficiently capture long-range context while maintaining local precision. To do\nthis, I2I-Mamba injects channel-mixed Mamba (cmMamba) blocks in the bottleneck\nof a convolutional backbone. In cmMamba blocks, SSM layers are used to learn\ncontext across the spatial dimension and channel-mixing layers are used to\nlearn context across the channel dimension of feature maps. Comprehensive\ndemonstrations are reported for imputing missing images in multi-contrast MRI\nand MRI-CT protocols. Our results indicate that I2I-Mamba offers superior\nperformance against state-of-the-art CNN- and transformer-based methods in\nsynthesizing target-modality images.\n","authors":["Omer F. Atli","Bilal Kabas","Fuat Arslan","Mahmut Yurt","Onat Dalmaz","Tolga Çukur"],"pdf_url":"https://arxiv.org/pdf/2405.14022v3.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2401.03060v3","updated":"2024-11-14T18:09:39Z","published":"2024-01-05T20:32:40Z","title":"Super-resolution multi-contrast unbiased eye atlases with deep\n  probabilistic refinement","summary":"  Purpose: Eye morphology varies significantly across the population,\nespecially for the orbit and optic nerve. These variations limit the\nfeasibility and robustness of generalizing population-wise features of eye\norgans to an unbiased spatial reference.\n  Approach: To tackle these limitations, we propose a process for creating\nhigh-resolution unbiased eye atlases. First, to restore spatial details from\nscans with a low through-plane resolution compared to a high in-plane\nresolution, we apply a deep learning-based super-resolution algorithm. Then, we\ngenerate an initial unbiased reference with an iterative metric-based\nregistration using a small portion of subject scans. We register the remaining\nscans to this template and refine the template using an unsupervised deep\nprobabilistic approach that generates a more expansive deformation field to\nenhance the organ boundary alignment. We demonstrate this framework using\nmagnetic resonance images across four different tissue contrasts, generating\nfour atlases in separate spatial alignments.\n  Results: For each tissue contrast, we find a significant improvement using\nthe Wilcoxon signed-rank test in the average Dice score across four labeled\nregions compared to a standard registration framework consisting of rigid,\naffine, and deformable transformations. These results highlight the effective\nalignment of eye organs and boundaries using our proposed process.\n  Conclusions: By combining super-resolution preprocessing and deep\nprobabilistic models, we address the challenge of generating an eye atlas to\nserve as a standardized reference across a largely variable population.\n","authors":["Ho Hin Lee","Adam M. Saunders","Michael E. Kim","Samuel W. Remedios","Lucas W. Remedios","Yucheng Tang","Qi Yang","Xin Yu","Shunxing Bao","Chloe Cho","Louise A. Mawn","Tonia S. Rex","Kevin L. Schey","Blake E. Dewey","Jeffrey M. Spraggins","Jerry L. Prince","Yuankai Huo","Bennett A. Landman"],"pdf_url":"https://arxiv.org/pdf/2401.03060v3.pdf","comment":"Published in SPIE Journal of Medical Imaging\n  (https://doi.org/10.1117/1.JMI.11.6.064004). 27 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.09627v1","updated":"2024-11-14T17:54:43Z","published":"2024-11-14T17:54:43Z","title":"One-Shot Manipulation Strategy Learning by Making Contact Analogies","summary":"  We present a novel approach, MAGIC (manipulation analogies for generalizable\nintelligent contacts), for one-shot learning of manipulation strategies with\nfast and extensive generalization to novel objects. By leveraging a reference\naction trajectory, MAGIC effectively identifies similar contact points and\nsequences of actions on novel objects to replicate a demonstrated strategy,\nsuch as using different hooks to retrieve distant objects of different shapes\nand sizes. Our method is based on a two-stage contact-point matching process\nthat combines global shape matching using pretrained neural features with local\ncurvature analysis to ensure precise and physically plausible contact points.\nWe experiment with three tasks including scooping, hanging, and hooking\nobjects. MAGIC demonstrates superior performance over existing methods,\nachieving significant improvements in runtime speed and generalization to\ndifferent object categories. Website: https://magic-2024.github.io/ .\n","authors":["Yuyao Liu","Jiayuan Mao","Joshua Tenenbaum","Tomás Lozano-Pérez","Leslie Pack Kaelbling"],"pdf_url":"https://arxiv.org/pdf/2411.09627v1.pdf","comment":"CoRL LEAP Workshop, 2024"},{"id":"http://arxiv.org/abs/2411.09623v1","updated":"2024-11-14T17:47:54Z","published":"2024-11-14T17:47:54Z","title":"Vision-based Manipulation of Transparent Plastic Bags in Industrial\n  Setups","summary":"  This paper addresses the challenges of vision-based manipulation for\nautonomous cutting and unpacking of transparent plastic bags in industrial\nsetups, aligning with the Industry 4.0 paradigm. Industry 4.0, driven by data,\nconnectivity, analytics, and robotics, promises enhanced accessibility and\nsustainability throughout the value chain. The integration of autonomous\nsystems, including collaborative robots (cobots), into industrial processes is\npivotal for efficiency and safety. The proposed solution employs advanced\nMachine Learning algorithms, particularly Convolutional Neural Networks (CNNs),\nto identify transparent plastic bags under varying lighting and background\nconditions. Tracking algorithms and depth sensing technologies are utilized for\n3D spatial awareness during pick and placement. The system addresses challenges\nin grasping and manipulation, considering optimal points, compliance control\nwith vacuum gripping technology, and real-time automation for safe interaction\nin dynamic environments. The system's successful testing and validation in the\nlab with the FRANKA robot arm, showcases its potential for widespread\nindustrial applications, while demonstrating effectiveness in automating the\nunpacking and cutting of transparent plastic bags for an 8-stack bulk-loader\nbased on specific requirements and rigorous testing.\n","authors":["F. Adetunji","A. Karukayil","P. Samant","S. Shabana","F. Varghese","U. Upadhyay","R. A. Yadav","A. Partridge","E. Pendleton","R. Plant","Y. Petillot","M. Koskinopoulou"],"pdf_url":"https://arxiv.org/pdf/2411.09623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20559v2","updated":"2024-11-14T17:40:16Z","published":"2024-05-31T00:57:58Z","title":"Information-driven design of imaging systems","summary":"  Most modern imaging systems process the data they capture algorithmically\nbefore-or instead of-human viewing. As a result, performance depends not on how\ninterpretable the measurements appear, but how effectively they encode details\nfor algorithmic processing. Information theory provides mathematical tools to\nanalyze this, but developing methods that can handle the complexity of\nreal-world measurements yet remain practical enough for widespread use has\nproven challenging. We introduce a data-driven approach for estimating the\ninformation content of imaging system measurements. Our framework requires only\nexperimental measurements and noise characterization, with no need for ground\ntruth data. We demonstrate that these information estimates reliably predict\nsystem performance across diverse imaging modalities, including color\nphotography, radio astronomy, lensless imaging, and label-free microscopy. To\nautomate the process of designing imaging systems that maximize information\ncapture we introduce an optimization technique called Information-Driven\nEncoder Analysis Learning (IDEAL). The tools we develop in this work unlock\ninformation theory as a powerful, practical tool for analyzing and designing\nimaging systems across a broad range of applications.\n  A video summarizing this work can be found at\nhttps://waller-lab.github.io/EncodingInformationWebsite/\n","authors":["Henry Pinkard","Leyla Kabuli","Eric Markley","Tiffany Chien","Jiantao Jiao","Laura Waller"],"pdf_url":"https://arxiv.org/pdf/2405.20559v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09604v1","updated":"2024-11-14T17:22:16Z","published":"2024-11-14T17:22:16Z","title":"Local-Global Attention: An Adaptive Mechanism for Multi-Scale Feature\n  Integration","summary":"  In recent years, attention mechanisms have significantly enhanced the\nperformance of object detection by focusing on key feature information.\nHowever, prevalent methods still encounter difficulties in effectively\nbalancing local and global features. This imbalance hampers their ability to\ncapture both fine-grained details and broader contextual information-two\ncritical elements for achieving accurate object detection.To address these\nchallenges, we propose a novel attention mechanism, termed Local-Global\nAttention, which is designed to better integrate both local and global\ncontextual features. Specifically, our approach combines multi-scale\nconvolutions with positional encoding, enabling the model to focus on local\ndetails while concurrently considering the broader global context.\nAdditionally, we introduce a learnable parameters, which allow the model to\ndynamically adjust the relative importance of local and global attention,\ndepending on the specific requirements of the task, thereby optimizing feature\nrepresentations across multiple scales.We have thoroughly evaluated the\nLocal-Global Attention mechanism on several widely used object detection and\nclassification datasets. Our experimental results demonstrate that this\napproach significantly enhances the detection of objects at various scales,\nwith particularly strong performance on multi-class and small object detection\ntasks. In comparison to existing attention mechanisms, Local-Global Attention\nconsistently outperforms them across several key metrics, all while maintaining\ncomputational efficiency.\n","authors":["Yifan Shao"],"pdf_url":"https://arxiv.org/pdf/2411.09604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09598v1","updated":"2024-11-14T17:15:51Z","published":"2024-11-14T17:15:51Z","title":"Assessing the Performance of the DINOv2 Self-supervised Learning Vision\n  Transformer Model for the Segmentation of the Left Atrium from MRI Images","summary":"  Accurate left atrium (LA) segmentation from pre-operative scans is crucial\nfor diagnosing atrial fibrillation, treatment planning, and supporting surgical\ninterventions. While deep learning models are key in medical image\nsegmentation, they often require extensive manually annotated data. Foundation\nmodels trained on larger datasets have reduced this dependency, enhancing\ngeneralizability and robustness through transfer learning. We explore DINOv2, a\nself-supervised learning vision transformer trained on natural images, for LA\nsegmentation using MRI. The challenges for LA's complex anatomy, thin\nboundaries, and limited annotated data make accurate segmentation difficult\nbefore & during the image-guided intervention. We demonstrate DINOv2's ability\nto provide accurate & consistent segmentation, achieving a mean Dice score of\n.871 & a Jaccard Index of .792 for end-to-end fine-tuning. Through few-shot\nlearning across various data sizes & patient counts, DINOv2 consistently\noutperforms baseline models. These results suggest that DINOv2 effectively\nadapts to MRI with limited data, highlighting its potential as a competitive\ntool for segmentation & encouraging broader use in medical imaging.\n","authors":["Bipasha Kundu","Bidur Khanal","Richard Simon","Cristian A. Linte"],"pdf_url":"https://arxiv.org/pdf/2411.09598v1.pdf","comment":"6 pages, 3 figures, SPIE Medical Imaging, 2025"},{"id":"http://arxiv.org/abs/2411.09595v1","updated":"2024-11-14T17:08:23Z","published":"2024-11-14T17:08:23Z","title":"LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models","summary":"  This work explores expanding the capabilities of large language models (LLMs)\npretrained on text to generate 3D meshes within a unified model. This offers\nkey advantages of (1) leveraging spatial knowledge already embedded in LLMs,\nderived from textual sources like 3D tutorials, and (2) enabling conversational\n3D generation and mesh understanding. A primary challenge is effectively\ntokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly.\nTo address this, we introduce LLaMA-Mesh, a novel approach that represents the\nvertex coordinates and face definitions of 3D meshes as plain text, allowing\ndirect integration with LLMs without expanding the vocabulary. We construct a\nsupervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate\n3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs\nas required, and (3) understand and interpret 3D meshes. Our work is the first\nto demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge\nfor 3D mesh generation in a text-based format, effectively unifying the 3D and\ntext modalities. LLaMA-Mesh achieves mesh generation quality on par with models\ntrained from scratch while maintaining strong text generation performance.\n","authors":["Zhengyi Wang","Jonathan Lorraine","Yikai Wang","Hang Su","Jun Zhu","Sanja Fidler","Xiaohui Zeng"],"pdf_url":"https://arxiv.org/pdf/2411.09595v1.pdf","comment":"See the project website at\n  https://research.nvidia.com/labs/toronto-ai/LLaMA-Mesh/"},{"id":"http://arxiv.org/abs/2410.18958v2","updated":"2024-11-14T17:06:55Z","published":"2024-10-24T17:55:52Z","title":"Stable Consistency Tuning: Understanding and Improving Consistency\n  Models","summary":"  Diffusion models achieve superior generation quality but suffer from slow\ngeneration speed due to the iterative nature of denoising. In contrast,\nconsistency models, a new generative family, achieve competitive performance\nwith significantly faster sampling. These models are trained either through\nconsistency distillation, which leverages pretrained diffusion models, or\nconsistency training/tuning directly from raw data. In this work, we propose a\nnovel framework for understanding consistency models by modeling the denoising\nprocess of the diffusion model as a Markov Decision Process (MDP) and framing\nconsistency model training as the value estimation through Temporal\nDifference~(TD) Learning. More importantly, this framework allows us to analyze\nthe limitations of current consistency training/tuning strategies. Built upon\nEasy Consistency Tuning (ECT), we propose Stable Consistency Tuning (SCT),\nwhich incorporates variance-reduced learning using the score identity. SCT\nleads to significant performance improvements on benchmarks such as CIFAR-10\nand ImageNet-64. On ImageNet-64, SCT achieves 1-step FID 2.42 and 2-step FID\n1.55, a new SoTA for consistency models.\n","authors":["Fu-Yun Wang","Zhengyang Geng","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2410.18958v2.pdf","comment":"Code is available at\n  https://github.com/G-U-N/Stable-Consistency-Tuning"},{"id":"http://arxiv.org/abs/2411.09593v1","updated":"2024-11-14T17:06:00Z","published":"2024-11-14T17:06:00Z","title":"SMILE-UHURA Challenge -- Small Vessel Segmentation at Mesoscopic Scale\n  from Ultra-High Resolution 7T Magnetic Resonance Angiograms","summary":"  The human brain receives nutrients and oxygen through an intricate network of\nblood vessels. Pathology affecting small vessels, at the mesoscopic scale,\nrepresents a critical vulnerability within the cerebral blood supply and can\nlead to severe conditions, such as Cerebral Small Vessel Diseases. The advent\nof 7 Tesla MRI systems has enabled the acquisition of higher spatial resolution\nimages, making it possible to visualise such vessels in the brain. However, the\nlack of publicly available annotated datasets has impeded the development of\nrobust, machine learning-driven segmentation algorithms. To address this, the\nSMILE-UHURA challenge was organised. This challenge, held in conjunction with\nthe ISBI 2023, in Cartagena de Indias, Colombia, aimed to provide a platform\nfor researchers working on related topics. The SMILE-UHURA challenge addresses\nthe gap in publicly available annotated datasets by providing an annotated\ndataset of Time-of-Flight angiography acquired with 7T MRI. This dataset was\ncreated through a combination of automated pre-segmentation and extensive\nmanual refinement. In this manuscript, sixteen submitted methods and two\nbaseline methods are compared both quantitatively and qualitatively on two\ndifferent datasets: held-out test MRAs from the same dataset as the training\ndata (with labels kept secret) and a separate 7T ToF MRA dataset where both\ninput volumes and labels are kept secret. The results demonstrate that most of\nthe submitted deep learning methods, trained on the provided training dataset,\nachieved reliable segmentation performance. Dice scores reached up to 0.838\n$\\pm$ 0.066 and 0.716 $\\pm$ 0.125 on the respective datasets, with an average\nperformance of up to 0.804 $\\pm$ 0.15.\n","authors":["Soumick Chatterjee","Hendrik Mattern","Marc Dörner","Alessandro Sciarra","Florian Dubost","Hannes Schnurre","Rupali Khatun","Chun-Chih Yu","Tsung-Lin Hsieh","Yi-Shan Tsai","Yi-Zeng Fang","Yung-Ching Yang","Juinn-Dar Huang","Marshall Xu","Siyu Liu","Fernanda L. Ribeiro","Saskia Bollmann","Karthikesh Varma Chintalapati","Chethan Mysuru Radhakrishna","Sri Chandana Hudukula Ram Kumara","Raviteja Sutrave","Abdul Qayyum","Moona Mazher","Imran Razzak","Cristobal Rodero","Steven Niederren","Fengming Lin","Yan Xia","Jiacheng Wang","Riyu Qiu","Liansheng Wang","Arya Yazdan Panah","Rosana El Jurdi","Guanghui Fu","Janan Arslan","Ghislain Vaillant","Romain Valabregue","Didier Dormont","Bruno Stankoff","Olivier Colliot","Luisa Vargas","Isai Daniel Chacón","Ioannis Pitsiorlas","Pablo Arbeláez","Maria A. Zuluaga","Stefanie Schreiber","Oliver Speck","Andreas Nürnberger"],"pdf_url":"https://arxiv.org/pdf/2411.09593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09439v1","updated":"2024-11-14T16:58:19Z","published":"2024-11-14T16:58:19Z","title":"Spider: Any-to-Many Multimodal LLM","summary":"  Multimodal LLMs (MLLMs) have emerged as an extension of Large Language Models\n(LLMs), enabling the integration of various modalities. However, Any-to-Any\nMLLMs are limited to generating pairwise modalities 'Text + X' within a single\nresponse, such as Text + {Image or Audio or Video}. To address this limitation,\nwe introduce Spider, a novel efficient Any-to-Many Modalities Generation (AMMG)\nframework, which can generate an arbitrary combination of modalities 'Text +\nXs', such as Text + {Image and Audio and Video}. To achieve efficient AMMG, our\nSpider integrates three core components: a Base Model for basic X-to-X (i.e.,\nAny-to-Any) modality processing, a novel Efficient Decoders-Controller for\ncontrolling multimodal Decoders to generate Xs (many-modal) contents, and an\nAny-to-Many Instruction Template designed for producing Xs signal prompts. To\ntrain Spider, we constructed a novel Text-formatted Many-Modal (TMM) dataset,\nwhich facilitates the learning of the X-to-Xs (i.e., Any-to-Many) capability\nnecessary for AMMG. Ultimately, the well-trained Spider generates a pseudo\nX-to-Xs dataset, the first-ever X-to-Xs many-modal dataset, enhancing the\npotential for AMMG task in future research. Overall, this work not only pushes\nthe boundary of multimodal interaction but also provides rich data support for\nadvancing the field.\n","authors":["Jinxiang Lai","Jie Zhang","Jun Liu","Jian Li","Xiaocheng Lu","Song Guo"],"pdf_url":"https://arxiv.org/pdf/2411.09439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16824v4","updated":"2024-11-14T16:35:48Z","published":"2024-04-25T17:59:45Z","title":"V2A-Mark: Versatile Deep Visual-Audio Watermarking for Manipulation\n  Localization and Copyright Protection","summary":"  AI-generated video has revolutionized short video production, filmmaking, and\npersonalized media, making video local editing an essential tool. However, this\nprogress also blurs the line between reality and fiction, posing challenges in\nmultimedia forensics. To solve this urgent issue, V2A-Mark is proposed to\naddress the limitations of current video tampering forensics, such as poor\ngeneralizability, singular function, and single modality focus. Combining the\nfragility of video-into-video steganography with deep robust watermarking, our\nmethod can embed invisible visual-audio localization watermarks and copyright\nwatermarks into the original video frames and audio, enabling precise\nmanipulation localization and copyright protection. We also design a temporal\nalignment and fusion module and degradation prompt learning to enhance the\nlocalization accuracy and decoding robustness. Meanwhile, we introduce a\nsample-level audio localization method and a cross-modal copyright extraction\nmechanism to couple the information of audio and video frames. The\neffectiveness of V2A-Mark has been verified on a visual-audio tampering\ndataset, emphasizing its superiority in localization precision and copyright\naccuracy, crucial for the sustainable development of video editing in the AIGC\nvideo era.\n","authors":["Xuanyu Zhang","Youmin Xu","Runyi Li","Jiwen Yu","Weiqi Li","Zhipei Xu","Jian Zhang"],"pdf_url":"https://arxiv.org/pdf/2404.16824v4.pdf","comment":"Accepted by ACM MM 2024"},{"id":"http://arxiv.org/abs/2411.09572v1","updated":"2024-11-14T16:29:45Z","published":"2024-11-14T16:29:45Z","title":"Dynamic Reconstruction of Hand-Object Interaction with Distributed\n  Force-aware Contact Representation","summary":"  We present ViTaM-D, a novel visual-tactile framework for dynamic hand-object\ninteraction reconstruction, integrating distributed tactile sensing for more\naccurate contact modeling. While existing methods focus primarily on visual\ninputs, they struggle with capturing detailed contact interactions such as\nobject deformation. Our approach leverages distributed tactile sensors to\naddress this limitation by introducing DF-Field. This distributed force-aware\ncontact representation models both kinetic and potential energy in hand-object\ninteraction. ViTaM-D first reconstructs hand-object interactions using a\nvisual-only network, VDT-Net, and then refines contact details through a\nforce-aware optimization (FO) process, enhancing object deformation modeling.\nTo benchmark our approach, we introduce the HOT dataset, which features 600\nsequences of hand-object interactions, including deformable objects, built in a\nhigh-precision simulation environment. Extensive experiments on both the DexYCB\nand HOT datasets demonstrate significant improvements in accuracy over previous\nstate-of-the-art methods such as gSDF and HOTrack. Our results highlight the\nsuperior performance of ViTaM-D in both rigid and deformable object\nreconstruction, as well as the effectiveness of DF-Field in refining hand\nposes. This work offers a comprehensive solution to dynamic hand-object\ninteraction reconstruction by seamlessly integrating visual and tactile data.\nCodes, models, and datasets will be available.\n","authors":["Zhenjun Yu","Wenqiang Xu","Pengfei Xie","Yutong Li","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2411.09572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09567v1","updated":"2024-11-14T16:21:47Z","published":"2024-11-14T16:21:47Z","title":"VPBSD:Vessel-Pattern-Based Semi-Supervised Distillation for Efficient 3D\n  Microscopic Cerebrovascular Segmentation","summary":"  3D microscopic cerebrovascular images are characterized by their high\nresolution, presenting significant annotation challenges, large data volumes,\nand intricate variations in detail. Together, these factors make achieving\nhigh-quality, efficient whole-brain segmentation particularly demanding. In\nthis paper, we propose a novel Vessel-Pattern-Based Semi-Supervised\nDistillation pipeline (VpbSD) to address the challenges of 3D microscopic\ncerebrovascular segmentation. This pipeline initially constructs a\nvessel-pattern codebook that captures diverse vascular structures from\nunlabeled data during the teacher model's pretraining phase. In the knowledge\ndistillation stage, the codebook facilitates the transfer of rich knowledge\nfrom a heterogeneous teacher model to a student model, while the\nsemi-supervised approach further enhances the student model's exposure to\ndiverse learning samples. Experimental results on real-world data, including\ncomparisons with state-of-the-art methods and ablation studies, demonstrate\nthat our pipeline and its individual components effectively address the\nchallenges inherent in microscopic cerebrovascular segmentation.\n","authors":["Xi Lin","Shixuan Zhao","Xinxu Wei","Amir Shmuel","Yongjie Li"],"pdf_url":"https://arxiv.org/pdf/2411.09567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06503v2","updated":"2024-11-14T16:15:20Z","published":"2024-11-10T15:57:53Z","title":"Diffusion Sampling Correction via Approximately 10 Parameters","summary":"  Diffusion Probabilistic Models (DPMs) have demonstrated exceptional\nperformance in generative tasks, but this comes at the expense of sampling\nefficiency. To enhance sampling speed without sacrificing quality, various\ndistillation-based accelerated sampling algorithms have been recently proposed.\nHowever, they typically require significant additional training costs and model\nparameter storage, which limit their practical application. In this work, we\npropose PCA-based Adaptive Search (PAS), which optimizes existing solvers for\nDPMs with minimal learnable parameters and training costs. Specifically, we\nfirst employ PCA to obtain a few orthogonal unit basis vectors to span the\nhigh-dimensional sampling space, which enables us to learn just a set of\ncoordinates to correct the sampling direction; furthermore, based on the\nobservation that the cumulative truncation error exhibits an ``S''-shape, we\ndesign an adaptive search strategy that further enhances the sampling\nefficiency and reduces the number of stored parameters to approximately 10.\nExtensive experiments demonstrate that PAS can significantly enhance existing\nfast solvers in a plug-and-play manner with negligible costs. For instance, on\nCIFAR10, PAS requires only 12 parameters and less than 1 minute of training on\na single NVIDIA A100 GPU to optimize the DDIM from 15.69 FID (NFE=10) to 4.37.\n","authors":["Guangyi Wang","Wei Peng","Lijiang Li","Wenyu Chen","Yuren Cai","Songzhi Su"],"pdf_url":"https://arxiv.org/pdf/2411.06503v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09558v1","updated":"2024-11-14T16:10:15Z","published":"2024-11-14T16:10:15Z","title":"Adaptive Deviation Learning for Visual Anomaly Detection with Data\n  Contamination","summary":"  Visual anomaly detection targets to detect images that notably differ from\nnormal pattern, and it has found extensive application in identifying defective\nparts within the manufacturing industry. These anomaly detection paradigms\npredominantly focus on training detection models using only clean, unlabeled\nnormal samples, assuming an absence of contamination; a condition often unmet\nin real-world scenarios. The performance of these methods significantly depends\non the quality of the data and usually decreases when exposed to noise. We\nintroduce a systematic adaptive method that employs deviation learning to\ncompute anomaly scores end-to-end while addressing data contamination by\nassigning relative importance to the weights of individual instances. In this\napproach, the anomaly scores for normal instances are designed to approximate\nscalar scores obtained from the known prior distribution. Meanwhile, anomaly\nscores for anomaly examples are adjusted to exhibit statistically significant\ndeviations from these reference scores. Our approach incorporates a constrained\noptimization problem within the deviation learning framework to update instance\nweights, resolving this problem for each mini-batch. Comprehensive experiments\non the MVTec and VisA benchmark datasets indicate that our proposed method\nsurpasses competing techniques and exhibits both stability and robustness in\nthe presence of data contamination.\n","authors":["Anindya Sundar Das","Guansong Pang","Monowar Bhuyan"],"pdf_url":"https://arxiv.org/pdf/2411.09558v1.pdf","comment":"Accepted to IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV 2025)"},{"id":"http://arxiv.org/abs/2411.09555v1","updated":"2024-11-14T16:07:04Z","published":"2024-11-14T16:07:04Z","title":"Image Processing for Motion Magnification","summary":"  Motion Magnification (MM) is a collection of relative recent techniques\nwithin the realm of Image Processing. The main motivation of introducing these\ntechniques in to support the human visual system to capture relevant\ndisplacements of an object of interest; these motions can be in object color\nand in object location. In fact, the goal is to opportunely process a video\nsequence to obtain as output a new video in which motions are magnified and\nvisible to the viewer. We propose a numerical technique using the Phase-Based\nMotion Magnification which analyses the video sequence in the Fourier Domain\nand rely on the Fourier Shifting Property. We describe the mathematical\nfoundation of this method and the corresponding implementation in a numerical\nalgorithm. We present preliminary experiments, focusing on some basic test made\nup using synthetic images.\n","authors":["Nadaniela Egidi","Josephin Giacomini","Paolo Leonesi","Pierluigi Maponi","Federico Mearelli","Edin Trebovic"],"pdf_url":"https://arxiv.org/pdf/2411.09555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09553v1","updated":"2024-11-14T16:06:30Z","published":"2024-11-14T16:06:30Z","title":"OOD-SEG: Out-Of-Distribution detection for image SEGmentation with\n  sparse multi-class positive-only annotations","summary":"  Despite significant advancements, segmentation based on deep neural networks\nin medical and surgical imaging faces several challenges, two of which we aim\nto address in this work. First, acquiring complete pixel-level segmentation\nlabels for medical images is time-consuming and requires domain expertise.\nSecond, typical segmentation pipelines cannot detect out-of-distribution (OOD)\npixels, leaving them prone to spurious outputs during deployment. In this work,\nwe propose a novel segmentation approach exploiting OOD detection that learns\nonly from sparsely annotated pixels from multiple positive-only classes. %but\n\\emph{no background class} annotation. These multi-class positive annotations\nnaturally fall within the in-distribution (ID) set. Unlabelled pixels may\ncontain positive classes but also negative ones, including what is typically\nreferred to as \\emph{background} in standard segmentation formulations. Here,\nwe forgo the need for background annotation and consider these together with\nany other unseen classes as part of the OOD set. Our framework can integrate,\nat a pixel-level, any OOD detection approaches designed for classification\ntasks. To address the lack of existing OOD datasets and established evaluation\nmetric for medical image segmentation, we propose a cross-validation strategy\nthat treats held-out labelled classes as OOD. Extensive experiments on both\nmulti-class hyperspectral and RGB surgical imaging datasets demonstrate the\nrobustness and generalisation capability of our proposed framework.\n","authors":["Junwen Wang","Zhonghao Wang","Oscar MacCormac","Jonathan Shapey","Tom Vercauteren"],"pdf_url":"https://arxiv.org/pdf/2411.09553v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09551v1","updated":"2024-11-14T16:06:10Z","published":"2024-11-14T16:06:10Z","title":"MFTIQ: Multi-Flow Tracker with Independent Matching Quality Estimation","summary":"  In this work, we present MFTIQ, a novel dense long-term tracking model that\nadvances the Multi-Flow Tracker (MFT) framework to address challenges in\npoint-level visual tracking in video sequences. MFTIQ builds upon the\nflow-chaining concepts of MFT, integrating an Independent Quality (IQ) module\nthat separates correspondence quality estimation from optical flow\ncomputations. This decoupling significantly enhances the accuracy and\nflexibility of the tracking process, allowing MFTIQ to maintain reliable\ntrajectory predictions even in scenarios of prolonged occlusions and complex\ndynamics. Designed to be \"plug-and-play\", MFTIQ can be employed with any\noff-the-shelf optical flow method without the need for fine-tuning or\narchitectural modifications. Experimental validations on the TAP-Vid Davis\ndataset show that MFTIQ with RoMa optical flow not only surpasses MFT but also\nperforms comparably to state-of-the-art trackers while having substantially\nfaster processing speed. Code and models available at\nhttps://github.com/serycjon/MFTIQ .\n","authors":["Jonas Serych","Michal Neoral","Jiri Matas"],"pdf_url":"https://arxiv.org/pdf/2411.09551v1.pdf","comment":"accepted to WACV 2025"},{"id":"http://arxiv.org/abs/2411.09540v1","updated":"2024-11-14T15:56:11Z","published":"2024-11-14T15:56:11Z","title":"Prompting the Unseen: Detecting Hidden Backdoors in Black-Box Models","summary":"  Visual prompting (VP) is a new technique that adapts well-trained frozen\nmodels for source domain tasks to target domain tasks. This study examines VP's\nbenefits for black-box model-level backdoor detection. The visual prompt in VP\nmaps class subspaces between source and target domains. We identify a\nmisalignment, termed class subspace inconsistency, between clean and poisoned\ndatasets. Based on this, we introduce \\textsc{BProm}, a black-box model-level\ndetection method to identify backdoors in suspicious models, if any.\n\\textsc{BProm} leverages the low classification accuracy of prompted models\nwhen backdoors are present. Extensive experiments confirm \\textsc{BProm}'s\neffectiveness.\n","authors":["Zi-Xuan Huang","Jia-Wei Chen","Zhi-Peng Zhang","Chia-Mu Yu"],"pdf_url":"https://arxiv.org/pdf/2411.09540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09538v1","updated":"2024-11-14T15:55:21Z","published":"2024-11-14T15:55:21Z","title":"Marker-free Human Gait Analysis using a Smart Edge Sensor System","summary":"  The human gait is a complex interplay between the neuronal and the muscular\nsystems, reflecting an individual's neurological and physiological condition.\nThis makes gait analysis a valuable tool for biomechanics and medical experts.\nTraditional observational gait analysis is cost-effective but lacks reliability\nand accuracy, while instrumented gait analysis, particularly using marker-based\noptical systems, provides accurate data but is expensive and time-consuming. In\nthis paper, we introduce a novel markerless approach for gait analysis using a\nmulti-camera setup with smart edge sensors to estimate 3D body poses without\nfiducial markers. We propose a Siamese embedding network with triplet loss\ncalculation to identify individuals by their gait pattern. This network\neffectively maps gait sequences to an embedding space that enables clustering\nsequences from the same individual or activity closely together while\nseparating those of different ones. Our results demonstrate the potential of\nthe proposed system for efficient automated gait analysis in diverse real-world\nenvironments, facilitating a wide range of applications.\n","authors":["Eva Katharina Bauer","Simon Bultmann","Sven Behnke"],"pdf_url":"https://arxiv.org/pdf/2411.09538v1.pdf","comment":"accepted for SII 2025"},{"id":"http://arxiv.org/abs/2408.08700v2","updated":"2024-11-14T15:47:59Z","published":"2024-08-16T12:27:46Z","title":"HyCoT: A Transformer-Based Autoencoder for Hyperspectral Image\n  Compression","summary":"  The development of learning-based hyperspectral image (HSI) compression\nmodels has recently attracted significant interest. Existing models\npredominantly utilize convolutional filters, which capture only local\ndependencies. Furthermore,they often incur high training costs and exhibit\nsubstantial computational complexity. To address these limitations, in this\npaper we propose Hyperspectral Compression Transformer (HyCoT) that is a\ntransformer-based autoencoder for pixelwise HSI compression. Additionally, we\napply a simple yet effective training set reduction approach to accelerate the\ntraining process. Experimental results on the HySpecNet-11k dataset demonstrate\nthat HyCoT surpasses the state of the art across various compression ratios by\nover 1 dB of PSNR with significantly reduced computational requirements. Our\ncode and pre-trained weights are publicly available at\nhttps://git.tu-berlin.de/rsim/hycot .\n","authors":["Martin Hermann Paul Fuchs","Behnood Rasti","Begüm Demir"],"pdf_url":"https://arxiv.org/pdf/2408.08700v2.pdf","comment":"Accepted at 14th IEEE GRSS Workshop on Hyperspectral Image and Signal\n  Processing: Evolution in Remote Sensing (WHISPERS), 2024"},{"id":"http://arxiv.org/abs/2405.14325v4","updated":"2024-11-14T15:47:04Z","published":"2024-05-23T08:55:20Z","title":"Dinomaly: The Less Is More Philosophy in Multi-Class Unsupervised\n  Anomaly Detection","summary":"  Recent studies highlighted a practical setting of unsupervised anomaly\ndetection (UAD) that builds a unified model for multi-class images. Despite\nvarious advancements addressing this challenging task, the detection\nperformance under the multi-class setting still lags far behind\nstate-of-the-art class-separated models. Our research aims to bridge this\nsubstantial performance gap. In this paper, we introduce a minimalistic\nreconstruction-based anomaly detection framework, namely Dinomaly, which\nleverages pure Transformer architectures without relying on complex designs,\nadditional modules, or specialized tricks. Given this powerful framework\nconsisted of only Attentions and MLPs, we found four simple components that are\nessential to multi-class anomaly detection: (1) Foundation Transformers that\nextracts universal and discriminative features, (2) Noisy Bottleneck where\npre-existing Dropouts do all the noise injection tricks, (3) Linear Attention\nthat naturally cannot focus, and (4) Loose Reconstruction that does not force\nlayer-to-layer and point-by-point reconstruction. Extensive experiments are\nconducted across popular anomaly detection benchmarks including MVTec-AD, VisA,\nand Real-IAD. Our proposed Dinomaly achieves impressive image-level AUROC of\n99.6%, 98.7%, and 89.3% on the three datasets respectively, which is not only\nsuperior to state-of-the-art multi-class UAD methods, but also achieves the\nmost advanced class-separated UAD records.\n","authors":["Jia Guo","Shuai Lu","Weihang Zhang","Fang Chen","Hongen Liao","Huiqi Li"],"pdf_url":"https://arxiv.org/pdf/2405.14325v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07635v2","updated":"2024-11-14T15:40:59Z","published":"2024-11-12T08:30:59Z","title":"Breaking the Low-Rank Dilemma of Linear Attention","summary":"  The Softmax attention mechanism in Transformer models is notoriously\ncomputationally expensive, particularly due to its quadratic complexity, posing\nsignificant challenges in vision applications. In contrast, linear attention\nprovides a far more efficient solution by reducing the complexity to linear\nlevels. However, compared to Softmax attention, linear attention often\nexperiences significant performance degradation. Our experiments indicate that\nthis performance drop is due to the low-rank nature of linear attention's\nfeature map, which hinders its ability to adequately model complex spatial\ninformation. In this paper, to break the low-rank dilemma of linear attention,\nwe conduct rank analysis from two perspectives: the KV buffer and the output\nfeatures. Consequently, we introduce Rank-Augmented Linear Attention (RALA),\nwhich rivals the performance of Softmax attention while maintaining linear\ncomplexity and high efficiency. Based on RALA, we construct the Rank-Augmented\nVision Linear Transformer (RAVLT). Extensive experiments demonstrate that RAVLT\nachieves excellent performance across various vision tasks. Specifically,\nwithout using any additional labels, data, or supervision during training,\nRAVLT achieves an 84.4% Top-1 accuracy on ImageNet-1k with only 26M parameters\nand 4.6G FLOPs. This result significantly surpasses previous linear attention\nmechanisms, fully illustrating the potential of RALA. Code will be available at\nhttps://github.com/qhfan/RALA.\n","authors":["Qihang Fan","Huaibo Huang","Ran He"],"pdf_url":"https://arxiv.org/pdf/2411.07635v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.08514v4","updated":"2024-11-14T15:39:54Z","published":"2023-05-15T10:23:14Z","title":"Generative Adversarial Networks for Spatio-Spectral Compression of\n  Hyperspectral Images","summary":"  The development of deep learning-based models for the compression of\nhyperspectral images (HSIs) has recently attracted great attention in remote\nsensing due to the sharp growing of hyperspectral data archives. Most of the\nexisting models achieve either spectral or spatial compression, and do not\njointly consider the spatio-spectral redundancies present in HSIs. To address\nthis problem, in this paper we focus our attention on the High Fidelity\nCompression (HiFiC) model (which is proven to be highly effective for spatial\ncompression problems) and adapt it to perform spatio-spectral compression of\nHSIs. In detail, we introduce two new models: i) HiFiC using Squeeze and\nExcitation (SE) blocks (denoted as HiFiC$_{SE}$); and ii) HiFiC with 3D\nconvolutions (denoted as HiFiC$_{3D}$) in the framework of compression of HSIs.\nWe analyze the effectiveness of HiFiC$_{SE}$ and HiFiC$_{3D}$ in compressing\nthe spatio-spectral redundancies with channel attention and inter-dependency\nanalysis. Experimental results show the efficacy of the proposed models in\nperforming spatio-spectral compression, while reconstructing images at reduced\nbitrates with higher reconstruction quality. The code of the proposed models is\npublicly available at https://git.tu-berlin.de/rsim/HSI-SSC .\n","authors":["Martin Hermann Paul Fuchs","Akshara Preethy Byju","Alisa Walda","Behnood Rasti","Begüm Demir"],"pdf_url":"https://arxiv.org/pdf/2305.08514v4.pdf","comment":"Accepted at 14th IEEE GRSS Workshop on Hyperspectral Image and Signal\n  Processing: Evolution in Remote Sensing (WHISPERS), 2024"},{"id":"http://arxiv.org/abs/2409.07271v3","updated":"2024-11-14T15:36:29Z","published":"2024-09-11T13:46:35Z","title":"CFCPalsy: Facial Image Synthesis with Cross-Fusion Cycle Diffusion Model\n  for Facial Paralysis Individuals","summary":"  Currently, the diagnosis of facial paralysis remains a challenging task,\noften relying heavily on the subjective judgment and experience of clinicians,\nwhich can introduce variability and uncertainty in the assessment process. One\npromising application in real-life situations is the automatic estimation of\nfacial paralysis. However, the scarcity of facial paralysis datasets limits the\ndevelopment of robust machine learning models for automated diagnosis and\ntherapeutic interventions. To this end, this study aims to synthesize a\nhigh-quality facial paralysis dataset to address this gap, enabling more\naccurate and efficient algorithm training. Specifically, a novel Cross-Fusion\nCycle Palsy Expression Generative Model (CFCPalsy) based on the diffusion model\nis proposed to combine different features of facial information and enhance the\nvisual details of facial appearance and texture in facial regions, thus\ncreating synthetic facial images that accurately represent various degrees and\ntypes of facial paralysis. We have qualitatively and quantitatively evaluated\nthe proposed method on the commonly used public clinical datasets of facial\nparalysis to demonstrate its effectiveness. Experimental results indicate that\nthe proposed method surpasses state-of-the-art methods, generating more\nrealistic facial images and maintaining identity consistency.\n","authors":["Weixiang Gao","Yifan Xia"],"pdf_url":"https://arxiv.org/pdf/2409.07271v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09512v1","updated":"2024-11-14T15:26:10Z","published":"2024-11-14T15:26:10Z","title":"GAN-Based Architecture for Low-dose Computed Tomography Imaging\n  Denoising","summary":"  Generative Adversarial Networks (GANs) have surfaced as a revolutionary\nelement within the domain of low-dose computed tomography (LDCT) imaging,\nproviding an advanced resolution to the enduring issue of reconciling radiation\nexposure with image quality. This comprehensive review synthesizes the rapid\nadvancements in GAN-based LDCT denoising techniques, examining the evolution\nfrom foundational architectures to state-of-the-art models incorporating\nadvanced features such as anatomical priors, perceptual loss functions, and\ninnovative regularization strategies. We critically analyze various GAN\narchitectures, including conditional GANs (cGANs), CycleGANs, and\nSuper-Resolution GANs (SRGANs), elucidating their unique strengths and\nlimitations in the context of LDCT denoising. The evaluation provides both\nqualitative and quantitative results related to the improvements in performance\nin benchmark and clinical datasets with metrics such as PSNR, SSIM, and LPIPS.\nAfter highlighting the positive results, we discuss some of the challenges\npreventing a wider clinical use, including the interpretability of the images\ngenerated by GANs, synthetic artifacts, and the need for clinically relevant\nmetrics. The review concludes by highlighting the essential significance of\nGAN-based methodologies in the progression of precision medicine via tailored\nLDCT denoising models, underlining the transformative possibilities presented\nby artificial intelligence within contemporary radiological practice.\n","authors":["Yunuo Wang","Ningning Yang","Jialin Li"],"pdf_url":"https://arxiv.org/pdf/2411.09512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05612v2","updated":"2024-11-14T15:22:27Z","published":"2023-06-09T01:11:50Z","title":"Spatial Re-parameterization for N:M Sparsity","summary":"  This paper presents a Spatial Re-parameterization (SpRe) method for the N:M\nsparsity in CNNs. SpRe is stemmed from an observation regarding the restricted\nvariety in spatial sparsity present in N:M sparsity compared with unstructured\nsparsity. Particularly, N:M sparsity exhibits a fixed sparsity rate within the\nspatial domains due to its distinctive pattern that mandates N non-zero\ncomponents among M successive weights in the input channel dimension of\nconvolution filters. On the contrary, we observe that unstructured sparsity\ndisplays a substantial divergence in sparsity across the spatial domains, which\nwe experimentally verified to be very crucial for its robust performance\nretention compared with N:M sparsity. Therefore, SpRe employs the\nspatial-sparsity distribution of unstructured sparsity to assign an extra\nbranch in conjunction with the original N:M branch at training time, which\nallows the N:M sparse network to sustain a similar distribution of spatial\nsparsity with unstructured sparsity. During inference, the extra branch can be\nfurther re-parameterized into the main N:M branch, without exerting any\ndistortion on the sparse pattern or additional computation costs. SpRe has\nachieved a commendable feat by matching the performance of N:M sparsity methods\nwith state-of-the-art unstructured sparsity methods across various benchmarks.\nCode and models are anonymously available at\n\\url{https://github.com/zyxxmu/SpRe}.\n","authors":["Yuxin Zhang","Mingliang Xu","Yonghong Tian","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2306.05612v2.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.09502v1","updated":"2024-11-14T15:13:13Z","published":"2024-11-14T15:13:13Z","title":"Golden Noise for Diffusion Models: A Learning Framework","summary":"  Text-to-image diffusion model is a popular paradigm that synthesizes\npersonalized images by providing a text prompt and a random Gaussian noise.\nWhile people observe that some noises are ``golden noises'' that can achieve\nbetter text-image alignment and higher human preference than others, we still\nlack a machine learning framework to obtain those golden noises. To learn\ngolden noises for diffusion sampling, we mainly make three contributions in\nthis paper. First, we identify a new concept termed the \\textit{noise prompt},\nwhich aims at turning a random Gaussian noise into a golden noise by adding a\nsmall desirable perturbation derived from the text prompt. Following the\nconcept, we first formulate the \\textit{noise prompt learning} framework that\nsystematically learns ``prompted'' golden noise associated with a text prompt\nfor diffusion models. Second, we design a noise prompt data collection pipeline\nand collect a large-scale \\textit{noise prompt dataset}~(NPD) that contains\n100k pairs of random noises and golden noises with the associated text prompts.\nWith the prepared NPD as the training dataset, we trained a small \\textit{noise\nprompt network}~(NPNet) that can directly learn to transform a random noise\ninto a golden noise. The learned golden noise perturbation can be considered as\na kind of prompt for noise, as it is rich in semantic information and tailored\nto the given text prompt. Third, our extensive experiments demonstrate the\nimpressive effectiveness and generalization of NPNet on improving the quality\nof synthesized images across various diffusion models, including SDXL,\nDreamShaper-xl-v2-turbo, and Hunyuan-DiT. Moreover, NPNet is a small and\nefficient controller that acts as a plug-and-play module with very limited\nadditional inference and computational costs, as it just provides a golden\nnoise instead of a random noise without accessing the original pipeline.\n","authors":["Zikai Zhou","Shitong Shao","Lichen Bai","Zhiqiang Xu","Bo Han","Zeke Xie"],"pdf_url":"https://arxiv.org/pdf/2411.09502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.24006v2","updated":"2024-11-14T14:58:26Z","published":"2024-10-31T15:09:36Z","title":"DiffPAD: Denoising Diffusion-based Adversarial Patch Decontamination","summary":"  In the ever-evolving adversarial machine learning landscape, developing\neffective defenses against patch attacks has become a critical challenge,\nnecessitating reliable solutions to safeguard real-world AI systems. Although\ndiffusion models have shown remarkable capacity in image synthesis and have\nbeen recently utilized to counter $\\ell_p$-norm bounded attacks, their\npotential in mitigating localized patch attacks remains largely underexplored.\nIn this work, we propose DiffPAD, a novel framework that harnesses the power of\ndiffusion models for adversarial patch decontamination. DiffPAD first performs\nsuper-resolution restoration on downsampled input images, then adopts\nbinarization, dynamic thresholding scheme and sliding window for effective\nlocalization of adversarial patches. Such a design is inspired by the\ntheoretically derived correlation between patch size and diffusion restoration\nerror that is generalized across diverse patch attack scenarios. Finally,\nDiffPAD applies inpainting techniques to the original input images with the\nestimated patch region being masked. By integrating closed-form solutions for\nsuper-resolution restoration and image inpainting into the conditional reverse\nsampling process of a pre-trained diffusion model, DiffPAD obviates the need\nfor text guidance or fine-tuning. Through comprehensive experiments, we\ndemonstrate that DiffPAD not only achieves state-of-the-art adversarial\nrobustness against patch attacks but also excels in recovering naturalistic\nimages without patch remnants. The source code is available at\nhttps://github.com/JasonFu1998/DiffPAD.\n","authors":["Jia Fu","Xiao Zhang","Sepideh Pashami","Fatemeh Rahimian","Anders Holst"],"pdf_url":"https://arxiv.org/pdf/2410.24006v2.pdf","comment":"Accepted to 2025 IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV)"},{"id":"http://arxiv.org/abs/2406.01395v3","updated":"2024-11-14T14:39:07Z","published":"2024-06-03T14:58:49Z","title":"TE-NeXt: A LiDAR-Based 3D Sparse Convolutional Network for\n  Traversability Estimation","summary":"  This paper presents TE-NeXt, a novel and efficient architecture for\nTraversability Estimation (TE) from sparse LiDAR point clouds based on a\nresidual convolution block. TE-NeXt block fuses notions of current trends such\nas attention mechanisms and 3D sparse convolutions. TE-NeXt aims to demonstrate\nhigh capacity for generalisation in a variety of urban and natural\nenvironments, using well-known and accessible datasets such as SemanticKITTI,\nRellis-3D and SemanticUSL. Thus, the designed architecture ouperforms\nstate-of-the-art methods in the problem of semantic segmentation, demonstrating\nbetter results in unstructured environments and maintaining high reliability\nand robustness in urbans environments, which leads to better abstraction.\nImplementation is available in a open repository to the scientific community\nwith the aim of ensuring the reproducibility of results.\n","authors":["Antonio Santo","Juan J. Cabrera","David Valiente","Carlos Viegas","Arturo Gil"],"pdf_url":"https://arxiv.org/pdf/2406.01395v3.pdf","comment":"This work has been submitted to the Expert Systems With applications"},{"id":"http://arxiv.org/abs/2411.09484v1","updated":"2024-11-14T14:37:50Z","published":"2024-11-14T14:37:50Z","title":"Image Matching Filtering and Refinement by Planes and Beyond","summary":"  This paper introduces a modular, non-deep learning method for filtering and\nrefining sparse correspondences in image matching. Assuming that motion flow\nwithin the scene can be approximated by local homography transformations,\nmatches are aggregated into overlapping clusters corresponding to virtual\nplanes using an iterative RANSAC-based approach, with non-conforming\ncorrespondences discarded. Moreover, the underlying planar structural design\nprovides an explicit map between local patches associated with the matches,\nenabling optional refinement of keypoint positions through cross-correlation\ntemplate matching after patch reprojection. Finally, to enhance robustness and\nfault-tolerance against violations of the piece-wise planar approximation\nassumption, a further strategy is designed for minimizing relative patch\ndistortion in the plane reprojection by introducing an intermediate homography\nthat projects both patches into a common plane. The proposed method is\nextensively evaluated on standard datasets and image matching pipelines, and\ncompared with state-of-the-art approaches. Unlike other current comparisons,\nthe proposed benchmark also takes into account the more general, real, and\npractical cases where camera intrinsics are unavailable. Experimental results\ndemonstrate that our proposed non-deep learning, geometry-based approach\nachieves performances that are either superior to or on par with recent\nstate-of-the-art deep learning methods. Finally, this study suggests that there\nare still development potential in actual image matching solutions in the\nconsidered research direction, which could be in the future incorporated in\nnovel deep image matching architectures.\n","authors":["Fabio Bellavia","Zhenjun Zhao","Luca Morelli","Fabio Remondino"],"pdf_url":"https://arxiv.org/pdf/2411.09484v1.pdf","comment":"project page: https://github.com/fb82/MiHo"},{"id":"http://arxiv.org/abs/2410.03979v3","updated":"2024-11-14T14:34:13Z","published":"2024-10-04T23:37:21Z","title":"Improving Arabic Multi-Label Emotion Classification using Stacked\n  Embeddings and Hybrid Loss Function","summary":"  In multi-label emotion classification, particularly for low-resource\nlanguages like Arabic, the challenges of class imbalance and label correlation\nhinder model performance, especially in accurately predicting minority\nemotions. To address these issues, this study proposes a novel approach that\ncombines stacked embeddings, meta-learning, and a hybrid loss function to\nenhance multi-label emotion classification for the Arabic language. The study\nextracts contextual embeddings from three fine-tuned language\nmodels-ArabicBERT, MarBERT, and AraBERT-which are then stacked to form enriched\nembeddings. A meta-learner is trained on these stacked embeddings, and the\nresulting concatenated representations are provided as input to a Bi-LSTM\nmodel, followed by a fully connected neural network for multi-label\nclassification. To further improve performance, a hybrid loss function is\nintroduced, incorporating class weighting, label correlation matrix, and\ncontrastive learning, effectively addressing class imbalances and improving the\nhandling of label correlations. Extensive experiments validate the proposed\nmodel's performance across key metrics such as Precision, Recall, F1-Score,\nJaccard Accuracy, and Hamming Loss. The class-wise performance analysis\ndemonstrates the hybrid loss function's ability to significantly reduce\ndisparities between majority and minority classes, resulting in a more balanced\nemotion classification. An ablation study highlights the contribution of each\ncomponent, showing the superiority of the model compared to baseline approaches\nand other loss functions. This study not only advances multi-label emotion\nclassification for Arabic but also presents a generalizable framework that can\nbe adapted to other languages and domains, providing a significant step forward\nin addressing the challenges of low-resource emotion classification tasks.\n","authors":["Muhammad Azeem Aslam","Wang Jun","Nisar Ahmed","Muhammad Imran Zaman","Li Yanan","Hu Hongfei","Wang Shiyu","Xin Liu"],"pdf_url":"https://arxiv.org/pdf/2410.03979v3.pdf","comment":"The paper is submitted in Scientific Reports and is currently under\n  review"},{"id":"http://arxiv.org/abs/2411.09471v1","updated":"2024-11-14T14:21:49Z","published":"2024-11-14T14:21:49Z","title":"Renal Cell Carcinoma subtyping: learning from multi-resolution\n  localization","summary":"  Renal Cell Carcinoma is typically asymptomatic at the early stages for many\npatients. This leads to a late diagnosis of the tumor, where the curability\nlikelihood is lower, and makes the mortality rate of Renal Cell Carcinoma high,\nwith respect to its incidence rate. To increase the survival chance, a fast and\ncorrect categorization of the tumor subtype is paramount. Nowadays,\ncomputerized methods, based on artificial intelligence, represent an\ninteresting opportunity to improve the productivity and the objectivity of the\nmicroscopy-based Renal Cell Carcinoma diagnosis. Nonetheless, much of their\nexploitation is hampered by the paucity of annotated dataset, essential for a\nproficient training of supervised machine learning technologies. This study\nsets out to investigate a novel self supervised training strategy for machine\nlearning diagnostic tools, based on the multi-resolution nature of the\nhistological samples. We aim at reducing the need of annotated dataset, without\nsignificantly reducing the accuracy of the tool. We demonstrate the\nclassification capability of our tool on a whole slide imaging dataset for\nRenal Cancer subtyping, and we compare our solution with several\nstate-of-the-art classification counterparts.\n","authors":["Mohamad Mohamad","Francesco Ponzio","Santa Di Cataldo","Damien Ambrosetti","Xavier Descombes"],"pdf_url":"https://arxiv.org/pdf/2411.09471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09462v1","updated":"2024-11-14T14:12:16Z","published":"2024-11-14T14:12:16Z","title":"SINETRA: a Versatile Framework for Evaluating Single Neuron Tracking in\n  Behaving Animals","summary":"  Accurately tracking neuronal activity in behaving animals presents\nsignificant challenges due to complex motions and background noise. The lack of\nannotated datasets limits the evaluation and improvement of such tracking\nalgorithms. To address this, we developed SINETRA, a versatile simulator that\ngenerates synthetic tracking data for particles on a deformable background,\nclosely mimicking live animal recordings. This simulator produces annotated 2D\nand 3D videos that reflect the intricate movements seen in behaving animals\nlike Hydra Vulgaris. We evaluated four state-of-the-art tracking algorithms\nhighlighting the current limitations of these methods in challenging scenarios\nand paving the way for improved cell tracking techniques in dynamic biological\nsystems.\n","authors":["Raphael Reme","Alasdair Newson","Elsa Angelini","Jean-Christophe Olivo-Marin","Thibault Lagach"],"pdf_url":"https://arxiv.org/pdf/2411.09462v1.pdf","comment":"5 pages, 3 figures, submitted at 2025 IEEE International Symposium on\n  Biomedical Imaging (ISBI)"},{"id":"http://arxiv.org/abs/2402.03227v4","updated":"2024-11-14T14:11:57Z","published":"2024-02-05T17:38:49Z","title":"IGUANe: a 3D generalizable CycleGAN for multicenter harmonization of\n  brain MR images","summary":"  In MRI studies, the aggregation of imaging data from multiple acquisition\nsites enhances sample size but may introduce site-related variabilities that\nhinder consistency in subsequent analyses. Deep learning methods for image\ntranslation have emerged as a solution for harmonizing MR images across sites.\nIn this study, we introduce IGUANe (Image Generation with Unified Adversarial\nNetworks), an original 3D model that leverages the strengths of domain\ntranslation and straightforward application of style transfer methods for\nmulticenter brain MR image harmonization. IGUANe extends CycleGAN by\nintegrating an arbitrary number of domains for training through a many-to-one\narchitecture. The framework based on domain pairs enables the implementation of\nsampling strategies that prevent confusion between site-related and biological\nvariabilities. During inference, the model can be applied to any image, even\nfrom an unknown acquisition site, making it a universal generator for\nharmonization. Trained on a dataset comprising T1-weighted images from 11\ndifferent scanners, IGUANe was evaluated on data from unseen sites. The\nassessments included the transformation of MR images with traveling subjects,\nthe preservation of pairwise distances between MR images within domains, the\nevolution of volumetric patterns related to age and Alzheimer$'$s disease (AD),\nand the performance in age regression and patient classification tasks.\nComparisons with other harmonization and normalization methods suggest that\nIGUANe better preserves individual information in MR images and is more\nsuitable for maintaining and reinforcing variabilities related to age and AD.\nFuture studies may further assess IGUANe in other multicenter contexts, either\nusing the same model or retraining it for applications to different image\nmodalities. IGUANe is available at\nhttps://github.com/RocaVincent/iguane_harmonization.git.\n","authors":["Vincent Roca","Grégory Kuchcinski","Jean-Pierre Pruvo","Dorian Manouvriez","Renaud Lopes"],"pdf_url":"https://arxiv.org/pdf/2402.03227v4.pdf","comment":"29 pages, 14 figures"},{"id":"http://arxiv.org/abs/2411.08656v2","updated":"2024-11-14T14:11:06Z","published":"2024-11-13T14:46:41Z","title":"MikuDance: Animating Character Art with Mixed Motion Dynamics","summary":"  We propose MikuDance, a diffusion-based pipeline incorporating mixed motion\ndynamics to animate stylized character art. MikuDance consists of two key\ntechniques: Mixed Motion Modeling and Mixed-Control Diffusion, to address the\nchallenges of high-dynamic motion and reference-guidance misalignment in\ncharacter art animation. Specifically, a Scene Motion Tracking strategy is\npresented to explicitly model the dynamic camera in pixel-wise space, enabling\nunified character-scene motion modeling. Building on this, the Mixed-Control\nDiffusion implicitly aligns the scale and body shape of diverse characters with\nmotion guidance, allowing flexible control of local character motion.\nSubsequently, a Motion-Adaptive Normalization module is incorporated to\neffectively inject global scene motion, paving the way for comprehensive\ncharacter art animation. Through extensive experiments, we demonstrate the\neffectiveness and generalizability of MikuDance across various character art\nand motion guidance, consistently producing high-quality animations with\nremarkable motion dynamics.\n","authors":["Jiaxu Zhang","Xianfang Zeng","Xin Chen","Wei Zuo","Gang Yu","Zhigang Tu"],"pdf_url":"https://arxiv.org/pdf/2411.08656v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09453v1","updated":"2024-11-14T13:59:01Z","published":"2024-11-14T13:59:01Z","title":"Long-Tailed Object Detection Pre-training: Dynamic Rebalancing\n  Contrastive Learning with Dual Reconstruction","summary":"  Pre-training plays a vital role in various vision tasks, such as object\nrecognition and detection. Commonly used pre-training methods, which typically\nrely on randomized approaches like uniform or Gaussian distributions to\ninitialize model parameters, often fall short when confronted with long-tailed\ndistributions, especially in detection tasks. This is largely due to extreme\ndata imbalance and the issue of simplicity bias. In this paper, we introduce a\nnovel pre-training framework for object detection, called Dynamic Rebalancing\nContrastive Learning with Dual Reconstruction (2DRCL). Our method builds on a\nHolistic-Local Contrastive Learning mechanism, which aligns pre-training with\nobject detection by capturing both global contextual semantics and detailed\nlocal patterns. To tackle the imbalance inherent in long-tailed data, we design\na dynamic rebalancing strategy that adjusts the sampling of underrepresented\ninstances throughout the pre-training process, ensuring better representation\nof tail classes. Moreover, Dual Reconstruction addresses simplicity bias by\nenforcing a reconstruction task aligned with the self-consistency principle,\nspecifically benefiting underrepresented tail classes. Experiments on COCO and\nLVIS v1.0 datasets demonstrate the effectiveness of our method, particularly in\nimproving the mAP/AP scores for tail classes.\n","authors":["Chen-Long Duan","Yong Li","Xiu-Shen Wei","Lin Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.09453v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09449v1","updated":"2024-11-14T13:52:43Z","published":"2024-11-14T13:52:43Z","title":"Image Regeneration: Evaluating Text-to-Image Model via Generating\n  Identical Image with Multimodal Large Language Models","summary":"  Diffusion models have revitalized the image generation domain, playing\ncrucial roles in both academic research and artistic expression. With the\nemergence of new diffusion models, assessing the performance of text-to-image\nmodels has become increasingly important. Current metrics focus on directly\nmatching the input text with the generated image, but due to cross-modal\ninformation asymmetry, this leads to unreliable or incomplete assessment\nresults. Motivated by this, we introduce the Image Regeneration task in this\nstudy to assess text-to-image models by tasking the T2I model with generating\nan image according to the reference image. We use GPT4V to bridge the gap\nbetween the reference image and the text input for the T2I model, allowing T2I\nmodels to understand image content. This evaluation process is simplified as\ncomparisons between the generated image and the reference image are\nstraightforward. Two regeneration datasets spanning content-diverse and\nstyle-diverse evaluation dataset are introduced to evaluate the leading\ndiffusion models currently available. Additionally, we present ImageRepainter\nframework to enhance the quality of generated images by improving content\ncomprehension via MLLM guided iterative generation and revision. Our\ncomprehensive experiments have showcased the effectiveness of this framework in\nassessing the generative capabilities of models. By leveraging MLLM, we have\ndemonstrated that a robust T2M can produce images more closely resembling the\nreference image.\n","authors":["Chutian Meng","Fan Ma","Jiaxu Miao","Chi Zhang","Yi Yang","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2411.09449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06651v2","updated":"2024-11-14T13:26:35Z","published":"2024-11-11T01:36:48Z","title":"Machine learning-enabled velocity model building with uncertainty\n  quantification","summary":"  Accurately characterizing migration velocity models is crucial for a wide\nrange of geophysical applications, from hydrocarbon exploration to monitoring\nof CO2 sequestration projects. Traditional velocity model building methods such\nas Full-Waveform Inversion (FWI) are powerful but often struggle with the\ninherent complexities of the inverse problem, including noise, limited\nbandwidth, receiver aperture and computational constraints. To address these\nchallenges, we propose a scalable methodology that integrates generative\nmodeling, in the form of Diffusion networks, with physics-informed summary\nstatistics, making it suitable for complicated imaging problems including field\ndatasets. By defining these summary statistics in terms of subsurface-offset\nimage volumes for poor initial velocity models, our approach allows for\ncomputationally efficient generation of Bayesian posterior samples for\nmigration velocity models that offer a useful assessment of uncertainty. To\nvalidate our approach, we introduce a battery of tests that measure the quality\nof the inferred velocity models, as well as the quality of the inferred\nuncertainties. With modern synthetic datasets, we reconfirm gains from using\nsubsurface-image gathers as the conditioning observable. For complex velocity\nmodel building involving salt, we propose a new iterative workflow that refines\namortized posterior approximations with salt flooding and demonstrate how the\nuncertainty in the velocity model can be propagated to the final product\nreverse time migrated images. Finally, we present a proof of concept on field\ndatasets to show that our method can scale to industry-sized problems.\n","authors":["Rafael Orozco","Huseyin Tuna Erdinc","Yunlin Zeng","Mathias Louboutin","Felix J. Herrmann"],"pdf_url":"https://arxiv.org/pdf/2411.06651v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09420v1","updated":"2024-11-14T13:15:27Z","published":"2024-11-14T13:15:27Z","title":"SAG-ViT: A Scale-Aware, High-Fidelity Patching Approach with Graph\n  Attention for Vision Transformers","summary":"  Image classification is a computer vision task where a model analyzes an\nimage to categorize it into a specific label. Vision Transformers (ViT) improve\nthis task by leveraging self-attention to capture complex patterns and long\nrange relationships between image patches. However, a key challenge for ViTs is\nefficiently incorporating multiscale feature representations, which is inherent\nin CNNs through their hierarchical structure. In this paper, we introduce the\nScale-Aware Graph Attention Vision Transformer (SAG-ViT), a novel framework\nthat addresses this challenge by integrating multi-scale features. Using\nEfficientNet as a backbone, the model extracts multi-scale feature maps, which\nare divided into patches to preserve semantic information. These patches are\norganized into a graph based on spatial and feature similarities, with a Graph\nAttention Network (GAT) refining the node embeddings. Finally, a Transformer\nencoder captures long-range dependencies and complex interactions. The SAG-ViT\nis evaluated on benchmark datasets, demonstrating its effectiveness in\nenhancing image classification performance.\n","authors":["Shravan Venkatraman","Jaskaran Singh Walia","Joe Dhanith P R"],"pdf_url":"https://arxiv.org/pdf/2411.09420v1.pdf","comment":"10 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2405.20155v2","updated":"2024-11-14T13:07:26Z","published":"2024-05-30T15:30:38Z","title":"MotionDreamer: Exploring Semantic Video Diffusion features for Zero-Shot\n  3D Mesh Animation","summary":"  Animation techniques bring digital 3D worlds and characters to life. However,\nmanual animation is tedious and automated techniques are often specialized to\nnarrow shape classes. In our work, we propose a technique for automatic\nre-animation of various 3D shapes based on a motion prior extracted from a\nvideo diffusion model. Unlike existing 4D generation methods, we focus solely\non the motion, and we leverage an explicit mesh-based representation compatible\nwith existing computer-graphics pipelines. Furthermore, our utilization of\ndiffusion features enhances accuracy of our motion fitting. We analyze efficacy\nof these features for animation fitting and we experimentally validate our\napproach for two different diffusion models and four animation models. Finally,\nwe demonstrate that our time-efficient zero-shot method achieves a superior\nperformance re-animating a diverse set of 3D shapes when compared to existing\ntechniques in a user study. The project website is located at\nhttps://lukas.uzolas.com/MotionDreamer.\n","authors":["Lukas Uzolas","Elmar Eisemann","Petr Kellnhofer"],"pdf_url":"https://arxiv.org/pdf/2405.20155v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09413v1","updated":"2024-11-14T13:07:19Z","published":"2024-11-14T13:07:19Z","title":"Script-centric behavior understanding for assisted autism spectrum\n  disorder diagnosis","summary":"  Observing and analyzing children's social behaviors is crucial for the early\ndiagnosis of Autism Spectrum Disorders (ASD). This work focuses on\nautomatically detecting ASD using computer vision techniques and large language\nmodels (LLMs). Existing methods typically rely on supervised learning. However,\nthe scarcity of ASD diagnostic datasets and the lack of interpretability in\ndiagnostic results significantly limits its clinical application. To address\nthese challenges, we introduce a novel unsupervised approach based on\nscript-centric behavior understanding. Our pipeline converts video content into\nscripts that describe the behavior of characters, leveraging the\ngeneralizability of large language models to detect ASD in a zero-shot or\nfew-shot manner. Specifically, we propose a scripts transcription module for\nmultimodal behavior data textualization and a domain prompts module to bridge\nLLMs. Our method achieves an accuracy of 92.00\\% in diagnosing ASD in children\nwith an average age of 24 months, surpassing the performance of supervised\nlearning methods by 3.58\\% absolutely. Extensive experiments confirm the\neffectiveness of our approach and suggest its potential for advancing ASD\nresearch through LLMs.\n","authors":["Wenxing Liu","Yueran Pan","Ming Li"],"pdf_url":"https://arxiv.org/pdf/2411.09413v1.pdf","comment":"5 pages, 4 figures, submitted to ICASSP 2025"},{"id":"http://arxiv.org/abs/2411.09411v1","updated":"2024-11-14T13:06:18Z","published":"2024-11-14T13:06:18Z","title":"Building Height Estimation Using Shadow Length in Satellite Imagery","summary":"  Estimating building height from satellite imagery poses significant\nchallenges, especially when monocular images are employed, resulting in a loss\nof essential 3D information during imaging. This loss of spatial depth further\ncomplicates the height estimation process. We addressed this issue by using\nshadow length as an additional cue to compensate for the loss of building\nheight estimation using single-view imagery. We proposed a novel method that\nfirst localized a building and its shadow in the given satellite image. After\nlocalization, the shadow length is estimated using a regression model. To\nestimate the final height of each building, we utilize the principles of\nphotogrammetry, specifically considering the relationship between the solar\nelevation angle, the vertical edge length of the building, and the length of\nthe building's shadow. For the localization of buildings in our model, we\nutilized a modified YOLOv7 detector, and to regress the shadow length for each\nbuilding we utilized the ResNet18 as backbone architecture. Finally, we\nestimated the associated building height using solar elevation with shadow\nlength through analytical formulation. We evaluated our method on 42 different\ncities and the results showed that the proposed framework surpasses the\nstate-of-the-art methods with a suitable margin.\n","authors":["Mahd Qureshi","Shayaan Chaudhry","Sana Jabba","Murtaza Taj"],"pdf_url":"https://arxiv.org/pdf/2411.09411v1.pdf","comment":"6 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.17856v2","updated":"2024-11-14T12:29:41Z","published":"2024-10-23T13:26:59Z","title":"ROCKET-1: Mastering Open-World Interaction with Visual-Temporal Context\n  Prompting","summary":"  Vision-language models (VLMs) have excelled in multimodal tasks, but adapting\nthem to embodied decision-making in open-world environments presents\nchallenges. One critical issue is bridging the gap between discrete entities in\nlow-level observations and the abstract concepts required for effective\nplanning. A common solution is building hierarchical agents, where VLMs serve\nas high-level reasoners that break down tasks into executable sub-tasks,\ntypically specified using language. However, language suffers from the\ninability to communicate detailed spatial information. We propose\nvisual-temporal context prompting, a novel communication protocol between VLMs\nand policy models. This protocol leverages object segmentation from past\nobservations to guide policy-environment interactions. Using this approach, we\ntrain ROCKET-1, a low-level policy that predicts actions based on concatenated\nvisual observations and segmentation masks, supported by real-time object\ntracking from SAM-2. Our method unlocks the potential of VLMs, enabling them to\ntackle complex tasks that demand spatial reasoning. Experiments in Minecraft\nshow that our approach enables agents to achieve previously unattainable tasks,\nwith a $\\mathbf{76}\\%$ absolute improvement in open-world interaction\nperformance. Codes and demos are now available on the project page:\nhttps://craftjarvis.github.io/ROCKET-1.\n","authors":["Shaofei Cai","Zihao Wang","Kewei Lian","Zhancun Mu","Xiaojian Ma","Anji Liu","Yitao Liang"],"pdf_url":"https://arxiv.org/pdf/2410.17856v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09402v1","updated":"2024-11-14T12:27:31Z","published":"2024-11-14T12:27:31Z","title":"Automated Segmentation of Ischemic Stroke Lesions in Non-Contrast\n  Computed Tomography Images for Enhanced Treatment and Prognosis","summary":"  Stroke is the second leading cause of death worldwide, and is increasingly\nprevalent in low- and middle-income countries (LMICs). Timely interventions can\nsignificantly influence stroke survivability and the quality of life after\ntreatment. However, the standard and most widely available imaging method for\nconfirming strokes and their sub-types, the NCCT, is more challenging and\ntime-consuming to employ in cases of ischemic stroke. For this reason, we\ndeveloped an automated method for ischemic stroke lesion segmentation in NCCTs\nusing the nnU-Net frame work, aimed at enhancing early treatment and improving\nthe prognosis of ischemic stroke patients. We achieved Dice scores of 0.596 and\nIntersection over Union (IoU) scores of 0.501 on the sampled dataset. After\nadjusting for outliers, these scores improved to 0.752 for the Dice score and\n0.643 for the IoU. Proper delineation of the region of infarction can help\nclinicians better assess the potential impact of the infarction, and guide\ntreatment procedures.\n","authors":["Toufiq Musah","Prince Ebenezer Adjei","Kojo Obed Otoo"],"pdf_url":"https://arxiv.org/pdf/2411.09402v1.pdf","comment":"7 pages, 3 figures, MICCAI Meets Africa Workshop"},{"id":"http://arxiv.org/abs/2410.21991v5","updated":"2024-11-14T12:19:26Z","published":"2024-10-29T12:22:07Z","title":"From Explicit Rules to Implicit Reasoning in an Interpretable Violence\n  Monitoring System","summary":"  Recently, research based on pre-trained models has demonstrated outstanding\nperformance in violence surveillance tasks. However, most of them were\nblack-box systems which faced challenges regarding explainability during\ntraining and inference processes. An important question is how to incorporate\nexplicit knowledge into these implicit models, thereby designing expertdriven\nand interpretable violence surveillance systems. This paper proposes a new\nparadigm for weakly supervised violence monitoring (WSVM) called Rule base\nViolence Monitoring (RuleVM). The proposed RuleVM uses a dual-branch structure\nwith different designs for images and text. One of the branches is called the\nimplicit branch, which uses only visual features for coarse-grained binary\nclassification. In this branch, image feature extraction is divided into two\nchannels: one responsible for extracting scene frames and the other focusing on\nextracting actions. The other branch is called the explicit branch, which\nutilizes language-image alignment to perform fine-grained classification. For\nthe language channel design in the explicit branch, the proposed RuleVM uses\nthe state-of-the-art YOLOWorld model to detect objects in video frames, and\nassociation rules are identified through data mining methods as descriptions of\nthe video. Leveraging the dual-branch architecture, RuleVM achieves\ninterpretable coarse-grained and fine-grained violence surveillance. Extensive\nexperiments were conducted on two commonly used benchmarks, and the results\nshow that RuleVM achieved the best performance in both coarse-grained and\nfinegrained monitoring, significantly outperforming existing state-ofthe-art\nmethods. Moreover, interpretability experiments uncovered some interesting\nrules, such as the observation that as the number of people increases, the risk\nlevel of violent behavior also rises.\n","authors":["Wen-Dong Jiang","Chih-Yung Chang","Ssu-Chi Kuai","Diptendu Sinha Roy"],"pdf_url":"https://arxiv.org/pdf/2410.21991v5.pdf","comment":"12 pages,7 figures IEEE TSMCA (Under review)"},{"id":"http://arxiv.org/abs/2310.03525v4","updated":"2024-11-14T12:17:17Z","published":"2023-10-05T13:19:48Z","title":"V2X Cooperative Perception for Autonomous Driving: Recent Advances and\n  Challenges","summary":"  Achieving fully autonomous driving with heightened safety and efficiency\ndepends on vehicle-to-everything (V2X) cooperative perception (CP), which\nallows vehicles to share perception data, thereby enhancing situational\nawareness and overcoming the limitations of the sensing ability of individual\nvehicles. V2X CP is crucial for extending perception range, improving accuracy,\nand strengthening the decision-making and control capabilities of autonomous\nvehicles in complex environments. This paper provides a comprehensive survey of\nrecent advances in V2X CP, introducing mathematical models of CP processes\nacross various collaboration strategies. We examine essential techniques for\nreliable perception sharing, including agent selection, data alignment, and\nfusion methods. Key issues are analyzed, such as agent and model heterogeneity,\nperception uncertainty, and the impact of V2X communication constraints like\ndelays and data loss on CP effectiveness. To inspire further advancements in\nV2X CP, we outline promising avenues, including privacy-preserving artificial\nintelligence (AI), collaborative AI, and integrated sensing frameworks, as\npathways to enhance CP capabilities.\n","authors":["Tao Huang","Jianan Liu","Xi Zhou","Dinh C. Nguyen","Mostafa Rahimi Azghadi","Yuxuan Xia","Qing-Long Han","Sumei Sun"],"pdf_url":"https://arxiv.org/pdf/2310.03525v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12514v4","updated":"2024-11-14T12:03:37Z","published":"2024-09-19T07:10:18Z","title":"TinyVLA: Towards Fast, Data-Efficient Vision-Language-Action Models for\n  Robotic Manipulation","summary":"  Vision-Language-Action (VLA) models have shown remarkable potential in\nvisuomotor control and instruction comprehension through end-to-end learning\nprocesses. However, current VLA models face significant challenges: they are\nslow during inference and require extensive pre-training on large amounts of\nrobotic data, making real-world deployment difficult. In this paper, we\nintroduce a new family of compact vision-language-action models, called\nTinyVLA, which offers two key advantages over existing VLA models: (1) faster\ninference speeds, and (2) improved data efficiency, eliminating the need for\npre-training stage. Our framework incorporates two essential components to\nbuild TinyVLA: (1) initializing the policy backbone with robust, high-speed\nmultimodal models, and (2) integrating a diffusion policy decoder during\nfine-tuning to enable precise robot actions. We conducted extensive evaluations\nof TinyVLA in both simulation and on real robots, demonstrating that our\napproach significantly outperforms the state-of-the-art VLA model, OpenVLA, in\nterms of speed and data efficiency, while delivering comparable or superior\nperformance. Additionally, TinyVLA exhibits strong generalization capabilities\nacross various dimensions, including language instructions, novel objects,\nunseen positions, changes in object appearance, background variations, and\nenvironmental shifts, often matching or exceeding the performance of OpenVLA.\nWe believe that \\methodname offers an interesting perspective on utilizing\npre-trained multimodal models for policy learning. Our project is at\nhttps://tiny-vla.github.io.\n","authors":["Junjie Wen","Yichen Zhu","Jinming Li","Minjie Zhu","Kun Wu","Zhiyuan Xu","Ning Liu","Ran Cheng","Chaomin Shen","Yaxin Peng","Feifei Feng","Jian Tang"],"pdf_url":"https://arxiv.org/pdf/2409.12514v4.pdf","comment":"add more citations"},{"id":"http://arxiv.org/abs/2411.09387v1","updated":"2024-11-14T12:02:01Z","published":"2024-11-14T12:02:01Z","title":"Instruction-Driven Fusion of Infrared-Visible Images: Tailoring for\n  Diverse Downstream Tasks","summary":"  The primary value of infrared and visible image fusion technology lies in\napplying the fusion results to downstream tasks. However, existing methods face\nchallenges such as increased training complexity and significantly compromised\nperformance of individual tasks when addressing multiple downstream tasks\nsimultaneously. To tackle this, we propose Task-Oriented Adaptive Regulation\n(T-OAR), an adaptive mechanism specifically designed for multi-task\nenvironments. Additionally, we introduce the Task-related Dynamic Prompt\nInjection (T-DPI) module, which generates task-specific dynamic prompts from\nuser-input text instructions and integrates them into target representations.\nThis guides the feature extraction module to produce representations that are\nmore closely aligned with the specific requirements of downstream tasks. By\nincorporating the T-DPI module into the T-OAR framework, our approach generates\nfusion images tailored to task-specific requirements without the need for\nseparate training or task-specific weights. This not only reduces computational\ncosts but also enhances adaptability and performance across multiple tasks.\nExperimental results show that our method excels in object detection, semantic\nsegmentation, and salient object detection, demonstrating its strong\nadaptability, flexibility, and task specificity. This provides an efficient\nsolution for image fusion in multi-task environments, highlighting the\ntechnology's potential across diverse applications.\n","authors":["Zengyi Yang","Yafei Zhang","Huafeng Li","Yu Liu"],"pdf_url":"https://arxiv.org/pdf/2411.09387v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.05767v2","updated":"2024-11-14T11:27:41Z","published":"2024-10-08T07:48:34Z","title":"Grounding is All You Need? Dual Temporal Grounding for Video Dialog","summary":"  In the realm of video dialog response generation, the understanding of video\ncontent and the temporal nuances of conversation history are paramount. While a\nsegment of current research leans heavily on large-scale pretrained\nvisual-language models and often overlooks temporal dynamics, another delves\ndeep into spatial-temporal relationships within videos but demands intricate\nobject trajectory pre-extractions and sidelines dialog temporal dynamics. This\npaper introduces the Dual Temporal Grounding-enhanced Video Dialog model\n(DTGVD), strategically designed to merge the strengths of both dominant\napproaches. It emphasizes dual temporal relationships by predicting dialog\nturn-specific temporal regions, filtering video content accordingly, and\ngrounding responses in both video and dialog contexts. One standout feature of\nDTGVD is its heightened attention to chronological interplay. By recognizing\nand acting upon the dependencies between different dialog turns, it captures\nmore nuanced conversational dynamics. To further bolster the alignment between\nvideo and dialog temporal dynamics, we've implemented a list-wise contrastive\nlearning strategy. Within this framework, accurately grounded turn-clip\npairings are designated as positive samples, while less precise pairings are\ncategorized as negative. This refined classification is then funneled into our\nholistic end-to-end response generation mechanism. Evaluations using\nAVSD@DSTC-7 and AVSD@DSTC-8 datasets underscore the superiority of our\nmethodology.\n","authors":["You Qin","Wei Ji","Xinze Lan","Hao Fei","Xun Yang","Dan Guo","Roger Zimmermann","Lizi Liao"],"pdf_url":"https://arxiv.org/pdf/2410.05767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09373v1","updated":"2024-11-14T11:27:15Z","published":"2024-11-14T11:27:15Z","title":"Are nuclear masks all you need for improved out-of-domain\n  generalisation? A closer look at cancer classification in histopathology","summary":"  Domain generalisation in computational histopathology is challenging because\nthe images are substantially affected by differences among hospitals due to\nfactors like fixation and staining of tissue and imaging equipment. We\nhypothesise that focusing on nuclei can improve the out-of-domain (OOD)\ngeneralisation in cancer detection. We propose a simple approach to improve OOD\ngeneralisation for cancer detection by focusing on nuclear morphology and\norganisation, as these are domain-invariant features critical in cancer\ndetection. Our approach integrates original images with nuclear segmentation\nmasks during training, encouraging the model to prioritise nuclei and their\nspatial arrangement. Going beyond mere data augmentation, we introduce a\nregularisation technique that aligns the representations of masks and original\nimages. We show, using multiple datasets, that our method improves OOD\ngeneralisation and also leads to increased robustness to image corruptions and\nadversarial attacks. The source code is available at\nhttps://github.com/undercutspiky/SFL/\n","authors":["Dhananjay Tomar","Alexander Binder","Andreas Kleppe"],"pdf_url":"https://arxiv.org/pdf/2411.09373v1.pdf","comment":"Poster at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09371v1","updated":"2024-11-14T11:25:32Z","published":"2024-11-14T11:25:32Z","title":"DSCformer: A Dual-Branch Network Integrating Enhanced Dynamic Snake\n  Convolution and SegFormer for Crack Segmentation","summary":"  In construction quality monitoring, accurately detecting and segmenting\ncracks in concrete structures is paramount for safety and maintenance. Current\nconvolutional neural networks (CNNs) have demonstrated strong performance in\ncrack segmentation tasks, yet they often struggle with complex backgrounds and\nfail to capture fine-grained tubular structures fully. In contrast,\nTransformers excel at capturing global context but lack precision in detailed\nfeature extraction. We introduce DSCformer, a novel hybrid model that\nintegrates an enhanced Dynamic Snake Convolution (DSConv) with a Transformer\narchitecture for crack segmentation to address these challenges. Our key\ncontributions include the enhanced DSConv through a pyramid kernel for adaptive\noffset computation and a simultaneous bi-directional learnable offset\niteration, significantly improving the model's performance to capture intricate\ncrack patterns. Additionally, we propose a Weighted Convolutional Attention\nModule (WCAM), which refines channel attention, allowing for more precise and\nadaptive feature attention. We evaluate DSCformer on the Crack3238 and FIND\ndatasets, achieving IoUs of 59.22\\% and 87.24\\%, respectively. The experimental\nresults suggest that our DSCformer outperforms state-of-the-art methods across\ndifferent datasets.\n","authors":["Kaiwei Yu","I-Ming Chen","Jing Wu"],"pdf_url":"https://arxiv.org/pdf/2411.09371v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12778v2","updated":"2024-11-14T11:21:09Z","published":"2024-03-19T14:45:17Z","title":"ViTGaze: Gaze Following with Interaction Features in Vision Transformers","summary":"  Gaze following aims to interpret human-scene interactions by predicting the\nperson's focal point of gaze. Prevailing approaches often adopt a two-stage\nframework, whereby multi-modality information is extracted in the initial stage\nfor gaze target prediction. Consequently, the efficacy of these methods highly\ndepends on the precision of the preceding modality extraction. Others use a\nsingle-modality approach with complex decoders, increasing network\ncomputational load. Inspired by the remarkable success of pre-trained plain\nvision transformers (ViTs), we introduce a novel single-modality gaze following\nframework called ViTGaze. In contrast to previous methods, it creates a novel\ngaze following framework based mainly on powerful encoders (relative decoder\nparameters less than 1%). Our principal insight is that the inter-token\ninteractions within self-attention can be transferred to interactions between\nhumans and scenes. Leveraging this presumption, we formulate a framework\nconsisting of a 4D interaction encoder and a 2D spatial guidance module to\nextract human-scene interaction information from self-attention maps.\nFurthermore, our investigation reveals that ViT with self-supervised\npre-training has an enhanced ability to extract correlation information. Many\nexperiments have been conducted to demonstrate the performance of the proposed\nmethod. Our method achieves state-of-the-art (SOTA) performance among all\nsingle-modality methods (3.4% improvement in the area under curve (AUC) score,\n5.1% improvement in the average precision (AP)) and very comparable performance\nagainst multi-modality methods with 59% number of parameters less.\n","authors":["Yuehao Song","Xinggang Wang","Jingfeng Yao","Wenyu Liu","Jinglin Zhang","Xiangmin Xu"],"pdf_url":"https://arxiv.org/pdf/2403.12778v2.pdf","comment":"15 pages; Accepted by Visual Intelligence"},{"id":"http://arxiv.org/abs/2411.09361v1","updated":"2024-11-14T11:08:54Z","published":"2024-11-14T11:08:54Z","title":"Time-to-Event Pretraining for 3D Medical Imaging","summary":"  With the rise of medical foundation models and the growing availability of\nimaging data, scalable pretraining techniques offer a promising way to identify\nimaging biomarkers predictive of future disease risk. While current\nself-supervised methods for 3D medical imaging models capture local structural\nfeatures like organ morphology, they fail to link pixel biomarkers with\nlong-term health outcomes due to a missing context problem. Current approaches\nlack the temporal context necessary to identify biomarkers correlated with\ndisease progression, as they rely on supervision derived only from images and\nconcurrent text descriptions. To address this, we introduce time-to-event\npretraining, a pretraining framework for 3D medical imaging models that\nleverages large-scale temporal supervision from paired, longitudinal electronic\nhealth records (EHRs). Using a dataset of 18,945 CT scans (4.2 million 2D\nimages) and time-to-event distributions across thousands of EHR-derived tasks,\nour method improves outcome prediction, achieving an average AUROC increase of\n23.7% and a 29.4% gain in Harrell's C-index across 8 benchmark tasks.\nImportantly, these gains are achieved without sacrificing diagnostic\nclassification performance. This study lays the foundation for integrating\nlongitudinal EHR and 3D imaging data to advance clinical risk prediction.\n","authors":["Zepeng Huo","Jason Alan Fries","Alejandro Lozano","Jeya Maria Jose Valanarasu","Ethan Steinberg","Louis Blankemeier","Akshay S. Chaudhari","Curtis Langlotz","Nigam H. Shah"],"pdf_url":"https://arxiv.org/pdf/2411.09361v1.pdf","comment":"34 pages, 19 figures"},{"id":"http://arxiv.org/abs/2411.09344v1","updated":"2024-11-14T10:47:01Z","published":"2024-11-14T10:47:01Z","title":"Adaptively Augmented Consistency Learning: A Semi-supervised\n  Segmentation Framework for Remote Sensing","summary":"  Remote sensing (RS) involves the acquisition of data about objects or areas\nfrom a distance, primarily to monitor environmental changes, manage resources,\nand support planning and disaster response. A significant challenge in RS\nsegmentation is the scarcity of high-quality labeled images due to the\ndiversity and complexity of RS image, which makes pixel-level annotation\ndifficult and hinders the development of effective supervised segmentation\nalgorithms. To solve this problem, we propose Adaptively Augmented Consistency\nLearning (AACL), a semi-supervised segmentation framework designed to enhances\nRS segmentation accuracy under condictions of limited labeled data. AACL\nextracts additional information embedded in unlabeled images through the use of\nUniform Strength Augmentation (USAug) and Adaptive Cut-Mix (AdaCM). Evaluations\nacross various RS datasets demonstrate that AACL achieves competitive\nperformance in semi-supervised segmentation, showing up to a 20% improvement in\nspecific categories and 2% increase in overall performance compared to\nstate-of-the-art frameworks.\n","authors":["Hui Ye","Haodong Chen","Xiaoming Chen","Vera Chung"],"pdf_url":"https://arxiv.org/pdf/2411.09344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02562v2","updated":"2024-11-14T10:45:32Z","published":"2024-09-04T09:29:24Z","title":"One Homography is All You Need: IMM-based Joint Homography and Multiple\n  Object State Estimation","summary":"  A novel online MOT algorithm, IMM Joint Homography State Estimation\n(IMM-JHSE), is proposed. IMM-JHSE uses an initial homography estimate as the\nonly additional 3D information, whereas other 3D MOT methods use regular 3D\nmeasurements. By jointly modelling the homography matrix and its dynamics as\npart of track state vectors, IMM-JHSE removes the explicit influence of camera\nmotion compensation techniques on predicted track position states, which was\nprevalent in previous approaches. Expanding upon this, static and dynamic\ncamera motion models are combined using an IMM filter. A simple bounding box\nmotion model is used to predict bounding box positions to incorporate image\nplane information. In addition to applying an IMM to camera motion, a\nnon-standard IMM approach is applied where bounding-box-based BIoU scores are\nmixed with ground-plane-based Mahalanobis distances in an IMM-like fashion to\nperform association only, making IMM-JHSE robust to motion away from the ground\nplane. Finally, IMM-JHSE makes use of dynamic process and measurement noise\nestimation techniques. IMM-JHSE improves upon related techniques, including\nUCMCTrack, OC-SORT, C-BIoU and ByteTrack on the DanceTrack and KITTI-car\ndatasets, increasing HOTA by 2.64 and 2.11, respectively, while offering\ncompetitive performance on the MOT17, MOT20 and KITTI-pedestrian datasets.\nUsing publicly available detections, IMM-JHSE outperforms almost all other 2D\nMOT methods and is outperformed only by 3D MOT methods -- some of which are\noffline -- on the KITTI-car dataset. Compared to tracking-by-attention methods,\nIMM-JHSE shows remarkably similar performance on the DanceTrack dataset and\noutperforms them on the MOT17 dataset. The code is publicly available:\n\\url{https://github.com/Paulkie99/imm-jhse}.\n","authors":["Paul Johannes Claasen","Johan Pieter de Villiers"],"pdf_url":"https://arxiv.org/pdf/2409.02562v2.pdf","comment":"Preprint submitted to Information Fusion"},{"id":"http://arxiv.org/abs/2405.18839v3","updated":"2024-11-14T10:27:51Z","published":"2024-05-29T07:40:31Z","title":"MEGA: Masked Generative Autoencoder for Human Mesh Recovery","summary":"  Human Mesh Recovery (HMR) from a single RGB image is a highly ambiguous\nproblem, as an infinite set of 3D interpretations can explain the 2D\nobservation equally well. Nevertheless, most HMR methods overlook this issue\nand make a single prediction without accounting for this ambiguity. A few\napproaches generate a distribution of human meshes, enabling the sampling of\nmultiple predictions; however, none of them is competitive with the latest\nsingle-output model when making a single prediction. This work proposes a new\napproach based on masked generative modeling. By tokenizing the human pose and\nshape, we formulate the HMR task as generating a sequence of discrete tokens\nconditioned on an input image. We introduce MEGA, a MaskEd Generative\nAutoencoder trained to recover human meshes from images and partial human mesh\ntoken sequences. Given an image, our flexible generation scheme allows us to\npredict a single human mesh in deterministic mode or to generate multiple human\nmeshes in stochastic mode. Experiments on in-the-wild benchmarks show that MEGA\nachieves state-of-the-art performance in deterministic and stochastic modes,\noutperforming single-output and multi-output approaches.\n","authors":["Guénolé Fiche","Simon Leglaive","Xavier Alameda-Pineda","Francesc Moreno-Noguer"],"pdf_url":"https://arxiv.org/pdf/2405.18839v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.19513v3","updated":"2024-11-14T09:40:00Z","published":"2024-04-30T12:45:41Z","title":"A Smartphone-Based Method for Assessing Tomato Nutrient Status through\n  Trichome Density Measurement","summary":"  Early detection of fertilizer-induced stress in tomato plants is crucial for\noptimizing crop yield through timely management interventions. While\nconventional optical methods struggle to detect fertilizer stress in young\nleaves, these leaves contain valuable diagnostic information through their\nmicroscopic hair-like structures, particularly trichomes, which existing\napproaches have overlooked. This study introduces a smartphone-based\nnoninvasive technique that leverages mobile computing and digital imaging\ncapabilities to quantify trichome density on young leaves with superior\ndetection latency. Our method uniquely combines augmented reality technology\nwith image processing algorithms to analyze trichomes transferred onto\nspecialized measurement paper. A robust automated pipeline processes these\nimages through region extraction, perspective transformation, and illumination\ncorrection to precisely quantify trichome density. Validation experiments on\nhydroponically grown tomatoes under varying fertilizer conditions demonstrated\nthe method's effectiveness. Leave-one-out cross-validation revealed strong\npredictive performance with the area under the precision-recall curve (PR-AUC:\n0.82) and area under the receiver operating characteristic curve (ROC-AUC:\n0.64), while the predicted and observed trichome densities exhibited high\ncorrelation ($r = 0.79$). This innovative approach transforms smartphones into\nprecise diagnostic tools for plant nutrition assessment, offering a practical,\ncost-effective solution for precision agriculture.\n","authors":["Sho Ueda","Xujun Ye"],"pdf_url":"https://arxiv.org/pdf/2404.19513v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09310v1","updated":"2024-11-14T09:38:29Z","published":"2024-11-14T09:38:29Z","title":"Exploring Zero-Shot Anomaly Detection with CLIP in Medical Imaging: Are\n  We There Yet?","summary":"  Zero-shot anomaly detection (ZSAD) offers potential for identifying anomalies\nin medical imaging without task-specific training. In this paper, we evaluate\nCLIP-based models, originally developed for industrial tasks, on brain tumor\ndetection using the BraTS-MET dataset. Our analysis examines their ability to\ndetect medical-specific anomalies with no or minimal supervision, addressing\nthe challenges posed by limited data annotation. While these models show\npromise in transferring general knowledge to medical tasks, their performance\nfalls short of the precision required for clinical use. Our findings highlight\nthe need for further adaptation before CLIP-based models can be reliably\napplied to medical anomaly detection.\n","authors":["Aldo Marzullo","Marta Bianca Maria Ranzini"],"pdf_url":"https://arxiv.org/pdf/2411.09310v1.pdf","comment":"accepted at 3rd AIxIA Workshop on Artificial Intelligence for\n  Healthcare and 5th Data4SmartHealth"},{"id":"http://arxiv.org/abs/2411.09308v1","updated":"2024-11-14T09:34:36Z","published":"2024-11-14T09:34:36Z","title":"DT-JRD: Deep Transformer based Just Recognizable Difference Prediction\n  Model for Video Coding for Machines","summary":"  Just Recognizable Difference (JRD) represents the minimum visual difference\nthat is detectable by machine vision, which can be exploited to promote machine\nvision oriented visual signal processing. In this paper, we propose a Deep\nTransformer based JRD (DT-JRD) prediction model for Video Coding for Machines\n(VCM), where the accurately predicted JRD can be used reduce the coding bit\nrate while maintaining the accuracy of machine tasks. Firstly, we model the JRD\nprediction as a multi-class classification and propose a DT-JRD prediction\nmodel that integrates an improved embedding, a content and distortion feature\nextraction, a multi-class classification and a novel learning strategy.\nSecondly, inspired by the perception property that machine vision exhibits a\nsimilar response to distortions near JRD, we propose an asymptotic JRD loss by\nusing Gaussian Distribution-based Soft Labels (GDSL), which significantly\nextends the number of training labels and relaxes classification boundaries.\nFinally, we propose a DT-JRD based VCM to reduce the coding bits while\nmaintaining the accuracy of object detection. Extensive experimental results\ndemonstrate that the mean absolute error of the predicted JRD by the DT-JRD is\n5.574, outperforming the state-of-the-art JRD prediction model by 13.1%. Coding\nexperiments shows that comparing with the VVC, the DT-JRD based VCM achieves an\naverage of 29.58% bit rate reduction while maintaining the object detection\naccuracy.\n","authors":["Junqi Liu","Yun Zhang","Xiaoqi Wang","Xu Long","Sam Kwong"],"pdf_url":"https://arxiv.org/pdf/2411.09308v1.pdf","comment":"Submitted to IEEE Transactions on Multimedia"},{"id":"http://arxiv.org/abs/2411.09301v1","updated":"2024-11-14T09:23:40Z","published":"2024-11-14T09:23:40Z","title":"LHRS-Bot-Nova: Improved Multimodal Large Language Model for Remote\n  Sensing Vision-Language Interpretation","summary":"  Automatically and rapidly understanding Earth's surface is fundamental to our\ngrasp of the living environment and informed decision-making. This underscores\nthe need for a unified system with comprehensive capabilities in analyzing\nEarth's surface to address a wide range of human needs. The emergence of\nmultimodal large language models (MLLMs) has great potential in boosting the\nefficiency and convenience of intelligent Earth observation. These models can\nengage in human-like conversations, serve as unified platforms for\nunderstanding images, follow diverse instructions, and provide insightful\nfeedbacks. In this study, we introduce LHRS-Bot-Nova, an MLLM specialized in\nunderstanding remote sensing (RS) images, designed to expertly perform a wide\nrange of RS understanding tasks aligned with human instructions. LHRS-Bot-Nova\nfeatures an enhanced vision encoder and a novel bridge layer, enabling\nefficient visual compression and better language-vision alignment. To further\nenhance RS-oriented vision-language alignment, we propose a large-scale RS\nimage-caption dataset, generated through feature-guided image recaptioning.\nAdditionally, we introduce an instruction dataset specifically designed to\nimprove spatial recognition abilities. Extensive experiments demonstrate\nsuperior performance of LHRS-Bot-Nova across various RS image understanding\ntasks. We also evaluate different MLLM performances in complex RS perception\nand instruction following using a complicated multi-choice question evaluation\nbenchmark, providing a reliable guide for future model selection and\nimprovement. Data, code, and models will be available at\nhttps://github.com/NJU-LHRS/LHRS-Bot.\n","authors":["Zhenshi Li","Dilxat Muhtar","Feng Gu","Xueliang Zhang","Pengfeng Xiao","Guangjun He","Xiaoxiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2411.09301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09293v1","updated":"2024-11-14T09:12:18Z","published":"2024-11-14T09:12:18Z","title":"LLV-FSR: Exploiting Large Language-Vision Prior for Face\n  Super-resolution","summary":"  Existing face super-resolution (FSR) methods have made significant\nadvancements, but they primarily super-resolve face with limited visual\ninformation, original pixel-wise space in particular, commonly overlooking the\npluralistic clues, like the higher-order depth and semantics, as well as\nnon-visual inputs (text caption and description). Consequently, these methods\nstruggle to produce a unified and meaningful representation from the input\nface. We suppose that introducing the language-vision pluralistic\nrepresentation into unexplored potential embedding space could enhance FSR by\nencoding and exploiting the complementarity across language-vision prior. This\nmotivates us to propose a new framework called LLV-FSR, which marries the power\nof large vision-language model and higher-order visual prior with the\nchallenging task of FSR. Specifically, besides directly absorbing knowledge\nfrom original input, we introduce the pre-trained vision-language model to\ngenerate pluralistic priors, involving the image caption, descriptions, face\nsemantic mask and depths. These priors are then employed to guide the more\ncritical feature representation, facilitating realistic and high-quality face\nsuper-resolution. Experimental results demonstrate that our proposed framework\nsignificantly improves both the reconstruction quality and perceptual quality,\nsurpassing the SOTA by 0.43dB in terms of PSNR on the MMCelebA-HQ dataset.\n","authors":["Chenyang Wang","Wenjie An","Kui Jiang","Xianming Liu","Junjun Jiang"],"pdf_url":"https://arxiv.org/pdf/2411.09293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09283v1","updated":"2024-11-14T08:40:08Z","published":"2024-11-14T08:40:08Z","title":"Leveraging Auxiliary Classification for Rib Fracture Segmentation","summary":"  Thoracic trauma often results in rib fractures, which demand swift and\naccurate diagnosis for effective treatment. However, detecting these fractures\non rib CT scans poses considerable challenges, involving the analysis of many\nimage slices in sequence. Despite notable advancements in algorithms for\nautomated fracture segmentation, the persisting challenges stem from the\ndiverse shapes and sizes of these fractures. To address these issues, this\nstudy introduces a sophisticated deep-learning model with an auxiliary\nclassification task designed to enhance the accuracy of rib fracture\nsegmentation. The auxiliary classification task is crucial in distinguishing\nbetween fractured ribs and negative regions, encompassing non-fractured ribs\nand surrounding tissues, from the patches obtained from CT scans. By leveraging\nthis auxiliary task, the model aims to improve feature representation at the\nbottleneck layer by highlighting the regions of interest. Experimental results\non the RibFrac dataset demonstrate significant improvement in segmentation\nperformance.\n","authors":["Harini G.","Aiman Farooq","Deepak Mishra"],"pdf_url":"https://arxiv.org/pdf/2411.09283v1.pdf","comment":"Accepted at ICVGIP'24"},{"id":"http://arxiv.org/abs/2411.08756v2","updated":"2024-11-14T08:36:22Z","published":"2024-11-13T16:42:07Z","title":"Masked Image Modeling Boosting Semi-Supervised Semantic Segmentation","summary":"  In view of the fact that semi- and self-supervised learning share a\nfundamental principle, effectively modeling knowledge from unlabeled data,\nvarious semi-supervised semantic segmentation methods have integrated\nrepresentative self-supervised learning paradigms for further regularization.\nHowever, the potential of the state-of-the-art generative self-supervised\nparadigm, masked image modeling, has been scarcely studied. This paradigm\nlearns the knowledge through establishing connections between the masked and\nvisible parts of masked image, during the pixel reconstruction process. By\ninheriting and extending this insight, we successfully leverage masked image\nmodeling to boost semi-supervised semantic segmentation. Specifically, we\nintroduce a novel class-wise masked image modeling that independently\nreconstructs different image regions according to their respective classes. In\nthis way, the mask-induced connections are established within each class,\nmitigating the semantic confusion that arises from plainly reconstructing\nimages in basic masked image modeling. To strengthen these intra-class\nconnections, we further develop a feature aggregation strategy that minimizes\nthe distances between features corresponding to the masked and visible parts\nwithin the same class. Additionally, in semantic space, we explore the\napplication of masked image modeling to enhance regularization. Extensive\nexperiments conducted on well-known benchmarks demonstrate that our approach\nachieves state-of-the-art performance. The code will be available at\nhttps://github.com/haoxt/S4MIM.\n","authors":["Yangyang Li","Xuanting Hao","Ronghua Shang","Licheng Jiao"],"pdf_url":"https://arxiv.org/pdf/2411.08756v2.pdf","comment":"13 pages. This work has been submitted to the IEEE for possible\n  publication"},{"id":"http://arxiv.org/abs/2411.09268v1","updated":"2024-11-14T08:12:16Z","published":"2024-11-14T08:12:16Z","title":"LES-Talker: Fine-Grained Emotion Editing for Talking Head Generation in\n  Linear Emotion Space","summary":"  While existing one-shot talking head generation models have achieved progress\nin coarse-grained emotion editing, there is still a lack of fine-grained\nemotion editing models with high interpretability. We argue that for an\napproach to be considered fine-grained, it needs to provide clear definitions\nand sufficiently detailed differentiation. We present LES-Talker, a novel\none-shot talking head generation model with high interpretability, to achieve\nfine-grained emotion editing across emotion types, emotion levels, and facial\nunits. We propose a Linear Emotion Space (LES) definition based on Facial\nAction Units to characterize emotion transformations as vector transformations.\nWe design the Cross-Dimension Attention Net (CDAN) to deeply mine the\ncorrelation between LES representation and 3D model representation. Through\nmining multiple relationships across different feature and structure\ndimensions, we enable LES representation to guide the controllable deformation\nof 3D model. In order to adapt the multimodal data with deviations to the LES\nand enhance visual quality, we utilize specialized network design and training\nstrategies. Experiments show that our method provides high visual quality along\nwith multilevel and interpretable fine-grained emotion editing, outperforming\nmainstream methods.\n","authors":["Guanwen Feng","Zhihao Qian","Yunan Li","Siyu Jin","Qiguang Miao","Chi-Man Pun"],"pdf_url":"https://arxiv.org/pdf/2411.09268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09266v1","updated":"2024-11-14T08:07:02Z","published":"2024-11-14T08:07:02Z","title":"How Good is ChatGPT at Audiovisual Deepfake Detection: A Comparative\n  Study of ChatGPT, AI Models and Human Perception","summary":"  Multimodal deepfakes involving audiovisual manipulations are a growing threat\nbecause they are difficult to detect with the naked eye or using unimodal deep\nlearningbased forgery detection methods. Audiovisual forensic models, while\nmore capable than unimodal models, require large training datasets and are\ncomputationally expensive for training and inference. Furthermore, these models\nlack interpretability and often do not generalize well to unseen manipulations.\nIn this study, we examine the detection capabilities of a large language model\n(LLM) (i.e., ChatGPT) to identify and account for any possible visual and\nauditory artifacts and manipulations in audiovisual deepfake content. Extensive\nexperiments are conducted on videos from a benchmark multimodal deepfake\ndataset to evaluate the detection performance of ChatGPT and compare it with\nthe detection capabilities of state-of-the-art multimodal forensic models and\nhumans. Experimental results demonstrate the importance of domain knowledge and\nprompt engineering for video forgery detection tasks using LLMs. Unlike\napproaches based on end-to-end learning, ChatGPT can account for spatial and\nspatiotemporal artifacts and inconsistencies that may exist within or across\nmodalities. Additionally, we discuss the limitations of ChatGPT for multimedia\nforensic tasks.\n","authors":["Sahibzada Adil Shahzad","Ammarah Hashmi","Yan-Tsung Peng","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09265v1","updated":"2024-11-14T08:05:34Z","published":"2024-11-14T08:05:34Z","title":"BEARD: Benchmarking the Adversarial Robustness for Dataset Distillation","summary":"  Dataset Distillation (DD) is an emerging technique that compresses\nlarge-scale datasets into significantly smaller synthesized datasets while\npreserving high test performance and enabling the efficient training of large\nmodels. However, current research primarily focuses on enhancing evaluation\naccuracy under limited compression ratios, often overlooking critical security\nconcerns such as adversarial robustness. A key challenge in evaluating this\nrobustness lies in the complex interactions between distillation methods, model\narchitectures, and adversarial attack strategies, which complicate standardized\nassessments. To address this, we introduce BEARD, an open and unified benchmark\ndesigned to systematically assess the adversarial robustness of DD methods,\nincluding DM, IDM, and BACON. BEARD encompasses a variety of adversarial\nattacks (e.g., FGSM, PGD, C&W) on distilled datasets like CIFAR-10/100 and\nTinyImageNet. Utilizing an adversarial game framework, it introduces three key\nmetrics: Robustness Ratio (RR), Attack Efficiency Ratio (AE), and Comprehensive\nRobustness-Efficiency Index (CREI). Our analysis includes unified benchmarks,\nvarious Images Per Class (IPC) settings, and the effects of adversarial\ntraining. Results are available on the BEARD Leaderboard, along with a library\nproviding model and dataset pools to support reproducible research. Access the\ncode at BEARD.\n","authors":["Zheng Zhou","Wenquan Feng","Shuchang Lyu","Guangliang Cheng","Xiaowei Huang","Qi Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.09265v1.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.09263v1","updated":"2024-11-14T08:02:14Z","published":"2024-11-14T08:02:14Z","title":"Rethinking Weight-Averaged Model-merging","summary":"  Weight-averaged model-merging has emerged as a powerful approach in deep\nlearning, capable of enhancing model performance without fine-tuning or\nretraining. However, the underlying mechanisms that explain its effectiveness\nremain largely unexplored. In this paper, we investigate this technique from\nthree novel perspectives to provide deeper insights into how and why\nweight-averaged model-merging works: (1) we examine the intrinsic patterns\ncaptured by the learning of the model weights, through the visualizations of\ntheir patterns on several datasets, showing that these weights often encode\nstructured and interpretable patterns; (2) we investigate model ensemble\nmerging strategies based on averaging on weights versus averaging on features,\nproviding detailed analyses across diverse architectures and datasets; and (3)\nwe explore the impact on model-merging prediction stability in terms of\nchanging the parameter magnitude, revealing insights into the way of weight\naveraging works as regularization by showing the robustness across different\nparameter scales. Our findings shed light on the \"black box\" of weight-averaged\nmodel-merging, offering valuable insights and practical recommendations that\nadvance the model-merging process.\n","authors":["Hu Wang","Congbo Ma","Ibrahim Almakky","Ian Reid","Gustavo Carneiro","Mohammad Yaqub"],"pdf_url":"https://arxiv.org/pdf/2411.09263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09259v1","updated":"2024-11-14T07:51:51Z","published":"2024-11-14T07:51:51Z","title":"Jailbreak Attacks and Defenses against Multimodal Generative Models: A\n  Survey","summary":"  The rapid evolution of multimodal foundation models has led to significant\nadvancements in cross-modal understanding and generation across diverse\nmodalities, including text, images, audio, and video. However, these models\nremain susceptible to jailbreak attacks, which can bypass built-in safety\nmechanisms and induce the production of potentially harmful content.\nConsequently, understanding the methods of jailbreak attacks and existing\ndefense mechanisms is essential to ensure the safe deployment of multimodal\ngenerative models in real-world scenarios, particularly in security-sensitive\napplications. To provide comprehensive insight into this topic, this survey\nreviews jailbreak and defense in multimodal generative models. First, given the\ngeneralized lifecycle of multimodal jailbreak, we systematically explore\nattacks and corresponding defense strategies across four levels: input,\nencoder, generator, and output. Based on this analysis, we present a detailed\ntaxonomy of attack methods, defense mechanisms, and evaluation frameworks\nspecific to multimodal generative models. Additionally, we cover a wide range\nof input-output configurations, including modalities such as Any-to-Text,\nAny-to-Vision, and Any-to-Any within generative systems. Finally, we highlight\ncurrent research challenges and propose potential directions for future\nresearch.The open-source repository corresponding to this work can be found at\nhttps://github.com/liuxuannan/Awesome-Multimodal-Jailbreak.\n","authors":["Xuannan Liu","Xing Cui","Peipei Li","Zekun Li","Huaibo Huang","Shuhan Xia","Miaoxuan Zhang","Yueying Zou","Ran He"],"pdf_url":"https://arxiv.org/pdf/2411.09259v1.pdf","comment":"ongoing work"},{"id":"http://arxiv.org/abs/2311.10126v2","updated":"2024-11-14T07:43:14Z","published":"2023-11-16T13:07:47Z","title":"I&S-ViT: An Inclusive & Stable Method for Pushing the Limit of\n  Post-Training ViTs Quantization","summary":"  Albeit the scalable performance of vision transformers (ViTs), the dense\ncomputational costs (training & inference) undermine their position in\nindustrial applications. Post-training quantization (PTQ), tuning ViTs with a\ntiny dataset and running in a low-bit format, well addresses the cost issue but\nunluckily bears more performance drops in lower-bit cases. In this paper, we\nintroduce I&S-ViT, a novel method that regulates the PTQ of ViTs in an\ninclusive and stable fashion. I&S-ViT first identifies two issues in the PTQ of\nViTs: (1) Quantization inefficiency in the prevalent log2 quantizer for\npost-Softmax activations; (2) Rugged and magnified loss landscape in\ncoarse-grained quantization granularity for post-LayerNorm activations. Then,\nI&S-ViT addresses these issues by introducing: (1) A novel shift-uniform-log2\nquantizer (SULQ) that incorporates a shift mechanism followed by uniform\nquantization to achieve both an inclusive domain representation and accurate\ndistribution approximation; (2) A three-stage smooth optimization strategy\n(SOS) that amalgamates the strengths of channel-wise and layer-wise\nquantization to enable stable learning. Comprehensive evaluations across\ndiverse vision tasks validate I&S-ViT' superiority over existing PTQ of ViTs\nmethods, particularly in low-bit scenarios. For instance, I&S-ViT elevates the\nperformance of 3-bit ViT-B by an impressive 50.68%.\n","authors":["Yunshan Zhong","Jiawei Hu","Mengzhao Chen","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2311.10126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14955v4","updated":"2024-11-14T07:37:28Z","published":"2024-04-23T12:00:20Z","title":"A Comprehensive Survey for Hyperspectral Image Classification: The\n  Evolution from Conventional to Transformers and Mamba Models","summary":"  Hyperspectral Image Classification (HSC) presents significant challenges\nowing to the high dimensionality and intricate nature of Hyperspectral (HS)\ndata. While traditional Machine Learning (TML) approaches have demonstrated\neffectiveness, they often encounter substantial obstacles in real-world\napplications, including the variability of optimal feature sets, subjectivity\nin human-driven design, inherent biases, and methodological limitations.\nSpecifically, TML suffers from the curse of dimensionality, difficulties in\nfeature selection and extraction, insufficient consideration of spatial\ninformation, limited robustness against noise, scalability issues, and\ninadequate adaptability to complex data distributions. In recent years, Deep\nLearning (DL) techniques have emerged as robust solutions to address these\nchallenges. This survey offers a comprehensive overview of current trends and\nfuture prospects in HSC, emphasizing advancements from DL models to the\nincreasing adoption of Transformer and Mamba Model architectures. We\nsystematically review key concepts, methodologies, and state-of-the-art\napproaches in DL for HSC. Furthermore, we investigate the potential of\nTransformer-based models and the Mamba Model in HSC, detailing their advantages\nand challenges. Emerging trends in HSC are explored, including in-depth\ndiscussions on Explainable AI and Interoperability concepts, alongside\nDiffusion Models for image denoising, feature extraction, and image fusion.\nComprehensive experimental results were conducted on three HS datasets to\nsubstantiate the efficacy of various conventional DL models and Transformers.\nAdditionally, we identify several open challenges and pertinent research\nquestions in the field of HSC. Finally, we outline future research directions\nand potential applications aimed at enhancing the accuracy and efficiency of\nHSC.\n","authors":["Muhammad Ahmad","Salvatore Distifano","Adil Mehmood Khan","Manuel Mazzara","Chenyu Li","Hao Li","Jagannath Aryal","Yao Ding","Gemine Vivone","Danfeng Hong"],"pdf_url":"https://arxiv.org/pdf/2404.14955v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09251v1","updated":"2024-11-14T07:34:31Z","published":"2024-11-14T07:34:31Z","title":"Cross Space and Time: A Spatio-Temporal Unitized Model for Traffic Flow\n  Forecasting","summary":"  Predicting spatio-temporal traffic flow presents significant challenges due\nto complex interactions between spatial and temporal factors. Existing\napproaches often address these dimensions in isolation, neglecting their\ncritical interdependencies. In this paper, we introduce the Spatio-Temporal\nUnitized Model (STUM), a unified framework designed to capture both spatial and\ntemporal dependencies while addressing spatio-temporal heterogeneity through\ntechniques such as distribution alignment and feature fusion. It also ensures\nboth predictive accuracy and computational efficiency. Central to STUM is the\nAdaptive Spatio-temporal Unitized Cell (ASTUC), which utilizes low-rank\nmatrices to seamlessly store, update, and interact with space, time, as well as\ntheir correlations. Our framework is also modular, allowing it to integrate\nwith various spatio-temporal graph neural networks through components such as\nbackbone models, feature extractors, residual fusion blocks, and predictive\nmodules to collectively enhance forecasting outcomes. Experimental results\nacross multiple real-world datasets demonstrate that STUM consistently improves\nprediction performance with minimal computational cost. These findings are\nfurther supported by hyperparameter optimization, pre-training analysis, and\nresult visualization. We provide our source code for reproducibility at\nhttps://anonymous.4open.science/r/STUM-E4F0.\n","authors":["Weilin Ruan","Wenzhuo Wang","Siru Zhong","Wei Chen","Li Liu","Yuxuan Liang"],"pdf_url":"https://arxiv.org/pdf/2411.09251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09250v1","updated":"2024-11-14T07:31:12Z","published":"2024-11-14T07:31:12Z","title":"Embedding Space Allocation with Angle-Norm Joint Classifiers for\n  Few-Shot Class-Incremental Learning","summary":"  Few-shot class-incremental learning (FSCIL) aims to continually learn new\nclasses from only a few samples without forgetting previous ones, requiring\nintelligent agents to adapt to dynamic environments. FSCIL combines the\ncharacteristics and challenges of class-incremental learning and few-shot\nlearning: (i) Current classes occupy the entire feature space, which is\ndetrimental to learning new classes. (ii) The small number of samples in\nincremental rounds is insufficient for fully training. In existing mainstream\nvirtual class methods, for addressing the challenge (i), they attempt to use\nvirtual classes as placeholders. However, new classes may not necessarily align\nwith the virtual classes. For the challenge (ii), they replace trainable fully\nconnected layers with Nearest Class Mean (NCM) classifiers based on cosine\nsimilarity, but NCM classifiers do not account for sample imbalance issues. To\naddress these issues in previous methods, we propose the class-center guided\nembedding Space Allocation with Angle-Norm joint classifiers (SAAN) learning\nframework, which provides balanced space for all classes and leverages norm\ndifferences caused by sample imbalance to enhance classification criteria.\nSpecifically, for challenge (i), SAAN divides the feature space into multiple\nsubspaces and allocates a dedicated subspace for each session by guiding\nsamples with the pre-set category centers. For challenge (ii), SAAN establishes\na norm distribution for each class and generates angle-norm joint logits.\nExperiments demonstrate that SAAN can achieve state-of-the-art performance and\nit can be directly embedded into other SOTA methods as a plug-in, further\nenhancing their performance.\n","authors":["Dunwei Tu","Huiyu Yi","Tieyi Zhang","Ruotong Li","Furao Shen","Jian Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.09250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06526v2","updated":"2024-11-14T07:29:33Z","published":"2024-06-10T17:59:55Z","title":"GaussianCity: Generative Gaussian Splatting for Unbounded 3D City\n  Generation","summary":"  3D city generation with NeRF-based methods shows promising generation results\nbut is computationally inefficient. Recently 3D Gaussian Splatting (3D-GS) has\nemerged as a highly efficient alternative for object-level 3D generation.\nHowever, adapting 3D-GS from finite-scale 3D objects and humans to\ninfinite-scale 3D cities is non-trivial. Unbounded 3D city generation entails\nsignificant storage overhead (out-of-memory issues), arising from the need to\nexpand points to billions, often demanding hundreds of Gigabytes of VRAM for a\ncity scene spanning 10km^2. In this paper, we propose GaussianCity, a\ngenerative Gaussian Splatting framework dedicated to efficiently synthesizing\nunbounded 3D cities with a single feed-forward pass. Our key insights are\ntwo-fold: 1) Compact 3D Scene Representation: We introduce BEV-Point as a\nhighly compact intermediate representation, ensuring that the growth in VRAM\nusage for unbounded scenes remains constant, thus enabling unbounded city\ngeneration. 2) Spatial-aware Gaussian Attribute Decoder: We present\nspatial-aware BEV-Point decoder to produce 3D Gaussian attributes, which\nleverages Point Serializer to integrate the structural and contextual\ncharacteristics of BEV points. Extensive experiments demonstrate that\nGaussianCity achieves state-of-the-art results in both drone-view and\nstreet-view 3D city generation. Notably, compared to CityDreamer, GaussianCity\nexhibits superior performance with a speedup of 60 times (10.72 FPS v.s. 0.18\nFPS).\n","authors":["Haozhe Xie","Zhaoxi Chen","Fangzhou Hong","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2406.06526v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16725v2","updated":"2024-11-14T07:15:06Z","published":"2024-07-23T12:53:38Z","title":"Category-Extensible Out-of-Distribution Detection via Hierarchical\n  Context Descriptions","summary":"  The key to OOD detection has two aspects: generalized feature representation\nand precise category description. Recently, vision-language models such as CLIP\nprovide significant advances in both two issues, but constructing precise\ncategory descriptions is still in its infancy due to the absence of unseen\ncategories. This work introduces two hierarchical contexts, namely perceptual\ncontext and spurious context, to carefully describe the precise category\nboundary through automatic prompt tuning. Specifically, perceptual contexts\nperceive the inter-category difference (e.g., cats vs apples) for current\nclassification tasks, while spurious contexts further identify spurious\n(similar but exactly not) OOD samples for every single category (e.g., cats vs\npanthers, apples vs peaches). The two contexts hierarchically construct the\nprecise description for a certain category, which is, first roughly classifying\na sample to the predicted category and then delicately identifying whether it\nis truly an ID sample or actually OOD. Moreover, the precise descriptions for\nthose categories within the vision-language framework present a novel\napplication: CATegory-EXtensible OOD detection (CATEX). One can efficiently\nextend the set of recognizable categories by simply merging the hierarchical\ncontexts learned under different sub-task settings. And extensive experiments\nare conducted to demonstrate CATEX's effectiveness, robustness, and\ncategory-extensibility. For instance, CATEX consistently surpasses the rivals\nby a large margin with several protocols on the challenging ImageNet-1K\ndataset. In addition, we offer new insights on how to efficiently scale up the\nprompt engineering in vision-language models to recognize thousands of object\ncategories, as well as how to incorporate large language models (like GPT-3) to\nboost zero-shot applications. Code is publicly available at\nhttps://github.com/alibaba/catex.\n","authors":["Kai Liu","Zhihang Fu","Chao Chen","Sheng Jin","Ze Chen","Mingyuan Tao","Rongxin Jiang","Jieping Ye"],"pdf_url":"https://arxiv.org/pdf/2407.16725v2.pdf","comment":"Accepted by 37th Conference on Neural Information Processing Systems\n  (NeurIPS 2023). Code is available at https://github.com/alibaba/catex"},{"id":"http://arxiv.org/abs/2411.07579v3","updated":"2024-11-14T07:02:03Z","published":"2024-11-12T06:29:48Z","title":"Projecting Gaussian Ellipsoids While Avoiding Affine Projection\n  Approximation","summary":"  Recently, 3D Gaussian Splatting has dominated novel-view synthesis with its\nreal-time rendering speed and state-of-the-art rendering quality. However,\nduring the rendering process, the use of the Jacobian of the affine\napproximation of the projection transformation leads to inevitable errors,\nresulting in blurriness, artifacts and a lack of scene consistency in the final\nrendered images. To address this issue, we introduce an ellipsoid-based\nprojection method to calculate the projection of Gaussian ellipsoid onto the\nimage plane, which is the primitive of 3D Gaussian Splatting. As our proposed\nellipsoid-based projection method cannot handle Gaussian ellipsoids with camera\norigins inside them or parts lying below $z=0$ plane in the camera space, we\ndesigned a pre-filtering strategy. Experiments over multiple widely adopted\nbenchmark datasets show that our ellipsoid-based projection method can enhance\nthe rendering quality of 3D Gaussian Splatting and its extensions.\n","authors":["Han Qi","Tao Cai","Xiyue Han"],"pdf_url":"https://arxiv.org/pdf/2411.07579v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07032v2","updated":"2024-11-14T06:36:57Z","published":"2024-03-11T04:56:10Z","title":"STARFlow: Spatial Temporal Feature Re-embedding with Attentive Learning\n  for Real-world Scene Flow","summary":"  Scene flow prediction is a crucial underlying task in understanding dynamic\nscenes as it offers fundamental motion information. However, contemporary scene\nflow methods encounter three major challenges. Firstly, flow estimation solely\nbased on local receptive fields lacks long-dependency matching of point pairs.\nTo address this issue, we propose global attentive flow embedding to match\nall-to-all point pairs in both feature space and Euclidean space, providing\nglobal initialization before local refinement. Secondly, there are deformations\nexisting in non-rigid objects after warping, which leads to variations in the\nspatiotemporal relation between the consecutive frames. For a more precise\nestimation of residual flow, a spatial temporal feature re-embedding module is\ndevised to acquire the sequence features after deformation. Furthermore,\nprevious methods perform poor generalization due to the significant domain gap\nbetween the synthesized and LiDAR-scanned datasets. We leverage novel domain\nadaptive losses to effectively bridge the gap of motion inference from\nsynthetic to real-world. Experiments demonstrate that our approach achieves\nstate-of-the-art performance across various datasets, with particularly\noutstanding results on real-world LiDAR-scanned datasets. Our code is available\nat https://github.com/O-VIGIA/StarFlow.\n","authors":["Zhiyang Lu","Qinghan Chen","Ming Cheng"],"pdf_url":"https://arxiv.org/pdf/2403.07032v2.pdf","comment":"This paper was renamed to:\"SSRFlow: Semantic-aware Fusion with\n  Spatial Temporal Re-embedding for Real-world Scene Flow\" [arXiv:2408.07825]\n  and was accepted in 3DV 2025"},{"id":"http://arxiv.org/abs/2411.09219v1","updated":"2024-11-14T06:31:20Z","published":"2024-11-14T06:31:20Z","title":"Harnessing Vision Foundation Models for High-Performance, Training-Free\n  Open Vocabulary Segmentation","summary":"  While Contrastive Language-Image Pre-training (CLIP) has advanced\nopen-vocabulary predictions, its performance on semantic segmentation remains\nsuboptimal. This shortfall primarily stems from its spatial-invariant semantic\nfeatures and constrained resolution. While previous adaptations addressed\nspatial invariance semantic by modifying the self-attention in CLIP's image\nencoder, the issue of limited resolution remains unexplored. Different from\nprevious segment-then-splice methods that segment sub-images via a sliding\nwindow and splice the results, we introduce a splice-then-segment paradigm that\nincorporates Segment-Anything Model (SAM) to tackle the resolution issue since\nSAM excels at extracting fine-grained semantic correlations from\nhigh-resolution images. Specifically, we introduce Trident, a training-free\nframework that first splices features extracted by CLIP and DINO from\nsub-images, then leverages SAM's encoder to create a correlation matrix for\nglobal aggregation, enabling a broadened receptive field for effective\nsegmentation. Besides, we propose a refinement strategy for CLIP's coarse\nsegmentation outputs by transforming them into prompts for SAM, further\nenhancing the segmentation performance. Trident achieves a significant\nimprovement in the mIoU across eight benchmarks compared with the current SOTA,\nincreasing from 44.4 to 48.6.Code is available at\nhttps://github.com/YuHengsss/Trident.\n","authors":["Yuheng Shi","Minjing Dong","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2411.09219v1.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.09209v1","updated":"2024-11-14T06:13:05Z","published":"2024-11-14T06:13:05Z","title":"JoyVASA: Portrait and Animal Image Animation with Diffusion-Based\n  Audio-Driven Facial Dynamics and Head Motion Generation","summary":"  Audio-driven portrait animation has made significant advances with\ndiffusion-based models, improving video quality and lipsync accuracy. However,\nthe increasing complexity of these models has led to inefficiencies in training\nand inference, as well as constraints on video length and inter-frame\ncontinuity. In this paper, we propose JoyVASA, a diffusion-based method for\ngenerating facial dynamics and head motion in audio-driven facial animation.\nSpecifically, in the first stage, we introduce a decoupled facial\nrepresentation framework that separates dynamic facial expressions from static\n3D facial representations. This decoupling allows the system to generate longer\nvideos by combining any static 3D facial representation with dynamic motion\nsequences. Then, in the second stage, a diffusion transformer is trained to\ngenerate motion sequences directly from audio cues, independent of character\nidentity. Finally, a generator trained in the first stage uses the 3D facial\nrepresentation and the generated motion sequences as inputs to render\nhigh-quality animations. With the decoupled facial representation and the\nidentity-independent motion generation process, JoyVASA extends beyond human\nportraits to animate animal faces seamlessly. The model is trained on a hybrid\ndataset of private Chinese and public English data, enabling multilingual\nsupport. Experimental results validate the effectiveness of our approach.\nFuture work will focus on improving real-time performance and refining\nexpression control, further expanding the applications in portrait animation.\nThe code will be available at: https://jdhalgo.github.io/JoyVASA.\n","authors":["Xuyang Cao","Sheng Shi","Jun Zhao","Yang Yao","Jintao Fei","Minyu Gao","Guoxin Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08481v2","updated":"2024-11-14T05:13:21Z","published":"2024-09-13T02:13:11Z","title":"USTC-TD: A Test Dataset and Benchmark for Image and Video Coding in\n  2020s","summary":"  Image/video coding has been a remarkable research area for both academia and\nindustry for many years. Testing datasets, especially high-quality image/video\ndatasets are desirable for the justified evaluation of coding-related research,\npractical applications, and standardization activities. We put forward a test\ndataset namely USTC-TD, which has been successfully adopted in the practical\nend-to-end image/video coding challenge of the IEEE International Conference on\nVisual Communications and lmage Processing (VCIP) in 2022 and 2023. USTC-TD\ncontains 40 images at 4K spatial resolution and 10 video sequences at 1080p\nspatial resolution, featuring various content due to the diverse environmental\nfactors (e.g. scene type, texture, motion, view) and the designed imaging\nfactors (e.g. illumination, lens, shadow). We quantitatively evaluate USTC-TD\non different image/video features (spatial, temporal, color, lightness), and\ncompare it with the previous image/video test datasets, which verifies the\nwider coverage and more diversity of the proposed dataset. We also evaluate\nboth classic standardized and recent learned image/video coding schemes on\nUSTC-TD with PSNR and MS-SSIM, and provide an extensive benchmark for the\nevaluated schemes. Based on the characteristics and specific design of the\nproposed test dataset, we analyze the benchmark performance and shed light on\nthe future research and development of image/video coding. All the data are\nreleased online: https://esakak.github.io/USTC-TD .\n","authors":["Zhuoyuan Li","Junqi Liao","Chuanbo Tang","Haotian Zhang","Yuqi Li","Yifan Bian","Xihua Sheng","Xinmin Feng","Yao Li","Changsheng Gao","Li Li","Dong Liu","Feng Wu"],"pdf_url":"https://arxiv.org/pdf/2409.08481v2.pdf","comment":"23 pages. Project Page: https://esakak.github.io/USTC-TD"},{"id":"http://arxiv.org/abs/2411.09180v1","updated":"2024-11-14T04:39:10Z","published":"2024-11-14T04:39:10Z","title":"LEAP:D - A Novel Prompt-based Approach for Domain-Generalized Aerial\n  Object Detection","summary":"  Drone-captured images present significant challenges in object detection due\nto varying shooting conditions, which can alter object appearance and shape.\nFactors such as drone altitude, angle, and weather cause these variations,\ninfluencing the performance of object detection algorithms. To tackle these\nchallenges, we introduce an innovative vision-language approach using learnable\nprompts. This shift from conventional manual prompts aims to reduce\ndomain-specific knowledge interference, ultimately improving object detection\ncapabilities. Furthermore, we streamline the training process with a one-step\napproach, updating the learnable prompt concurrently with model training,\nenhancing efficiency without compromising performance. Our study contributes to\ndomain-generalized object detection by leveraging learnable prompts and\noptimizing training processes. This enhances model robustness and adaptability\nacross diverse environments, leading to more effective aerial object detection.\n","authors":["Chanyeong Park","Heegwang Kim","Joonki Paik"],"pdf_url":"https://arxiv.org/pdf/2411.09180v1.pdf","comment":"ICIP 2024 Workshop accepted paper"},{"id":"http://arxiv.org/abs/2411.09176v1","updated":"2024-11-14T04:29:07Z","published":"2024-11-14T04:29:07Z","title":"Gazing at Rewards: Eye Movements as a Lens into Human and AI\n  Decision-Making in Hybrid Visual Foraging","summary":"  Imagine searching a collection of coins for quarters ($0.25$), dimes\n($0.10$), nickels ($0.05$), and pennies ($0.01$)-a hybrid foraging task where\nobservers look for multiple instances of multiple target types. In such tasks,\nhow do target values and their prevalence influence foraging and eye movement\nbehaviors (e.g., should you prioritize rare quarters or common nickels)? To\nexplore this, we conducted human psychophysics experiments, revealing that\nhumans are proficient reward foragers. Their eye fixations are drawn to regions\nwith higher average rewards, fixation durations are longer on more valuable\ntargets, and their cumulative rewards exceed chance, approaching the upper\nbound of optimal foragers. To probe these decision-making processes of humans,\nwe developed a transformer-based Visual Forager (VF) model trained via\nreinforcement learning. Our VF model takes a series of targets, their\ncorresponding values, and the search image as inputs, processes the images\nusing foveated vision, and produces a sequence of eye movements along with\ndecisions on whether to collect each fixated item. Our model outperforms all\nbaselines, achieves cumulative rewards comparable to those of humans, and\napproximates human foraging behavior in eye movements and foraging biases\nwithin time-limited environments. Furthermore, stress tests on\nout-of-distribution tasks with novel targets, unseen values, and varying set\nsizes demonstrate the VF model's effective generalization. Our work offers\nvaluable insights into the relationship between eye movements and\ndecision-making, with our model serving as a powerful tool for further\nexploration of this connection. All data, code, and models will be made\npublicly available.\n","authors":["Bo Wang","Dingwei Tan","Yen-Ling Kuo","Zhaowei Sun","Jeremy M. Wolfe","Tat-Jen Cham","Mengmi Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.09176v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09174v1","updated":"2024-11-14T04:23:28Z","published":"2024-11-14T04:23:28Z","title":"Advancing Diffusion Models: Alias-Free Resampling and Enhanced\n  Rotational Equivariance","summary":"  Recent advances in image generation, particularly via diffusion models, have\nled to impressive improvements in image synthesis quality. Despite this,\ndiffusion models are still challenged by model-induced artifacts and limited\nstability in image fidelity. In this work, we hypothesize that the primary\ncause of this issue is the improper resampling operation that introduces\naliasing in the diffusion model and a careful alias-free resampling dictated by\nimage processing theory can improve the model's performance in image synthesis.\nWe propose the integration of alias-free resampling layers into the UNet\narchitecture of diffusion models without adding extra trainable parameters,\nthereby maintaining computational efficiency. We then assess whether these\ntheory-driven modifications enhance image quality and rotational equivariance.\nOur experimental results on benchmark datasets, including CIFAR-10, MNIST, and\nMNIST-M, reveal consistent gains in image quality, particularly in terms of FID\nand KID scores. Furthermore, we propose a modified diffusion process that\nenables user-controlled rotation of generated images without requiring\nadditional training. Our findings highlight the potential of theory-driven\nenhancements such as alias-free resampling in generative models to improve\nimage quality while maintaining model efficiency and pioneer future research\ndirections to incorporate them into video-generating diffusion models, enabling\ndeeper exploration of the applications of alias-free resampling in generative\nmodeling.\n","authors":["Md Fahim Anjum"],"pdf_url":"https://arxiv.org/pdf/2411.09174v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2405.18684v2","updated":"2024-11-14T04:13:08Z","published":"2024-05-29T01:25:43Z","title":"Learning Diffeomorphism for Image Registration with Time-Continuous\n  Networks using Semigroup Regularization","summary":"  Diffeomorphic image registration (DIR) is a critical task in 3D medical image\nanalysis, aimed at finding topology preserving deformations between pairs of\nimages. Focusing on the solution of the flow map differential equation as the\ndiffeomorphic deformation, recent methods use discrete timesteps along with\nvarious regularization terms to penalize the negative determinant of Jacobian\nand impose smoothness of the solution vector field. In this paper, we propose a\nnovel learning-based approach for diffeomorphic 3D-image registration which\nfinds the diffeomorphisms in the time continuum with only a single\nregularization term and no additional integration. As one of the fundamental\nproperties of flow maps, we exploit the semigroup property as the only form of\nregularization, ensuring temporally continuous diffeomorphic flows between\npairs of images. Leveraging this property, our method alleviates the need for\nadditional regularization terms and scaling and squaring integration during\nboth training and evaluation. To achieve time-continuous diffeomorphisms, we\nemploy time-embedded UNets, an architecture commonly utilized in diffusion\nmodels. The proposed method reveals that ensuring diffeomorphism in a\ncontinuous time interval leads to better registration results. Experimental\nresults on four public datasets demonstrate the superiority of our model over\nboth learning-based and optimization-based methods.\n","authors":["Mohammadjavad Matinkia","Nilanjan Ray"],"pdf_url":"https://arxiv.org/pdf/2405.18684v2.pdf","comment":"20 pages, 9 figures"},{"id":"http://arxiv.org/abs/2409.14289v3","updated":"2024-11-14T03:26:46Z","published":"2024-09-22T01:42:01Z","title":"Deep Learning Technology for Face Forgery Detection: A Survey","summary":"  Currently, the rapid development of computer vision and deep learning has\nenabled the creation or manipulation of high-fidelity facial images and videos\nvia deep generative approaches. This technology, also known as deepfake, has\nachieved dramatic progress and become increasingly popular in social media.\nHowever, the technology can generate threats to personal privacy and national\nsecurity by spreading misinformation. To diminish the risks of deepfake, it is\ndesirable to develop powerful forgery detection methods to distinguish fake\nfaces from real faces. This paper presents a comprehensive survey of recent\ndeep learning-based approaches for facial forgery detection. We attempt to\nprovide the reader with a deeper understanding of the current advances as well\nas the major challenges for deepfake detection based on deep learning. We\npresent an overview of deepfake techniques and analyse the characteristics of\nvarious deepfake datasets. We then provide a systematic review of different\ncategories of deepfake detection and state-of-the-art deepfake detection\nmethods. The drawbacks of existing detection methods are analyzed, and future\nresearch directions are discussed to address the challenges in improving both\nthe performance and generalization of deepfake detection.\n","authors":["Lixia Ma","Puning Yang","Yuting Xu","Ziming Yang","Peipei Li","Huaibo Huang"],"pdf_url":"https://arxiv.org/pdf/2409.14289v3.pdf","comment":"The paper \"Deep Learning Technology for Face Forgery Detection: A\n  Survey\" is hereby formally withdrawn. The reason for this withdrawal is that\n  I did not adequately consult and obtain proper authorization from the\n  corresponding author during the submission process. I sincerely apologize for\n  any inconvenience this may have caused the journal, reviewers, and readers"},{"id":"http://arxiv.org/abs/2411.05836v2","updated":"2024-11-14T03:21:12Z","published":"2024-11-06T12:28:26Z","title":"Prion-ViT: Prions-Inspired Vision Transformers for Temperature\n  prediction with Specklegrams","summary":"  Fiber Specklegram Sensors (FSS) are vital for environmental monitoring due to\ntheir high temperature sensitivity, but their complex data poses challeng-es\nfor predictive models. This study introduces Prion-ViT, a prion-inspired Vision\nTransformer model, inspired by biological prion memory mecha-nisms, to improve\nlong-term dependency modeling and temperature prediction accuracy using FSS\ndata. Prion-ViT leverages a persistent memory state to retain and propagate key\nfeatures across layers, reducing mean absolute error (MAE) to 0.52{\\deg}C and\noutperforming models like ResNet, Inception Net V2, and standard vision\ntransformers. This work highlights Prion-ViT's potential for real-time\nindustrial temperature monitoring and broader optical sensing applications.\n","authors":["Abhishek Sebastian","Pragna R"],"pdf_url":"https://arxiv.org/pdf/2411.05836v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09156v1","updated":"2024-11-14T03:19:57Z","published":"2024-11-14T03:19:57Z","title":"DyGASR: Dynamic Generalized Exponential Splatting with Surface Alignment\n  for Accelerated 3D Mesh Reconstruction","summary":"  Recent advancements in 3D Gaussian Splatting (3DGS), which lead to\nhigh-quality novel view synthesis and accelerated rendering, have remarkably\nimproved the quality of radiance field reconstruction. However, the extraction\nof mesh from a massive number of minute 3D Gaussian points remains great\nchallenge due to the large volume of Gaussians and difficulty of representation\nof sharp signals caused by their inherent low-pass characteristics. To address\nthis issue, we propose DyGASR, which utilizes generalized exponential function\ninstead of traditional 3D Gaussian to decrease the number of particles and\ndynamically optimize the representation of the captured signal. In addition, it\nis observed that reconstructing mesh with Generalized Exponential\nSplatting(GES) without modifications frequently leads to failures since the\ngeneralized exponential distribution centroids may not precisely align with the\nscene surface. To overcome this, we adopt Sugar's approach and introduce\nGeneralized Surface Regularization (GSR), which reduces the smallest scaling\nvector of each point cloud to zero and ensures normal alignment perpendicular\nto the surface, facilitating subsequent Poisson surface mesh reconstruction.\nAdditionally, we propose a dynamic resolution adjustment strategy that utilizes\na cosine schedule to gradually increase image resolution from low to high\nduring the training stage, thus avoiding constant full resolution, which\nsignificantly boosts the reconstruction speed. Our approach surpasses existing\n3DGS-based mesh reconstruction methods, as evidenced by extensive evaluations\non various scene datasets, demonstrating a 25\\% increase in speed, and a 30\\%\nreduction in memory usage.\n","authors":["Shengchao Zhao","Yundong Li"],"pdf_url":"https://arxiv.org/pdf/2411.09156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09153v1","updated":"2024-11-14T03:13:26Z","published":"2024-11-14T03:13:26Z","title":"VidMan: Exploiting Implicit Dynamics from Video Diffusion Model for\n  Effective Robot Manipulation","summary":"  Recent advancements utilizing large-scale video data for learning video\ngeneration models demonstrate significant potential in understanding complex\nphysical dynamics. It suggests the feasibility of leveraging diverse robot\ntrajectory data to develop a unified, dynamics-aware model to enhance robot\nmanipulation. However, given the relatively small amount of available robot\ndata, directly fitting data without considering the relationship between visual\nobservations and actions could lead to suboptimal data utilization. To this\nend, we propose VidMan (Video Diffusion for Robot Manipulation), a novel\nframework that employs a two-stage training mechanism inspired by dual-process\ntheory from neuroscience to enhance stability and improve data utilization\nefficiency. Specifically, in the first stage, VidMan is pre-trained on the Open\nX-Embodiment dataset (OXE) for predicting future visual trajectories in a video\ndenoising diffusion manner, enabling the model to develop a long horizontal\nawareness of the environment's dynamics. In the second stage, a flexible yet\neffective layer-wise self-attention adapter is introduced to transform VidMan\ninto an efficient inverse dynamics model that predicts action modulated by the\nimplicit dynamics knowledge via parameter sharing. Our VidMan framework\noutperforms state-of-the-art baseline model GR-1 on the CALVIN benchmark,\nachieving a 11.7% relative improvement, and demonstrates over 9% precision\ngains on the OXE small-scale dataset. These results provide compelling evidence\nthat world models can significantly enhance the precision of robot action\nprediction. Codes and models will be public.\n","authors":["Youpeng Wen","Junfan Lin","Yi Zhu","Jianhua Han","Hang Xu","Shen Zhao","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2411.09153v1.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09151v1","updated":"2024-11-14T03:01:36Z","published":"2024-11-14T03:01:36Z","title":"Mono2Stereo: Monocular Knowledge Transfer for Enhanced Stereo Matching","summary":"  The generalization and performance of stereo matching networks are limited\ndue to the domain gap of the existing synthetic datasets and the sparseness of\nGT labels in the real datasets. In contrast, monocular depth estimation has\nachieved significant advancements, benefiting from large-scale depth datasets\nand self-supervised strategies. To bridge the performance gap between monocular\ndepth estimation and stereo matching, we propose leveraging monocular knowledge\ntransfer to enhance stereo matching, namely Mono2Stereo. We introduce knowledge\ntransfer with a two-stage training process, comprising synthetic data\npre-training and real-world data fine-tuning. In the pre-training stage, we\ndesign a data generation pipeline that synthesizes stereo training data from\nmonocular images. This pipeline utilizes monocular depth for warping and novel\nview synthesis and employs our proposed Edge-Aware (EA) inpainting module to\nfill in missing contents in the generated images. In the fine-tuning stage, we\nintroduce a Sparse-to-Dense Knowledge Distillation (S2DKD) strategy encouraging\nthe distributions of predictions to align with dense monocular depths. This\nstrategy mitigates issues with edge blurring in sparse real-world labels and\nenhances overall consistency. Experimental results demonstrate that our\npre-trained model exhibits strong zero-shot generalization capabilities.\nFurthermore, domain-specific fine-tuning using our pre-trained model and S2DKD\nstrategy significantly increments in-domain performance. The code will be made\navailable soon.\n","authors":["Yuran Wang","Yingping Liang","Hesong Li","Ying Fu"],"pdf_url":"https://arxiv.org/pdf/2411.09151v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.09145v1","updated":"2024-11-14T02:57:11Z","published":"2024-11-14T02:57:11Z","title":"UniHOI: Learning Fast, Dense and Generalizable 4D Reconstruction for\n  Egocentric Hand Object Interaction Videos","summary":"  Egocentric Hand Object Interaction (HOI) videos provide valuable insights\ninto human interactions with the physical world, attracting growing interest\nfrom the computer vision and robotics communities. A key task in fully\nunderstanding the geometry and dynamics of HOI scenes is dense pointclouds\nsequence reconstruction. However, the inherent motion of both hands and the\ncamera makes this challenging. Current methods often rely on time-consuming\ntest-time optimization, making them impractical for reconstructing\ninternet-scale videos. To address this, we introduce UniHOI, a model that\nunifies the estimation of all variables necessary for dense 4D reconstruction,\nincluding camera intrinsic, camera poses, and video depth, for egocentric HOI\nscene in a fast feed-forward manner. We end-to-end optimize all these variables\nto improve their consistency in 3D space. Furthermore, our model could be\ntrained solely on large-scale monocular video dataset, overcoming the\nlimitation of scarce labeled HOI data. We evaluate UniHOI with both in-domain\nand zero-shot generalization setting, surpassing all baselines in pointclouds\nsequence reconstruction and long-term 3D scene flow recovery. UniHOI is the\nfirst approach to offer fast, dense, and generalizable monocular egocentric HOI\nscene reconstruction in the presence of motion. Code and trained model will be\nreleased in the future.\n","authors":["Chengbo Yuan","Geng Chen","Li Yi","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2411.09145v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09140v1","updated":"2024-11-14T02:40:34Z","published":"2024-11-14T02:40:34Z","title":"Adversarial Vessel-Unveiling Semi-Supervised Segmentation for\n  Retinopathy of Prematurity Diagnosis","summary":"  Accurate segmentation of retinal images plays a crucial role in aiding\nophthalmologists in diagnosing retinopathy of prematurity (ROP) and assessing\nits severity. However, due to their underdeveloped, thinner vessels, manual\nannotation in infant fundus images is very complex, and this presents\nchallenges for fully supervised learning. To address the scarcity of\nannotations, we propose a semi supervised segmentation framework designed to\nadvance ROP studies without the need for extensive manual vessel annotation.\nUnlike previous methods that rely solely on limited labeled data, our approach\nleverages teacher student learning by integrating two powerful components: an\nuncertainty weighted vessel unveiling module and domain adversarial learning.\nThe vessel unveiling module helps the model effectively reveal obscured and\nhard to detect vessel structures, while adversarial training aligns feature\nrepresentations across different domains, ensuring robust and generalizable\nvessel segmentations. We validate our approach on public datasets (CHASEDB,\nSTARE) and an in-house ROP dataset, demonstrating its superior performance\nacross multiple evaluation metrics. Additionally, we extend the model's utility\nto a downstream task of ROP multi-stage classification, where vessel masks\nextracted by our segmentation model improve diagnostic accuracy. The promising\nresults in classification underscore the model's potential for clinical\napplication, particularly in early-stage ROP diagnosis and intervention.\nOverall, our work offers a scalable solution for leveraging unlabeled data in\npediatric ophthalmology, opening new avenues for biomarker discovery and\nclinical research.\n","authors":["Gozde Merve Demirci","Jiachen Yao","Ming-Chih Ho","Xiaoling Hu","Wei-Chi Wu","Chao Chen","Chia-Ling Tsai"],"pdf_url":"https://arxiv.org/pdf/2411.09140v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.09137v1","updated":"2024-11-14T02:25:23Z","published":"2024-11-14T02:25:23Z","title":"Fast probabilistic snake algorithm","summary":"  Few people use the probability theory in order to achieve image segmentation\nwith snake models. In this article, we are presenting an active contour\nalgorithm based on a probability approach inspired by A. Blake work and P.\nR{\\'e}fr{\\'e}gier's team research in France. Our algorithm, both very fast and\nhighly accurate as far as contour description is concerned, is easily adaptable\nto any specific application.\n","authors":["Jérôme Gilles","Bertrand Collin"],"pdf_url":"https://arxiv.org/pdf/2411.09137v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09133v1","updated":"2024-11-14T02:13:25Z","published":"2024-11-14T02:13:25Z","title":"Computational metaoptics for imaging","summary":"  Metasurfaces -- ultrathin structures composed of subwavelength optical\nelements -- have revolutionized light manipulation by enabling precise control\nover electromagnetic waves' amplitude, phase, polarization, and spectral\nproperties. Concurrently, computational imaging leverages algorithms to\nreconstruct images from optically processed signals, overcoming limitations of\ntraditional imaging systems. This review explores the synergistic integration\nof metaoptics and computational imaging, \"computational metaoptics,\" which\ncombines the physical wavefront shaping ability of metasurfaces with advanced\ncomputational algorithms to enhance imaging performance beyond conventional\nlimits. We discuss how computational metaoptics addresses the inherent\nlimitations of single-layer metasurfaces in achieving multifunctionality\nwithout compromising efficiency. By treating metasurfaces as physical\npreconditioners and co-designing them with reconstruction algorithms through\nend-to-end (inverse) design, it is possible to jointly optimize the optical\nhardware and computational software. This holistic approach allows for the\nautomatic discovery of optimal metasurface designs and reconstruction methods\nthat significantly improve imaging capabilities. Advanced applications enabled\nby computational metaoptics are highlighted, including phase imaging and\nquantum state measurement, which benefit from the metasurfaces' ability to\nmanipulate complex light fields and the computational algorithms' capacity to\nreconstruct high-dimensional information. We also examine performance\nevaluation challenges, emphasizing the need for new metrics that account for\nthe combined optical and computational nature of these systems. Finally, we\nidentify new frontiers in computational metaoptics which point toward a future\nwhere computational metaoptics may play a central role in advancing imaging\nscience and technology.\n","authors":["Charles Roques-Carmes","Kai Wang","Yuanmu Yang","Arka Majumdar","Zin Lin"],"pdf_url":"https://arxiv.org/pdf/2411.09133v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06727v2","updated":"2024-11-14T02:11:56Z","published":"2024-11-11T05:44:48Z","title":"Can KAN Work? Exploring the Potential of Kolmogorov-Arnold Networks in\n  Computer Vision","summary":"  Kolmogorov-Arnold Networks(KANs), as a theoretically efficient neural network\narchitecture, have garnered attention for their potential in capturing complex\npatterns. However, their application in computer vision remains relatively\nunexplored. This study first analyzes the potential of KAN in computer vision\ntasks, evaluating the performance of KAN and its convolutional variants in\nimage classification and semantic segmentation. The focus is placed on\nexamining their characteristics across varying data scales and noise levels.\nResults indicate that while KAN exhibits stronger fitting capabilities, it is\nhighly sensitive to noise, limiting its robustness. To address this challenge,\nwe propose a smoothness regularization method and introduce a Segment\nDeactivation technique. Both approaches enhance KAN's stability and\ngeneralization, demonstrating its potential in handling complex visual data\ntasks.\n","authors":["Yueyang Cang","Yu hang liu","Li Shi"],"pdf_url":"https://arxiv.org/pdf/2411.06727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00289v3","updated":"2024-11-14T02:08:40Z","published":"2023-09-30T07:45:50Z","title":"Pubic Symphysis-Fetal Head Segmentation Using Pure Transformer with\n  Bi-level Routing Attention","summary":"  In this paper, we propose a method, named BRAU-Net, to solve the pubic\nsymphysis-fetal head segmentation task. The method adopts a U-Net-like pure\nTransformer architecture with bi-level routing attention and skip connections,\nwhich effectively learns local-global semantic information. The proposed\nBRAU-Net was evaluated on transperineal Ultrasound images dataset from the\npubic symphysis-fetal head segmentation and angle of progression (FH-PS-AOP)\nchallenge. The results demonstrate that the proposed BRAU-Net achieves\ncomparable a final score. The codes will be available at\nhttps://github.com/Caipengzhou/BRAU-Net.\n","authors":["Pengzhou Cai","Lu Jiang","Yanxin Li","Libin Lan"],"pdf_url":"https://arxiv.org/pdf/2310.00289v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09417v3","updated":"2024-11-14T02:00:33Z","published":"2024-01-17T18:56:18Z","title":"Vision Mamba: Efficient Visual Representation Learning with\n  Bidirectional State Space Model","summary":"  Recently the state space models (SSMs) with efficient hardware-aware designs,\ni.e., the Mamba deep learning model, have shown great potential for long\nsequence modeling. Meanwhile building efficient and generic vision backbones\npurely upon SSMs is an appealing direction. However, representing visual data\nis challenging for SSMs due to the position-sensitivity of visual data and the\nrequirement of global context for visual understanding. In this paper, we show\nthat the reliance on self-attention for visual representation learning is not\nnecessary and propose a new generic vision backbone with bidirectional Mamba\nblocks (Vim), which marks the image sequences with position embeddings and\ncompresses the visual representation with bidirectional state space models. On\nImageNet classification, COCO object detection, and ADE20k semantic\nsegmentation tasks, Vim achieves higher performance compared to\nwell-established vision transformers like DeiT, while also demonstrating\nsignificantly improved computation & memory efficiency. For example, Vim is\n2.8$\\times$ faster than DeiT and saves 86.8% GPU memory when performing batch\ninference to extract features on images with a resolution of 1248$\\times$1248.\nThe results demonstrate that Vim is capable of overcoming the computation &\nmemory constraints on performing Transformer-style understanding for\nhigh-resolution images and it has great potential to be the next-generation\nbackbone for vision foundation models. Code is available at\nhttps://github.com/hustvl/Vim.\n","authors":["Lianghui Zhu","Bencheng Liao","Qian Zhang","Xinlong Wang","Wenyu Liu","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2401.09417v3.pdf","comment":"Vision Mamba (Vim) is accepted by ICML 2024. Code is available at\n  https://github.com/hustvl/Vim"},{"id":"http://arxiv.org/abs/2411.09126v1","updated":"2024-11-14T01:53:17Z","published":"2024-11-14T01:53:17Z","title":"SCAN: Bootstrapping Contrastive Pre-training for Data Efficiency","summary":"  While contrastive pre-training is widely employed, its data efficiency\nproblem has remained relatively under-explored thus far. Existing methods often\nrely on static coreset selection algorithms to pre-identify important data for\ntraining. However, this static nature renders them unable to dynamically track\nthe data usefulness throughout pre-training, leading to subpar pre-trained\nmodels. To address this challenge, our paper introduces a novel dynamic\nbootstrapping dataset pruning method. It involves pruning data preparation\nfollowed by dataset mutation operations, both of which undergo iterative and\ndynamic updates. We apply this method to two prevalent contrastive pre-training\nframeworks: \\textbf{CLIP} and \\textbf{MoCo}, representing vision-language and\nvision-centric domains, respectively. In particular, we individually pre-train\nseven CLIP models on two large-scale image-text pair datasets, and two MoCo\nmodels on the ImageNet dataset, resulting in a total of 16 pre-trained models.\nWith a data pruning rate of 30-35\\% across all 16 models, our method exhibits\nonly marginal performance degradation (less than \\textbf{1\\%} on average)\ncompared to corresponding models trained on the full dataset counterparts\nacross various downstream datasets, and also surpasses several baselines with a\nlarge performance margin. Additionally, the byproduct from our method, \\ie\ncoresets derived from the original datasets after pre-training, also\ndemonstrates significant superiority in terms of downstream performance over\nother static coreset selection approaches.\n","authors":["Yangyang Guo","Mohan Kankanhalli"],"pdf_url":"https://arxiv.org/pdf/2411.09126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04997v2","updated":"2024-11-14T01:36:12Z","published":"2024-11-07T18:59:16Z","title":"LLM2CLIP: Powerful Language Model Unlocks Richer Visual Representation","summary":"  CLIP is one of the most important multimodal foundational models today. What\npowers CLIP's capabilities? The rich supervision signals provided by natural\nlanguage, the carrier of human knowledge, shape a powerful cross-modal\nrepresentation space. However, with the rapid advancements in large language\nmodels LLMs like GPT-4 and LLaMA, the boundaries of language comprehension and\ngeneration are continually being pushed. This raises an intriguing question:\ncan the capabilities of LLMs be harnessed to further improve multimodal\nrepresentation learning? The potential benefits of incorporating LLMs into CLIP\nare clear. LLMs' strong textual understanding can fundamentally improve CLIP's\nability to handle image captions, drastically enhancing its ability to process\nlong and complex texts, a well-known limitation of vanilla CLIP. Moreover, LLMs\nare trained on a vast corpus of text, possessing open-world knowledge. This\nallows them to expand on caption information during training, increasing the\nefficiency of the learning process. In this paper, we propose LLM2CLIP, a novel\napproach that embraces the power of LLMs to unlock CLIP's potential. By\nfine-tuning the LLM in the caption space with contrastive learning, we extract\nits textual capabilities into the output embeddings, significantly improving\nthe output layer's textual discriminability. We then design an efficient\ntraining process where the fine-tuned LLM acts as a powerful teacher for CLIP's\nvisual encoder. Thanks to the LLM's presence, we can now incorporate longer and\nmore complex captions without being restricted by vanilla CLIP's text encoder's\ncontext window and ability limitations. Our experiments demonstrate that this\napproach brings substantial improvements in cross-modal tasks.\n","authors":["Weiquan Huang","Aoqi Wu","Yifan Yang","Xufang Luo","Yuqing Yang","Liang Hu","Qi Dai","Xiyang Dai","Dongdong Chen","Chong Luo","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2411.04997v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15104v4","updated":"2024-11-14T01:32:30Z","published":"2024-06-21T12:45:07Z","title":"Deciphering the Definition of Adversarial Robustness for post-hoc OOD\n  Detectors","summary":"  Detecting out-of-distribution (OOD) inputs is critical for safely deploying\ndeep learning models in real-world scenarios. In recent years, many OOD\ndetectors have been developed, and even the benchmarking has been standardized,\ni.e. OpenOOD. The number of post-hoc detectors is growing fast. They are\nshowing an option to protect a pre-trained classifier against natural\ndistribution shifts and claim to be ready for real-world scenarios. However,\nits effectiveness in dealing with adversarial examples (AdEx) has been\nneglected in most studies. In cases where an OOD detector includes AdEx in its\nexperiments, the lack of uniform parameters for AdEx makes it difficult to\naccurately evaluate the performance of the OOD detector. This paper\ninvestigates the adversarial robustness of 16 post-hoc detectors against\nvarious evasion attacks. It also discusses a roadmap for adversarial defense in\nOOD detectors that would help adversarial robustness. We believe that level 1\n(AdEx on a unified dataset) should be added to any OOD detector to see the\nlimitations. The last level in the roadmap (defense against adaptive attacks)\nwe added for integrity from an adversarial machine learning (AML) point of\nview, which we do not believe is the ultimate goal for OOD detectors.\n","authors":["Peter Lorenz","Mario Fernandez","Jens Müller","Ullrich Köthe"],"pdf_url":"https://arxiv.org/pdf/2406.15104v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09105v1","updated":"2024-11-14T00:26:26Z","published":"2024-11-14T00:26:26Z","title":"VCBench: A Controllable Benchmark for Symbolic and Abstract Challenges\n  in Video Cognition","summary":"  Recent advancements in Large Video-Language Models (LVLMs) have driven the\ndevelopment of benchmarks designed to assess cognitive abilities in video-based\ntasks. However, most existing benchmarks heavily rely on web-collected videos\npaired with human annotations or model-generated questions, which limit control\nover the video content and fall short in evaluating advanced cognitive\nabilities involving symbolic elements and abstract concepts. To address these\nlimitations, we introduce VCBench, a controllable benchmark to assess LVLMs'\ncognitive abilities, involving symbolic and abstract concepts at varying\ndifficulty levels. By generating video data with the Python-based engine,\nVCBench allows for precise control over the video content, creating dynamic,\ntask-oriented videos that feature complex scenes and abstract concepts. Each\ntask pairs with tailored question templates that target specific cognitive\nchallenges, providing a rigorous evaluation test. Our evaluation reveals that\neven state-of-the-art (SOTA) models, such as Qwen2-VL-72B, struggle with simple\nvideo cognition tasks involving abstract concepts, with performance sharply\ndropping by 19% as video complexity rises. These findings reveal the current\nlimitations of LVLMs in advanced cognitive tasks and highlight the critical\nrole of VCBench in driving research toward more robust LVLMs for complex video\ncognition challenges.\n","authors":["Chenglin Li","Qianglong Chen","Zhi Li","Feng Tao","Yin Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.09105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09101v1","updated":"2024-11-14T00:18:04Z","published":"2024-11-14T00:18:04Z","title":"Heuristical Comparison of Vision Transformers Against Convolutional\n  Neural Networks for Semantic Segmentation on Remote Sensing Imagery","summary":"  Vision Transformers (ViT) have recently brought a new wave of research in the\nfield of computer vision. These models have done particularly well in the field\nof image classification and segmentation. Research on semantic and instance\nsegmentation has emerged to accelerate with the inception of the new\narchitecture, with over 80\\% of the top 20 benchmarks for the iSAID dataset\nbeing either based on the ViT architecture or the attention mechanism behind\nits success. This paper focuses on the heuristic comparison of three key\nfactors of using (or not using) ViT for semantic segmentation of remote sensing\naerial images on the iSAID. The experimental results observed during the course\nof the research were under the scrutinization of the following objectives: 1.\nUse of weighted fused loss function for the maximum mean Intersection over\nUnion (mIoU) score, Dice score, and minimization or conservation of entropy or\nclass representation, 2. Comparison of transfer learning on Meta's MaskFormer,\na ViT-based semantic segmentation model, against generic UNet Convolutional\nNeural Networks (CNNs) judged over mIoU, Dice scores, training efficiency, and\ninference time, and 3. What do we lose for what we gain? i.e., the comparison\nof the two models against current state-of-art segmentation models. We show the\nuse of the novel combined weighted loss function significantly boosts the CNN\nmodel's performance capacities as compared to transfer learning the ViT. The\ncode for this implementation can be found on\n\\url{https://github.com/ashimdahal/ViT-vs-CNN-ImageSegmentation}.\n","authors":["Ashim Dahal","Saydul Akbar Murad","Nick Rahimi"],"pdf_url":"https://arxiv.org/pdf/2411.09101v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09180v1","updated":"2024-11-14T04:39:10Z","published":"2024-11-14T04:39:10Z","title":"LEAP:D -- A Novel Prompt-based Approach for Domain-Generalized Aerial\n  Object Detection","summary":"  Drone-captured images present significant challenges in object detection due\nto varying shooting conditions, which can alter object appearance and shape.\nFactors such as drone altitude, angle, and weather cause these variations,\ninfluencing the performance of object detection algorithms. To tackle these\nchallenges, we introduce an innovative vision-language approach using learnable\nprompts. This shift from conventional manual prompts aims to reduce\ndomain-specific knowledge interference, ultimately improving object detection\ncapabilities. Furthermore, we streamline the training process with a one-step\napproach, updating the learnable prompt concurrently with model training,\nenhancing efficiency without compromising performance. Our study contributes to\ndomain-generalized object detection by leveraging learnable prompts and\noptimizing training processes. This enhances model robustness and adaptability\nacross diverse environments, leading to more effective aerial object detection.\n","authors":["Chanyeong Park","Heegwang Kim","Joonki Paik"],"pdf_url":"https://arxiv.org/pdf/2411.09180v1.pdf","comment":"ICIP 2024 Workshop accepted paper"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2411.09702v1","updated":"2024-11-14T18:59:40Z","published":"2024-11-14T18:59:40Z","title":"On the Surprising Effectiveness of Attention Transfer for Vision\n  Transformers","summary":"  Conventional wisdom suggests that pre-training Vision Transformers (ViT)\nimproves downstream performance by learning useful representations. Is this\nactually true? We investigate this question and find that the features and\nrepresentations learned during pre-training are not essential. Surprisingly,\nusing only the attention patterns from pre-training (i.e., guiding how\ninformation flows between tokens) is sufficient for models to learn high\nquality features from scratch and achieve comparable downstream performance. We\nshow this by introducing a simple method called attention transfer, where only\nthe attention patterns from a pre-trained teacher ViT are transferred to a\nstudent, either by copying or distilling the attention maps. Since attention\ntransfer lets the student learn its own features, ensembling it with a\nfine-tuned teacher also further improves accuracy on ImageNet. We\nsystematically study various aspects of our findings on the sufficiency of\nattention maps, including distribution shift settings where they underperform\nfine-tuning. We hope our exploration provides a better understanding of what\npre-training accomplishes and leads to a useful alternative to the standard\npractice of fine-tuning\n","authors":["Alexander C. Li","Yuandong Tian","Beidi Chen","Deepak Pathak","Xinlei Chen"],"pdf_url":"https://arxiv.org/pdf/2411.09702v1.pdf","comment":"NeurIPS 2024. Code:\n  https://github.com/alexlioralexli/attention-transfer"},{"id":"http://arxiv.org/abs/2405.09596v2","updated":"2024-11-14T18:57:09Z","published":"2024-05-15T13:43:07Z","title":"Enhancing Maritime Trajectory Forecasting via H3 Index and Causal\n  Language Modelling (CLM)","summary":"  The prediction of ship trajectories is a growing field of study in artificial\nintelligence. Traditional methods rely on the use of LSTM, GRU networks, and\neven Transformer architectures for the prediction of spatio-temporal series.\nThis study proposes a viable alternative for predicting these trajectories\nusing only GNSS positions. It considers this spatio-temporal problem as a\nnatural language processing problem. The latitude/longitude coordinates of AIS\nmessages are transformed into cell identifiers using the H3 index. Thanks to\nthe pseudo-octal representation, it becomes easier for language models to learn\nthe spatial hierarchy of the H3 index. The method is compared with a classical\nKalman filter, widely used in the maritime domain, and introduces the Fr\\'echet\ndistance as the main evaluation metric. We show that it is possible to predict\nship trajectories quite precisely up to 8 hours ahead with 30 minutes of\ncontext, using solely GNSS positions, without relying on any additional\ninformation such as speed, course, or external conditions - unlike many\ntraditional methods. We demonstrate that this alternative works well enough to\npredict trajectories worldwide.\n","authors":["Nicolas Drapier","Aladine Chetouani","Aurélien Chateigner"],"pdf_url":"https://arxiv.org/pdf/2405.09596v2.pdf","comment":"28 pages, 18 figures"},{"id":"http://arxiv.org/abs/2411.09686v1","updated":"2024-11-14T18:53:51Z","published":"2024-11-14T18:53:51Z","title":"Conditional regression for the Nonlinear Single-Variable Model","summary":"  Several statistical models for regression of a function $F$ on $\\mathbb{R}^d$\nwithout the statistical and computational curse of dimensionality exist, for\nexample by imposing and exploiting geometric assumptions on the distribution of\nthe data (e.g. that its support is low-dimensional), or strong smoothness\nassumptions on $F$, or a special structure $F$. Among the latter, compositional\nmodels assume $F=f\\circ g$ with $g$ mapping to $\\mathbb{R}^r$ with $r\\ll d$,\nhave been studied, and include classical single- and multi-index models and\nrecent works on neural networks. While the case where $g$ is linear is rather\nwell-understood, much less is known when $g$ is nonlinear, and in particular\nfor which $g$'s the curse of dimensionality in estimating $F$, or both $f$ and\n$g$, may be circumvented. In this paper, we consider a model\n$F(X):=f(\\Pi_\\gamma X) $ where $\\Pi_\\gamma:\\mathbb{R}^d\\to[0,\\rm{len}_\\gamma]$\nis the closest-point projection onto the parameter of a regular curve $\\gamma:\n[0,\\rm{len}_\\gamma]\\to\\mathbb{R}^d$ and $f:[0,\\rm{len}_\\gamma]\\to\\mathbb{R}^1$.\nThe input data $X$ is not low-dimensional, far from $\\gamma$, conditioned on\n$\\Pi_\\gamma(X)$ being well-defined. The distribution of the data, $\\gamma$ and\n$f$ are unknown. This model is a natural nonlinear generalization of the\nsingle-index model, which corresponds to $\\gamma$ being a line. We propose a\nnonparametric estimator, based on conditional regression, and show that under\nsuitable assumptions, the strongest of which being that $f$ is coarsely\nmonotone, it can achieve the $one$-$dimensional$ optimal min-max rate for\nnon-parametric regression, up to the level of noise in the observations, and be\nconstructed in time $\\mathcal{O}(d^2n\\log n)$. All the constants in the\nlearning bounds, in the minimal number of samples required for our bounds to\nhold, and in the computational complexity are at most low-order polynomials in\n$d$.\n","authors":["Yantao Wu","Mauro Maggioni"],"pdf_url":"https://arxiv.org/pdf/2411.09686v1.pdf","comment":"55 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.09683v1","updated":"2024-11-14T18:52:05Z","published":"2024-11-14T18:52:05Z","title":"Towards a Classification of Open-Source ML Models and Datasets for\n  Software Engineering","summary":"  Background: Open-Source Pre-Trained Models (PTMs) and datasets provide\nextensive resources for various Machine Learning (ML) tasks, yet these\nresources lack a classification tailored to Software Engineering (SE) needs.\nAims: We apply an SE-oriented classification to PTMs and datasets on a popular\nopen-source ML repository, Hugging Face (HF), and analyze the evolution of PTMs\nover time. Method: We conducted a repository mining study. We started with a\nsystematically gathered database of PTMs and datasets from the HF API. Our\nselection was refined by analyzing model and dataset cards and metadata, such\nas tags, and confirming SE relevance using Gemini 1.5 Pro. All analyses are\nreplicable, with a publicly accessible replication package. Results: The most\ncommon SE task among PTMs and datasets is code generation, with a primary focus\non software development and limited attention to software management. Popular\nPTMs and datasets mainly target software development. Among ML tasks, text\ngeneration is the most common in SE PTMs and datasets. There has been a marked\nincrease in PTMs for SE since 2023 Q2. Conclusions: This study underscores the\nneed for broader task coverage to enhance the integration of ML within SE\npractices.\n","authors":["Alexandra González","Xavier Franch","David Lo","Silverio Martínez-Fernández"],"pdf_url":"https://arxiv.org/pdf/2411.09683v1.pdf","comment":"5 pages, 8 figures"},{"id":"http://arxiv.org/abs/2411.09678v1","updated":"2024-11-14T18:44:31Z","published":"2024-11-14T18:44:31Z","title":"NeuralDEM - Real-time Simulation of Industrial Particulate Flows","summary":"  Advancements in computing power have made it possible to numerically simulate\nlarge-scale fluid-mechanical and/or particulate systems, many of which are\nintegral to core industrial processes. Among the different numerical methods\navailable, the discrete element method (DEM) provides one of the most accurate\nrepresentations of a wide range of physical systems involving granular and\ndiscontinuous materials. Consequently, DEM has become a widely accepted\napproach for tackling engineering problems connected to granular flows and\npowder mechanics. Additionally, DEM can be integrated with grid-based\ncomputational fluid dynamics (CFD) methods, enabling the simulation of chemical\nprocesses taking place, e.g., in fluidized beds. However, DEM is\ncomputationally intensive because of the intrinsic multiscale nature of\nparticulate systems, restricting simulation duration or number of particles.\nTowards this end, NeuralDEM presents an end-to-end approach to replace slow\nnumerical DEM routines with fast, adaptable deep learning surrogates. NeuralDEM\nis capable of picturing long-term transport processes across different regimes\nusing macroscopic observables without any reference to microscopic model\nparameters. First, NeuralDEM treats the Lagrangian discretization of DEM as an\nunderlying continuous field, while simultaneously modeling macroscopic behavior\ndirectly as additional auxiliary fields. Second, NeuralDEM introduces\nmulti-branch neural operators scalable to real-time modeling of\nindustrially-sized scenarios - from slow and pseudo-steady to fast and\ntransient. Such scenarios have previously posed insurmountable challenges for\ndeep learning models. Notably, NeuralDEM faithfully models coupled CFD-DEM\nfluidized bed reactors of 160k CFD cells and 500k DEM particles for\ntrajectories of 28s. NeuralDEM will open many new doors to advanced engineering\nand much faster process cycles.\n","authors":["Benedikt Alkin","Tobias Kronlachner","Samuele Papa","Stefan Pirker","Thomas Lichtenegger","Johannes Brandstetter"],"pdf_url":"https://arxiv.org/pdf/2411.09678v1.pdf","comment":"Project page: https://nx-ai.github.io/NeuralDEM/"},{"id":"http://arxiv.org/abs/2411.09648v1","updated":"2024-11-14T18:17:30Z","published":"2024-11-14T18:17:30Z","title":"Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable\n  Medical Information","summary":"  This paper introduces Med-Bot, an AI-powered chatbot designed to provide\nusers with accurate and reliable medical information. Utilizing advanced\nlibraries and frameworks such as PyTorch, Chromadb, Langchain and Autogptq,\nMed-Bot is built to handle the complexities of natural language understanding\nin a healthcare context. The integration of llamaassisted data processing and\nAutoGPT-Q provides enhanced performance in processing and responding to queries\nbased on PDFs of medical literature, ensuring that users receive precise and\ntrustworthy information. This research details the methodologies employed in\ndeveloping Med-Bot and evaluates its effectiveness in disseminating healthcare\ninformation.\n","authors":["Ahan Bhatt","Nandan Vaghela"],"pdf_url":"https://arxiv.org/pdf/2411.09648v1.pdf","comment":"3 figures, 5 pages Keywords-LLM, AI-powered healthcare, Medical\n  chatbot, Context-based interaction, Llama-assisted data processing,\n  AutoGPT-Q, PyTorch, TensorFlow, Reliable medical information, Machine\n  learning in healthcare, Conversational AI"},{"id":"http://arxiv.org/abs/2411.09645v1","updated":"2024-11-14T18:14:32Z","published":"2024-11-14T18:14:32Z","title":"How do Machine Learning Models Change?","summary":"  The proliferation of Machine Learning (ML) models and their open-source\nimplementations has transformed Artificial Intelligence research and\napplications. Platforms like Hugging Face (HF) enable the development, sharing,\nand deployment of these models, fostering an evolving ecosystem. While previous\nstudies have examined aspects of models hosted on platforms like HF, a\ncomprehensive longitudinal study of how these models change remains\nunderexplored. This study addresses this gap by utilizing both repository\nmining and longitudinal analysis methods to examine over 200,000 commits and\n1,200 releases from over 50,000 models on HF. We replicate and extend an ML\nchange taxonomy for classifying commits and utilize Bayesian networks to\nuncover patterns in commit and release activities over time. Our findings\nindicate that commit activities align with established data science\nmethodologies, such as CRISP-DM, emphasizing iterative refinement and\ncontinuous improvement. Additionally, release patterns tend to consolidate\nsignificant updates, particularly in documentation, distinguishing between\ngranular changes and milestone-based releases. Furthermore, projects with\nhigher popularity prioritize infrastructure enhancements early in their\nlifecycle, and those with intensive collaboration practices exhibit improved\ndocumentation standards. These and other insights enhance the understanding of\nmodel changes on community platforms and provide valuable guidance for best\npractices in model maintenance.\n","authors":["Joel Castaño","Rafael Cabañas","Antonio Salmerón","David Lo","Silverio Martínez-Fernández"],"pdf_url":"https://arxiv.org/pdf/2411.09645v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04783v2","updated":"2024-11-14T18:14:00Z","published":"2024-03-02T16:52:22Z","title":"AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks","summary":"  Despite extensive pre-training in moral alignment to prevent generating\nharmful information, large language models (LLMs) remain vulnerable to\njailbreak attacks. In this paper, we propose AutoDefense, a multi-agent defense\nframework that filters harmful responses from LLMs. With the response-filtering\nmechanism, our framework is robust against different jailbreak attack prompts,\nand can be used to defend different victim models. AutoDefense assigns\ndifferent roles to LLM agents and employs them to complete the defense task\ncollaboratively. The division in tasks enhances the overall\ninstruction-following of LLMs and enables the integration of other defense\ncomponents as tools. With AutoDefense, small open-source LMs can serve as\nagents and defend larger models against jailbreak attacks. Our experiments show\nthat AutoDefense can effectively defense against different jailbreak attacks,\nwhile maintaining the performance at normal user request. For example, we\nreduce the attack success rate on GPT-3.5 from 55.74% to 7.95% using\nLLaMA-2-13b with a 3-agent system. Our code and data are publicly available at\nhttps://github.com/XHMY/AutoDefense.\n","authors":["Yifan Zeng","Yiran Wu","Xiao Zhang","Huazheng Wang","Qingyun Wu"],"pdf_url":"https://arxiv.org/pdf/2403.04783v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09644v1","updated":"2024-11-14T18:12:06Z","published":"2024-11-14T18:12:06Z","title":"Neural Operators Can Play Dynamic Stackelberg Games","summary":"  Dynamic Stackelberg games are a broad class of two-player games in which the\nleader acts first, and the follower chooses a response strategy to the leader's\nstrategy. Unfortunately, only stylized Stackelberg games are explicitly\nsolvable since the follower's best-response operator (as a function of the\ncontrol of the leader) is typically analytically intractable. This paper\naddresses this issue by showing that the \\textit{follower's best-response\noperator} can be approximately implemented by an \\textit{attention-based neural\noperator}, uniformly on compact subsets of adapted open-loop controls for the\nleader. We further show that the value of the Stackelberg game where the\nfollower uses the approximate best-response operator approximates the value of\nthe original Stackelberg game. Our main result is obtained using our universal\napproximation theorem for attention-based neural operators between spaces of\nsquare-integrable adapted stochastic processes, as well as stability results\nfor a general class of Stackelberg games.\n","authors":["Guillermo Alvarez","Ibrahim Ekren","Anastasis Kratsios","Xuwei Yang"],"pdf_url":"https://arxiv.org/pdf/2411.09644v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09642v1","updated":"2024-11-14T18:06:55Z","published":"2024-11-14T18:06:55Z","title":"On the Limits of Language Generation: Trade-Offs Between Hallucination\n  and Mode Collapse","summary":"  Specifying all desirable properties of a language model is challenging, but\ncertain requirements seem essential. Given samples from an unknown language,\nthe trained model should produce valid strings not seen in training and be\nexpressive enough to capture the language's full richness. Otherwise,\noutputting invalid strings constitutes \"hallucination,\" and failing to capture\nthe full range leads to \"mode collapse.\" We ask if a language model can meet\nboth requirements.\n  We investigate this within a statistical language generation setting building\non Gold and Angluin. Here, the model receives random samples from a\ndistribution over an unknown language K, which belongs to a possibly infinite\ncollection of languages. The goal is to generate unseen strings from K. We say\nthe model generates from K with consistency and breadth if, as training size\nincreases, its output converges to all unseen strings in K.\n  Kleinberg and Mullainathan [KM24] asked if consistency and breadth in\nlanguage generation are possible. We answer this negatively: for a large class\nof language models, including next-token prediction models, this is impossible\nfor most collections of candidate languages. This contrasts with [KM24]'s\nresult, showing consistent generation without breadth is possible for any\ncountable collection of languages. Our finding highlights that generation with\nbreadth fundamentally differs from generation without breadth.\n  As a byproduct, we establish near-tight bounds on the number of samples\nneeded for generation with or without breadth.\n  Finally, our results offer hope: consistent generation with breadth is\nachievable for any countable collection of languages when negative examples\n(strings outside K) are available alongside positive ones. This suggests that\npost-training feedback, which encodes negative examples, can be crucial in\nreducing hallucinations while limiting mode collapse.\n","authors":["Alkis Kalavasis","Anay Mehrotra","Grigoris Velegkas"],"pdf_url":"https://arxiv.org/pdf/2411.09642v1.pdf","comment":"Abstract shortened to fit arXiv limit"},{"id":"http://arxiv.org/abs/2411.09639v1","updated":"2024-11-14T18:03:44Z","published":"2024-11-14T18:03:44Z","title":"MCCE: Missingness-aware Causal Concept Explainer","summary":"  Causal concept effect estimation is gaining increasing interest in the field\nof interpretable machine learning. This general approach explains the behaviors\nof machine learning models by estimating the causal effect of\nhuman-understandable concepts, which represent high-level knowledge more\ncomprehensibly than raw inputs like tokens. However, existing causal concept\neffect explanation methods assume complete observation of all concepts involved\nwithin the dataset, which can fail in practice due to incomplete annotations or\nmissing concept data. We theoretically demonstrate that unobserved concepts can\nbias the estimation of the causal effects of observed concepts. To address this\nlimitation, we introduce the Missingness-aware Causal Concept Explainer (MCCE),\na novel framework specifically designed to estimate causal concept effects when\nnot all concepts are observable. Our framework learns to account for residual\nbias resulting from missing concepts and utilizes a linear predictor to model\nthe relationships between these concepts and the outputs of black-box machine\nlearning models. It can offer explanations on both local and global levels. We\nconduct validations using a real-world dataset, demonstrating that MCCE\nachieves promising performance compared to state-of-the-art explanation methods\nin causal concept effect estimation.\n","authors":["Jifan Gao","Guanhua Chen"],"pdf_url":"https://arxiv.org/pdf/2411.09639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09635v1","updated":"2024-11-14T18:01:02Z","published":"2024-11-14T18:01:02Z","title":"Counterfactual Uncertainty Quantification of Factual Estimand of\n  Efficacy from Before-and-After Treatment Repeated Measures Randomized\n  Controlled Trials","summary":"  The ideal estimand for comparing a new treatment $Rx$ with a control $C$ is\nthe $\\textit{counterfactual}$ efficacy $Rx:C$, the expected differential\noutcome between $Rx$ and $C$ if each patient were given $\\textit{both}$. While\ncounterfactual $\\textit{point estimation}$ from $\\textit{factual}$ Randomized\nControlled Trials (RCTs) has been available, this article shows\n$\\textit{counterfactual}$ uncertainty quantification (CUQ), quantifying\nuncertainty for factual point estimates but in a counterfactual setting, is\nsurprisingly achievable. We achieve CUQ whose variability is typically smaller\nthan factual UQ, by creating a new statistical modeling principle called ETZ\nwhich is applicable to RCTs with $\\textit{Before-and-After}$ treatment Repeated\nMeasures, common in many therapeutic areas.\n  We urge caution when estimate of the unobservable true condition of a patient\nbefore treatment has measurement error, because that violation of standard\nregression assumption can cause attenuation in estimating treatment effects.\nFortunately, we prove that, for traditional medicine in general, and for\ntargeted therapy with efficacy defined as averaged over the population,\ncounterfactual point estimation is unbiased. However, for targeted therapy,\nboth Real Human and Digital Twins approaches should respect this limitation,\nlest predicted treatment effect in $\\textit{subgroups}$ will have bias.\n","authors":["Xingya Wang","Yang Han","Yushi Liu","Szu-Yu Tang","Jason C. Hsu"],"pdf_url":"https://arxiv.org/pdf/2411.09635v1.pdf","comment":"39 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.09625v1","updated":"2024-11-14T17:49:27Z","published":"2024-11-14T17:49:27Z","title":"Local deployment of large-scale music AI models on commodity hardware","summary":"  We present the MIDInfinite, a web application capable of generating symbolic\nmusic using a large-scale generative AI model locally on commodity hardware.\nCreating this demo involved porting the Anticipatory Music Transformer, a large\nlanguage model (LLM) pre-trained on the Lakh MIDI dataset, to the Machine\nLearning Compilation (MLC) framework. Once the model is ported, MLC facilitates\ninference on a variety of runtimes including C++, mobile, and the browser. We\nenvision that MLC has the potential to bridge the gap between the landscape of\nincreasingly capable music AI models and technology more familiar to music\nsoftware developers. As a proof of concept, we build a web application that\nallows users to generate endless streams of multi-instrumental MIDI in the\nbrowser, either from scratch or conditioned on a prompt. On commodity hardware\n(an M3 Macbook Pro), our demo can generate 51 notes per second, which is faster\nthan real-time playback for 72.9% of generations, and increases to 86.3% with 2\nseconds of upfront buffering.\n","authors":["Xun Zhou","Charlie Ruan","Zihe Zhao","Tianqi Chen","Chris Donahue"],"pdf_url":"https://arxiv.org/pdf/2411.09625v1.pdf","comment":"2 pages"},{"id":"http://arxiv.org/abs/2411.09618v1","updated":"2024-11-14T17:37:19Z","published":"2024-11-14T17:37:19Z","title":"MICCAI-CDMRI 2023 QuantConn Challenge Findings on Achieving Robust\n  Quantitative Connectivity through Harmonized Preprocessing of Diffusion MRI","summary":"  White matter alterations are increasingly implicated in neurological diseases\nand their progression. International-scale studies use diffusion-weighted\nmagnetic resonance imaging (DW-MRI) to qualitatively identify changes in white\nmatter microstructure and connectivity. Yet, quantitative analysis of DW-MRI\ndata is hindered by inconsistencies stemming from varying acquisition\nprotocols. There is a pressing need to harmonize the preprocessing of DW-MRI\ndatasets to ensure the derivation of robust quantitative diffusion metrics\nacross acquisitions. In the MICCAI-CDMRI 2023 QuantConn challenge, participants\nwere provided raw data from the same individuals collected on the same scanner\nbut with two different acquisitions and tasked with preprocessing the DW-MRI to\nminimize acquisition differences while retaining biological variation.\nSubmissions are evaluated on the reproducibility and comparability of\ncross-acquisition bundle-wise microstructure measures, bundle shape features,\nand connectomics. The key innovations of the QuantConn challenge are that (1)\nwe assess bundles and tractography in the context of harmonization for the\nfirst time, (2) we assess connectomics in the context of harmonization for the\nfirst time, and (3) we have 10x additional subjects over prior harmonization\nchallenge, MUSHAC and 100x over SuperMUDI. We find that bundle surface area,\nfractional anisotropy, connectome assortativity, betweenness centrality, edge\ncount, modularity, nodal strength, and participation coefficient measures are\nmost biased by acquisition and that machine learning voxel-wise correction,\nRISH mapping, and NeSH methods effectively reduce these biases. In addition,\nmicrostructure measures AD, MD, RD, bundle length, connectome density,\nefficiency, and path length are least biased by these acquisition differences.\n","authors":["Nancy R. Newlin","Kurt Schilling","Serge Koudoro","Bramsh Qamar Chandio","Praitayini Kanakaraj","Daniel Moyer","Claire E. Kelly","Sila Genc","Jian Chen","Joseph Yuan-Mou Yang","Ye Wu","Yifei He","Jiawei Zhang","Qingrun Zeng","Fan Zhang","Nagesh Adluru","Vishwesh Nath","Sudhir Pathak","Walter Schneider","Anurag Gade","Yogesh Rathi","Tom Hendriks","Anna Vilanova","Maxime Chamberland","Tomasz Pieciak","Dominika Ciupek","Antonio Tristán Vega","Santiago Aja-Fernández","Maciej Malawski","Gani Ouedraogo","Julia Machnio","Christian Ewert","Paul M. Thompson","Neda Jahanshad","Eleftherios Garyfallidis","Bennett A. Landman"],"pdf_url":"https://arxiv.org/pdf/2411.09618v1.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2024/019"},{"id":"http://arxiv.org/abs/2411.09612v1","updated":"2024-11-14T17:32:03Z","published":"2024-11-14T17:32:03Z","title":"The Moral Foundations Weibo Corpus","summary":"  Moral sentiments expressed in natural language significantly influence both\nonline and offline environments, shaping behavioral styles and interaction\npatterns, including social media selfpresentation, cyberbullying, adherence to\nsocial norms, and ethical decision-making. To effectively measure moral\nsentiments in natural language processing texts, it is crucial to utilize\nlarge, annotated datasets that provide nuanced understanding for accurate\nanalysis and modeltraining. However, existing corpora, while valuable, often\nface linguistic limitations. To address this gap in the Chinese language\ndomain,we introduce the Moral Foundation Weibo Corpus. This corpus consists of\n25,671 Chinese comments on Weibo, encompassing six diverse topic areas. Each\ncomment is manually annotated by at least three systematically trained\nannotators based on ten moral categories derived from a grounded theory of\nmorality. To assess annotator reliability, we present the kappa testresults, a\ngold standard for measuring consistency. Additionally, we apply several the\nlatest large language models to supplement the manual annotations, conducting\nanalytical experiments to compare their performance and report baseline results\nfor moral sentiment classification.\n","authors":["Renjie Cao","Miaoyan Hu","Jiahan Wei","Baha Ihnaini"],"pdf_url":"https://arxiv.org/pdf/2411.09612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07104v2","updated":"2024-11-14T17:28:37Z","published":"2024-11-11T16:27:25Z","title":"Learning Multi-Agent Loco-Manipulation for Long-Horizon Quadrupedal\n  Pushing","summary":"  Recently, quadrupedal locomotion has achieved significant success, but their\nmanipulation capabilities, particularly in handling large objects, remain\nlimited, restricting their usefulness in demanding real-world applications such\nas search and rescue, construction, industrial automation, and room\norganization. This paper tackles the task of obstacle-aware, long-horizon\npushing by multiple quadrupedal robots. We propose a hierarchical multi-agent\nreinforcement learning framework with three levels of control. The high-level\ncontroller integrates an RRT planner and a centralized adaptive policy to\ngenerate subgoals, while the mid-level controller uses a decentralized\ngoal-conditioned policy to guide the robots toward these sub-goals. A\npre-trained low-level locomotion policy executes the movement commands. We\nevaluate our method against several baselines in simulation, demonstrating\nsignificant improvements over baseline approaches, with 36.0% higher success\nrates and 24.5% reduction in completion time than the best baseline. Our\nframework successfully enables long-horizon, obstacle-aware manipulation tasks\nlike Push-Cuboid and Push-T on Go1 robots in the real world.\n","authors":["Yuming Feng","Chuye Hong","Yaru Niu","Shiqi Liu","Yuxiang Yang","Wenhao Yu","Tingnan Zhang","Jie Tan","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.07104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09600v1","updated":"2024-11-14T17:18:24Z","published":"2024-11-14T17:18:24Z","title":"Latency Optimization in LEO Satellite Communications with Hybrid Beam\n  Pattern and Interference Control","summary":"  The rapid advancement of low Earth orbit (LEO) satellite communication\nsystems has significantly enhanced global connectivity, offering high-capacity,\nlow-latency services crucial for next-generation applications. However, the\ndense configuration of LEO constellations poses challenges in resource\nallocation optimization and interference management, complicating coexistence\nwith other communication systems. To address these limitations, this paper\nproposes a novel framework for optimizing the beam scheduling and resource\nallocation in multi-beam LEO systems. To satisfy the uneven terrestrial traffic\ndemand, a hybrid beam pattern is employed to enhance the downlink quality of\nservice and minimize the transmission latency from LEO satellites to ground\nuser terminals. Additionally, a dynamic co-channel interference (CCI) control\nmechanism is developed to mitigate inter-beam interference within the LEO\nconstellation and limit cross-system interference affecting protected users\nfrom other networks. The problem of user-beam-frequency allocation with power\noptimization is formulated as a mixed-integer dynamic programming model and\nsolved using a low-complexity neural network-based graph generation algorithm.\nSimulation results show that the proposed approach outperforms the baseline\nmethods of full frequency reuse and single-channel transmission, and highlights\nthe potential for further performance improvement with multi-user\ntransmissions.\n","authors":["Qianqian Zhang","Ye Hu","Minchae Jung"],"pdf_url":"https://arxiv.org/pdf/2411.09600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09595v1","updated":"2024-11-14T17:08:23Z","published":"2024-11-14T17:08:23Z","title":"LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models","summary":"  This work explores expanding the capabilities of large language models (LLMs)\npretrained on text to generate 3D meshes within a unified model. This offers\nkey advantages of (1) leveraging spatial knowledge already embedded in LLMs,\nderived from textual sources like 3D tutorials, and (2) enabling conversational\n3D generation and mesh understanding. A primary challenge is effectively\ntokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly.\nTo address this, we introduce LLaMA-Mesh, a novel approach that represents the\nvertex coordinates and face definitions of 3D meshes as plain text, allowing\ndirect integration with LLMs without expanding the vocabulary. We construct a\nsupervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate\n3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs\nas required, and (3) understand and interpret 3D meshes. Our work is the first\nto demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge\nfor 3D mesh generation in a text-based format, effectively unifying the 3D and\ntext modalities. LLaMA-Mesh achieves mesh generation quality on par with models\ntrained from scratch while maintaining strong text generation performance.\n","authors":["Zhengyi Wang","Jonathan Lorraine","Yikai Wang","Hang Su","Jun Zhu","Sanja Fidler","Xiaohui Zeng"],"pdf_url":"https://arxiv.org/pdf/2411.09595v1.pdf","comment":"See the project website at\n  https://research.nvidia.com/labs/toronto-ai/LLaMA-Mesh/"},{"id":"http://arxiv.org/abs/2410.18958v2","updated":"2024-11-14T17:06:55Z","published":"2024-10-24T17:55:52Z","title":"Stable Consistency Tuning: Understanding and Improving Consistency\n  Models","summary":"  Diffusion models achieve superior generation quality but suffer from slow\ngeneration speed due to the iterative nature of denoising. In contrast,\nconsistency models, a new generative family, achieve competitive performance\nwith significantly faster sampling. These models are trained either through\nconsistency distillation, which leverages pretrained diffusion models, or\nconsistency training/tuning directly from raw data. In this work, we propose a\nnovel framework for understanding consistency models by modeling the denoising\nprocess of the diffusion model as a Markov Decision Process (MDP) and framing\nconsistency model training as the value estimation through Temporal\nDifference~(TD) Learning. More importantly, this framework allows us to analyze\nthe limitations of current consistency training/tuning strategies. Built upon\nEasy Consistency Tuning (ECT), we propose Stable Consistency Tuning (SCT),\nwhich incorporates variance-reduced learning using the score identity. SCT\nleads to significant performance improvements on benchmarks such as CIFAR-10\nand ImageNet-64. On ImageNet-64, SCT achieves 1-step FID 2.42 and 2-step FID\n1.55, a new SoTA for consistency models.\n","authors":["Fu-Yun Wang","Zhengyang Geng","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2410.18958v2.pdf","comment":"Code is available at\n  https://github.com/G-U-N/Stable-Consistency-Tuning"},{"id":"http://arxiv.org/abs/2411.09591v1","updated":"2024-11-14T17:02:41Z","published":"2024-11-14T17:02:41Z","title":"Expert Study on Interpretable Machine Learning Models with Missing Data","summary":"  Inherently interpretable machine learning (IML) models provide valuable\ninsights for clinical decision-making but face challenges when features have\nmissing values. Classical solutions like imputation or excluding incomplete\nrecords are often unsuitable in applications where values are missing at test\ntime. In this work, we conducted a survey with 71 clinicians from 29 trauma\ncenters across France, including 20 complete responses to study the interaction\nbetween medical professionals and IML applied to data with missing values. This\nprovided valuable insights into how missing data is interpreted in clinical\nmachine learning. We used the prediction of hemorrhagic shock as a concrete\nexample to gauge the willingness and readiness of the participants to adopt IML\nmodels from three classes of methods. Our findings show that, while clinicians\nvalue interpretability and are familiar with common IML methods, classical\nimputation techniques often misalign with their intuition, and that models that\nnatively handle missing values are preferred. These results emphasize the need\nto integrate clinical intuition into future IML models for better\nhuman-computer interaction.\n","authors":["Lena Stempfle","Arthur James","Julie Josse","Tobias Gauss","Fredrik D. Johansson"],"pdf_url":"https://arxiv.org/pdf/2411.09591v1.pdf","comment":"Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 13 pages"},{"id":"http://arxiv.org/abs/2407.16677v3","updated":"2024-11-14T16:54:02Z","published":"2024-07-23T17:44:54Z","title":"From Imitation to Refinement -- Residual RL for Precise Assembly","summary":"  Advances in behavior cloning (BC), like action-chunking and diffusion, have\nenabled impressive capabilities. Still, imitation alone remains insufficient\nfor learning reliable policies for tasks requiring precise aligning and\ninserting of objects, like assembly. Our key insight is that chunked BC\npolicies effectively function as trajectory planners, enabling long-horizon\ntasks. Conversely, as they execute action chunks open-loop, they lack the\nfine-grained reactivity necessary for reliable execution. Further, we find that\nthe performance of BC policies saturates despite increasing data. Reinforcement\nlearning (RL) is a natural way to overcome BC's limitations, but it is not\nstraightforward to apply directly to action-chunked models like diffusion\npolicies. We present a simple yet effective method, ResiP (Residual for Precise\nManipulation), that sidesteps these challenges by augmenting a frozen, chunked\nBC model with a fully closed-loop residual policy trained with RL. The residual\npolicy is trained via on-policy RL, addressing distribution shifts and\nintroducing reactive control without altering the BC trajectory planner.\nEvaluation on high-precision manipulation tasks demonstrates strong performance\nof ResiP over BC methods and direct RL fine-tuning. Videos, code, and data are\navailable at https://residual-assembly.github.io.\n","authors":["Lars Ankile","Anthony Simeonov","Idan Shenfeld","Marcel Torne","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2407.16677v3.pdf","comment":"Project website: https://residual-assembly.github.io"},{"id":"http://arxiv.org/abs/2402.02681v3","updated":"2024-11-14T16:30:13Z","published":"2024-02-05T02:35:11Z","title":"Equivariant Symmetry Breaking Sets","summary":"  Equivariant neural networks (ENNs) have been shown to be extremely effective\nin applications involving underlying symmetries. By construction ENNs cannot\nproduce lower symmetry outputs given a higher symmetry input. However, symmetry\nbreaking occurs in many physical systems and we may obtain a less symmetric\nstable state from an initial highly symmetric one. Hence, it is imperative that\nwe understand how to systematically break symmetry in ENNs. In this work, we\npropose a novel symmetry breaking framework that is fully equivariant and is\nthe first which fully addresses spontaneous symmetry breaking. We emphasize\nthat our approach is general and applicable to equivariance under any group. To\nachieve this, we introduce the idea of symmetry breaking sets (SBS). Rather\nthan redesign existing networks, we design sets of symmetry breaking objects\nwhich we feed into our network based on the symmetry of our inputs and outputs.\nWe show there is a natural way to define equivariance on these sets, which\ngives an additional constraint. Minimizing the size of these sets equates to\ndata efficiency. We prove that minimizing these sets translates to a well\nstudied group theory problem, and tabulate solutions to this problem for the\npoint groups. Finally, we provide some examples of symmetry breaking to\ndemonstrate how our approach works in practice. The code for these examples is\navailable at \\url{https://github.com/atomicarchitects/equivariant-SBS}.\n","authors":["YuQing Xie","Tess Smidt"],"pdf_url":"https://arxiv.org/pdf/2402.02681v3.pdf","comment":"50 pages, 19 figures Published in Transactions on Machine Learning\n  Research, October 2024"},{"id":"http://arxiv.org/abs/2411.01881v2","updated":"2024-11-14T16:17:40Z","published":"2024-11-04T08:24:56Z","title":"Causal Discovery and Classification Using Lempel-Ziv Complexity","summary":"  Inferring causal relationships in the decision-making processes of machine\nlearning algorithms is a crucial step toward achieving explainable Artificial\nIntelligence (AI). In this research, we introduce a novel causality measure and\na distance metric derived from Lempel-Ziv (LZ) complexity. We explore how the\nproposed causality measure can be used in decision trees by enabling splits\nbased on features that most strongly \\textit{cause} the outcome. We further\nevaluate the effectiveness of the causality-based decision tree and the\ndistance-based decision tree in comparison to a traditional decision tree using\nGini impurity. While the proposed methods demonstrate comparable classification\nperformance overall, the causality-based decision tree significantly\noutperforms both the distance-based decision tree and the Gini-based decision\ntree on datasets generated from causal models. This result indicates that the\nproposed approach can capture insights beyond those of classical decision\ntrees, especially in causally structured data. Based on the features used in\nthe LZ causal measure based decision tree, we introduce a causal strength for\neach features in the dataset so as to infer the predominant causal variables\nfor the occurrence of the outcome.\n","authors":[" Dhruthi","Nithin Nagaraj","Harikrishnan N B"],"pdf_url":"https://arxiv.org/pdf/2411.01881v2.pdf","comment":"17 pages, 8 figures, 5 tables"},{"id":"http://arxiv.org/abs/2411.06503v2","updated":"2024-11-14T16:15:20Z","published":"2024-11-10T15:57:53Z","title":"Diffusion Sampling Correction via Approximately 10 Parameters","summary":"  Diffusion Probabilistic Models (DPMs) have demonstrated exceptional\nperformance in generative tasks, but this comes at the expense of sampling\nefficiency. To enhance sampling speed without sacrificing quality, various\ndistillation-based accelerated sampling algorithms have been recently proposed.\nHowever, they typically require significant additional training costs and model\nparameter storage, which limit their practical application. In this work, we\npropose PCA-based Adaptive Search (PAS), which optimizes existing solvers for\nDPMs with minimal learnable parameters and training costs. Specifically, we\nfirst employ PCA to obtain a few orthogonal unit basis vectors to span the\nhigh-dimensional sampling space, which enables us to learn just a set of\ncoordinates to correct the sampling direction; furthermore, based on the\nobservation that the cumulative truncation error exhibits an ``S''-shape, we\ndesign an adaptive search strategy that further enhances the sampling\nefficiency and reduces the number of stored parameters to approximately 10.\nExtensive experiments demonstrate that PAS can significantly enhance existing\nfast solvers in a plug-and-play manner with negligible costs. For instance, on\nCIFAR10, PAS requires only 12 parameters and less than 1 minute of training on\na single NVIDIA A100 GPU to optimize the DDIM from 15.69 FID (NFE=10) to 4.37.\n","authors":["Guangyi Wang","Wei Peng","Lijiang Li","Wenyu Chen","Yuren Cai","Songzhi Su"],"pdf_url":"https://arxiv.org/pdf/2411.06503v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09558v1","updated":"2024-11-14T16:10:15Z","published":"2024-11-14T16:10:15Z","title":"Adaptive Deviation Learning for Visual Anomaly Detection with Data\n  Contamination","summary":"  Visual anomaly detection targets to detect images that notably differ from\nnormal pattern, and it has found extensive application in identifying defective\nparts within the manufacturing industry. These anomaly detection paradigms\npredominantly focus on training detection models using only clean, unlabeled\nnormal samples, assuming an absence of contamination; a condition often unmet\nin real-world scenarios. The performance of these methods significantly depends\non the quality of the data and usually decreases when exposed to noise. We\nintroduce a systematic adaptive method that employs deviation learning to\ncompute anomaly scores end-to-end while addressing data contamination by\nassigning relative importance to the weights of individual instances. In this\napproach, the anomaly scores for normal instances are designed to approximate\nscalar scores obtained from the known prior distribution. Meanwhile, anomaly\nscores for anomaly examples are adjusted to exhibit statistically significant\ndeviations from these reference scores. Our approach incorporates a constrained\noptimization problem within the deviation learning framework to update instance\nweights, resolving this problem for each mini-batch. Comprehensive experiments\non the MVTec and VisA benchmark datasets indicate that our proposed method\nsurpasses competing techniques and exhibits both stability and robustness in\nthe presence of data contamination.\n","authors":["Anindya Sundar Das","Guansong Pang","Monowar Bhuyan"],"pdf_url":"https://arxiv.org/pdf/2411.09558v1.pdf","comment":"Accepted to IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV 2025)"},{"id":"http://arxiv.org/abs/2411.09545v1","updated":"2024-11-14T15:59:41Z","published":"2024-11-14T15:59:41Z","title":"Equation-informed data-driven identification of flow budgets and\n  dynamics","summary":"  Computational Fluid Dynamics (CFD) is an indispensable method of fluid\nmodelling in engineering applications, reducing the need for physical\nprototypes and testing for tasks such as design optimisation and performance\nanalysis. Depending on the complexity of the system under consideration, models\nranging from low to high fidelity can be used for prediction, allowing\nsignificant speed-up. However, the choice of model requires information about\nthe actual dynamics of the flow regime. Correctly identifying the\nregions/clusters of flow that share the same dynamics has been a challenging\nresearch topic to date. In this study, we propose a novel hybrid approach to\nflow clustering. It consists of characterising each sample point of the system\nwith equation-based features, i.e. features are budgets that represent the\ncontribution of each term from the original governing equation to the local\ndynamics at each sample point. This was achieved by applying the Sparse\nIdentification of Nonlinear Dynamical systems (SINDy) method pointwise to time\nevolution data. The method proceeds with equation-based clustering using the\nGirvan-Newman algorithm. This allows the detection of communities that share\nthe same physical dynamics. The algorithm is implemented in both Eulerian and\nLagrangian frameworks. In the Lagrangian, i.e. dynamic approach, the clustering\nis performed on the trajectory of each point, allowing the change of clusters\nto be represented also in time. The performance of the algorithm is first\ntested on a flow around a cylinder. The construction of the dynamic clusters in\nthis test case clearly shows the evolution of the wake from the steady state\nsolution through the transient to the oscillatory solution. Dynamic clustering\nwas then successfully tested on turbulent flow data. Two distinct and\nwell-defined clusters were identified and their temporal evolution was\nreconstructed.\n","authors":["Nataliya Sevryugina","Serena Costanzo","Steve de Bruyn Kops","Colm-cille Caulfield","Iraj Mortazavi","Taraneh Sayadi"],"pdf_url":"https://arxiv.org/pdf/2411.09545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09540v1","updated":"2024-11-14T15:56:11Z","published":"2024-11-14T15:56:11Z","title":"Prompting the Unseen: Detecting Hidden Backdoors in Black-Box Models","summary":"  Visual prompting (VP) is a new technique that adapts well-trained frozen\nmodels for source domain tasks to target domain tasks. This study examines VP's\nbenefits for black-box model-level backdoor detection. The visual prompt in VP\nmaps class subspaces between source and target domains. We identify a\nmisalignment, termed class subspace inconsistency, between clean and poisoned\ndatasets. Based on this, we introduce \\textsc{BProm}, a black-box model-level\ndetection method to identify backdoors in suspicious models, if any.\n\\textsc{BProm} leverages the low classification accuracy of prompted models\nwhen backdoors are present. Extensive experiments confirm \\textsc{BProm}'s\neffectiveness.\n","authors":["Zi-Xuan Huang","Jia-Wei Chen","Zhi-Peng Zhang","Chia-Mu Yu"],"pdf_url":"https://arxiv.org/pdf/2411.09540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09539v1","updated":"2024-11-14T15:55:37Z","published":"2024-11-14T15:55:37Z","title":"A Practical Guide to Fine-tuning Language Models with Limited Data","summary":"  Employing pre-trained Large Language Models (LLMs) has become the de facto\nstandard in Natural Language Processing (NLP) despite their extensive data\nrequirements. Motivated by the recent surge in research focused on training\nLLMs with limited data, particularly in low-resource domains and languages,\nthis paper surveys recent transfer learning approaches to optimize model\nperformance in downstream tasks where data is scarce. We first address initial\nand continued pre-training strategies to better leverage prior knowledge in\nunseen domains and languages. We then examine how to maximize the utility of\nlimited data during fine-tuning and few-shot learning. The final section takes\na task-specific perspective, reviewing models and methods suited for different\nlevels of data scarcity. Our goal is to provide practitioners with practical\nguidelines for overcoming the challenges posed by constrained data while also\nhighlighting promising directions for future research.\n","authors":["Márton Szép","Daniel Rueckert","Rüdiger von Eisenhart-Rothe","Florian Hinterwimmer"],"pdf_url":"https://arxiv.org/pdf/2411.09539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09517v1","updated":"2024-11-14T15:28:40Z","published":"2024-11-14T15:28:40Z","title":"Randomized Truthful Auctions with Learning Agents","summary":"  We study a setting where agents use no-regret learning algorithms to\nparticipate in repeated auctions. \\citet{kolumbus2022auctions} showed, rather\nsurprisingly, that when bidders participate in second-price auctions using\nno-regret bidding algorithms, no matter how large the number of interactions\n$T$ is, the runner-up bidder may not converge to bidding truthfully. Our first\nresult shows that this holds for \\emph{general deterministic} truthful\nauctions. We also show that the ratio of the learning rates of the bidders can\n\\emph{qualitatively} affect the convergence of the bidders. Next, we consider\nthe problem of revenue maximization in this environment. In the setting with\nfully rational bidders, \\citet{myerson1981optimal} showed that revenue can be\nmaximized by using a second-price auction with reserves.We show that, in stark\ncontrast, in our setting with learning bidders, \\emph{randomized} auctions can\nhave strictly better revenue guarantees than second-price auctions with\nreserves, when $T$ is large enough. Finally, we study revenue maximization in\nthe non-asymptotic regime. We define a notion of {\\em auctioneer regret}\ncomparing the revenue generated to the revenue of a second price auction with\ntruthful bids. When the auctioneer has to use the same auction throughout the\ninteraction, we show an (almost) tight regret bound of $\\smash{\\widetilde\n\\Theta(T^{3/4})}.$ If the auctioneer can change auctions during the\ninteraction, but in a way that is oblivious to the bids, we show an (almost)\ntight bound of $\\smash{\\widetilde \\Theta(\\sqrt{T})}.$\n","authors":["Gagan Aggarwal","Anupam Gupta","Andres Perlroth","Grigoris Velegkas"],"pdf_url":"https://arxiv.org/pdf/2411.09517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09512v1","updated":"2024-11-14T15:26:10Z","published":"2024-11-14T15:26:10Z","title":"GAN-Based Architecture for Low-dose Computed Tomography Imaging\n  Denoising","summary":"  Generative Adversarial Networks (GANs) have surfaced as a revolutionary\nelement within the domain of low-dose computed tomography (LDCT) imaging,\nproviding an advanced resolution to the enduring issue of reconciling radiation\nexposure with image quality. This comprehensive review synthesizes the rapid\nadvancements in GAN-based LDCT denoising techniques, examining the evolution\nfrom foundational architectures to state-of-the-art models incorporating\nadvanced features such as anatomical priors, perceptual loss functions, and\ninnovative regularization strategies. We critically analyze various GAN\narchitectures, including conditional GANs (cGANs), CycleGANs, and\nSuper-Resolution GANs (SRGANs), elucidating their unique strengths and\nlimitations in the context of LDCT denoising. The evaluation provides both\nqualitative and quantitative results related to the improvements in performance\nin benchmark and clinical datasets with metrics such as PSNR, SSIM, and LPIPS.\nAfter highlighting the positive results, we discuss some of the challenges\npreventing a wider clinical use, including the interpretability of the images\ngenerated by GANs, synthetic artifacts, and the need for clinically relevant\nmetrics. The review concludes by highlighting the essential significance of\nGAN-based methodologies in the progression of precision medicine via tailored\nLDCT denoising models, underlining the transformative possibilities presented\nby artificial intelligence within contemporary radiological practice.\n","authors":["Yunuo Wang","Ningning Yang","Jialin Li"],"pdf_url":"https://arxiv.org/pdf/2411.09512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09510v1","updated":"2024-11-14T15:19:01Z","published":"2024-11-14T15:19:01Z","title":"Communication Compression for Tensor Parallel LLM Inference","summary":"  Large Language Models (LLMs) have pushed the frontier of artificial\nintelligence but are comprised of hundreds of billions of parameters and\noperations. For faster inference latency, LLMs are deployed on multiple\nhardware accelerators through various Model Parallelism strategies. Our paper\nlooks into the details on one such strategy - Tensor Parallel - and proposes to\nreduce latency by compressing inter-accelerator communication. We leverage fine\ngrained quantization techniques to compress selected activations by 3.5 - 4.5x.\nOur proposed method leads up to 2x reduction of time-to-first-token (TTFT) with\nnegligible model performance degradation.\n","authors":["Jan Hansen-Palmus","Michael Truong-Le","Oliver Hausdörfer","Alok Verma"],"pdf_url":"https://arxiv.org/pdf/2411.09510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09502v1","updated":"2024-11-14T15:13:13Z","published":"2024-11-14T15:13:13Z","title":"Golden Noise for Diffusion Models: A Learning Framework","summary":"  Text-to-image diffusion model is a popular paradigm that synthesizes\npersonalized images by providing a text prompt and a random Gaussian noise.\nWhile people observe that some noises are ``golden noises'' that can achieve\nbetter text-image alignment and higher human preference than others, we still\nlack a machine learning framework to obtain those golden noises. To learn\ngolden noises for diffusion sampling, we mainly make three contributions in\nthis paper. First, we identify a new concept termed the \\textit{noise prompt},\nwhich aims at turning a random Gaussian noise into a golden noise by adding a\nsmall desirable perturbation derived from the text prompt. Following the\nconcept, we first formulate the \\textit{noise prompt learning} framework that\nsystematically learns ``prompted'' golden noise associated with a text prompt\nfor diffusion models. Second, we design a noise prompt data collection pipeline\nand collect a large-scale \\textit{noise prompt dataset}~(NPD) that contains\n100k pairs of random noises and golden noises with the associated text prompts.\nWith the prepared NPD as the training dataset, we trained a small \\textit{noise\nprompt network}~(NPNet) that can directly learn to transform a random noise\ninto a golden noise. The learned golden noise perturbation can be considered as\na kind of prompt for noise, as it is rich in semantic information and tailored\nto the given text prompt. Third, our extensive experiments demonstrate the\nimpressive effectiveness and generalization of NPNet on improving the quality\nof synthesized images across various diffusion models, including SDXL,\nDreamShaper-xl-v2-turbo, and Hunyuan-DiT. Moreover, NPNet is a small and\nefficient controller that acts as a plug-and-play module with very limited\nadditional inference and computational costs, as it just provides a golden\nnoise instead of a random noise without accessing the original pipeline.\n","authors":["Zikai Zhou","Shitong Shao","Lichen Bai","Zhiqiang Xu","Bo Han","Zeke Xie"],"pdf_url":"https://arxiv.org/pdf/2411.09502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09499v1","updated":"2024-11-14T15:06:50Z","published":"2024-11-14T15:06:50Z","title":"Developement of Reinforcement Learning based Optimisation Method for\n  Side-Sill Design","summary":"  Optimisation for crashworthiness is a critical part of the vehicle\ndevelopment process. Due to stringent regulations and increasing market\ndemands, multiple factors must be considered within a limited timeframe.\nHowever, for optimal crashworthiness design, multiobjective optimisation is\nnecessary, and for complex parts, multiple design parameters must be evaluated.\nThis crashworthiness analysis requires computationally intensive finite element\nsimulations. This challenge leads to the need for inverse multi-parameter\nmulti-objective optimisation. This challenge leads to the need for\nmulti-parameter, multi-objective inverse optimisation. This article\ninvestigates a machine learning-based method for this type of optimisation,\nfocusing on the design optimisation of a multi-cell side sill to improve\ncrashworthiness results. Furthermore, the optimiser is coupled with an FE\nsolver to achieve improved results.\n","authors":["Aditya Borse","Rutwik Gulakala","Marcus Stoffel"],"pdf_url":"https://arxiv.org/pdf/2411.09499v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.03648v3","updated":"2024-11-14T15:06:12Z","published":"2023-08-07T14:58:53Z","title":"Generative Forests","summary":"  We focus on generative AI for a type of data that still represent one of the\nmost prevalent form of data: tabular data. Our paper introduces two key\ncontributions: a new powerful class of forest-based models fit for such tasks\nand a simple training algorithm with strong convergence guarantees in a\nboosting model that parallels that of the original weak / strong supervised\nlearning setting. This algorithm can be implemented by a few tweaks to the most\npopular induction scheme for decision tree induction (i.e. supervised learning)\nwith two classes. Experiments on the quality of generated data display\nsubstantial improvements compared to the state of the art. The losses our\nalgorithm minimize and the structure of our models make them practical for\nrelated tasks that require fast estimation of a density given a generative\nmodel and an observation (even partially specified): such tasks include missing\ndata imputation and density estimation. Additional experiments on these tasks\nreveal that our models can be notably good contenders to diverse state of the\nart methods, relying on models as diverse as (or mixing elements of) trees,\nneural nets, kernels or graphical models.\n","authors":["Richard Nock","Mathieu Guillame-Bert"],"pdf_url":"https://arxiv.org/pdf/2308.03648v3.pdf","comment":"NeurIPS'24"},{"id":"http://arxiv.org/abs/2410.01440v3","updated":"2024-11-14T15:04:33Z","published":"2024-10-02T11:42:49Z","title":"Closed-Loop Long-Horizon Robotic Planning via Equilibrium Sequence\n  Modeling","summary":"  In the endeavor to make autonomous robots take actions, task planning is a\nmajor challenge that requires translating high-level task descriptions into\nlong-horizon action sequences. Despite recent advances in language model\nagents, they remain prone to planning errors and limited in their ability to\nplan ahead. To address these limitations in robotic planning, we advocate a\nself-refining scheme that iteratively refines a draft plan until an equilibrium\nis reached. Remarkably, this process can be optimized end-to-end from an\nanalytical perspective without the need to curate additional verifiers or\nreward models, allowing us to train self-refining planners in a simple\nsupervised learning fashion. Meanwhile, a nested equilibrium sequence modeling\nprocedure is devised for efficient closed-loop planning that incorporates\nuseful feedback from the environment (or an internal world model). Our method\nis evaluated on the VirtualHome-Env benchmark, showing advanced performance\nwith better scaling for inference computation. Code is available at\nhttps://github.com/Singularity0104/equilibrium-planner.\n","authors":["Jinghan Li","Zhicheng Sun","Fei Li","Cao Sheng","Jiazhong Yu","Yadong Mu"],"pdf_url":"https://arxiv.org/pdf/2410.01440v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.24006v2","updated":"2024-11-14T14:58:26Z","published":"2024-10-31T15:09:36Z","title":"DiffPAD: Denoising Diffusion-based Adversarial Patch Decontamination","summary":"  In the ever-evolving adversarial machine learning landscape, developing\neffective defenses against patch attacks has become a critical challenge,\nnecessitating reliable solutions to safeguard real-world AI systems. Although\ndiffusion models have shown remarkable capacity in image synthesis and have\nbeen recently utilized to counter $\\ell_p$-norm bounded attacks, their\npotential in mitigating localized patch attacks remains largely underexplored.\nIn this work, we propose DiffPAD, a novel framework that harnesses the power of\ndiffusion models for adversarial patch decontamination. DiffPAD first performs\nsuper-resolution restoration on downsampled input images, then adopts\nbinarization, dynamic thresholding scheme and sliding window for effective\nlocalization of adversarial patches. Such a design is inspired by the\ntheoretically derived correlation between patch size and diffusion restoration\nerror that is generalized across diverse patch attack scenarios. Finally,\nDiffPAD applies inpainting techniques to the original input images with the\nestimated patch region being masked. By integrating closed-form solutions for\nsuper-resolution restoration and image inpainting into the conditional reverse\nsampling process of a pre-trained diffusion model, DiffPAD obviates the need\nfor text guidance or fine-tuning. Through comprehensive experiments, we\ndemonstrate that DiffPAD not only achieves state-of-the-art adversarial\nrobustness against patch attacks but also excels in recovering naturalistic\nimages without patch remnants. The source code is available at\nhttps://github.com/JasonFu1998/DiffPAD.\n","authors":["Jia Fu","Xiao Zhang","Sepideh Pashami","Fatemeh Rahimian","Anders Holst"],"pdf_url":"https://arxiv.org/pdf/2410.24006v2.pdf","comment":"Accepted to 2025 IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV)"},{"id":"http://arxiv.org/abs/2411.09483v1","updated":"2024-11-14T14:37:47Z","published":"2024-11-14T14:37:47Z","title":"Sparse Bayesian Generative Modeling for Compressive Sensing","summary":"  This work addresses the fundamental linear inverse problem in compressive\nsensing (CS) by introducing a new type of regularizing generative prior. Our\nproposed method utilizes ideas from classical dictionary-based CS and, in\nparticular, sparse Bayesian learning (SBL), to integrate a strong\nregularization towards sparse solutions. At the same time, by leveraging the\nnotion of conditional Gaussianity, it also incorporates the adaptability from\ngenerative models to training data. However, unlike most state-of-the-art\ngenerative models, it is able to learn from a few compressed and noisy data\nsamples and requires no optimization algorithm for solving the inverse problem.\nAdditionally, similar to Dirichlet prior networks, our model parameterizes a\nconjugate prior enabling its application for uncertainty quantification. We\nsupport our approach theoretically through the concept of variational inference\nand validate it empirically using different types of compressible signals.\n","authors":["Benedikt Böck","Sadaf Syed","Wolfgang Utschick"],"pdf_url":"https://arxiv.org/pdf/2411.09483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09481v1","updated":"2024-11-14T14:37:15Z","published":"2024-11-14T14:37:15Z","title":"What makes a good BIM design: quantitative linking between design\n  behavior and quality","summary":"  In the Architecture Engineering & Construction (AEC) industry, how design\nbehaviors impact design quality remains unclear. This study proposes a novel\napproach, which, for the first time, identifies and quantitatively describes\nthe relationship between design behaviors and quality of design based on\nBuilding Information Modeling (BIM). Real-time collection and log mining are\nintegrated to collect raw data of design behaviors. Feature engineering and\nvarious machine learning models are then utilized for quantitative modeling and\ninterpretation. Results confirm an existing quantifiable relationship which can\nbe learned by various models. The best-performing model using Extremely Random\nTrees achieved an R2 value of 0.88 on the test set. Behavioral features related\nto designer's skill level and changes of design intentions are identified to\nhave significant impacts on design quality. These findings deepen our\nunderstanding of the design process and help forming BIM designs with better\nquality.\n","authors":["Xiang-Rui Ni","Peng Pan","Jia-Rui Lin"],"pdf_url":"https://arxiv.org/pdf/2411.09481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09476v1","updated":"2024-11-14T14:31:52Z","published":"2024-11-14T14:31:52Z","title":"Graph Neural Networks and Differential Equations: A hybrid approach for\n  data assimilation of fluid flows","summary":"  This study presents a novel hybrid approach that combines Graph Neural\nNetworks (GNNs) with Reynolds-Averaged Navier Stokes (RANS) equations to\nenhance the accuracy of mean flow reconstruction across a range of fluid\ndynamics applications. Traditional purely data-driven Neural Networks (NNs)\nmodels, often struggle maintaining physical consistency. Moreover, they\ntypically require large datasets to achieve reliable performances. The GNN\nframework, which naturally handles unstructured data such as complex geometries\nin Computational Fluid Dynamics (CFD), is here integrated with RANS equations\nas a physical baseline model. The methodology leverages the adjoint method,\nenabling the use of RANS-derived gradients as optimization terms in the GNN\ntraining process. This ensures that the learned model adheres to the governing\nphysics, maintaining physical consistency while improving the prediction\naccuracy. We test our approach on multiple CFD scenarios, including cases\ninvolving generalization with respect to the Reynolds number, sparse\nmeasurements, denoising and inpainting of missing portions of the mean flow.\nThe results demonstrate significant improvements in the accuracy of the\nreconstructed mean flow compared to purely data-driven models, using limited\namounts of data in the training dataset. The key strengths of this study are\nthe integration of physical laws into the training process of the GNN, and the\nability to achieve high-accuracy predictions with a limited amount of data,\nmaking this approach particularly valuable for applications in fluid dynamics\nwhere data is often scarce.\n","authors":["M. Quattromini","M. A. Bucci","S. Cherubini","O. Semeraro"],"pdf_url":"https://arxiv.org/pdf/2411.09476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09475v1","updated":"2024-11-14T14:31:30Z","published":"2024-11-14T14:31:30Z","title":"ResidualDroppath: Enhancing Feature Reuse over Residual Connections","summary":"  Residual connections are one of the most important components in neural\nnetwork architectures for mitigating the vanishing gradient problem and\nfacilitating the training of much deeper networks. One possible explanation for\nhow residual connections aid deeper network training is by promoting feature\nreuse. However, we identify and analyze the limitations of feature reuse with\nvanilla residual connections. To address these limitations, we propose\nmodifications in training methods. Specifically, we provide an additional\nopportunity for the model to learn feature reuse with residual connections\nthrough two types of iterations during training. The first type of iteration\ninvolves using droppath, which enforces feature reuse by randomly dropping a\nsubset of layers. The second type of iteration focuses on training the dropped\nparts of the model while freezing the undropped parts. As a result, the dropped\nparts learn in a way that encourages feature reuse, as the model relies on the\nundropped parts with feature reuse in mind. Overall, we demonstrated\nperformance improvements in models with residual connections for image\nclassification in certain cases.\n","authors":["Sejik Park"],"pdf_url":"https://arxiv.org/pdf/2411.09475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02407v3","updated":"2024-11-14T14:26:42Z","published":"2024-08-05T12:01:42Z","title":"Terracorder: Sense Long and Prosper","summary":"  In-situ sensing devices need to be deployed in remote environments for long\nperiods of time; minimizing their power consumption is vital for maximising\nboth their operational lifetime and coverage. We introduce Terracorder -- a\nversatile multi-sensor device -- and showcase its exceptionally low power\nconsumption using an on-device reinforcement learning scheduler. We prototype a\nunique device setup for biodiversity monitoring and compare its battery life\nusing our scheduler against a number of fixed schedules; the scheduler captures\nmore than 80% of events at less than 50% of the number of activations of the\nbest-performing fixed schedule. We then explore how a collaborative scheduler\ncan maximise the useful operation of a network of devices, improving overall\nnetwork power consumption and robustness.\n","authors":["Josh Millar","Sarab Sethi","Hamed Haddadi","Anil Madhavapeddy"],"pdf_url":"https://arxiv.org/pdf/2408.02407v3.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2411.01013v2","updated":"2024-11-14T14:23:29Z","published":"2024-11-01T20:33:49Z","title":"A Similarity-Based Oversampling Method for Multi-label Imbalanced Text\n  Data","summary":"  In real-world applications, as data availability increases, obtaining labeled\ndata for machine learning (ML) projects remains challenging due to the high\ncosts and intensive efforts required for data annotation. Many ML projects,\nparticularly those focused on multi-label classification, also grapple with\ndata imbalance issues, where certain classes may lack sufficient data to train\neffective classifiers. This study introduces and examines a novel oversampling\nmethod for multi-label text classification, designed to address performance\nchallenges associated with data imbalance. The proposed method identifies\npotential new samples from unlabeled data by leveraging similarity measures\nbetween instances. By iteratively searching the unlabeled dataset, the method\nlocates instances similar to those in underrepresented classes and evaluates\ntheir contribution to classifier performance enhancement. Instances that\ndemonstrate performance improvement are then added to the labeled dataset.\nExperimental results indicate that the proposed approach effectively enhances\nclassifier performance post-oversampling.\n","authors":["Ismail Hakki Karaman","Gulser Koksal","Levent Eriskin","Salih Salihoglu"],"pdf_url":"https://arxiv.org/pdf/2411.01013v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09471v1","updated":"2024-11-14T14:21:49Z","published":"2024-11-14T14:21:49Z","title":"Renal Cell Carcinoma subtyping: learning from multi-resolution\n  localization","summary":"  Renal Cell Carcinoma is typically asymptomatic at the early stages for many\npatients. This leads to a late diagnosis of the tumor, where the curability\nlikelihood is lower, and makes the mortality rate of Renal Cell Carcinoma high,\nwith respect to its incidence rate. To increase the survival chance, a fast and\ncorrect categorization of the tumor subtype is paramount. Nowadays,\ncomputerized methods, based on artificial intelligence, represent an\ninteresting opportunity to improve the productivity and the objectivity of the\nmicroscopy-based Renal Cell Carcinoma diagnosis. Nonetheless, much of their\nexploitation is hampered by the paucity of annotated dataset, essential for a\nproficient training of supervised machine learning technologies. This study\nsets out to investigate a novel self supervised training strategy for machine\nlearning diagnostic tools, based on the multi-resolution nature of the\nhistological samples. We aim at reducing the need of annotated dataset, without\nsignificantly reducing the accuracy of the tool. We demonstrate the\nclassification capability of our tool on a whole slide imaging dataset for\nRenal Cancer subtyping, and we compare our solution with several\nstate-of-the-art classification counterparts.\n","authors":["Mohamad Mohamad","Francesco Ponzio","Santa Di Cataldo","Damien Ambrosetti","Xavier Descombes"],"pdf_url":"https://arxiv.org/pdf/2411.09471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09468v1","updated":"2024-11-14T14:16:50Z","published":"2024-11-14T14:16:50Z","title":"Harnessing Machine Learning for Single-Shot Measurement of Free Electron\n  Laser Pulse Power","summary":"  Electron beam accelerators are essential in many scientific and technological\nfields. Their operation relies heavily on the stability and precision of the\nelectron beam. Traditional diagnostic techniques encounter difficulties in\naddressing the complex and dynamic nature of electron beams. Particularly in\nthe context of free-electron lasers (FELs), it is fundamentally impossible to\nmeasure the lasing-on and lasingoff electron power profiles for a single\nelectron bunch. This is a crucial hurdle in the exact reconstruction of the\nphoton pulse profile. To overcome this hurdle, we developed a machine learning\nmodel that predicts the temporal power profile of the electron bunch in the\nlasing-off regime using machine parameters that can be obtained when lasing is\non. The model was statistically validated and showed superior predictions\ncompared to the state-of-the-art batch calibrations. The work we present here\nis a critical element for a virtual pulse reconstruction diagnostic (VPRD) tool\ndesigned to reconstruct the power profile of individual photon pulses without\nrequiring repeated measurements in the lasing-off regime. This promises to\nsignificantly enhance the diagnostic capabilities in FELs at large.\n","authors":["Till Korten","Vladimir Rybnikov","Mathias Vogt","Juliane Roensch-Schulenburg","Peter Steinbach","Najmeh Mirian"],"pdf_url":"https://arxiv.org/pdf/2411.09468v1.pdf","comment":"10 pages, 4 figures, Machine Learning and the Physical Sciences\n  Workshop, NeurIPS 2024 https://neurips.cc/virtual/2024/100009"},{"id":"http://arxiv.org/abs/2402.03227v4","updated":"2024-11-14T14:11:57Z","published":"2024-02-05T17:38:49Z","title":"IGUANe: a 3D generalizable CycleGAN for multicenter harmonization of\n  brain MR images","summary":"  In MRI studies, the aggregation of imaging data from multiple acquisition\nsites enhances sample size but may introduce site-related variabilities that\nhinder consistency in subsequent analyses. Deep learning methods for image\ntranslation have emerged as a solution for harmonizing MR images across sites.\nIn this study, we introduce IGUANe (Image Generation with Unified Adversarial\nNetworks), an original 3D model that leverages the strengths of domain\ntranslation and straightforward application of style transfer methods for\nmulticenter brain MR image harmonization. IGUANe extends CycleGAN by\nintegrating an arbitrary number of domains for training through a many-to-one\narchitecture. The framework based on domain pairs enables the implementation of\nsampling strategies that prevent confusion between site-related and biological\nvariabilities. During inference, the model can be applied to any image, even\nfrom an unknown acquisition site, making it a universal generator for\nharmonization. Trained on a dataset comprising T1-weighted images from 11\ndifferent scanners, IGUANe was evaluated on data from unseen sites. The\nassessments included the transformation of MR images with traveling subjects,\nthe preservation of pairwise distances between MR images within domains, the\nevolution of volumetric patterns related to age and Alzheimer$'$s disease (AD),\nand the performance in age regression and patient classification tasks.\nComparisons with other harmonization and normalization methods suggest that\nIGUANe better preserves individual information in MR images and is more\nsuitable for maintaining and reinforcing variabilities related to age and AD.\nFuture studies may further assess IGUANe in other multicenter contexts, either\nusing the same model or retraining it for applications to different image\nmodalities. IGUANe is available at\nhttps://github.com/RocaVincent/iguane_harmonization.git.\n","authors":["Vincent Roca","Grégory Kuchcinski","Jean-Pierre Pruvo","Dorian Manouvriez","Renaud Lopes"],"pdf_url":"https://arxiv.org/pdf/2402.03227v4.pdf","comment":"29 pages, 14 figures"},{"id":"http://arxiv.org/abs/2411.09459v1","updated":"2024-11-14T14:10:31Z","published":"2024-11-14T14:10:31Z","title":"Caravan MultiMet: Extending Caravan with Multiple Weather Nowcasts and\n  Forecasts","summary":"  The Caravan large-sample hydrology dataset (Kratzert et al., 2023) was\ncreated to standardize and harmonize streamflow data from various regional\ndatasets, combined with globally available meteorological forcing and catchment\nattributes. This community-driven project also allows researchers to\nconveniently extend the dataset for additional basins, as done 6 times to date\n(see https://github.com/kratzert/Caravan/discussions/10). We present a novel\nextension to Caravan, focusing on enriching the meteorological forcing data.\nOur extension adds three precipitation nowcast products (CPC, IMERG v07 Early,\nand CHIRPS) and three weather forecast products (ECMWF IFS HRES, GraphCast, and\nCHIRPS-GEFS) to the existing ERA5-Land reanalysis data. The inclusion of\ndiverse data sources, particularly weather forecasts, enables more robust\nevaluation and benchmarking of hydrological models, especially for real-time\nforecasting scenarios. To the best of our knowledge, this extension makes\nCaravan the first large-sample hydrology dataset to incorporate weather\nforecast data, significantly enhancing its capabilities and fostering\nadvancements in hydrological research, benchmarking, and real-time hydrologic\nforecasting. The data is publicly available under a CC-BY-4.0 license on Zenodo\nin two parts (https://zenodo.org/records/14161235,\nhttps://zenodo.org/records/14161281) and on Google Cloud Platform (GCP) - see\nmore under the Data Availability chapter.\n","authors":["Guy Shalev","Frederik Kratzert"],"pdf_url":"https://arxiv.org/pdf/2411.09459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09453v1","updated":"2024-11-14T13:59:01Z","published":"2024-11-14T13:59:01Z","title":"Long-Tailed Object Detection Pre-training: Dynamic Rebalancing\n  Contrastive Learning with Dual Reconstruction","summary":"  Pre-training plays a vital role in various vision tasks, such as object\nrecognition and detection. Commonly used pre-training methods, which typically\nrely on randomized approaches like uniform or Gaussian distributions to\ninitialize model parameters, often fall short when confronted with long-tailed\ndistributions, especially in detection tasks. This is largely due to extreme\ndata imbalance and the issue of simplicity bias. In this paper, we introduce a\nnovel pre-training framework for object detection, called Dynamic Rebalancing\nContrastive Learning with Dual Reconstruction (2DRCL). Our method builds on a\nHolistic-Local Contrastive Learning mechanism, which aligns pre-training with\nobject detection by capturing both global contextual semantics and detailed\nlocal patterns. To tackle the imbalance inherent in long-tailed data, we design\na dynamic rebalancing strategy that adjusts the sampling of underrepresented\ninstances throughout the pre-training process, ensuring better representation\nof tail classes. Moreover, Dual Reconstruction addresses simplicity bias by\nenforcing a reconstruction task aligned with the self-consistency principle,\nspecifically benefiting underrepresented tail classes. Experiments on COCO and\nLVIS v1.0 datasets demonstrate the effectiveness of our method, particularly in\nimproving the mAP/AP scores for tail classes.\n","authors":["Chen-Long Duan","Yong Li","Xiu-Shen Wei","Lin Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.09453v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09451v1","updated":"2024-11-14T13:56:02Z","published":"2024-11-14T13:56:02Z","title":"DiffRoad: Realistic and Diverse Road Scenario Generation for Autonomous\n  Vehicle Testing","summary":"  Generating realistic and diverse road scenarios is essential for autonomous\nvehicle testing and validation. Nevertheless, owing to the complexity and\nvariability of real-world road environments, creating authentic and varied\nscenarios for intelligent driving testing is challenging. In this paper, we\npropose DiffRoad, a novel diffusion model designed to produce controllable and\nhigh-fidelity 3D road scenarios. DiffRoad leverages the generative capabilities\nof diffusion models to synthesize road layouts from white noise through an\ninverse denoising process, preserving real-world spatial features. To enhance\nthe quality of generated scenarios, we design the Road-UNet architecture,\noptimizing the balance between backbone and skip connections for high-realism\nscenario generation. Furthermore, we introduce a road scenario evaluation\nmodule that screens adequate and reasonable scenarios for intelligent driving\ntesting using two critical metrics: road continuity and road reasonableness.\nExperimental results on multiple real-world datasets demonstrate DiffRoad's\nability to generate realistic and smooth road structures while maintaining the\noriginal distribution. Additionally, the generated scenarios can be fully\nautomated into the OpenDRIVE format, facilitating generalized autonomous\nvehicle simulation testing. DiffRoad provides a rich and diverse scenario\nlibrary for large-scale autonomous vehicle testing and offers valuable insights\nfor future infrastructure designs that are better suited for autonomous\nvehicles.\n","authors":["Junjie Zhou","Lin Wang","Qiang Meng","Xiaofan Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09451v1.pdf","comment":"14 pages, 9 figures"},{"id":"http://arxiv.org/abs/2312.11166v4","updated":"2024-11-14T13:54:32Z","published":"2023-12-18T13:09:55Z","title":"Volume-Preserving Transformers for Learning Time Series Data with\n  Structure","summary":"  Two of the many trends in neural network research of the past few years have\nbeen (i) the learning of dynamical systems, especially with recurrent neural\nnetworks such as long short-term memory networks (LSTMs) and (ii) the\nintroduction of transformer neural networks for natural language processing\n(NLP) tasks.\n  While some work has been performed on the intersection of these two trends,\nthose efforts were largely limited to using the vanilla transformer directly\nwithout adjusting its architecture for the setting of a physical system.\n  In this work we develop a transformer-inspired neural network and use it to\nlearn a dynamical system. We (for the first time) change the activation\nfunction of the attention layer to imbue the transformer with\nstructure-preserving properties to improve long-term stability. This is shown\nto be of great advantage when applying the neural network to learning the\ntrajectory of a rigid body.\n","authors":["Benedikt Brantner","Guillaume de Romemont","Michael Kraus","Zeyuan Li"],"pdf_url":"https://arxiv.org/pdf/2312.11166v4.pdf","comment":"Will be published as part of \"Cemracs Proceedings 2023\" (status:\n  accepted)"},{"id":"http://arxiv.org/abs/2411.09444v1","updated":"2024-11-14T13:45:22Z","published":"2024-11-14T13:45:22Z","title":"Learning efficient and provably convergent splitting methods","summary":"  Splitting methods are widely used for solving initial value problems (IVPs)\ndue to their ability to simplify complicated evolutions into more manageable\nsubproblems which can be solved efficiently and accurately. Traditionally,\nthese methods are derived using analytic and algebraic techniques from\nnumerical analysis, including truncated Taylor series and their Lie algebraic\nanalogue, the Baker--Campbell--Hausdorff formula. These tools enable the\ndevelopment of high-order numerical methods that provide exceptional accuracy\nfor small timesteps. Moreover, these methods often (nearly) conserve important\nphysical invariants, such as mass, unitarity, and energy. However, in many\npractical applications the computational resources are limited. Thus, it is\ncrucial to identify methods that achieve the best accuracy within a fixed\ncomputational budget, which might require taking relatively large timesteps. In\nthis regime, high-order methods derived with traditional methods often exhibit\nlarge errors since they are only designed to be asymptotically optimal. Machine\nLearning techniques offer a potential solution since they can be trained to\nefficiently solve a given IVP with less computational resources. However, they\nare often purely data-driven, come with limited convergence guarantees in the\nsmall-timestep regime and do not necessarily conserve physical invariants. In\nthis work, we propose a framework for finding machine learned splitting methods\nthat are computationally efficient for large timesteps and have provable\nconvergence and conservation guarantees in the small-timestep limit. We\ndemonstrate numerically that the learned methods, which by construction\nconverge quadratically in the timestep size, can be significantly more\nefficient than established methods for the Schr\\\"{o}dinger equation if the\ncomputational budget is limited.\n","authors":["L. M. Kreusser","H. E. Lockyer","E. H. Müller","P. Singh"],"pdf_url":"https://arxiv.org/pdf/2411.09444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06651v2","updated":"2024-11-14T13:26:35Z","published":"2024-11-11T01:36:48Z","title":"Machine learning-enabled velocity model building with uncertainty\n  quantification","summary":"  Accurately characterizing migration velocity models is crucial for a wide\nrange of geophysical applications, from hydrocarbon exploration to monitoring\nof CO2 sequestration projects. Traditional velocity model building methods such\nas Full-Waveform Inversion (FWI) are powerful but often struggle with the\ninherent complexities of the inverse problem, including noise, limited\nbandwidth, receiver aperture and computational constraints. To address these\nchallenges, we propose a scalable methodology that integrates generative\nmodeling, in the form of Diffusion networks, with physics-informed summary\nstatistics, making it suitable for complicated imaging problems including field\ndatasets. By defining these summary statistics in terms of subsurface-offset\nimage volumes for poor initial velocity models, our approach allows for\ncomputationally efficient generation of Bayesian posterior samples for\nmigration velocity models that offer a useful assessment of uncertainty. To\nvalidate our approach, we introduce a battery of tests that measure the quality\nof the inferred velocity models, as well as the quality of the inferred\nuncertainties. With modern synthetic datasets, we reconfirm gains from using\nsubsurface-image gathers as the conditioning observable. For complex velocity\nmodel building involving salt, we propose a new iterative workflow that refines\namortized posterior approximations with salt flooding and demonstrate how the\nuncertainty in the velocity model can be propagated to the final product\nreverse time migrated images. Finally, we present a proof of concept on field\ndatasets to show that our method can scale to industry-sized problems.\n","authors":["Rafael Orozco","Huseyin Tuna Erdinc","Yunlin Zeng","Mathias Louboutin","Felix J. Herrmann"],"pdf_url":"https://arxiv.org/pdf/2411.06651v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09420v1","updated":"2024-11-14T13:15:27Z","published":"2024-11-14T13:15:27Z","title":"SAG-ViT: A Scale-Aware, High-Fidelity Patching Approach with Graph\n  Attention for Vision Transformers","summary":"  Image classification is a computer vision task where a model analyzes an\nimage to categorize it into a specific label. Vision Transformers (ViT) improve\nthis task by leveraging self-attention to capture complex patterns and long\nrange relationships between image patches. However, a key challenge for ViTs is\nefficiently incorporating multiscale feature representations, which is inherent\nin CNNs through their hierarchical structure. In this paper, we introduce the\nScale-Aware Graph Attention Vision Transformer (SAG-ViT), a novel framework\nthat addresses this challenge by integrating multi-scale features. Using\nEfficientNet as a backbone, the model extracts multi-scale feature maps, which\nare divided into patches to preserve semantic information. These patches are\norganized into a graph based on spatial and feature similarities, with a Graph\nAttention Network (GAT) refining the node embeddings. Finally, a Transformer\nencoder captures long-range dependencies and complex interactions. The SAG-ViT\nis evaluated on benchmark datasets, demonstrating its effectiveness in\nenhancing image classification performance.\n","authors":["Shravan Venkatraman","Jaskaran Singh Walia","Joe Dhanith P R"],"pdf_url":"https://arxiv.org/pdf/2411.09420v1.pdf","comment":"10 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.07974v3","updated":"2024-11-14T12:51:52Z","published":"2024-10-10T14:32:16Z","title":"Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition\n  Path Sampling","summary":"  Rare event sampling in dynamical systems is a fundamental problem arising in\nthe natural sciences, which poses significant computational challenges due to\nan exponentially large space of trajectories. For settings where the dynamical\nsystem of interest follows a Brownian motion with known drift, the question of\nconditioning the process to reach a given endpoint or desired rare event is\ndefinitively answered by Doob's h-transform. However, the naive estimation of\nthis transform is infeasible, as it requires simulating sufficiently many\nforward trajectories to estimate rare event probabilities. In this work, we\npropose a variational formulation of Doob's h-transform as an optimization\nproblem over trajectories between a given initial point and the desired ending\npoint. To solve this optimization, we propose a simulation-free training\nobjective with a model parameterization that imposes the desired boundary\nconditions by design. Our approach significantly reduces the search space over\ntrajectories and avoids expensive trajectory simulation and inefficient\nimportance sampling estimators which are required in existing methods. We\ndemonstrate the ability of our method to find feasible transition paths on\nreal-world molecular simulation and protein folding tasks.\n","authors":["Yuanqi Du","Michael Plainer","Rob Brekelmans","Chenru Duan","Frank Noé","Carla P. Gomes","Alán Aspuru-Guzik","Kirill Neklyudov"],"pdf_url":"https://arxiv.org/pdf/2410.07974v3.pdf","comment":"Accepted as Spotlight at Conference on Neural Information Processing\n  Systems (NeurIPS 2024); Alanine dipeptide results updated after fixing\n  unphysical parameterization"},{"id":"http://arxiv.org/abs/2411.05757v2","updated":"2024-11-14T12:12:15Z","published":"2024-11-08T18:18:18Z","title":"Tract-RLFormer: A Tract-Specific RL policy based Decoder-only\n  Transformer Network","summary":"  Fiber tractography is a cornerstone of neuroimaging, enabling the detailed\nmapping of the brain's white matter pathways through diffusion MRI. This is\ncrucial for understanding brain connectivity and function, making it a valuable\ntool in neurological applications. Despite its importance, tractography faces\nchallenges due to its complexity and susceptibility to false positives,\nmisrepresenting vital pathways. To address these issues, recent strategies have\nshifted towards deep learning, utilizing supervised learning, which depends on\nprecise ground truth, or reinforcement learning, which operates without it. In\nthis work, we propose Tract-RLFormer, a network utilizing both supervised and\nreinforcement learning, in a two-stage policy refinement process that markedly\nimproves the accuracy and generalizability across various data-sets. By\nemploying a tract-specific approach, our network directly delineates the tracts\nof interest, bypassing the traditional segmentation process. Through rigorous\nvalidation on datasets such as TractoInferno, HCP, and ISMRM-2015, our\nmethodology demonstrates a leap forward in tractography, showcasing its ability\nto accurately map the brain's white matter tracts.\n","authors":["Ankita Joshi","Ashutosh Sharma","Anoushkrit Goel","Ranjeet Ranjan Jha","Chirag Ahuja","Arnav Bhavsar","Aditya Nigam"],"pdf_url":"https://arxiv.org/pdf/2411.05757v2.pdf","comment":"Accepted at 27th International Conference on Pattern Recognition\n  (ICPR), 2024"},{"id":"http://arxiv.org/abs/2411.09393v1","updated":"2024-11-14T12:11:08Z","published":"2024-11-14T12:11:08Z","title":"Inherently Interpretable and Uncertainty-Aware Models for Online\n  Learning in Cyber-Security Problems","summary":"  In this paper, we address the critical need for interpretable and\nuncertainty-aware machine learning models in the context of online learning for\nhigh-risk industries, particularly cyber-security. While deep learning and\nother complex models have demonstrated impressive predictive capabilities,\ntheir opacity and lack of uncertainty quantification present significant\nquestions about their trustworthiness. We propose a novel pipeline for online\nsupervised learning problems in cyber-security, that harnesses the inherent\ninterpretability and uncertainty awareness of Additive Gaussian Processes\n(AGPs) models. Our approach aims to balance predictive performance with\ntransparency while improving the scalability of AGPs, which represents their\nmain drawback, potentially enabling security analysts to better validate threat\ndetection, troubleshoot and reduce false positives, and generally make\ntrustworthy, informed decisions. This work contributes to the growing field of\ninterpretable AI by proposing a class of models that can be significantly\nbeneficial for high-stake decision problems such as the ones typical of the\ncyber-security domain. The source code is available.\n","authors":["Benjamin Kolicic","Alberto Caron","Chris Hicks","Vasilios Mavroudis"],"pdf_url":"https://arxiv.org/pdf/2411.09393v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09389v1","updated":"2024-11-14T12:05:35Z","published":"2024-11-14T12:05:35Z","title":"Less is More: Unseen Domain Fake News Detection via Causal Propagation\n  Substructures","summary":"  The spread of fake news on social media poses significant threats to\nindividuals and society. Text-based and graph-based models have been employed\nfor fake news detection by analysing news content and propagation networks,\nshowing promising results in specific scenarios. However, these data-driven\nmodels heavily rely on pre-existing in-distribution data for training, limiting\ntheir performance when confronted with fake news from emerging or previously\nunseen domains, known as out-of-distribution (OOD) data. Tackling OOD fake news\nis a challenging yet critical task. In this paper, we introduce the Causal\nSubgraph-oriented Domain Adaptive Fake News Detection (CSDA) model, designed to\nenhance zero-shot fake news detection by extracting causal substructures from\npropagation graphs using in-distribution data and generalising this approach to\nOOD data. The model employs a graph neural network based mask generation\nprocess to identify dominant nodes and edges within the propagation graph,\nusing these substructures for fake news detection. Additionally, the\nperformance of CSDA is further improved through contrastive learning in\nfew-shot scenarios, where a limited amount of OOD data is available for\ntraining. Extensive experiments on public social media datasets demonstrate\nthat CSDA effectively handles OOD fake news detection, achieving a 7 to 16\npercents accuracy improvement over other state-of-the-art models.\n","authors":["Shuzhi Gong","Richard O. Sinnott","Jianzhong Qi","Cecile Paris"],"pdf_url":"https://arxiv.org/pdf/2411.09389v1.pdf","comment":"9 pages, 2 figures, 5 tables"},{"id":"http://arxiv.org/abs/2411.09388v1","updated":"2024-11-14T12:05:08Z","published":"2024-11-14T12:05:08Z","title":"A survey of probabilistic generative frameworks for molecular\n  simulations","summary":"  Generative artificial intelligence is now a widely used tool in molecular\nscience. Despite the popularity of probabilistic generative models, numerical\nexperiments benchmarking their performance on molecular data are lacking. In\nthis work, we introduce and explain several classes of generative models,\nbroadly sorted into two categories: flow-based models and diffusion models. We\nselect three representative models: Neural Spline Flows, Conditional Flow\nMatching, and Denoising Diffusion Probabilistic Models, and examine their\naccuracy, computational cost, and generation speed across datasets with tunable\ndimensionality, complexity, and modal asymmetry. Our findings are varied, with\nno one framework being the best for all purposes. In a nutshell, (i) Neural\nSpline Flows do best at capturing mode asymmetry present in low-dimensional\ndata, (ii) Conditional Flow Matching outperforms other models for\nhigh-dimensional data with low complexity, and (iii) Denoising Diffusion\nProbabilistic Models appears the best for low-dimensional data with high\ncomplexity. Our datasets include a Gaussian mixture model and the dihedral\ntorsion angle distribution of the Aib\\textsubscript{9} peptide, generated via a\nmolecular dynamics simulation. We hope our taxonomy of probabilistic generative\nframeworks and numerical results may guide model selection for a wide range of\nmolecular tasks.\n","authors":["Richard John","Lukas Herron","Pratyush Tiwary"],"pdf_url":"https://arxiv.org/pdf/2411.09388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.07506v2","updated":"2024-11-14T12:02:01Z","published":"2024-01-15T07:13:43Z","title":"SeMaScore : a new evaluation metric for automatic speech recognition\n  tasks","summary":"  In this study, we present SeMaScore, generated using a segment-wise mapping\nand scoring algorithm that serves as an evaluation metric for automatic speech\nrecognition tasks. SeMaScore leverages both the error rate and a more robust\nsimilarity score. We show that our algorithm's score generation improves upon\nthe state-of-the-art BERTScore. Our experimental results show that SeMaScore\ncorresponds well with expert human assessments, signal-to-noise ratio levels,\nand other natural language metrics. We outperform BERTScore by 41x in metric\ncomputation speed. Overall, we demonstrate that SeMaScore serves as a more\ndependable evaluation metric, particularly in real-world situations involving\natypical speech patterns.\n","authors":["Zitha Sasindran","Harsha Yelchuri","T. V. Prabhakar"],"pdf_url":"https://arxiv.org/pdf/2401.07506v2.pdf","comment":"Accepted at Interspeech 2024"},{"id":"http://arxiv.org/abs/2404.07940v3","updated":"2024-11-14T11:51:00Z","published":"2024-03-11T02:06:30Z","title":"InfiBench: Evaluating the Question-Answering Capabilities of Code Large\n  Language Models","summary":"  Large Language Models for code (code LLMs) have witnessed tremendous progress\nin recent years. With the rapid development of code LLMs, many popular\nevaluation benchmarks, such as HumanEval, DS-1000, and MBPP, have emerged to\nmeasure the performance of code LLMs with a particular focus on code generation\ntasks. However, they are insufficient to cover the full range of expected\ncapabilities of code LLMs, which span beyond code generation to answering\ndiverse coding-related questions. To fill this gap, we propose InfiBench, the\nfirst large-scale freeform question-answering (QA) benchmark for code to our\nknowledge, comprising 234 carefully selected high-quality Stack Overflow\nquestions that span across 15 programming languages. InfiBench uses four types\nof model-free automatic metrics to evaluate response correctness where domain\nexperts carefully concretize the criterion for each question. We conduct a\nsystematic evaluation for over 100 latest code LLMs on InfiBench, leading to a\nseries of novel and insightful findings. Our detailed analyses showcase\npotential directions for further advancement of code LLMs. InfiBench is fully\nopen source at https://infi-coder.github.io/infibench and continuously\nexpanding to foster more scientific and systematic practices for code LLM\nevaluation.\n","authors":["Linyi Li","Shijie Geng","Zhenwen Li","Yibo He","Hao Yu","Ziyue Hua","Guanghan Ning","Siwei Wang","Tao Xie","Hongxia Yang"],"pdf_url":"https://arxiv.org/pdf/2404.07940v3.pdf","comment":"31 pages. Appear at NeurIPS 2024 Datasets and Benchmarks track.\n  Project website: https://infi-coder.github.io/infibench"},{"id":"http://arxiv.org/abs/2411.09373v1","updated":"2024-11-14T11:27:15Z","published":"2024-11-14T11:27:15Z","title":"Are nuclear masks all you need for improved out-of-domain\n  generalisation? A closer look at cancer classification in histopathology","summary":"  Domain generalisation in computational histopathology is challenging because\nthe images are substantially affected by differences among hospitals due to\nfactors like fixation and staining of tissue and imaging equipment. We\nhypothesise that focusing on nuclei can improve the out-of-domain (OOD)\ngeneralisation in cancer detection. We propose a simple approach to improve OOD\ngeneralisation for cancer detection by focusing on nuclear morphology and\norganisation, as these are domain-invariant features critical in cancer\ndetection. Our approach integrates original images with nuclear segmentation\nmasks during training, encouraging the model to prioritise nuclei and their\nspatial arrangement. Going beyond mere data augmentation, we introduce a\nregularisation technique that aligns the representations of masks and original\nimages. We show, using multiple datasets, that our method improves OOD\ngeneralisation and also leads to increased robustness to image corruptions and\nadversarial attacks. The source code is available at\nhttps://github.com/undercutspiky/SFL/\n","authors":["Dhananjay Tomar","Alexander Binder","Andreas Kleppe"],"pdf_url":"https://arxiv.org/pdf/2411.09373v1.pdf","comment":"Poster at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09365v1","updated":"2024-11-14T11:16:32Z","published":"2024-11-14T11:16:32Z","title":"Stability and Generalization for Distributed SGDA","summary":"  Minimax optimization is gaining increasing attention in modern machine\nlearning applications. Driven by large-scale models and massive volumes of data\ncollected from edge devices, as well as the concern to preserve client privacy,\ncommunication-efficient distributed minimax optimization algorithms become\npopular, such as Local Stochastic Gradient Descent Ascent (Local-SGDA), and\nLocal Decentralized SGDA (Local-DSGDA). While most existing research on\ndistributed minimax algorithms focuses on convergence rates, computation\ncomplexity, and communication efficiency, the generalization performance\nremains underdeveloped, whereas generalization ability is a pivotal indicator\nfor evaluating the holistic performance of a model when fed with unknown data.\nIn this paper, we propose the stability-based generalization analytical\nframework for Distributed-SGDA, which unifies two popular distributed minimax\nalgorithms including Local-SGDA and Local-DSGDA, and conduct a comprehensive\nanalysis of stability error, generalization gap, and population risk across\ndifferent metrics under various settings, e.g., (S)C-(S)C, PL-SC, and NC-NC\ncases. Our theoretical results reveal the trade-off between the generalization\ngap and optimization error and suggest hyperparameters choice to obtain the\noptimal population risk. Numerical experiments for Local-SGDA and Local-DSGDA\nvalidate the theoretical results.\n","authors":["Miaoxi Zhu","Yan Sun","Li Shen","Bo Du","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2411.09365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09361v1","updated":"2024-11-14T11:08:54Z","published":"2024-11-14T11:08:54Z","title":"Time-to-Event Pretraining for 3D Medical Imaging","summary":"  With the rise of medical foundation models and the growing availability of\nimaging data, scalable pretraining techniques offer a promising way to identify\nimaging biomarkers predictive of future disease risk. While current\nself-supervised methods for 3D medical imaging models capture local structural\nfeatures like organ morphology, they fail to link pixel biomarkers with\nlong-term health outcomes due to a missing context problem. Current approaches\nlack the temporal context necessary to identify biomarkers correlated with\ndisease progression, as they rely on supervision derived only from images and\nconcurrent text descriptions. To address this, we introduce time-to-event\npretraining, a pretraining framework for 3D medical imaging models that\nleverages large-scale temporal supervision from paired, longitudinal electronic\nhealth records (EHRs). Using a dataset of 18,945 CT scans (4.2 million 2D\nimages) and time-to-event distributions across thousands of EHR-derived tasks,\nour method improves outcome prediction, achieving an average AUROC increase of\n23.7% and a 29.4% gain in Harrell's C-index across 8 benchmark tasks.\nImportantly, these gains are achieved without sacrificing diagnostic\nclassification performance. This study lays the foundation for integrating\nlongitudinal EHR and 3D imaging data to advance clinical risk prediction.\n","authors":["Zepeng Huo","Jason Alan Fries","Alejandro Lozano","Jeya Maria Jose Valanarasu","Ethan Steinberg","Louis Blankemeier","Akshay S. Chaudhari","Curtis Langlotz","Nigam H. Shah"],"pdf_url":"https://arxiv.org/pdf/2411.09361v1.pdf","comment":"34 pages, 19 figures"},{"id":"http://arxiv.org/abs/2410.21858v3","updated":"2024-11-14T10:54:53Z","published":"2024-10-29T08:42:22Z","title":"Joint Estimation of Conditional Mean and Covariance for Unbalanced\n  Panels","summary":"  We propose a nonparametric, kernel-based joint estimator for conditional mean\nand covariance matrices in large unbalanced panels. Our estimator, with proven\nconsistency and finite-sample guarantees, is applied to a comprehensive panel\nof monthly US stock excess returns from 1962 to 2021, conditioned on\nmacroeconomic and firm-specific covariates. The estimator captures time-varying\ncross-sectional dependencies effectively, demonstrating robust statistical\nperformance. In asset pricing, it generates conditional mean-variance efficient\nportfolios with out-of-sample Sharpe ratios that substantially exceed those of\nequal-weighted benchmarks.\n","authors":["Damir Filipovic","Paul Schneider"],"pdf_url":"https://arxiv.org/pdf/2410.21858v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09341v1","updated":"2024-11-14T10:37:34Z","published":"2024-11-14T10:37:34Z","title":"Approximated Variational Bayesian Inverse Reinforcement Learning for\n  Large Language Model Alignment","summary":"  The alignment of large language models (LLMs) is crucial for generating\nhelpful and harmless content. Existing approaches leverage preference-based\nhuman feedback data to learn the reward function and align the LLM with the\nfeedback data. However, these approaches focus on modeling the reward\ndifference between the chosen and rejected demonstrations, rather than directly\nmodeling the true reward from each demonstration. Moreover, these approaches\nassume that the reward is only obtained at the end of the sentence, which\noverlooks the modeling of intermediate rewards. These issues lead to\ninsufficient use of training signals in the feedback data, limiting the\nrepresentation and generalization ability of the reward and potentially\nresulting in reward hacking. In this paper, we formulate LLM alignment as a\nBayesian Inverse Reinforcement Learning (BIRL) problem and propose a novel\ntraining objective, Approximated Variational Alignment (AVA), to perform LLM\nalignment through Approximated Variational Reward Imitation Learning (AVRIL).\nThe BIRL formulation facilitates intermediate reward modeling and direct reward\nmodeling on each single demonstration, which enhances the utilization of\ntraining signals in the feedback data. Experiments show that AVA outperforms\nexisting LLM alignment approaches in reward modeling, RL fine-tuning, and\ndirect optimization.\n","authors":["Yuang Cai","Yuyu Yuan","Jinsheng Shi","Qinhong Lin"],"pdf_url":"https://arxiv.org/pdf/2411.09341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02930v2","updated":"2024-11-14T10:24:06Z","published":"2024-02-05T11:52:23Z","title":"Embedding Hardware Approximations in Discrete Genetic-based Training for\n  Printed MLPs","summary":"  Printed Electronics (PE) stands out as a promisingtechnology for widespread\ncomputing due to its distinct attributes, such as low costs and flexible\nmanufacturing. Unlike traditional silicon-based technologies, PE enables\nstretchable, conformal,and non-toxic hardware. However, PE are constrained by\nlarger feature sizes, making it challenging to implement complex circuits such\nas machine learning (ML) classifiers. Approximate computing has been proven to\nreduce the hardware cost of ML circuits such as Multilayer Perceptrons (MLPs).\nIn this paper, we maximize the benefits of approximate computing by integrating\nhardware approximation into the MLP training process. Due to the discrete\nnature of hardware approximation, we propose and implement a genetic-based,\napproximate, hardware-aware training approach specifically designed for printed\nMLPs. For a 5% accuracy loss, our MLPs achieve over 5x area and power reduction\ncompared to the baseline while outperforming state of-the-art approximate and\nstochastic printed MLPs.\n","authors":["Florentia Afentaki","Michael Hefenbrock","Georgios Zervakis","Mehdi B. Tahoori"],"pdf_url":"https://arxiv.org/pdf/2402.02930v2.pdf","comment":"Accepted for publication at the 27th Design, Automation and Test in\n  Europe Conference (DATE'24), Mar 25-27 2024, Valencia, Spain"},{"id":"http://arxiv.org/abs/2312.17612v3","updated":"2024-11-14T10:22:05Z","published":"2023-12-29T14:16:11Z","title":"Bespoke Approximation of Multiplication-Accumulation and Activation\n  Targeting Printed Multilayer Perceptrons","summary":"  Printed Electronics (PE) feature distinct and remarkable characteristics that\nmake them a prominent technology for achieving true ubiquitous computing. This\nis particularly relevant in application domains that require conformal and\nultra-low cost solutions, which have experienced limited penetration of\ncomputing until now. Unlike silicon-based technologies, PE offer unparalleled\nfeatures such as non-recurring engineering costs, ultra-low manufacturing cost,\nand on-demand fabrication of conformal, flexible, non-toxic, and stretchable\nhardware. However, PE face certain limitations due to their large feature\nsizes, that impede the realization of complex circuits, such as machine\nlearning classifiers. In this work, we address these limitations by leveraging\nthe principles of Approximate Computing and Bespoke (fully-customized) design.\nWe propose an automated framework for designing ultra-low power Multilayer\nPerceptron (MLP) classifiers which employs, for the first time, a holistic\napproach to approximate all functions of the MLP's neurons: multiplication,\naccumulation, and activation. Through comprehensive evaluation across various\nMLPs of varying size, our framework demonstrates the ability to enable\nbattery-powered operation of even the most intricate MLP architecture examined,\nsignificantly surpassing the current state of the art.\n","authors":["Florentia Afentaki","Gurol Saglam","Argyris Kokkinis","Kostas Siozios","Georgios Zervakis","Mehdi B Tahoori"],"pdf_url":"https://arxiv.org/pdf/2312.17612v3.pdf","comment":"Accepted for publication at the 42th IEEE/ACM International\n  Conference on Computer Aided Design (ICCAD) 2023, San Francisco, USA"},{"id":"http://arxiv.org/abs/2411.09329v1","updated":"2024-11-14T10:21:41Z","published":"2024-11-14T10:21:41Z","title":"Improving hp-Variational Physics-Informed Neural Networks for\n  Steady-State Convection-Dominated Problems","summary":"  This paper proposes and studies two extensions of applying hp-variational\nphysics-informed neural networks, more precisely the FastVPINNs framework, to\nconvection-dominated convection-diffusion-reaction problems. First, a term in\nthe spirit of a SUPG stabilization is included in the loss functional and a\nnetwork architecture is proposed that predicts spatially varying stabilization\nparameters. Having observed that the selection of the indicator function in\nhard-constrained Dirichlet boundary conditions has a big impact on the accuracy\nof the computed solutions, the second novelty is the proposal of a network\narchitecture that learns good parameters for a class of indicator functions.\nNumerical studies show that both proposals lead to noticeably more accurate\nresults than approaches that can be found in the literature.\n","authors":["Thivin Anandh","Divij Ghose","Himanshu Jain","Pratham Sunkad","Sashikumaar Ganesan","Volker John"],"pdf_url":"https://arxiv.org/pdf/2411.09329v1.pdf","comment":"25 pages, 11 figures, 8 tables"},{"id":"http://arxiv.org/abs/2309.17196v4","updated":"2024-11-14T10:16:35Z","published":"2023-09-29T12:45:39Z","title":"ResBit: Residual Bit Vector for Categorical Values","summary":"  One-hot vectors, a common method for representing discrete/categorical data,\nin machine learning are widely used because of their simplicity and\nintuitiveness. However, one-hot vectors suffer from a linear increase in\ndimensionality, posing computational and memory challenges, especially when\ndealing with datasets containing numerous categories. In this paper, we focus\non tabular data generation, and reveal the multinomial diffusion faces the mode\ncollapse phenomenon when the cardinality is high. Moreover, due to the\nlimitations of one-hot vectors, the training phase takes time longer in such a\nsituation. To address these issues, we propose Residual Bit Vectors (ResBit), a\ntechnique for densely representing categorical data. ResBit is an extension of\nanalog bits and overcomes limitations of analog bits when applied to tabular\ndata generation. Our experiments demonstrate that ResBit not only accelerates\ntraining but also maintains performance when compared with the situations\nbefore applying ResBit. Furthermore, our results indicate that many existing\nmethods struggle with high-cardinality data, underscoring the need for\nlower-dimensional representations, such as ResBit and latent vectors.\n","authors":["Masane Fuchi","Amar Zanashir","Hiroto Minami","Tomohiro Takagi"],"pdf_url":"https://arxiv.org/pdf/2309.17196v4.pdf","comment":"25 pages, 29 tables, and 10 figures"},{"id":"http://arxiv.org/abs/2407.02279v2","updated":"2024-11-14T10:15:35Z","published":"2024-07-02T14:08:23Z","title":"How to Boost Any Loss Function","summary":"  Boosting is a highly successful ML-born optimization setting in which one is\nrequired to computationally efficiently learn arbitrarily good models based on\nthe access to a weak learner oracle, providing classifiers performing at least\nslightly differently from random guessing. A key difference with gradient-based\noptimization is that boosting's original model does not requires access to\nfirst order information about a loss, yet the decades long history of boosting\nhas quickly evolved it into a first order optimization setting -- sometimes\neven wrongfully defining it as such. Owing to recent progress extending\ngradient-based optimization to use only a loss' zeroth ($0^{th}$) order\ninformation to learn, this begs the question: what loss functions can be\nefficiently optimized with boosting and what is the information really needed\nfor boosting to meet the original boosting blueprint's requirements?\n  We provide a constructive formal answer essentially showing that any loss\nfunction can be optimized with boosting and thus boosting can achieve a feat\nnot yet known to be possible in the classical $0^{th}$ order setting, since\nloss functions are not required to be be convex, nor differentiable or\nLipschitz -- and in fact not required to be continuous either. Some tools we\nuse are rooted in quantum calculus, the mathematical field -- not to be\nconfounded with quantum computation -- that studies calculus without passing to\nthe limit, and thus without using first order information.\n","authors":["Richard Nock","Yishay Mansour"],"pdf_url":"https://arxiv.org/pdf/2407.02279v2.pdf","comment":"NeurIPS'24"},{"id":"http://arxiv.org/abs/2411.09317v1","updated":"2024-11-14T09:50:41Z","published":"2024-11-14T09:50:41Z","title":"Pie: Pooling CPU Memory for LLM Inference","summary":"  The rapid growth of LLMs has revolutionized natural language processing and\nAI analysis, but their increasing size and memory demands present significant\nchallenges. A common solution is to spill over to CPU memory; however,\ntraditional GPU-CPU memory swapping often results in higher latency and lower\nthroughput.\n  This paper introduces Pie, an LLM inference framework that addresses these\nchallenges with performance-transparent swapping and adaptive expansion. By\nleveraging predictable memory access patterns and the high bandwidth of modern\nhardware like the NVIDIA GH200 Grace Hopper Superchip, Pie enables concurrent\ndata swapping without affecting foreground computation, expanding effective\nmemory without added latency. Adaptive expansion dynamically adjusts CPU memory\nallocation based on real-time information, optimizing memory usage and\nperformance under varying conditions.\n  Pie maintains low computation latency, high throughput, and high elasticity.\nOur experimental evaluation demonstrates that Pie achieves optimal swapping\npolicy during cache warmup and effectively balances increased memory capacity\nwith negligible impact on computation. With its extended capacity, Pie\noutperforms vLLM by up to 1.9X in throughput and 2X in latency. Additionally,\nPie can reduce GPU memory usage by up to 1.67X while maintaining the same\nperformance. Compared to FlexGen, an offline profiling-based swapping solution,\nPie achieves magnitudes lower latency and 9.4X higher throughput.\n","authors":["Yi Xu","Ziming Mao","Xiangxi Mo","Shu Liu","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2411.09317v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09312v1","updated":"2024-11-14T09:38:58Z","published":"2024-11-14T09:38:58Z","title":"Approximate Probabilistic Inference forTime-Series Data A Robust Latent\n  Gaussian Model With Temporal Awareness","summary":"  The development of robust generative models for highly varied non-stationary\ntime series data is a complex yet important problem. Traditional models for\ntime series data prediction, such as Long Short-Term Memory (LSTM), are\ninefficient and generalize poorly as they cannot capture complex temporal\nrelationships. In this paper, we present a probabilistic generative model that\ncan be trained to capture temporal information, and that is robust to data\nerrors. We call it Time Deep Latent Gaussian Model (tDLGM). Its novel\narchitecture is inspired by Deep Latent Gaussian Model (DLGM). Our model is\ntrained to minimize a loss function based on the negative log loss. One\ncontributing factor to Time Deep Latent Gaussian Model (tDLGM) robustness is\nour regularizer, which accounts for data trends. Experiments conducted show\nthat tDLGM is able to reconstruct and generate complex time series data, and\nthat it is robust against to noise and faulty data.\n","authors":["Anton Johansson","Arunselvan Ramaswamy"],"pdf_url":"https://arxiv.org/pdf/2411.09312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09311v1","updated":"2024-11-14T09:38:41Z","published":"2024-11-14T09:38:41Z","title":"Compression Method for Solar Polarization Spectra Collected from Hinode\n  SOT/SP Observations","summary":"  The complex structure and extensive details of solar spectral data, combined\nwith a recent surge in volume, present significant processing challenges. To\naddress this, we propose a deep learning-based compression technique using deep\nautoencoder (DAE) and 1D-convolutional autoencoder (CAE) models developed with\nHinode SOT/SP data. We focused on compressing Stokes I and V polarization\nspectra from the quiet Sun, as well as from active regions, providing a novel\ninsight into comprehensive spectral analysis by incorporating spectra from\nextreme magnetic fields. The results indicate that the CAE model outperforms\nthe DAE model in reconstructing Stokes profiles, demonstrating greater\nrobustness and achieving reconstruction errors around the observational noise\nlevel. The proposed method has proven effective in compressing Stokes I and V\nspectra from both the quiet Sun and active regions, highlighting its potential\nfor impactful applications in solar spectral analysis, such as detection of\nunusual spectral signals.\n","authors":["Jargalmaa Batmunkh","Yusuke Iida","Takayoshi Oba","Haruhisa Iijima"],"pdf_url":"https://arxiv.org/pdf/2411.09311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.03017v2","updated":"2024-11-14T09:19:43Z","published":"2024-02-05T13:55:54Z","title":"Toward Green and Human-Like Artificial Intelligence: A Complete Survey\n  on Contemporary Few-Shot Learning Approaches","summary":"  Despite deep learning's widespread success, its data-hungry and\ncomputationally expensive nature makes it impractical for many data-constrained\nreal-world applications. Few-Shot Learning (FSL) aims to address these\nlimitations by enabling rapid adaptation to novel learning tasks, seeing\nsignificant growth in recent years. This survey provides a comprehensive\noverview of the field's latest advancements. Initially, FSL is formally\ndefined, and its relationship with different learning fields is presented. A\nnovel taxonomy is introduced, extending previously proposed ones, and\nreal-world applications in classic and novel fields are described. Finally,\nrecent trends shaping the field, outstanding challenges, and promising future\nresearch directions are discussed.\n","authors":["Georgios Tsoumplekas","Vladislav Li","Panagiotis Sarigiannidis","Vasileios Argyriou"],"pdf_url":"https://arxiv.org/pdf/2402.03017v2.pdf","comment":"35 pages, 9 figures. Submitted to ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2410.14979v4","updated":"2024-11-14T09:17:48Z","published":"2024-10-19T05:01:56Z","title":"Do Large Language Models Truly Grasp Mathematics? An Empirical\n  Exploration From Cognitive Psychology","summary":"  The cognitive mechanism by which Large Language Models (LLMs) solve\nmathematical problems remains a widely debated and unresolved issue. Currently,\nthere is little interpretable experimental evidence that connects LLMs'\nproblem-solving with human cognitive psychology.To determine if LLMs possess\nhuman-like mathematical reasoning, we modified the problems used in the human\nCognitive Reflection Test (CRT). Our results show that, even with the use of\nChains of Thought (CoT) prompts, mainstream LLMs, including the latest o1 model\n(noted for its reasoning capabilities), have a high error rate when solving\nthese modified CRT problems. Specifically, the average accuracy rate dropped by\nup to 50% compared to the original questions.Further analysis of LLMs'\nincorrect answers suggests that they primarily rely on pattern matching from\ntheir training data, which aligns more with human intuition (System 1 thinking)\nrather than with human-like reasoning (System 2 thinking). This finding\nchallenges the belief that LLMs have genuine mathematical reasoning abilities\ncomparable to humans. As a result, this work may adjust overly optimistic views\non LLMs' progress towards artificial general intelligence.\n","authors":["Wei Xie","Shuoyoucheng Ma","Zhenhua Wang","Enze Wang","Kai Chen","Xiaobing Sun","Baosheng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14979v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21862v2","updated":"2024-11-14T09:17:31Z","published":"2024-10-29T08:56:29Z","title":"Hierarchical mixtures of Unigram models for short text clustering: the\n  role of Beta-Liouville priors","summary":"  This paper presents a variant of the Multinomial mixture model tailored for\nthe unsupervised classification of short text data. Traditionally, the\nMultinomial probability vector in this hierarchical model is assigned a\nDirichlet prior distribution. Here, however, we explore an alternative\nprior--the Beta-Liouville distribution--which offers a more flexible\ncorrelation structure than the Dirichlet. We examine the theoretical properties\nof the Beta-Liouville distribution, focusing on its conjugacy with the\nMultinomial likelihood. This property enables the derivation of update\nequations for a CAVI (Coordinate Ascent Variational Inference) variational\nalgorithm, facilitating the approximate posterior estimation of model\nparameters. Additionally, we propose a stochastic variant of the CAVI algorithm\nthat enhances scalability. The paper concludes with data examples that\ndemonstrate effective strategies for setting the Beta-Liouville\nhyperparameters.\n","authors":["Massimo Bilancia","Samuele Magro"],"pdf_url":"https://arxiv.org/pdf/2410.21862v2.pdf","comment":"32 pages, 4 figures. Submitted"},{"id":"http://arxiv.org/abs/2411.09296v1","updated":"2024-11-14T09:15:28Z","published":"2024-11-14T09:15:28Z","title":"Enhancing generalization in high energy physics using white-box\n  adversarial attacks","summary":"  Machine learning is becoming increasingly popular in the context of particle\nphysics. Supervised learning, which uses labeled Monte Carlo (MC) simulations,\nremains one of the most widely used methods for discriminating signals beyond\nthe Standard Model. However, this paper suggests that supervised models may\ndepend excessively on artifacts and approximations from Monte Carlo\nsimulations, potentially limiting their ability to generalize well to real\ndata. This study aims to enhance the generalization properties of supervised\nmodels by reducing the sharpness of local minima. It reviews the application of\nfour distinct white-box adversarial attacks in the context of classifying Higgs\nboson decay signals. The attacks are divided into weight space attacks, and\nfeature space attacks. To study and quantify the sharpness of different local\nminima this paper presents two analysis methods: gradient ascent and reduced\nHessian eigenvalue analysis. The results show that white-box adversarial\nattacks significantly improve generalization performance, albeit with increased\ncomputational complexity.\n","authors":["Franck Rothen","Samuel Klein","Matthew Leigh","Tobias Golling"],"pdf_url":"https://arxiv.org/pdf/2411.09296v1.pdf","comment":"10 pages, 4 figures, 8 tables, 3 algorithms, to be published in\n  Physical Review D (PRD), presented at the ML4Jets 2024 conference"},{"id":"http://arxiv.org/abs/2404.08434v2","updated":"2024-11-14T09:11:26Z","published":"2024-04-12T12:31:06Z","title":"An improved tabular data generator with VAE-GMM integration","summary":"  The rising use of machine learning in various fields requires robust methods\nto create synthetic tabular data. Data should preserve key characteristics\nwhile addressing data scarcity challenges. Current approaches based on\nGenerative Adversarial Networks, such as the state-of-the-art CTGAN model,\nstruggle with the complex structures inherent in tabular data. These data often\ncontain both continuous and discrete features with non-Gaussian distributions.\nTherefore, we propose a novel Variational Autoencoder (VAE)-based model that\naddresses these limitations. Inspired by the TVAE model, our approach\nincorporates a Bayesian Gaussian Mixture model (BGM) within the VAE\narchitecture. This avoids the limitations imposed by assuming a strictly\nGaussian latent space, allowing for a more accurate representation of the\nunderlying data distribution during data generation. Furthermore, our model\noffers enhanced flexibility by allowing the use of various differentiable\ndistributions for individual features, making it possible to handle both\ncontinuous and discrete data types. We thoroughly validate our model on three\nreal-world datasets with mixed data types, including two medically relevant\nones, based on their resemblance and utility. This evaluation demonstrates\nsignificant outperformance against CTGAN and TVAE, establishing its potential\nas a valuable tool for generating synthetic tabular data in various domains,\nparticularly in healthcare.\n","authors":["Patricia A. Apellániz","Juan Parras","Santiago Zazo"],"pdf_url":"https://arxiv.org/pdf/2404.08434v2.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.09286v1","updated":"2024-11-14T08:53:23Z","published":"2024-11-14T08:53:23Z","title":"A Centralized-Distributed Transfer Model for Cross-Domain Recommendation\n  Based on Multi-Source Heterogeneous Transfer Learning","summary":"  Cross-domain recommendation (CDR) methods are proposed to tackle the sparsity\nproblem in click through rate (CTR) estimation. Existing CDR methods directly\ntransfer knowledge from the source domains to the target domain and ignore the\nheterogeneities among domains, including feature dimensional heterogeneity and\nlatent space heterogeneity, which may lead to negative transfer. Besides, most\nof the existing methods are based on single-source transfer, which cannot\nsimultaneously utilize knowledge from multiple source domains to further\nimprove the model performance in the target domain. In this paper, we propose a\ncentralized-distributed transfer model (CDTM) for CDR based on multi-source\nheterogeneous transfer learning. To address the issue of feature dimension\nheterogeneity, we build a dual embedding structure: domain specific embedding\n(DSE) and global shared embedding (GSE) to model the feature representation in\nthe single domain and the commonalities in the global space,separately. To\nsolve the latent space heterogeneity, the transfer matrix and attention\nmechanism are used to map and combine DSE and GSE adaptively. Extensive offline\nand online experiments demonstrate the effectiveness of our model.\n","authors":["Ke Xu","Ziliang Wang","Wei Zheng","Yuhao Ma","Chenglin Wang","Nengxue Jiang","Cai Cao"],"pdf_url":"https://arxiv.org/pdf/2411.09286v1.pdf","comment":"Published in: 2022 IEEE International Conference on Data Mining\n  (ICDM) (The authors were affiliated Hangzhou NetEase Cloud Music Technology\n  Co., Ltd.)"},{"id":"http://arxiv.org/abs/2410.02367v2","updated":"2024-11-14T08:39:54Z","published":"2024-10-03T10:25:23Z","title":"SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference\n  Acceleration","summary":"  The transformer architecture predominates across various models. As the heart\nof the transformer, attention has a computational complexity of O(N^2),\ncompared to O(N) for linear transformations. When handling large sequence\nlengths, attention becomes the primary time-consuming component. Although\nquantization has proven to be an effective method for accelerating model\ninference, existing quantization methods primarily focus on optimizing the\nlinear layer. In response, we first analyze the feasibility of quantization in\nattention detailedly. Following that, we propose SageAttention, a highly\nefficient and accurate quantization method for attention. The OPS (operations\nper second) of our approach outperforms FlashAttention2 and xformers by about\n2.1 times and 2.7 times, respectively. SageAttention also achieves superior\naccuracy performance over FlashAttention3. Comprehensive experiments confirm\nthat our approach incurs almost no end-to-end metrics loss across diverse\nmodels, including those for large language processing, image generation, and\nvideo generation. The codes are available at\nhttps://github.com/thu-ml/SageAttention.\n","authors":["Jintao Zhang","Jia wei","Haofeng Huang","Pengle Zhang","Jun Zhu","Jianfei Chen"],"pdf_url":"https://arxiv.org/pdf/2410.02367v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14212v2","updated":"2024-11-14T08:31:10Z","published":"2024-10-18T07:01:56Z","title":"Comparative Evaluation of Clustered Federated Learning Methods","summary":"  Over recent years, Federated Learning (FL) has proven to be one of the most\npromising methods of distributed learning which preserves data privacy. As the\nmethod evolved and was confronted to various real-world scenarios, new\nchallenges have emerged. One such challenge is the presence of highly\nheterogeneous (often referred as non-IID) data distributions among participants\nof the FL protocol. A popular solution to this hurdle is Clustered Federated\nLearning (CFL), which aims to partition clients into groups where the\ndistribution are homogeneous. In the literature, state-of-the-art CFL\nalgorithms are often tested using a few cases of data heterogeneities, without\nsystematically justifying the choices. Further, the taxonomy used for\ndifferentiating the different heterogeneity scenarios is not always\nstraightforward. In this paper, we explore the performance of two\nstate-of-theart CFL algorithms with respect to a proposed taxonomy of data\nheterogeneities in federated learning (FL). We work with three image\nclassification datasets and analyze the resulting clusters against the\nheterogeneity classes using extrinsic clustering metrics. Our objective is to\nprovide a clearer understanding of the relationship between CFL performances\nand data heterogeneity scenarios.\n","authors":["Michael Ben Ali","Omar El-Rifai","Imen Megdiche","André Peninou","Olivier Teste"],"pdf_url":"https://arxiv.org/pdf/2410.14212v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07176v2","updated":"2024-11-14T08:20:22Z","published":"2024-11-11T17:56:28Z","title":"More Expressive Attention with Negative Weights","summary":"  We propose a novel attention mechanism, named Cog Attention, that enables\nattention weights to be negative for enhanced expressiveness, which stems from\ntwo key factors: (1) Cog Attention can shift the token deletion and copying\nfunction from a static OV matrix to dynamic QK inner products, with the OV\nmatrix now focusing more on refinement or modification. The attention head can\nsimultaneously delete, copy, or retain tokens by assigning them negative,\npositive, or minimal attention weights, respectively. As a result, a single\nattention head becomes more flexible and expressive. (2) Cog Attention improves\nthe model's robustness against representational collapse, which can occur when\nearlier tokens are over-squashed into later positions, leading to homogeneous\nrepresentations. Negative weights reduce effective information paths from\nearlier to later tokens, helping to mitigate this issue. We develop\nTransformer-like models which use Cog Attention as attention modules, including\ndecoder-only models for language modeling and U-ViT diffusion models for image\ngeneration. Experiments show that models using Cog Attention exhibit superior\nperformance compared to those employing traditional softmax attention modules.\nOur approach suggests a promising research direction for rethinking and\nbreaking the entrenched constraints of traditional softmax attention, such as\nthe requirement for non-negative weights.\n","authors":["Ang Lv","Ruobing Xie","Shuaipeng Li","Jiayi Liao","Xingwu Sun","Zhanhui Kang","Di Wang","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2411.07176v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09267v1","updated":"2024-11-14T08:08:25Z","published":"2024-11-14T08:08:25Z","title":"Towards efficient compression and communication for prototype-based\n  decentralized learning","summary":"  In prototype-based federated learning, the exchange of model parameters\nbetween clients and the master server is replaced by transmission of prototypes\nor quantized versions of the data samples to the aggregation server. A fully\ndecentralized deployment of prototype- based learning, without a central\nagregartor of prototypes, is more robust upon network failures and reacts\nfaster to changes in the statistical distribution of the data, suggesting\npotential advantages and quick adaptation in dynamic learning tasks, e.g., when\nthe data sources are IoT devices or when data is non-iid. In this paper, we\nconsider the problem of designing a communication-efficient decentralized\nlearning system based on prototypes. We address the challenge of prototype\nredundancy by leveraging on a twofold data compression technique, i.e., sending\nonly update messages if the prototypes are informationtheoretically useful (via\nthe Jensen-Shannon distance), and using clustering on the prototypes to\ncompress the update messages used in the gossip protocol. We also use parallel\ninstead of sequential gossiping, and present an analysis of its\nage-of-information (AoI). Our experimental results show that, with these\nimprovements, the communications load can be substantially reduced without\ndecreasing the convergence rate of the learning algorithm.\n","authors":["Pablo Fernández-Piñeiro","Manuel Ferández-Veiga","Rebeca P. Díaz-Redondo","Ana Fernández-Vilas","Martín González-Soto"],"pdf_url":"https://arxiv.org/pdf/2411.09267v1.pdf","comment":"15 pages, 2 tables, 7 figures, 6 algorithms"},{"id":"http://arxiv.org/abs/2411.09266v1","updated":"2024-11-14T08:07:02Z","published":"2024-11-14T08:07:02Z","title":"How Good is ChatGPT at Audiovisual Deepfake Detection: A Comparative\n  Study of ChatGPT, AI Models and Human Perception","summary":"  Multimodal deepfakes involving audiovisual manipulations are a growing threat\nbecause they are difficult to detect with the naked eye or using unimodal deep\nlearningbased forgery detection methods. Audiovisual forensic models, while\nmore capable than unimodal models, require large training datasets and are\ncomputationally expensive for training and inference. Furthermore, these models\nlack interpretability and often do not generalize well to unseen manipulations.\nIn this study, we examine the detection capabilities of a large language model\n(LLM) (i.e., ChatGPT) to identify and account for any possible visual and\nauditory artifacts and manipulations in audiovisual deepfake content. Extensive\nexperiments are conducted on videos from a benchmark multimodal deepfake\ndataset to evaluate the detection performance of ChatGPT and compare it with\nthe detection capabilities of state-of-the-art multimodal forensic models and\nhumans. Experimental results demonstrate the importance of domain knowledge and\nprompt engineering for video forgery detection tasks using LLMs. Unlike\napproaches based on end-to-end learning, ChatGPT can account for spatial and\nspatiotemporal artifacts and inconsistencies that may exist within or across\nmodalities. Additionally, we discuss the limitations of ChatGPT for multimedia\nforensic tasks.\n","authors":["Sahibzada Adil Shahzad","Ammarah Hashmi","Yan-Tsung Peng","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09276v2","updated":"2024-11-14T08:06:46Z","published":"2024-05-15T11:46:47Z","title":"Dual-Segment Clustering Strategy for Hierarchical Federated Learning in\n  Heterogeneous Wireless Environments","summary":"  Non-independent and identically distributed (Non- IID) data adversely affects\nfederated learning (FL) while heterogeneity in communication quality can\nundermine the reliability of model parameter transmission, potentially\ndegrading wireless FL convergence. This paper proposes a novel dual-segment\nclustering (DSC) strategy that jointly addresses communication and data\nheterogeneity in FL. This is achieved by defining a new signal-to-noise ratio\n(SNR) matrix and information quantity matrix to capture the communication and\ndata heterogeneity, respectively. The celebrated affinity propagation algorithm\nis leveraged to iteratively refine the clustering of clients based on the newly\ndefined matrices effectively enhancing model aggregation in heterogeneous\nenvironments. The convergence analysis and experimental results show that the\nDSC strategy can improve the convergence rate of wireless FL and demonstrate\nsuperior accuracy in heterogeneous environments compared to classical\nclustering methods.\n","authors":["Pengcheng Sun","Erwu Liu","Wei Ni","Kanglei Yu","Xinyu Qu","Rui Wang","Yanlong Bi","Chuanchun Zhang","Abbas Jamalipour"],"pdf_url":"https://arxiv.org/pdf/2405.09276v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09263v1","updated":"2024-11-14T08:02:14Z","published":"2024-11-14T08:02:14Z","title":"Rethinking Weight-Averaged Model-merging","summary":"  Weight-averaged model-merging has emerged as a powerful approach in deep\nlearning, capable of enhancing model performance without fine-tuning or\nretraining. However, the underlying mechanisms that explain its effectiveness\nremain largely unexplored. In this paper, we investigate this technique from\nthree novel perspectives to provide deeper insights into how and why\nweight-averaged model-merging works: (1) we examine the intrinsic patterns\ncaptured by the learning of the model weights, through the visualizations of\ntheir patterns on several datasets, showing that these weights often encode\nstructured and interpretable patterns; (2) we investigate model ensemble\nmerging strategies based on averaging on weights versus averaging on features,\nproviding detailed analyses across diverse architectures and datasets; and (3)\nwe explore the impact on model-merging prediction stability in terms of\nchanging the parameter magnitude, revealing insights into the way of weight\naveraging works as regularization by showing the robustness across different\nparameter scales. Our findings shed light on the \"black box\" of weight-averaged\nmodel-merging, offering valuable insights and practical recommendations that\nadvance the model-merging process.\n","authors":["Hu Wang","Congbo Ma","Ibrahim Almakky","Ian Reid","Gustavo Carneiro","Mohammad Yaqub"],"pdf_url":"https://arxiv.org/pdf/2411.09263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14193v2","updated":"2024-11-14T07:58:03Z","published":"2024-10-18T06:07:22Z","title":"xPerT: Extended Persistence Transformer","summary":"  A persistence diagram provides a compact summary of persistent homology,\nwhich captures the topological features of a space at different scales.\nHowever, due to its nature as a set, incorporating it as a feature into a\nmachine learning framework is challenging. Several methods have been proposed\nto use persistence diagrams as input for machine learning models, but they\noften require complex preprocessing steps and extensive hyperparameter tuning.\nIn this paper, we propose a novel transformer architecture called the\n\\textit{Extended Persistence Transformer (xPerT)}, which is highly scalable\nthan the compared to Persformer, an existing transformer for persistence\ndiagrams. xPerT reduces GPU memory usage by over 90\\% and improves accuracy on\nmultiple datasets. Additionally, xPerT does not require complex preprocessing\nsteps or extensive hyperparameter tuning, making it easy to use in practice.\nOur code is available at https://github.com/sehunfromdaegu/xpert.\n","authors":["Sehun Kim"],"pdf_url":"https://arxiv.org/pdf/2410.14193v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09242v1","updated":"2024-11-14T07:16:23Z","published":"2024-11-14T07:16:23Z","title":"FluidML: Fast and Memory Efficient Inference Optimization","summary":"  Machine learning models deployed on edge devices have enabled numerous\nexciting new applications, such as humanoid robots, AR glasses, and autonomous\nvehicles. However, the computing resources available on these edge devices are\nnot catching up with the ever-growing number of parameters in these models. As\nthe models become bigger and more complicated, the novel yet sophisticated\nstructure challenges the inference runtime optimization. We present FluidML, a\ngeneric runtime memory management and optimization framework that can flexibly\ntransform the model execution blueprint to achieve faster and more\nmemory-efficient inference. Evaluations across different platforms show that\nFluidML can consistently reduce the end-to-end inference latency by up to\n25.38% for popular language models and reduce peak memory usage by up to\n41.47%, compared to state-of-the-art approaches. FluidML is of ~30K line of\ncodes, built for general-purpose usage, and will be released as an open-source\ninference runtime optimization framework to the community.\n","authors":["Jinjie Liu","Hang Qiu"],"pdf_url":"https://arxiv.org/pdf/2411.09242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09238v1","updated":"2024-11-14T07:13:08Z","published":"2024-11-14T07:13:08Z","title":"Rethinking the \"Heatmap + Monte Carlo Tree Search\" Paradigm for Solving\n  Large Scale TSP","summary":"  The Travelling Salesman Problem (TSP) remains a fundamental challenge in\ncombinatorial optimization, inspiring diverse algorithmic strategies. This\npaper revisits the \"heatmap + Monte Carlo Tree Search (MCTS)\" paradigm that has\nrecently gained traction for learning-based TSP solutions. Within this\nframework, heatmaps encode the likelihood of edges forming part of the optimal\ntour, and MCTS refines this probabilistic guidance to discover optimal\nsolutions. Contemporary approaches have predominantly emphasized the refinement\nof heatmap generation through sophisticated learning models, inadvertently\nsidelining the critical role of MCTS. Our extensive empirical analysis reveals\ntwo pivotal insights: 1) The configuration of MCTS strategies profoundly\ninfluences the solution quality, demanding meticulous tuning to leverage their\nfull potential; 2) Our findings demonstrate that a rudimentary and\nparameter-free heatmap, derived from the intrinsic $k$-nearest nature of TSP,\ncan rival or even surpass the performance of complicated heatmaps, with strong\ngeneralizability across various scales. Empirical evaluations across various\nTSP scales underscore the efficacy of our approach, achieving competitive\nresults. These observations challenge the prevailing focus on heatmap\nsophistication, advocating a reevaluation of the paradigm to harness both\ncomponents synergistically. Our code is available at:\nhttps://github.com/LOGO-CUHKSZ/rethink_mcts_tsp.\n","authors":["Xuanhao Pan","Chenguang Wang","Chaolong Ying","Ye Xue","Tianshu Yu"],"pdf_url":"https://arxiv.org/pdf/2411.09238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00996v2","updated":"2024-11-14T06:55:27Z","published":"2024-07-01T06:22:38Z","title":"Can Small Language Models Learn, Unlearn, and Retain Noise Patterns?","summary":"  Small Language Models (SLMs) are generally considered more compact versions\nof large language models (LLMs). This study investigates the ability of SLMs\nwith parameters between 1 and 3 billion to learn, retain, and subsequently\neliminate different types of noise present in the data. Four pre-trained SLMs\nwere utilized for this: Olmo 1B, Qwen1.5 1.8B, Gemma 2B, and Phi2 2.7B. The\nmodels were instruction-tuned on noise-free data and tested using in-context\nexamples to determine if they could learn noise through examples. Subsequently,\nnoise patterns were introduced in instruction tuning to evaluate the noise\nlearning, unlearning, and retention capabilities of the models. Olmo, the\nsmallest model, was highly sensitive to noise, quickly adapting to noisy\npatterns. Phi2 resisted learning character-level and transliteration noise,\nlikely due to its carefully curated, structured, and high-quality pretraining\ndata. Gemma excelled with transliteration noise, likely benefiting from its\nmultilingual pretraining. The findings can be used to develop robust training\nstrategies for SLMs.\n","authors":["Nicy Scaria","Silvester John Joseph Kennedy","Deepak Subramani"],"pdf_url":"https://arxiv.org/pdf/2407.00996v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15750v3","updated":"2024-11-14T06:33:26Z","published":"2024-09-24T05:12:10Z","title":"The Roles of Generative Artificial Intelligence in Internet of Electric\n  Vehicles","summary":"  With the advancements of generative artificial intelligence (GenAI) models,\ntheir capabilities are expanding significantly beyond content generation and\nthe models are increasingly being used across diverse applications.\nParticularly, GenAI shows great potential in addressing challenges in the\nelectric vehicle (EV) ecosystem ranging from charging management to\ncyber-attack prevention. In this paper, we specifically consider Internet of\nelectric vehicles (IoEV) and we categorize GenAI for IoEV into four different\nlayers namely, EV's battery layer, individual EV layer, smart grid layer, and\nsecurity layer. We introduce various GenAI techniques used in each layer of\nIoEV applications. Subsequently, public datasets available for training the\nGenAI models are summarized. Finally, we provide recommendations for future\ndirections. This survey not only categorizes the applications of GenAI in IoEV\nacross different layers but also serves as a valuable resource for researchers\nand practitioners by highlighting the design and implementation challenges\nwithin each layer. Furthermore, it provides a roadmap for future research\ndirections, enabling the development of more robust and efficient IoEV systems\nthrough the integration of advanced GenAI techniques.\n","authors":["Hanwen Zhang","Dusit Niyato","Wei Zhang","Changyuan Zhao","Hongyang Du","Abbas Jamalipour","Sumei Sun","Yiyang Pei"],"pdf_url":"https://arxiv.org/pdf/2409.15750v3.pdf","comment":"25 Pages"},{"id":"http://arxiv.org/abs/2411.09210v1","updated":"2024-11-14T06:14:39Z","published":"2024-11-14T06:14:39Z","title":"Classical Verification of Quantum Learning Advantages with Noises","summary":"  Classical verification of quantum learning allows classical clients to\nreliably leverage quantum computing advantages by interacting with untrusted\nquantum servers. Yet, current quantum devices available in practice suffers\nfrom a variety of noises and whether existed classical verification protocols\ncarry over to noisy scenarios remains unclear. Here, we propose an efficient\nclassical error rectification algorithm to reconstruct the noise-free results\ngiven by the quantum Fourier sampling circuit with practical constant-level\nnoises. In particular, we prove that the error rectification algorithm can\nrestore the heavy Fourier coefficients by using a small number of noisy samples\nthat scales logarithmically with the problem size. We apply this algorithm to\nthe agnostic parity learning task with uniform input marginal and prove that\nthis task can be accomplished in an efficient way on noisy quantum devices with\nour algorithm. In addition, we prove that a classical client with access to the\nrandom example oracle can verify the agnostic parity learning results from the\nnoisy quantum prover in an efficient way, under the condition that the Fourier\ncoefficients are sparse. Our results demonstrate the feasibility of classical\nverification of quantum learning advantages with noises, which provide a\nvaluable guide for both theoretical studies and practical applications with\ncurrent noisy intermediate scale quantum devices.\n","authors":["Yinghao Ma","Jiaxi Su","Dong-Ling Deng"],"pdf_url":"https://arxiv.org/pdf/2411.09210v1.pdf","comment":"13 pages 1 figure"},{"id":"http://arxiv.org/abs/2411.09199v1","updated":"2024-11-14T05:43:42Z","published":"2024-11-14T05:43:42Z","title":"Ghost-Connect Net: A Generalization-Enhanced Guidance For Sparse Deep\n  Networks Under Distribution Shifts","summary":"  Sparse deep neural networks (DNNs) excel in real-world applications like\nrobotics and computer vision, by reducing computational demands that hinder\nusability. However, recent studies aim to boost DNN efficiency by trimming\nredundant neurons or filters based on task relevance, but neglect their\nadaptability to distribution shifts. We aim to enhance these existing\ntechniques by introducing a companion network, Ghost Connect-Net (GC-Net), to\nmonitor the connections in the original network with distribution\ngeneralization advantage. GC-Net's weights represent connectivity measurements\nbetween consecutive layers of the original network. After pruning GC-Net, the\npruned locations are mapped back to the original network as pruned connections,\nallowing for the combination of magnitude and connectivity-based pruning\nmethods. Experimental results using common DNN benchmarks, such as CIFAR-10,\nFashion MNIST, and Tiny ImageNet show promising results for hybridizing the\nmethod, and using GC-Net guidance for later layers of a network and direct\npruning on earlier layers. We provide theoretical foundations for GC-Net's\napproach to improving generalization under distribution shifts.\n","authors":["Mary Isabelle Wisell","Salimeh Yasaei Sekeh"],"pdf_url":"https://arxiv.org/pdf/2411.09199v1.pdf","comment":"21 pages, 4 figures, 3 subfigures, 42 tables"},{"id":"http://arxiv.org/abs/2406.05964v2","updated":"2024-11-14T05:00:13Z","published":"2024-06-10T01:46:42Z","title":"Distributionally Robust Safe Sample Elimination under Covariate Shift","summary":"  We consider a machine learning setup where one training dataset is used to\ntrain multiple models across slightly different data distributions. This occurs\nwhen customized models are needed for various deployment environments. To\nreduce storage and training costs, we propose the DRSSS method, which combines\ndistributionally robust (DR) optimization and safe sample screening (SSS). The\nkey benefit of this method is that models trained on the reduced dataset will\nperform the same as those trained on the full dataset for all possible\ndifferent environments. In this paper, we focus on covariate shift as a type of\ndata distribution change and demonstrate the effectiveness of our method\nthrough experiments.\n","authors":["Hiroyuki Hanada","Tatsuya Aoyama","Satoshi Akahane","Tomonari Tanaka","Yoshito Okura","Yu Inatsu","Noriaki Hashimoto","Shion Takeno","Taro Murayama","Hanju Lee","Shinya Kojima","Ichiro Takeuchi"],"pdf_url":"https://arxiv.org/pdf/2406.05964v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.08318v2","updated":"2024-11-14T04:52:16Z","published":"2024-05-14T04:58:23Z","title":"No-Regret Learning of Nash Equilibrium for Black-Box Games via Gaussian\n  Processes","summary":"  This paper investigates the challenge of learning in black-box games, where\nthe underlying utility function is unknown to any of the agents. While there is\nan extensive body of literature on the theoretical analysis of algorithms for\ncomputing the Nash equilibrium with complete information about the game,\nstudies on Nash equilibrium in black-box games are less common. In this paper,\nwe focus on learning the Nash equilibrium when the only available information\nabout an agent's payoff comes in the form of empirical queries. We provide a\nno-regret learning algorithm that utilizes Gaussian processes to identify the\nequilibrium in such games. Our approach not only ensures a theoretical\nconvergence rate but also demonstrates effectiveness across a variety\ncollection of games through experimental validation.\n","authors":["Minbiao Han","Fengxue Zhang","Yuxin Chen"],"pdf_url":"https://arxiv.org/pdf/2405.08318v2.pdf","comment":"40th Conference on Uncertainty in Artificial Intelligence (UAI 2024)"},{"id":"http://arxiv.org/abs/2411.09184v1","updated":"2024-11-14T04:46:08Z","published":"2024-11-14T04:46:08Z","title":"Dynamic technology impact analysis: A multi-task learning approach to\n  patent citation prediction","summary":"  Machine learning (ML) models are valuable tools for analyzing the impact of\ntechnology using patent citation information. However, existing ML-based\nmethods often struggle to account for the dynamic nature of the technology\nimpact over time and the interdependencies of these impacts across different\nperiods. This study proposes a multi-task learning (MTL) approach to enhance\nthe prediction of technology impact across various time frames by leveraging\nknowledge sharing and simultaneously monitoring the evolution of technology\nimpact. First, we quantify the technology impacts and identify patterns through\ncitation analysis over distinct time periods. Next, we develop MTL models to\npredict citation counts using multiple patent indicators over time. Finally, we\nexamine the changes in key input indicators and their patterns over different\nperiods using the SHapley Additive exPlanation method. We also offer guidelines\nfor validating and interpreting the results by employing statistical methods\nand natural language processing techniques. A case study on battery\ntechnologies demonstrates that our approach not only deepens the understanding\nof technology impact, but also improves prediction accuracy, yielding valuable\ninsights for both academia and industry.\n","authors":["Youngjin Seol","Jaewoong Choi","Seunghyun Lee","Janghyeok Yoon"],"pdf_url":"https://arxiv.org/pdf/2411.09184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09181v1","updated":"2024-11-14T04:39:30Z","published":"2024-11-14T04:39:30Z","title":"DeBaTeR: Denoising Bipartite Temporal Graph for Recommendation","summary":"  Due to the difficulty of acquiring large-scale explicit user feedback,\nimplicit feedback (e.g., clicks or other interactions) is widely applied as an\nalternative source of data, where user-item interactions can be modeled as a\nbipartite graph. Due to the noisy and biased nature of implicit real-world\nuser-item interactions, identifying and rectifying noisy interactions are vital\nto enhance model performance and robustness. Previous works on purifying\nuser-item interactions in collaborative filtering mainly focus on mining the\ncorrelation between user/item embeddings and noisy interactions, neglecting the\nbenefit of temporal patterns in determining noisy interactions. Time\ninformation, while enhancing the model utility, also bears its natural\nadvantage in helping to determine noisy edges, e.g., if someone usually watches\nhorror movies at night and talk shows in the morning, a record of watching a\nhorror movie in the morning is more likely to be noisy interaction. Armed with\nthis observation, we introduce a simple yet effective mechanism for generating\ntime-aware user/item embeddings and propose two strategies for denoising\nbipartite temporal graph in recommender systems (DeBaTeR): the first is through\nreweighting the adjacency matrix (DeBaTeR-A), where a reliability score is\ndefined to reweight the edges through both soft assignment and hard assignment;\nthe second is through reweighting the loss function (DeBaTeR-L), where weights\nare generated to reweight user-item samples in the losses. Extensive\nexperiments have been conducted to demonstrate the efficacy of our methods and\nillustrate how time information indeed helps identifying noisy edges.\n","authors":["Xinyu He","Jose Sepulveda","Mostafa Rahmani","Alyssa Woo","Fei Wang","Hanghang Tong"],"pdf_url":"https://arxiv.org/pdf/2411.09181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09178v1","updated":"2024-11-14T04:36:12Z","published":"2024-11-14T04:36:12Z","title":"SAFES: Sequential Privacy and Fairness Enhancing Data Synthesis for\n  Responsible AI","summary":"  As data-driven and AI-based decision making gains widespread adoption in most\ndisciplines, it is crucial that both data privacy and decision fairness are\nappropriately addressed. While differential privacy (DP) provides a robust\nframework for guaranteeing privacy and several widely accepted methods have\nbeen proposed for improving fairness, the vast majority of existing literature\ntreats the two concerns independently. For methods that do consider privacy and\nfairness simultaneously, they often only apply to a specific machine learning\ntask, limiting their generalizability. In response, we introduce SAFES, a\nSequential PrivAcy and Fairness Enhancing data Synthesis procedure that\nsequentially combines DP data synthesis with a fairness-aware data\ntransformation. SAFES allows full control over the privacy-fairness-utility\ntrade-off via tunable privacy and fairness parameters. We illustrate SAFES by\ncombining AIM, a graphical model-based DP data synthesizer, with a popular\nfairness-aware data pre-processing transformation. Empirical evaluations on the\nAdult and COMPAS datasets demonstrate that for reasonable privacy loss,\nSAFES-generated synthetic data achieve significantly improved fairness metrics\nwith relatively low utility loss.\n","authors":["Spencer Giddens","Fang Liu"],"pdf_url":"https://arxiv.org/pdf/2411.09178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09175v1","updated":"2024-11-14T04:26:47Z","published":"2024-11-14T04:26:47Z","title":"Hybrid deep additive neural networks","summary":"  Traditional neural networks (multi-layer perceptrons) have become an\nimportant tool in data science due to their success across a wide range of\ntasks. However, their performance is sometimes unsatisfactory, and they often\nrequire a large number of parameters, primarily due to their reliance on the\nlinear combination structure. Meanwhile, additive regression has been a popular\nalternative to linear regression in statistics. In this work, we introduce\nnovel deep neural networks that incorporate the idea of additive regression.\nOur neural networks share architectural similarities with Kolmogorov-Arnold\nnetworks but are based on simpler yet flexible activation and basis functions.\nAdditionally, we introduce several hybrid neural networks that combine this\narchitecture with that of traditional neural networks. We derive their\nuniversal approximation properties and demonstrate their effectiveness through\nsimulation studies and a real-data application. The numerical results indicate\nthat our neural networks generally achieve better performance than traditional\nneural networks while using fewer parameters.\n","authors":["Gyu Min Kim","Jeong Min Jeon"],"pdf_url":"https://arxiv.org/pdf/2411.09175v1.pdf","comment":"29 pages, 13 figures"},{"id":"http://arxiv.org/abs/2411.09174v1","updated":"2024-11-14T04:23:28Z","published":"2024-11-14T04:23:28Z","title":"Advancing Diffusion Models: Alias-Free Resampling and Enhanced\n  Rotational Equivariance","summary":"  Recent advances in image generation, particularly via diffusion models, have\nled to impressive improvements in image synthesis quality. Despite this,\ndiffusion models are still challenged by model-induced artifacts and limited\nstability in image fidelity. In this work, we hypothesize that the primary\ncause of this issue is the improper resampling operation that introduces\naliasing in the diffusion model and a careful alias-free resampling dictated by\nimage processing theory can improve the model's performance in image synthesis.\nWe propose the integration of alias-free resampling layers into the UNet\narchitecture of diffusion models without adding extra trainable parameters,\nthereby maintaining computational efficiency. We then assess whether these\ntheory-driven modifications enhance image quality and rotational equivariance.\nOur experimental results on benchmark datasets, including CIFAR-10, MNIST, and\nMNIST-M, reveal consistent gains in image quality, particularly in terms of FID\nand KID scores. Furthermore, we propose a modified diffusion process that\nenables user-controlled rotation of generated images without requiring\nadditional training. Our findings highlight the potential of theory-driven\nenhancements such as alias-free resampling in generative models to improve\nimage quality while maintaining model efficiency and pioneer future research\ndirections to incorporate them into video-generating diffusion models, enabling\ndeeper exploration of the applications of alias-free resampling in generative\nmodeling.\n","authors":["Md Fahim Anjum"],"pdf_url":"https://arxiv.org/pdf/2411.09174v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.04204v2","updated":"2024-11-14T04:14:55Z","published":"2024-11-06T19:02:42Z","title":"Online Budgeted Matching with General Bids","summary":"  Online Budgeted Matching (OBM) is a classic problem with important\napplications in online advertising, online service matching, revenue\nmanagement, and beyond. Traditional online algorithms typically assume a small\nbid setting, where the maximum bid-to-budget ratio (\\kappa) is infinitesimally\nsmall. While recent algorithms have tried to address scenarios with non-small\nor general bids, they often rely on the Fractional Last Matching (FLM)\nassumption, which allows for accepting partial bids when the remaining budget\nis insufficient. This assumption, however, does not hold for many applications\nwith indivisible bids. In this paper, we remove the FLM assumption and tackle\nthe open problem of OBM with general bids. We first establish an upper bound of\n1-\\kappa on the competitive ratio for any deterministic online algorithm. We\nthen propose a novel meta algorithm, called MetaAd, which reduces to different\nalgorithms with first known provable competitive ratios parameterized by the\nmaximum bid-to-budget ratio \\kappa \\in [0, 1]. As a by-product, we extend\nMetaAd to the FLM setting and get provable competitive algorithms. Finally, we\napply our competitive analysis to the design learning-augmented algorithms.\n","authors":["Jianyi Yang","Pengfei Li","Adam Wierman","Shaolei Ren"],"pdf_url":"https://arxiv.org/pdf/2411.04204v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09170v1","updated":"2024-11-14T04:12:47Z","published":"2024-11-14T04:12:47Z","title":"Towards Scalable Handwriting Communication via EEG Decoding and Latent\n  Embedding Integration","summary":"  In recent years, brain-computer interfaces have made advances in decoding\nvarious motor-related tasks, including gesture recognition and movement\nclassification, utilizing electroencephalogram (EEG) data. These developments\nare fundamental in exploring how neural signals can be interpreted to recognize\nspecific physical actions. This study centers on a written alphabet\nclassification task, where we aim to decode EEG signals associated with\nhandwriting. To achieve this, we incorporate hand kinematics to guide the\nextraction of the consistent embeddings from high-dimensional neural recordings\nusing auxiliary variables (CEBRA). These CEBRA embeddings, along with the EEG,\nare processed by a parallel convolutional neural network model that extracts\nfeatures from both data sources simultaneously. The model classifies nine\ndifferent handwritten characters, including symbols such as exclamation marks\nand commas, within the alphabet. We evaluate the model using a quantitative\nfive-fold cross-validation approach and explore the structure of the embedding\nspace through visualizations. Our approach achieves a classification accuracy\nof 91 % for the nine-class task, demonstrating the feasibility of fine-grained\nhandwriting decoding from EEG.\n","authors":["Jun-Young Kim","Deok-Seon Kim","Seo-Hyun Lee"],"pdf_url":"https://arxiv.org/pdf/2411.09170v1.pdf","comment":"4 pages, 2 figures, 1 table, Name of Conference: International\n  Conference on Brain-Computer Interface"},{"id":"http://arxiv.org/abs/2411.09160v1","updated":"2024-11-14T03:28:02Z","published":"2024-11-14T03:28:02Z","title":"Rationality based Innate-Values-driven Reinforcement Learning","summary":"  Innate values describe agents' intrinsic motivations, which reflect their\ninherent interests and preferences to pursue goals and drive them to develop\ndiverse skills satisfying their various needs. The essence of reinforcement\nlearning (RL) is learning from interaction based on reward-driven behaviors,\nmuch like natural agents. It is an excellent model to describe the\ninnate-values-driven (IV) behaviors of AI agents. Especially developing the\nawareness of the AI agent through balancing internal and external utilities\nbased on its needs in different tasks is a crucial problem for individuals\nlearning to support AI agents integrating human society with safety and harmony\nin the long term. This paper proposes a hierarchical compound intrinsic value\nreinforcement learning model -- innate-values-driven reinforcement learning\ntermed IVRL to describe the complex behaviors of AI agents' interaction. We\nformulated the IVRL model and proposed two IVRL models: DQN and A2C. By\ncomparing them with benchmark algorithms such as DQN, DDQN, A2C, and PPO in the\nRole-Playing Game (RPG) reinforcement learning test platform VIZDoom, we\ndemonstrated that rationally organizing various individual needs can\neffectively achieve better performance.\n","authors":["Qin Yang"],"pdf_url":"https://arxiv.org/pdf/2411.09160v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2401.05572"},{"id":"http://arxiv.org/abs/2411.09152v1","updated":"2024-11-14T03:07:57Z","published":"2024-11-14T03:07:57Z","title":"GRAINRec: Graph and Attention Integrated Approach for Real-Time\n  Session-Based Item Recommendations","summary":"  Recent advancements in session-based recommendation models using deep\nlearning techniques have demonstrated significant performance improvements.\nWhile they can enhance model sophistication and improve the relevance of\nrecommendations, they also make it challenging to implement a scalable\nreal-time solution. To addressing this challenge, we propose GRAINRec- a Graph\nand Attention Integrated session-based recommendation model that generates\nrecommendations in real-time. Our scope of work is item recommendations in\nonline retail where a session is defined as an ordered sequence of digital\nguest actions, such as page views or adds to cart. The proposed model generates\nrecommendations by considering the importance of all items in the session\ntogether, letting us predict relevant recommendations dynamically as the\nsession evolves. We also propose a heuristic approach to implement real-time\ninferencing that meets Target platform's service level agreement (SLA). The\nproposed architecture lets us predict relevant recommendations dynamically as\nthe session evolves, rather than relying on pre-computed recommendations for\neach item. Evaluation results of the proposed model show an average improvement\nof 1.5% across all offline evaluation metrics. A/B tests done over a 2 week\nduration showed an increase of 10% in click through rate and 9% increase in\nattributable demand. Extensive ablation studies are also done to understand our\nmodel performance for different parameters.\n","authors":["Bhavtosh Rath","Pushkar Chennu","David Relyea","Prathyusha Kanmanth Reddy","Amit Pande"],"pdf_url":"https://arxiv.org/pdf/2411.09152v1.pdf","comment":"Accepted to the 2024 IEEE International Conference on Big Data (IEEE\n  BigData 2024)"},{"id":"http://arxiv.org/abs/2411.09142v1","updated":"2024-11-14T02:52:47Z","published":"2024-11-14T02:52:47Z","title":"Laplace Transform Interpretation of Differential Privacy","summary":"  We introduce a set of useful expressions of Differential Privacy (DP) notions\nin terms of the Laplace transform of the privacy loss distribution. Its bare\nform expression appears in several related works on analyzing DP, either as an\nintegral or an expectation. We show that recognizing the expression as a\nLaplace transform unlocks a new way to reason about DP properties by exploiting\nthe duality between time and frequency domains. Leveraging our interpretation,\nwe connect the $(q, \\rho(q))$-R\\'enyi DP curve and the $(\\epsilon,\n\\delta(\\epsilon))$-DP curve as being the Laplace and inverse-Laplace transforms\nof one another. This connection shows that the R\\'enyi divergence is\nwell-defined for complex orders $q = \\gamma + i \\omega$. Using our Laplace\ntransform-based analysis, we also prove an adaptive composition theorem for\n$(\\epsilon, \\delta)$-DP guarantees that is exactly tight (i.e., matches even in\nconstants) for all values of $\\epsilon$. Additionally, we resolve an issue\nregarding symmetry of $f$-DP on subsampling that prevented equivalence across\nall functional DP notions.\n","authors":["Rishav Chourasia","Uzair Javaid","Biplap Sikdar"],"pdf_url":"https://arxiv.org/pdf/2411.09142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.09417v3","updated":"2024-11-14T02:00:33Z","published":"2024-01-17T18:56:18Z","title":"Vision Mamba: Efficient Visual Representation Learning with\n  Bidirectional State Space Model","summary":"  Recently the state space models (SSMs) with efficient hardware-aware designs,\ni.e., the Mamba deep learning model, have shown great potential for long\nsequence modeling. Meanwhile building efficient and generic vision backbones\npurely upon SSMs is an appealing direction. However, representing visual data\nis challenging for SSMs due to the position-sensitivity of visual data and the\nrequirement of global context for visual understanding. In this paper, we show\nthat the reliance on self-attention for visual representation learning is not\nnecessary and propose a new generic vision backbone with bidirectional Mamba\nblocks (Vim), which marks the image sequences with position embeddings and\ncompresses the visual representation with bidirectional state space models. On\nImageNet classification, COCO object detection, and ADE20k semantic\nsegmentation tasks, Vim achieves higher performance compared to\nwell-established vision transformers like DeiT, while also demonstrating\nsignificantly improved computation & memory efficiency. For example, Vim is\n2.8$\\times$ faster than DeiT and saves 86.8% GPU memory when performing batch\ninference to extract features on images with a resolution of 1248$\\times$1248.\nThe results demonstrate that Vim is capable of overcoming the computation &\nmemory constraints on performing Transformer-style understanding for\nhigh-resolution images and it has great potential to be the next-generation\nbackbone for vision foundation models. Code is available at\nhttps://github.com/hustvl/Vim.\n","authors":["Lianghui Zhu","Bencheng Liao","Qian Zhang","Xinlong Wang","Wenyu Liu","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2401.09417v3.pdf","comment":"Vision Mamba (Vim) is accepted by ICML 2024. Code is available at\n  https://github.com/hustvl/Vim"},{"id":"http://arxiv.org/abs/2411.09127v1","updated":"2024-11-14T02:00:22Z","published":"2024-11-14T02:00:22Z","title":"Complexity-Aware Training of Deep Neural Networks for Optimal Structure\n  Discovery","summary":"  We propose a novel algorithm for combined unit/filter and layer pruning of\ndeep neural networks that functions during training and without requiring a\npre-trained network to apply. Our algorithm optimally trades-off learning\naccuracy and pruning levels while balancing layer vs. unit/filter pruning and\ncomputational vs. parameter complexity using only three user-defined\nparameters, which are easy to interpret and tune. The optimal network structure\nis found as the solution of a stochastic optimization problem over the network\nweights and the parameters of variational Bernoulli distributions for 0/1\nRandom Variables scaling the units and layers of the network. Pruning occurs\nwhen a variational parameter converges to 0 rendering the corresponding\nstructure permanently inactive, thus saving computations during training and\nprediction. A key contribution of our approach is to define a cost function\nthat combines the objectives of prediction accuracy and network pruning in a\ncomputational/parameter complexity-aware manner and the automatic selection of\nthe many regularization parameters. We show that the solutions of the\noptimization problem to which the algorithm converges are deterministic\nnetworks. We analyze the ODE system that underlies our stochastic optimization\nalgorithm and establish domains of attraction around zero for the dynamics of\nthe network parameters. These results provide theoretical support for safely\npruning units/filters and/or layers during training and lead to practical\npruning conditions. We evaluate our method on the CIFAR-10/100 and ImageNet\ndatasets using ResNet architectures and demonstrate that our method improves\nupon layer only or unit only pruning and favorably competes with combined\nunit/filter and layer pruning algorithms requiring pre-trained networks with\nrespect to pruning ratios and test accuracy.\n","authors":["Valentin Frank Ingmar Guenter","Athanasios Sideris"],"pdf_url":"https://arxiv.org/pdf/2411.09127v1.pdf","comment":"28 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2411.09120v1","updated":"2024-11-14T01:41:00Z","published":"2024-11-14T01:41:00Z","title":"Neural Graph Simulator for Complex Systems","summary":"  Numerical simulation is a predominant tool for studying the dynamics in\ncomplex systems, but large-scale simulations are often intractable due to\ncomputational limitations. Here, we introduce the Neural Graph Simulator (NGS)\nfor simulating time-invariant autonomous systems on graphs. Utilizing a graph\nneural network, the NGS provides a unified framework to simulate diverse\ndynamical systems with varying topologies and sizes without constraints on\nevaluation times through its non-uniform time step and autoregressive approach.\nThe NGS offers significant advantages over numerical solvers by not requiring\nprior knowledge of governing equations and effectively handling noisy or\nmissing data with a robust training scheme. It demonstrates superior\ncomputational efficiency over conventional methods, improving performance by\nover $10^5$ times in stiff problems. Furthermore, it is applied to real traffic\ndata, forecasting traffic flow with state-of-the-art accuracy. The versatility\nof the NGS extends beyond the presented cases, offering numerous potential\navenues for enhancement.\n","authors":["Hoyun Choi","Sungyeop Lee","B. Kahng","Junghyo Jo"],"pdf_url":"https://arxiv.org/pdf/2411.09120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09118v1","updated":"2024-11-14T01:37:24Z","published":"2024-11-14T01:37:24Z","title":"FxTS-Net: Fixed-Time Stable Learning Framework for Neural ODEs","summary":"  Neural Ordinary Differential Equations (Neural ODEs), as a novel category of\nmodeling big data methods, cleverly link traditional neural networks and\ndynamical systems. However, it is challenging to ensure the dynamics system\nreaches a correctly predicted state within a user-defined fixed time. To\naddress this problem, we propose a new method for training Neural ODEs using\nfixed-time stability (FxTS) Lyapunov conditions. Our framework, called\nFxTS-Net, is based on the novel FxTS loss (FxTS-Loss) designed on Lyapunov\nfunctions, which aims to encourage convergence to accurate predictions in a\nuser-defined fixed time. We also provide an innovative approach for\nconstructing Lyapunov functions to meet various tasks and network architecture\nrequirements, achieved by leveraging supervised information during training. By\ndeveloping a more precise time upper bound estimation for bounded\nnon-vanishingly perturbed systems, we demonstrate that minimizing FxTS-Loss not\nonly guarantees FxTS behavior of the dynamics but also input perturbation\nrobustness. For optimising FxTS-Loss, we also propose a learning algorithm, in\nwhich the simulated perturbation sampling method can capture sample points in\ncritical regions to approximate FxTS-Loss. Experimentally, we find that\nFxTS-Net provides better prediction performance and better robustness under\ninput perturbation.\n","authors":["Chaoyang Luo","Yan Zou","Wanying Li","Nanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2411.09118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09117v1","updated":"2024-11-14T01:37:02Z","published":"2024-11-14T01:37:02Z","title":"Efficiently learning and sampling multimodal distributions with\n  data-based initialization","summary":"  We consider the problem of sampling a multimodal distribution with a Markov\nchain given a small number of samples from the stationary measure. Although\nmixing can be arbitrarily slow, we show that if the Markov chain has a $k$th\norder spectral gap, initialization from a set of $\\tilde O(k/\\varepsilon^2)$\nsamples from the stationary distribution will, with high probability over the\nsamples, efficiently generate a sample whose conditional law is\n$\\varepsilon$-close in TV distance to the stationary measure. In particular,\nthis applies to mixtures of $k$ distributions satisfying a Poincar\\'e\ninequality, with faster convergence when they satisfy a log-Sobolev inequality.\nOur bounds are stable to perturbations to the Markov chain, and in particular\nwork for Langevin diffusion over $\\mathbb R^d$ with score estimation error, as\nwell as Glauber dynamics combined with approximation error from\npseudolikelihood estimation. This justifies the success of data-based\ninitialization for score matching methods despite slow mixing for the data\ndistribution, and improves and generalizes the results of Koehler and Vuong\n(2023) to have linear, rather than exponential, dependence on $k$ and apply to\narbitrary semigroups. As a consequence of our results, we show for the first\ntime that a natural class of low-complexity Ising measures can be efficiently\nlearned from samples.\n","authors":["Frederic Koehler","Holden Lee","Thuy-Duong Vuong"],"pdf_url":"https://arxiv.org/pdf/2411.09117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13306v4","updated":"2024-11-14T01:18:01Z","published":"2023-01-30T21:59:30Z","title":"Autobidders with Budget and ROI Constraints: Efficiency, Regret, and\n  Pacing Dynamics","summary":"  We study a game between autobidding algorithms that compete in an online\nadvertising platform. Each autobidder is tasked with maximizing its\nadvertiser's total value over multiple rounds of a repeated auction, subject to\nbudget and return-on-investment constraints. We propose a gradient-based\nlearning algorithm that is guaranteed to satisfy all constraints and achieves\nvanishing individual regret. Our algorithm uses only bandit feedback and can be\nused with the first- or second-price auction, as well as with any\n\"intermediate\" auction format. Our main result is that when these autobidders\nplay against each other, the resulting expected liquid welfare over all rounds\nis at least half of the expected optimal liquid welfare achieved by any\nallocation. This holds whether or not the bidding dynamics converges to an\nequilibrium.\n","authors":["Brendan Lucier","Sarath Pattathil","Aleksandrs Slivkins","Mengxiao Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.13306v4.pdf","comment":"Appeared at COLT 2024. Numerical experiments added since Jun'24\n  version"},{"id":"http://arxiv.org/abs/2411.09111v1","updated":"2024-11-14T00:59:13Z","published":"2024-11-14T00:59:13Z","title":"Reducing Reasoning Costs - The Path of Optimization for Chain of Thought\n  via Sparse Attention Mechanism","summary":"  In order to address the chain of thought in the large language model\ninference cost surge, this research proposes to use a sparse attention\nmechanism that only focuses on a few relevant tokens. The researcher\nconstructed a new attention mechanism and used GiantRabbit trained with custom\nGPTs as an experimental tool. The experiment tested and compared the reasoning\ntime, correctness score and chain of thought length of this model and o1\nPreview in solving the linear algebra test questions of MIT OpenCourseWare. The\nresults show that GiantRabbit's reasoning time and chain of thought length are\nsignificantly lower than o1 Preview, confirming the feasibility of the sparse\nattention mechanism in reducing chain of thought reasoning. Detailed\narchitectural details and experimental process have been uploaded to Github,\nthe link is:https://github.com/brucewang123456789/GeniusTrail.git.\n","authors":["Libo Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09111v1.pdf","comment":"The main text is 9 pages, totaling 13 pages; 5 figures, 3 tables;\n  preprints have been submitted to NeurIPS 2024 Workshop MusIML and OpenReview"},{"id":"http://arxiv.org/abs/2410.13986v2","updated":"2024-11-14T00:09:09Z","published":"2024-10-17T19:32:25Z","title":"Recurrent Neural Goodness-of-Fit Test for Time Series","summary":"  Time series data are crucial across diverse domains such as finance and\nhealthcare, where accurate forecasting and decision-making rely on advanced\nmodeling techniques. While generative models have shown great promise in\ncapturing the intricate dynamics inherent in time series, evaluating their\nperformance remains a major challenge. Traditional evaluation metrics fall\nshort due to the temporal dependencies and potential high dimensionality of the\nfeatures. In this paper, we propose the REcurrent NeurAL (RENAL)\nGoodness-of-Fit test, a novel and statistically rigorous framework for\nevaluating generative time series models. By leveraging recurrent neural\nnetworks, we transform the time series into conditionally independent data\npairs, enabling the application of a chi-square-based goodness-of-fit test to\nthe temporal dependencies within the data. This approach offers a robust,\ntheoretically grounded solution for assessing the quality of generative models,\nparticularly in settings with limited time sequences. We demonstrate the\nefficacy of our method across both synthetic and real-world datasets,\noutperforming existing methods in terms of reliability and accuracy. Our method\nfills a critical gap in the evaluation of time series generative models,\noffering a tool that is both practical and adaptable to high-stakes\napplications.\n","authors":["Aoran Zhang","Wenbin Zhou","Liyan Xie","Shixiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.13986v2.pdf","comment":"27 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.09678v1","updated":"2024-11-14T18:44:31Z","published":"2024-11-14T18:44:31Z","title":"NeuralDEM -- Real-time Simulation of Industrial Particulate Flows","summary":"  Advancements in computing power have made it possible to numerically simulate\nlarge-scale fluid-mechanical and/or particulate systems, many of which are\nintegral to core industrial processes. Among the different numerical methods\navailable, the discrete element method (DEM) provides one of the most accurate\nrepresentations of a wide range of physical systems involving granular and\ndiscontinuous materials. Consequently, DEM has become a widely accepted\napproach for tackling engineering problems connected to granular flows and\npowder mechanics. Additionally, DEM can be integrated with grid-based\ncomputational fluid dynamics (CFD) methods, enabling the simulation of chemical\nprocesses taking place, e.g., in fluidized beds. However, DEM is\ncomputationally intensive because of the intrinsic multiscale nature of\nparticulate systems, restricting simulation duration or number of particles.\nTowards this end, NeuralDEM presents an end-to-end approach to replace slow\nnumerical DEM routines with fast, adaptable deep learning surrogates. NeuralDEM\nis capable of picturing long-term transport processes across different regimes\nusing macroscopic observables without any reference to microscopic model\nparameters. First, NeuralDEM treats the Lagrangian discretization of DEM as an\nunderlying continuous field, while simultaneously modeling macroscopic behavior\ndirectly as additional auxiliary fields. Second, NeuralDEM introduces\nmulti-branch neural operators scalable to real-time modeling of\nindustrially-sized scenarios - from slow and pseudo-steady to fast and\ntransient. Such scenarios have previously posed insurmountable challenges for\ndeep learning models. Notably, NeuralDEM faithfully models coupled CFD-DEM\nfluidized bed reactors of 160k CFD cells and 500k DEM particles for\ntrajectories of 28s. NeuralDEM will open many new doors to advanced engineering\nand much faster process cycles.\n","authors":["Benedikt Alkin","Tobias Kronlachner","Samuele Papa","Stefan Pirker","Thomas Lichtenegger","Johannes Brandstetter"],"pdf_url":"https://arxiv.org/pdf/2411.09678v1.pdf","comment":"Project page: https://nx-ai.github.io/NeuralDEM/"},{"id":"http://arxiv.org/abs/2411.09267v1","updated":"2024-11-14T08:08:25Z","published":"2024-11-14T08:08:25Z","title":"Towards efficient compression and communication for prototype-based\n  decentralized learning","summary":"  In prototype-based federated learning, the exchange of model parameters\nbetween clients and the master server is replaced by transmission of prototypes\nor quantized versions of the data samples to the aggregation server. A fully\ndecentralized deployment of prototype-based learning, without a central\nagregartor of prototypes, is more robust upon network failures and reacts\nfaster to changes in the statistical distribution of the data, suggesting\npotential advantages and quick adaptation in dynamic learning tasks, e.g., when\nthe data sources are IoT devices or when data is non-iid. In this paper, we\nconsider the problem of designing a communication-efficient decentralized\nlearning system based on prototypes. We address the challenge of prototype\nredundancy by leveraging on a twofold data compression technique, i.e., sending\nonly update messages if the prototypes are informationtheoretically useful (via\nthe Jensen-Shannon distance), and using clustering on the prototypes to\ncompress the update messages used in the gossip protocol. We also use parallel\ninstead of sequential gossiping, and present an analysis of its\nage-of-information (AoI). Our experimental results show that, with these\nimprovements, the communications load can be substantially reduced without\ndecreasing the convergence rate of the learning algorithm.\n","authors":["Pablo Fernández-Piñeiro","Manuel Ferández-Veiga","Rebeca P. Díaz-Redondo","Ana Fernández-Vilas","Martín González-Soto"],"pdf_url":"https://arxiv.org/pdf/2411.09267v1.pdf","comment":"15 pages, 2 tables, 7 figures, 6 algorithms"},{"id":"http://arxiv.org/abs/2411.09152v1","updated":"2024-11-14T03:07:57Z","published":"2024-11-14T03:07:57Z","title":"GRAINRec: Graph and Attention Integrated Approach for Real-Time\n  Session-Based Item Recommendations","summary":"  Recent advancements in session-based recommendation models using deep\nlearning techniques have demonstrated significant performance improvements.\nWhile they can enhance model sophistication and improve the relevance of\nrecommendations, they also make it challenging to implement a scalable\nreal-time solution. To addressing this challenge, we propose GRAINRec: a Graph\nand Attention Integrated session-based recommendation model that generates\nrecommendations in real-time. Our scope of work is item recommendations in\nonline retail where a session is defined as an ordered sequence of digital\nguest actions, such as page views or adds to cart. The proposed model generates\nrecommendations by considering the importance of all items in the session\ntogether, letting us predict relevant recommendations dynamically as the\nsession evolves. We also propose a heuristic approach to implement real-time\ninferencing that meets Target platform's service level agreement (SLA). The\nproposed architecture lets us predict relevant recommendations dynamically as\nthe session evolves, rather than relying on pre-computed recommendations for\neach item. Evaluation results of the proposed model show an average improvement\nof 1.5% across all offline evaluation metrics. A/B tests done over a 2 week\nduration showed an increase of 10% in click through rate and 9% increase in\nattributable demand. Extensive ablation studies are also done to understand our\nmodel performance for different parameters.\n","authors":["Bhavtosh Rath","Pushkar Chennu","David Relyea","Prathyusha Kanmanth Reddy","Amit Pande"],"pdf_url":"https://arxiv.org/pdf/2411.09152v1.pdf","comment":"Accepted to the 2024 IEEE International Conference on Big Data (IEEE\n  BigData 2024)"},{"id":"http://arxiv.org/abs/2411.09111v1","updated":"2024-11-14T00:59:13Z","published":"2024-11-14T00:59:13Z","title":"Reducing Reasoning Costs -- The Path of Optimization for Chain of\n  Thought via Sparse Attention Mechanism","summary":"  In order to address the chain of thought in the large language model\ninference cost surge, this research proposes to use a sparse attention\nmechanism that only focuses on a few relevant tokens. The researcher\nconstructed a new attention mechanism and used GiantRabbit trained with custom\nGPTs as an experimental tool. The experiment tested and compared the reasoning\ntime, correctness score and chain of thought length of this model and o1\nPreview in solving the linear algebra test questions of MIT OpenCourseWare. The\nresults show that GiantRabbit's reasoning time and chain of thought length are\nsignificantly lower than o1 Preview, confirming the feasibility of the sparse\nattention mechanism in reducing chain of thought reasoning. Detailed\narchitectural details and experimental process have been uploaded to Github,\nthe link is:https://github.com/brucewang123456789/GeniusTrail.git.\n","authors":["Libo Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09111v1.pdf","comment":"The main text is 9 pages, totaling 13 pages; 5 figures, 3 tables;\n  preprints have been submitted to NeurIPS 2024 Workshop MusIML and OpenReview"}],"Multimedia":[{"id":"http://arxiv.org/abs/2410.05767v2","updated":"2024-11-14T11:27:41Z","published":"2024-10-08T07:48:34Z","title":"Grounding is All You Need? Dual Temporal Grounding for Video Dialog","summary":"  In the realm of video dialog response generation, the understanding of video\ncontent and the temporal nuances of conversation history are paramount. While a\nsegment of current research leans heavily on large-scale pretrained\nvisual-language models and often overlooks temporal dynamics, another delves\ndeep into spatial-temporal relationships within videos but demands intricate\nobject trajectory pre-extractions and sidelines dialog temporal dynamics. This\npaper introduces the Dual Temporal Grounding-enhanced Video Dialog model\n(DTGVD), strategically designed to merge the strengths of both dominant\napproaches. It emphasizes dual temporal relationships by predicting dialog\nturn-specific temporal regions, filtering video content accordingly, and\ngrounding responses in both video and dialog contexts. One standout feature of\nDTGVD is its heightened attention to chronological interplay. By recognizing\nand acting upon the dependencies between different dialog turns, it captures\nmore nuanced conversational dynamics. To further bolster the alignment between\nvideo and dialog temporal dynamics, we've implemented a list-wise contrastive\nlearning strategy. Within this framework, accurately grounded turn-clip\npairings are designated as positive samples, while less precise pairings are\ncategorized as negative. This refined classification is then funneled into our\nholistic end-to-end response generation mechanism. Evaluations using\nAVSD@DSTC-7 and AVSD@DSTC-8 datasets underscore the superiority of our\nmethodology.\n","authors":["You Qin","Wei Ji","Xinze Lan","Hao Fei","Xun Yang","Dan Guo","Roger Zimmermann","Lizi Liao"],"pdf_url":"https://arxiv.org/pdf/2410.05767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09266v1","updated":"2024-11-14T08:07:02Z","published":"2024-11-14T08:07:02Z","title":"How Good is ChatGPT at Audiovisual Deepfake Detection: A Comparative\n  Study of ChatGPT, AI Models and Human Perception","summary":"  Multimodal deepfakes involving audiovisual manipulations are a growing threat\nbecause they are difficult to detect with the naked eye or using unimodal deep\nlearningbased forgery detection methods. Audiovisual forensic models, while\nmore capable than unimodal models, require large training datasets and are\ncomputationally expensive for training and inference. Furthermore, these models\nlack interpretability and often do not generalize well to unseen manipulations.\nIn this study, we examine the detection capabilities of a large language model\n(LLM) (i.e., ChatGPT) to identify and account for any possible visual and\nauditory artifacts and manipulations in audiovisual deepfake content. Extensive\nexperiments are conducted on videos from a benchmark multimodal deepfake\ndataset to evaluate the detection performance of ChatGPT and compare it with\nthe detection capabilities of state-of-the-art multimodal forensic models and\nhumans. Experimental results demonstrate the importance of domain knowledge and\nprompt engineering for video forgery detection tasks using LLMs. Unlike\napproaches based on end-to-end learning, ChatGPT can account for spatial and\nspatiotemporal artifacts and inconsistencies that may exist within or across\nmodalities. Additionally, we discuss the limitations of ChatGPT for multimedia\nforensic tasks.\n","authors":["Sahibzada Adil Shahzad","Ammarah Hashmi","Yan-Tsung Peng","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09266v1.pdf","comment":null}]}}